{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf1859a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import preliz as pz\n",
    "from scipy.special import expit as logistic\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69606f8e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "az.style.use('arviz-doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43ae267",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".CodeMirror {\n",
       "    width: 100vw;\n",
       "}\n",
       "\n",
       ".container {\n",
       "    width: 99% !important;\n",
       "}\n",
       "\n",
       ".rendered_html {\n",
       "  font-size:0.8em;\n",
       "}\n",
       ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "     font-size: 100%;\n",
       "}\n",
       "\n",
       "\n",
       "body {\n",
       "  font-family: Ubuntu;\n",
       "  background: #F0F0F0;\n",
       "  background-color: #F0F0F0;\n",
       "}\n",
       "\n",
       "\n",
       ".reveal h1,\n",
       ".reveal h2,\n",
       ".reveal h3,\n",
       ".reveal h4,\n",
       ".reveal h5,\n",
       ".reveal h6 {\n",
       "  margin: 0 0 20px 0;\n",
       "  color: #2a2eec;\n",
       "  font-family: Ubuntu;\n",
       "  line-height: 0.9em;\n",
       "  letter-spacing: 0.02em;\n",
       "  text-transform: none;\n",
       "  text-shadow: none;\n",
       "}\n",
       "\n",
       ".reveal blockquote {\n",
       "  display: block;\n",
       "  position: relative;\n",
       "  background: #fa7c17;\n",
       "  border-radius: 15px;\n",
       "  box-shadow: 0px 0px 2px rgba(0, 0, 0, 0.2);\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "\n",
    ".CodeMirror {\n",
    "    width: 100vw;\n",
    "}\n",
    "\n",
    ".container {\n",
    "    width: 99% !important;\n",
    "}\n",
    "\n",
    ".rendered_html {\n",
    "  font-size:0.8em;\n",
    "}\n",
    ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
    "     font-size: 100%;\n",
    "}\n",
    "\n",
    "\n",
    "body {\n",
    "  font-family: Ubuntu;\n",
    "  background: #F0F0F0;\n",
    "  background-color: #F0F0F0;\n",
    "}\n",
    "\n",
    "\n",
    ".reveal h1,\n",
    ".reveal h2,\n",
    ".reveal h3,\n",
    ".reveal h4,\n",
    ".reveal h5,\n",
    ".reveal h6 {\n",
    "  margin: 0 0 20px 0;\n",
    "  color: #2a2eec;\n",
    "  font-family: Ubuntu;\n",
    "  line-height: 0.9em;\n",
    "  letter-spacing: 0.02em;\n",
    "  text-transform: none;\n",
    "  text-shadow: none;\n",
    "}\n",
    "\n",
    ".reveal blockquote {\n",
    "  display: block;\n",
    "  position: relative;\n",
    "  background: #fa7c17;\n",
    "  border-radius: 15px;\n",
    "  box-shadow: 0px 0px 2px rgba(0, 0, 0, 0.2);\n",
    "  font-weight: bold;\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5402e70",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "path = \"/home/osvaldo/anaconda3/etc/jupyter/nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=path)\n",
    "cm.update(\"livereveal\", {\n",
    "              \"theme\": \"serif\",\n",
    "              \"transition\": \"zoom\",\n",
    "              \"start_slideshow_at\": \"selected\",\n",
    "              \"controls\": \"True\",\n",
    "              \"progress\": \"False\",\n",
    "              \"shortcut\": \"False\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c0707",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/Logo_UNSAM.png\" width=\"200\"></center>\n",
    "<br>\n",
    "<br>\n",
    "<h1 align=\"center\">Árboles de regresión aditivos Bayesianos</h1>    \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c73aaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objetivos\n",
    "\n",
    "<br>\n",
    "\n",
    "* Árboles de decisión\n",
    "* Modelos BART\n",
    "* Regresión flexible con BART\n",
    "* Gráficos de dependencia parcial\n",
    "* Gráficos de expectativas condicionales individuales\n",
    "* Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212e8b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funciones no-lineales\n",
    "\n",
    "<br>\n",
    "Vimos que podíamos excribir GLMs como:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &= \\alpha + \\beta X \\\\\n",
    "Y &\\sim \\phi(L(\\mu), \\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* El objetivo de este capítulo es generar modelos de la forma de:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &= f(X) \\\\\n",
    "Y &\\sim \\phi(L(\\mu), \\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "donde $f$ es una función que aproximamos de forma no paramétrica.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcfbbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Árboles vs GPs\n",
    "\n",
    "<br>\n",
    "\n",
    "* Anteriormente vimos que era posible modelar funciones usando GPs como priors\n",
    "* Ahora vamos a ver una alternativa basada en árboles\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea755779",
   "metadata": {},
   "source": [
    "## Árboles al rescate\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* Informalmente podemos pensar un árbol como un diagrama de flujo\n",
    "* Empezamos siempre desde la \"raíz\" y vamos contestando una serie de pregunta del tipo si/no\n",
    "* Eventualmente alcanzaremos una \"hoja\" que tendrá la respuesta a nuestro problema.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eeb76e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Árboles de decisión\n",
    "\n",
    "<br>\n",
    "Supongamos que tenemos dos variables $X_1$ y $X_2$ y queremos usar esas variables para clasificar objetos en dos clases: ⬤ o ▲. \n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"../img/decision_tree.png\" width=\"700\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29845e",
   "metadata": {},
   "source": [
    "## Árboles formales\n",
    "\n",
    "<br>\n",
    "\n",
    "* Un poco más formal podemos decir que:\n",
    "    * Un árbol es un conjunto de nodos y lados, es decir un gráfo.\n",
    "    * Los árboles NO tiene ciclos, de forma que cualquier par de nodos está conectado por un único camino.\n",
    "    * El nodo raiz NO tiene padres\n",
    "    * Los nodos hoja NO tienen hijos \n",
    "    * Un árbol binario es aquel en donde cualquier nodo no tiene más de dos hijos \n",
    "        * A veces se define como cada nodo no-hoja tiene exactamente dos hijos\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d170122",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Árboles de regresión\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Cuando los valores de los nodos hojas son clases --> árboles de decisión\n",
    "* Cuando los valores de los nodos hojas son reales --> árboles de regresión\n",
    "* En la práctica es común tener combinaciones\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3f774",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"../img/decision_tree_reg.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ecbb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Árboles y splines\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Vimos que con los splines podíamos definir una función como una suma pesada de funciones base.\n",
    "* Para ellos utilizamos un tipo particular de polinomio definidos/restringidos utilizando un conjunto de nudos.\n",
    "* Si restringuimos los polinomios a orden 0, es decir constantes, los splines y los árboles son equivalentes.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b849c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/splines_weighted.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b15f2f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Árboles y splines\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* La diferencia está en como se usan!\n",
    "* Para los splines necesitamos definir los nudos de antemano, en los árboles podemos \"aprenderlos\"\n",
    "* Por construcción los splines suelen estar limitados a pocas dimensiones (1, 2, 3, ...), los árboles no.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6f667",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretabilidad Flexibilidad\n",
    "\n",
    "* Los árboles, como los que hemos visto, representan funciones escalonadas\n",
    "* En principio podemos aproximar cualquier función continua con una función escalonada\n",
    "* Los árboles ofrecen un método muy flexible.\n",
    "* La contracara de esta flexibilidad es el sobreajuste. La siguiente figura muestra un ejemplo de un árbol que ha sobreajustado los datos.   \n",
    "\n",
    "\n",
    "Una característica atractiva de los árboles de decisión/regresión es su interpretabilidad: literalmente se puede leer el árbol y seguir los pasos necesarios para resolver un determinado problema. Y, por lo tanto, se puede comprender de forma transparente qué está haciendo el método, porque funciona y porque algunas clases pueden no estar clasificadas adecuadamente o porque algunos datos no están bien aproximados. Además, también es fácil explicar el resultado a una audiencia no técnica con términos simples.\n",
    "\n",
    "Además los árboles ofrecen un método muy flexible, ya que siempre se puede encontrar un árbol lo suficientemente complejo como para que cada nodo hoja tenga asociado una observación. La contracara de esta flexibilidad es el sobreajuste. La siguiente figura muestra un ejemplo de un árbol que ha sobreajustado los datos.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffaa133",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretabilidad y flexibilidad\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Una característica atractiva de los árboles es su interpretabilidad: literalmente se puede leer el árbol y seguir los pasos necesarios para resolver un determinado problema\n",
    "* Los árboles pueden representar tanto efectos principales como interacciones. \n",
    "    * Cuando un árbol depende de una sola variable $X_0$, estamos representando un efecto principal\n",
    "    * Cuando un árbol depende de más de una variable $X_0, X_1, \\dots$ estamos representando una interacción. \n",
    "* Como la profundidad de los árboles es arbitraria, en principio podemos modelar interaccioens de orden arbitrario*\n",
    "* En la práctica estimar una interacción requiere de más datos que estimar una efecto principal y estimar una interacción de bajo orden requiere menos datos que una de mayor orden.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870f41d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpretabilidad y flexibilidad\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Los árboles son muy flexible, en principio es posible encontrar un árbol lo suficientemente complejo como para ajustar cualquier dataset.\n",
    "* La contracara es el sobreajuste. \n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cdf076",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/decision_tree_overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf995aca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularizando los árboles\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Es común introducir dispositivos para regularizar la complejidad de los árboles y disminuir el riesgo de sobreajuste. \n",
    "* Una solución común es utilizar un conjunto de árboles y no un solo árbol\n",
    "* Cada árbol está restringido en uno o más aspectos, por ej la profundidad, de esa forma no puede sobreajustar\n",
    "* Luego los árboles se combinan para genera una única respuesta.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ba9eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularizando los árboles\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* Estrictamente una suma de árboles es equivalente a un nuevo árbol más profundo.\n",
    "* En principio sería posible trabajar con un solo árbol y encontrar una solución que no sobreajuste. Pero empiricamente esta tarea no es simple\n",
    "* Una desventaja de utilizar conjuntos de árboles es que perdemos la interpretabilidad de un único árbol.\n",
    "* Para obtener una respuesta no podemos seguir un solo árbol, debemos considerar a todos, lo que generalmente dificulta cualquier interpretación directa.\n",
    "* Hemos cambiado la interpretabilidad por la flexibilidad y la generalización\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e90cf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BART\n",
    "\n",
    "\n",
    "De forma general podemos escribir un modelo BART como:\n",
    "\n",
    "$$\n",
    "Y = \\phi \\left(\\sum_{j=0}^m G(\\boldsymbol{X}; \\mathcal{T}_i, \\mathcal{M}_i), \\theta \\right)\n",
    "$$\n",
    "\n",
    "* $G$ representa una función árbol parametrizada por \n",
    "    * $\\mathcal{T}_i$, la estructucta del grafo junto con las reglas de decisión asociadas con los nodos internos\n",
    "    * $\\mathcal{M}_i$, el conjunto de valores de los nodos hojas.\n",
    "* $\\phi$ representa una distribución de probabilidad arbitraria que se usará como likelihood en nuestro modelo\n",
    "* $\\theta$ otros parámetros de $\\phi$ no modelados como una suma de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbede47a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Priors para BART\n",
    "\n",
    "\n",
    "* En el [artículo original](https://arxiv.org/abs/0806.3286) de BART y en general en posteriores modificaciones, los priors para BART son conjugados. En PyMC-BART no\n",
    "* Para simplificar la especificación de los priors asumimos que la estructura del árbol $\\mathcal{T}$ y los valores de las hojas $\\mathcal{M}$ son independientes.\n",
    "* Además estos priors son independientes de los priors para $\\theta$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b453112",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Priors para BART\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "El prior para $\\mathcal{T}$ se especifica como:\n",
    "\n",
    "* La probabilidad de que un nodo de profundidad $d=(0, 1, 2, \\dots)$ sea interno -->  $\\alpha(1 + d)^{-\\beta}$ con $\\alpha \\in (0, 1)$ y $\\beta \\in [0, \\infty)$.\n",
    "* La distribución sobre la variable de partición. Uniforme entre las covariables disponibles --> PyMC-BART lo ajusta durante la fase de tuning\n",
    "* La distribución sobre los valores de partición. Uniforme sobre los valores disponibles.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768230e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Priors para BART\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "El prior para los valores de las hojas $\\mu_{ij}$\n",
    "\n",
    "\n",
    "* Usamos $\\mathcal{N}(\\mu_\\text{pred}, {\\varepsilon^2})$, donde $\\mu_\\text{pred}$ se calcula como la media de la suma actual de árboles dividida por número de árboles $m$. \n",
    "* El valor inicial de $\\varepsilon$ se calcula a partir de $Y$, siendo $\\varepsilon = \\frac{3}{\\sqrt{m}}$ para datos binomiales y $\\varepsilon = \\frac{Y_\\text{std}}{\\sqrt{m}}$ para datos distintos del binomial, pero durante la fase de tuning se ajusta\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1f614",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Priors para BART\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "* El número de árboles $m$ debe ser especificado, los valores comunmente usados suelen ser 50, 100 o 200.\n",
    "* En principio se podría colocar un prior sobre $m$ pero en la práctica parece que nadie a encontrado una forma eficiente/correcta de hacerlo.\n",
    "* Es posible usar validación cruzada para determinar $m$, también es posible usar LOO.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5a811",
   "metadata": {},
   "source": [
    "## Inferencia sobre árboles de regresión aditiva bayesiana\n",
    "\n",
    "<br>\n",
    "\n",
    "* Hasta ahora hemso discutido como especificar árboles, pero no como hacer inferencia.\n",
    "* Para ajustar árboles no podemos usar métodos basados en gradientes como HMC\n",
    "\n",
    "A grandes rasgos, cada paso del método implementado en PyMC-BART consiste en elegir uno de los $m_i$ árboles disponibles y proponer un nuevo árbol que lo reemplace. Para ello se procede de la siguiente forma:\n",
    "\n",
    "1) Se hacen crecer $N$ árboles, comenzando desde la raíz y siguiendo los priors.\n",
    "2) Se calcula un peso para cada uno de los $N$ árboles y para el árbol $m_i$\n",
    "3) Se reemplaza el árbol $m_i$ por un árbol muestreado de forma proporcional a los pesos del punto 2\n",
    "\n",
    "<br>\n",
    "\n",
    "[Detalles](https://arxiv.org/abs/2206.03619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fdcd5",
   "metadata": {},
   "source": [
    "## Inferencia sobre árboles de regresión aditiva bayesiana\n",
    "\n",
    "<br>\n",
    "\n",
    "* En este algoritmo los priors son utilizado como distribución de propuesta, esto no es lo más común.\n",
    "* El peso calculado en el punto 2 es el log-likelihood, teniendo en cuenta la suma del árbol de propuesta y todos los demás árboles $m_{-i}$. \n",
    "* Siempre es posible elegir el árbol que se intenta reemplazar. Es decir es posible \"quedarse en el lugar\"\n",
    "* Como sucede con métodos MCMC, la probabilidad de elegir un árbol que \"empeore\" el ajuste es no nula.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34e8b03",
   "metadata": {},
   "source": [
    "## Minería de carbón con BART\n",
    "\n",
    "* Vamos a utilizar el mismo ejemplo que usamos con GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f36867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretizar datos\n",
    "years = int(coal.max() - coal.min())\n",
    "bins = years // 4\n",
    "hist, x_edges = np.histogram(coal, bins=bins)\n",
    "# Calcular la ubicación de los centros de los datos discretizados\n",
    "x_centers = x_edges[:-1] + (x_edges[1] - x_edges[0]) / 2\n",
    "# x_data debe ser 2D para BART\n",
    "x_data = x_centers[:, None]\n",
    "# Expresar los datos como la tasa de número de accidentes por año\n",
    "y_data = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fea859",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as modelo_coal:\n",
    "    μ_ = pmb.BART(\"μ_\", X=x_data, Y=np.log(y_data), m=20)\n",
    "    μ = pm.Deterministic(\"μ\", pm.math.exp(μ_))\n",
    "    y_pred = pm.Poisson(\"y_pred\", mu=μ, observed=y_data)\n",
    "    idata_coal = pm.sample(random_seed=RANDOM_SEED)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
