[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística a Inferencia II",
    "section": "",
    "text": "‎\nLa estadística trata sobre la recolección, organización, análisis e interpretación de datos, es por ello que la estadística es esencial para el correcto análisis de datos.\nExisten dos grandes conjuntos de herramientas para analizar datos:\nAnálisis Exploratorio de Datos (EDA): Consiste en resúmenes numéricos como la media, moda, desviación estándar, rangos intercuartiles, etc (esto se conoce también como estadística descriptiva). Además hace énfasis en el uso de métodos visuales para inspeccionar los datos, como por ejemplo histogramas y gráficos de dispersión.\nEstadística Inferencial: Consiste en usar datos para generar enunciados que exceden los propios datos. A veces esto implica realizar predicciones, a veces entender los detalles de algún fenómeno en particular o elegir entre varias explicaciones plausibles.\nMuchos de los cursos y libros sobre estadística, principalmente aquellos dirigidos a no-estadísticos, enseñan una serie de recetas que más o menos tienen la siguiente forma.\nLa principal meta de estos cursos es la de enseñar a usar la lata adecuada y con suerte alguna que otra discusión sobre el emplatado. Esta aproximación pedagógica, dificulta entender conceptualmente la unidad de los diferentes métodos enseñados y tiene como resultado la reproducción de prácticas poco transparentes y/o útiles.\nEn este curso se intenta una aproximación totalmente diferente. También aprenderemos recetas, pero intentaremos que los platos tengan un sabor más casero y menos enlatado, aprenderemos a mezclar ingredientes frescos que se acomoden a diferentes situaciones gastronómicas.\nEste enfoque es posible por dos razones:",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#a-quienes-está-dirijido",
    "href": "index.html#a-quienes-está-dirijido",
    "title": "Estadística a Inferencia II",
    "section": "A quienes está dirijido?",
    "text": "A quienes está dirijido?\nEste es un curso introductorio para personas sin conocimiento previo de estadística o ciencia de datos. Se asume familiaridad con Python y librerías de Python usadas en análisis de datos como Numpy, matplotlib, Pandas, etc.\nQuienes no sepan Python, pero tengan familiaridad con otros lenguajes de programación también podrán aprovechar el curso, aunque puede que experimente un poco más de fricción.\nPor último quienes no tengan interés en aprender a usar código para analisis de datos pueden aún aprovechar parte del material para obtener una visión a vuelo de pájaro de los métodos Bayesianos.",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#programa",
    "href": "index.html#programa",
    "title": "Estadística a Inferencia II",
    "section": "Programa",
    "text": "Programa\n\nInferencia Bayesiana\n\nProgramación probabilista\n\nModelos jerárquicos Bayesianos\n\nFlujo de trabajo Bayesiano\n\nModelos Líneales Generalizados (GLMs)\n\nModelos de Mezcla (MM)\n\nProcesos Gaussianos (GP)\n\nÁrboles de Regresión Aditiva Bayesiana (BART)",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#cronograma-2024",
    "href": "index.html#cronograma-2024",
    "title": "Estadística a Inferencia II",
    "section": "Cronograma (2024)",
    "text": "Cronograma (2024)\nAgosto:\n- 6 al 13: Inferencia Bayesiana y Programación probabilista.\n- 16 y 20: Modelos Jerárquicos bayesianos.\n- 23 al 30: Evaluación.\nSeptiembre:\n- 3 al 13: Flujo de trabajo Bayesiano.\n- 17 al 27: GLM.\nOctubre\n- 1 y 4: GLM.\n- 8 y 11: Evaluación.\n- 15 al 22: MM.\n- 25 y 29: GP.\nNoviembre:\n- 1 y 5: GP.\n- 8 y 12: BART.\n- 15: Consultas.\n- 19 y 22: Evaluación.",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#cómo-usar-este-material",
    "href": "index.html#cómo-usar-este-material",
    "title": "Estadística a Inferencia II",
    "section": "Cómo usar este material",
    "text": "Cómo usar este material\n\nVersión estática: Esta página contiene una versión estática del material. Es decir podrás ver el texto y las figuras pero no podrás modificarlos, ni interactuar con el material.\nVersión interactiva online: . Esta versión permite interactuar con el material, modificarlo y ejecutarlo en tu navegador.\nVersión interactiva local: También es posible descargar el material y ejecutarlo en tu propia computadora. Para ello hacé click y seguí las instrucciones de la próxima sección (Instalación).",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#instalación",
    "href": "index.html#instalación",
    "title": "Estadística a Inferencia II",
    "section": "Instalación",
    "text": "Instalación\nPara usar este material es necesario tener instalado Python. Se recomienda la versión 3.9 o superior. Además es necesario instalar los siguientes paquetes:\n\nPyMC 5.8.2\nArviZ 0.16.1\nPreliZ 0.3.3\ngraphviz (una dependencia opcional de PyMC)\n\nSe recomienda instalar primero Anaconda. Luego instalar el resto de los paquetes con los comandos:\nconda install pip\npip install pymc==5.8.3 arviz==0.16.1 preliz==0.3.3 graphviz\nComo alternativa pueden crear un ambiente con los paquetes necesario descargando el archivo y ejecutando el comando\nconda env create -f environment.yml",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "index.html#contribuciones",
    "href": "index.html#contribuciones",
    "title": "Estadística a Inferencia II",
    "section": "Contribuciones",
    "text": "Contribuciones\nTodo el contenido de este repositorio es abierto, esto quiere decir que cualquier persona interesada puede contribuir al mismo. Todas las contribuciones serán bien recibidas incluyendo:\n\nCorrecciones ortográficas\nNuevas figuras\nCorrecciones en el código Python, incluidas mejoras de estilo\nMejores ejemplos\nMejores explicaciones\nCorrecciones de errores conceptuales\n\nLa forma de contribuir es vía Github, es decir los cambios deberán ser hechos en forma de pull requests y los problemas/bugs deberán reportarse como Issues.",
    "crumbs": [
      "‎"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html",
    "href": "01_Inferencia_Bayesiana.html",
    "title": "1  Inferencia Bayesiana",
    "section": "",
    "text": "1.1 El universo Bayesiano\nEn este curso aprenderemos sobre una forma de hacer estadística llamada usualmente estadística Bayesiana. El nombre se debe a Thomas Bayes (1702-1761) un ministro presbiteriano, y matemático aficionado, quien derivó por primera vez lo que ahora conocemos como el teorema de Bayes, el cual fue publicado (postumanente) en 1763. Sin embargo una de las primeras personas en realmente desarrollar métodos Bayesianos, fue Pierre-Simon Laplace (1749-1827), por lo que tal vez sería un poco más correcto hablar de Estadística Laplaciana y no Bayesiana.\nHay dos ideas centrales que hacen que un método sea Bayesiano:\nEn el universo Bayesiano las cantidades conocidas son consideradas fijas y usualmente les llamamos datos. Por el contrario toda cantidad desconocida es considerada como una variable aleatoria y es considerada un parámetros dentro de un modelo Bayesiano.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#el-universo-bayesiano",
    "href": "01_Inferencia_Bayesiana.html#el-universo-bayesiano",
    "title": "1  Inferencia Bayesiana",
    "section": "",
    "text": "Toda cantidad desconocida es modelada utilizando una distribución de probabilidad de algún tipo.\nEl teorema de Bayes es usado para actualizar dicha distribución a la luz de los datos.\n\n\n\n1.1.1 Teorema de Bayes\nEl teorema de Bayes es una consecuencia directa de la regla del producto, veamos.\n\\[\\begin{align}\np(\\theta, Y) = p(\\theta \\mid Y)\\; p(Y) \\\\\np(\\theta, Y) = p(Y \\mid \\theta)\\; p(\\theta)\n\\end{align}\\] Dado que los dos términos a la derecha de la igualdad son iguales entre si podemos escribir que:\n\\[\np(\\theta \\mid Y) \\; p(Y) = p(Y \\mid \\theta)\\; p(\\theta)\n\\]\nReordenando llegamos al Teorema de Bayes!\n\\[\np(\\theta \\mid Y) = \\frac{p(Y \\mid \\theta) p(\\theta)}{p(Y)}\n\\]\nEl cual también suele ser escrito de la siguiente forma:\n\\[\n\\overbrace{p(\\theta \\mid Y)}^{\\text{posterior}} = \\frac{\\overbrace{p(Y \\mid \\theta)}^{\\text{likelihood}} \\overbrace{p(\\theta)}^{\\text{prior}}}{\\underbrace{\\int_{\\Theta} p(Y \\mid \\theta) p(\\theta) \\text{d}\\theta}_{\\text{likelihood marginal}}}\n\\]\nEl a priori es la forma de introducir conocimiento previo sobre los valores que pueden tomar los parámetros. A veces cuando no sabemos demasiado se suelen usar a prioris que asignan igual probabilidad a todos los valores de los parámetros, otras veces se puede elegir a prioris que restrinjan los valores de los parámetros a rangos razonables, algo que se conoce como regularización, por ejemplo solo valores positivos. Muchas veces contamos con información mucho más precisa como medidas experimentales previas o límites impuesto por alguna teoría.\nEl likelihood es la forma de incluir nuestros datos en el análisis. Es una expresión matemática que especifica la plausibilidad de los datos. El likelihood es central tanto en estadística Bayesiana como en estadística no-Bayesiana. A medida que la cantidad de datos aumenta el likelihood tiene cada vez más peso en los resultados, esto explica el porqué a veces los resultados de la estadística Bayesiana y frecuentista coinciden cuando la muestra es grande.\nEl a posteriori es la distribución de probabilidad para los parámetros. Es la consecuencia lógica de haber usado un conjunto de datos, un likelihood y un a priori. Se lo suele pensar como la versión actualizada del a priori. De hecho un a posteriori puede ser un a priori de un análisis a futuro.\nLa likelihood marginal (también llamado evidencia) es el likelihood promediado sobre todas los posibles hipótesis (o conjunto de parámetros) \\(\\theta\\), esto es equivalente a \\(p(Y)\\). En general, la evidencia puede ser vista como una simple constante de normalización que en la mayoría de los problemas prácticos puede (y suele) omitirse. Por lo que el teorema de Bayes suele aparecer escrito como:\n\\[\np(\\theta \\mid Y) \\propto p(Y \\mid \\theta) p(\\theta)\n\\]\nEl rol de todos estos términos irá quedando más claro a medida que avancemos.\n\n\n1.1.2 El a posteriori como único estimador\nEl a posteriori representa todo lo que sabemos de un problema, dado un modelo y un conjunto de datos. Y por lo tanto cualquier cantidad que nos interese sobre el problema puede deducirse a partir de él. Típicamente esto toma la forma de integrales como la siguiente.\n\\[\nJ = \\int \\varphi(\\theta) \\ \\ p(\\theta \\mid Y) d\\theta\n\\]\nPor ejemplo, para calcular la media de \\(\\theta\\) deberíamos reemplazar \\(\\varphi(\\theta)\\), por \\(\\theta\\):\n\\[\n\\bar \\theta = \\int \\theta \\ \\ p(\\theta \\mid Y) d\\theta\n\\]\nEsto no es más que la definición de un promedio pesado, donde cada valor de \\(\\theta\\) es pesado según la probabilidad asignada por el a posteriori.\nEn la práctica, y al usar métodos computacionales como los usados en este curso, estas integrales pueden aproximarse usando sumas.\n\n\n1.1.3 Estadística Bayesiana en tres pasos\nEl teorema de Bayes es el único estimador usado en estadística Bayesiana. Por lo que conceptualmente la estadística Bayesiana resulta muy simple. Según George Box y Andrew Gelman et al. (2013) la estadística Bayesiana se reduce a tres pasos:\n\nCrear un modelo probabilístico. Los modelos probabilísticos son historias que dan cuenta de como se generan los datos observados (o por observar). Los modelos se expresan usando distribuciones de probabilidad.\nCondicionar el modelo a los datos observados a fin de obtener el a posteriori. Usando el teorema de Bayes se actualizan las probabilidades asignadas a priori de acuerdo a los datos observados obteniéndose las probabilidades a posteriori.\nCriticar el ajuste del modelo generado a los datos y evaluar las consecuencias del modelo. Se puede demostrar que dada la información previa y los datos observados no existe otro mecanismo capaz de generar una mejor inferencia que la estadística Bayesiana. Esto parece maravilloso, pero hay un problema, sólo es cierto si se asumen que los datos y el modelo son correctos. En la práctica, los datos pueden contener errores y los modelos son a duras penas aproximaciones de fenómenos reales. Por lo tanto es necesario realizar varias evaluaciones, incluyendo si las predicciones generadas por el modelo se ajustan a los datos observados, si las conclusiones obtenidas tienen sentido dado el marco conceptual en el que uno trabaja, la sensibilidad de los resultados a los detalles del modelo (sobre todo a detalles para los cuales no tenemos demasiada información), etc. Además, es posible que realizar inferencia Bayesiana sea demasiado costosa en la práctica por lo que sea conveniente realizar aproximaciones.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#inferencia-bayesiana",
    "href": "01_Inferencia_Bayesiana.html#inferencia-bayesiana",
    "title": "1  Inferencia Bayesiana",
    "section": "1.2 Inferencia Bayesiana",
    "text": "1.2 Inferencia Bayesiana\nEn la práctica la mayoría de los modelos tendrán más de un parámetro, pero empecemos con un modelo con un solo parámetro.\n\n1.2.1 El problema de la moneda\nA juzgar por la cantidad de ejemplos sobre monedas arrojadas al aires en libros de estadística y probabilidad, pareciera que las monedas son uno de los objetos de estudio centrales de estas disciplinas.\nUna de las razones detrás de la ubiquidad de este ejemplo es que las monedas son objetos familiares que facilitan discutir conceptos que de otra forma podrían sonar demasiado abstractos. De todas formas quizá la razón más importante sea que el problema puede ser modelado de forma simple y que muchos problemas reales son conceptualmente similares, de hecho cualquier problema en donde obtengamos resultados binarios (0/1, enfermo/sano, spam/no-spam, etc) puede ser pensado como si estuviéramos hablando de monedas. En definitiva el modelo que veremos a continuación (ejemplificado con monedas) sirve para cualquier situación en la cual los datos observados solo pueden tomar dos valores mutuamente excluyentes. Debido a que estos valores son nominales y son dos, a este modelo se le llama binomial.\nEn el siguiente ejemplo trataremos de determinar el grado en que una moneda está sesgada. En general cuando se habla de sesgo se hace referencia a la desviación de algún valor (por ejemplo, igual proporción de caras y cecas), pero aquí usaremos el termino sesgo de forma más general. Diremos que el sesgo es un valor en el intervalo [0, 1], siendo 0 para una moneda que siempre cae ceca y 1 para una moneda que siempre cae cara y lo representaremos con la variable \\(\\theta\\). A fin de cuantificar \\(\\theta\\) arrojaremos una moneda al aire repetidas veces, por practicidad arrojaremos la moneda de forma computacional (¡pero nada nos impide hacerlo manualmente!). Llevaremos registro del resultado en la variable \\(y\\). Siendo \\(y\\) la cantidad de caras obtenidas en un experimento.\nHabiendo definido nuestro problema debemos expresarlo en términos del teorema de Bayes,\n\\[\np(\\theta \\mid Y) \\propto p(Y \\mid  \\theta) p(\\theta)\n\\]\nDonde, como dijimos \\(\\theta = 1\\) quiere decir 100% cara y \\(\\theta = 0\\) 100% ceca.\nAhora sólo restar reemplazar los dos términos a la derecha de la igualdad, el a priori y el likelihood, por distribuciones de probabilidad adecuadas y luego multiplicarlas para obtener el término a la izquierda, el a posteriori. Como es la primera vez que haremos ésto, lo haremos paso a paso y analíticamente. En el próximo capítulo veremos cómo hacerlo computacionalmente.\n\n\n1.2.2 Definiendo el a priori\nEl a priori lo modelaremos usando una distribución Beta, que es una distribución muy usada en estadística Bayesiana. La \\(pdf\\) de esta distribución es:\n\\[\np(\\theta)= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\, \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n\\]\nEl primer término es una constante de normalización. Por suerte para nuestro problema nos basta con establecer una proporcionalidad, por lo que podemos simplificar esta expresión y escribir la distribución Beta de la siguiente forma.\n\\[\np(\\theta) \\propto  \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}\n\\]\nHay varias razones para usar una distribución Beta para este y otros problemas:\n\nLa distribución Beta varía entre 0 y 1, de igual forma que lo hace \\(\\theta\\) en nuestro modelo.\nEsta distribución combinada con la que elegiremos como likelihood (ver más adelante), nos permitirá resolver el problema de forma analítica.\nEs una distribución versátil para expresar distintas situaciones.\n\nRespecto al último punto, veamos un ejemplo. Supongamos que el experimento de la moneda es realizado por tres personas. Una de ellas dice no saber nada de la moneda por lo tanto a priori todos los valores de \\(\\theta\\) son igualmente probables. La segunda persona desconfía de la moneda, ya que sospecha que es una moneda trucada, por lo tanto considera que está sesgada, pero no sabe para cual de las dos opciones. Por último, la tercer persona asegura que lo más probable es que \\(\\theta\\) tome un valor alrededor de 0.5 ya que así lo indican experimentos previos y análisis teóricos sobre tiradas de monedas. Todas estas situaciones pueden ser modeladas por la distribución Beta, como se ve a continuación.\n\n_, axes = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\n\nparams = [(1, 1), (0.5, 0.5), (20, 20)]\n\nfor (a, b), ax  in zip(params, axes):\n    ax = pz.Beta(a, b).plot_pdf(ax=ax, legend=\"title\")\n    ax.set_ylim(0, 7)\n\n\n\n\n\n\n\n\n\npz.Beta().plot_interactive(xy_lim=(None, None, None, 10))\n\n\n\n\n\n\n1.2.3 Definiendo el likelihood\nHabiendo definido el a priori veamos ahora el likelihood. Asumiendo que el resultado obtenido al arrojar una moneda no influye en el resultado de posteriores experimentos (es decir los experimentos son independientes entre sí) es razonable utilizar como likelihood la distribución binomial.\n\\[\np(y \\mid \\theta) = \\frac{N!}{y!(N-y)!} \\theta^y (1 - \\theta)^{N−y}\n\\]\nDonde N es la cantidad total de experimentos (monedas arrojadas al aire) e \\(y\\) es la cantidad de caras obtenidas. A los fines prácticos podríamos simplificar la igualdad anterior y convertirla en una proporcionalidad, eliminando el término \\(\\frac{N!}{y!(N-y)!}\\) ya que ese término no depende de \\(\\theta\\) que es lo que nos interesa averiguar. Por lo que podríamos establecer que:\n\\[\np(y \\mid \\theta) \\propto \\theta^y (1 - \\theta)^{N−y}\n\\]\nLa elección de esta distribución para modelar nuestro problema es razonable ya que \\(\\theta\\) es la chance de obtener una cara al arrojar una moneda y ese hecho ha ocurrido \\(y\\) veces, de la misma forma \\(1-\\theta\\) es la chance de obtener ceca lo cual ha sido observado \\(N-y\\) veces.\n\npz.Binomial(1, 0.5).plot_interactive(pointinterval=False, xy_lim=(None, None, None, 1))\n\n\n\n\n\n\n1.2.4 Obteniendo el a posteriori\nSe puede demostrar que siempre que usemos como prior una función Beta y como likelihood una distribución binomial obtendremos como resultado una distribución a posteriori, la cual será una Beta con los siguientes parámetros:\n\\[\np(\\theta \\mid y) = \\operatorname{Beta}(\\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nVeamos de donde surge este resultado, según el teorema de Bayes la distribución a posteriori es el producto del likelihood y la distribución a priori.\n\\[\np(\\theta \\mid y) = p(y \\mid \\theta) p(\\theta) * c\n\\]\nPor lo tanto, en nuestro caso tendremos que:\n\\[\np(\\theta \\mid y) \\propto \\underbrace{{\\color{gray}{\\frac{N!}{y!(N-y)!}}} \\theta^y (1 - \\theta)^{N−y}}_{\\text{likelihood}} \\underbrace{{\\color{gray}{\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}}}\\, \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}_{\\text{prior}}\n\\]\nSi omitimos las constantes de normalizando del likelihood y prior, obtenemos que el a posteriori es:\n\\[\np(\\theta \\mid y) \\propto \\theta^{\\alpha-1+y}(1-\\theta)^{\\beta-1+N−y}\n\\]\nPodemos ver que la expresión a la derecha de la proporcionalidad tiene la misma forma funcional (sin considerar la constante de proporcionalidad) que una distribución Beta. Como la distribución a posterior debe intergrar a 1 entonces podemos escribir.\n\\[\np(\\theta \\mid y) = \\frac{\\Gamma(\\alpha + y +\\beta + N -y)}{\\Gamma(\\alpha + y)\\Gamma(\\beta + N - y)}\\, \\theta^{\\alpha-1+y}(1-\\theta)^{\\beta-1+n-y}\n\\]\nLo que es equivalente a una distribución Beta con parámetros \\(\\alpha_{\\text{a posteriori}} = \\alpha_{\\text{a priori}} + y \\quad \\beta_{\\text{a posteriori}} = \\beta_{\\text{a priori}} + N - y\\).\nCuando se cumple que para un cierto likelihood la forma funcional del a priori y la del a posteriori coinciden se dice que el a priori es conjugado con el likelihood. Históricamente los problemas en estadística Bayesiana estuvieron restringidos al uso de a prioris conjugados, ya que estos garantizan la tratabilidad matemática del problema, es decir garantizan que es posible obtener una expresión analítica para nuestro problema. En el próximo capítulo veremos técnicas computacionales modernas que permiten calcular la distribución a posteriori incluso cuando no se usan a prioris conjugados. Estas técnicas computacionales han permitido el resurgimiento de la estadística Bayesiana en las últimas décadas.\n\n\n1.2.5 Notación y visualización de modelos Bayesianos\nPara representar modelos en estadística Bayesiana (y en probabilidad en general) se suele utilizar la siguiente notación\n\\[\n\\begin{align}\n\\theta \\sim & \\operatorname{Beta}(\\alpha, \\beta) \\\\\nY \\sim & \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\n\\]\nEl símbolo \\(\\sim\\) indica que la variable a la izquierda se distribuye según la distribución a la derecha. Entonces podríamos decir que \\(\\mathbf{\\theta}\\) es una variable aleatoria con distribución \\(\\operatorname{Beta}\\), y que \\(\\operatorname{Beta}\\) está definida por los parámetros \\(\\alpha\\) y \\(\\beta\\), este es nuestro a priori. En la siguiente línea tenemos el likelihood el cual está definido por una distribución binomial con parámetros \\(n=1\\) y \\(p=\\theta\\).\nGráficamente esto se puede representar usando los diagramas de Kruschke:\n\n\nEn el primer nivel (de arriba hacia abajo) se observa el a priori, luego el likelihood, y por último los datos. Las flechas indican la vinculación entre las partes del modelo y el signo \\(\\sim\\) la naturaleza estocástica de las variables.\n\n\n1.2.6 Obteniendo los datos\nBien, ahora que sabemos cómo calcular el a posteriori, lo único que resta es conseguir los datos. En este ejemplo los datos son sintéticos, es decir los obtuve computacionalmente mediante un generador de números (pseudo)aleatorios, pero bien podrían haber surgido de un experimento con una moneda real.\n\n\n1.2.7 Calculando el a posteriori\nEn el próximo capítulo veremos cómo usar métodos computacionales para computar un a posteriori sin necesidad de derivarlo analíticamente. Esto es lo que haremos para resolver el resto de los problemas del curso. Pero dado que ya nos tomamos el trabajo de derivar analíticamente la expresión para el a posteriori vamos a usar esa expresión. Si miran el código de la siguiente celda verán que la mayoría de las lineas se encargan de dibujar los resultados y no de calcularlos. El cálculo del a posteriori ocurre en la línea 20. Cada una de estas lineas computa el a posteriori para cada uno de los a prioris que vimos antes. El cálculo es simple, tan solo se computa el valor del a posteriori (usando la función pdf de la distribución Beta provista por PreliZ) para 2000 puntos igualmente espaciados entre 0 y 1 (linea 9). El loop que empieza en la linea 11 se debe a que exploraremos cómo cambian las distribuciones a posteriori para distinta cantidad de datos (n_intentos). Con un círculo negro de contorno blanco se indica el valor real de \\(\\theta\\), valor que por supuesto es desconocido en una situación real, pero conocido para mí, ya que los datos son sintéticos.\n\nplt.figure(figsize=(12, 9))\n\nn_trials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150]\ndata = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48]\ntheta_real = 0.35\n\nbeta_params = [(1, 1), (0.5, 0.5), (20, 20)]\ndist = pz.Beta\nx = np.linspace(0, 1, 2000)\n\nfor idx, N in enumerate(n_trials):\n    if idx == 0:\n        plt.subplot(4, 3, 2)\n        plt.xlabel('θ')\n    else:\n        plt.subplot(4, 3, idx+3)\n        plt.xticks([])\n    y = data[idx]\n    for (a_prior, b_prior) in beta_params:\n        posterior = dist(a_prior + y, b_prior + N - y).pdf(x)\n        plt.fill_between(x, 0, posterior, alpha=0.7)\n\n    plt.plot(theta_real, 0, ms=9, marker='o', mec='w', mfc='k')\n    plt.plot(0, 0, label=f'{N:4d} experimentos\\n{y:4d} caras', alpha=0)\n    plt.xlim(0, 1)\n    plt.ylim(0, 12)\n    plt.legend()\n    plt.yticks([])\n\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/numba/np/ufunc/dufunc.py:287: RuntimeWarning: divide by zero encountered in nb_logpdf\n  return super().__call__(*args, **kws)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#analizando-los-resultados",
    "href": "01_Inferencia_Bayesiana.html#analizando-los-resultados",
    "title": "1  Inferencia Bayesiana",
    "section": "1.3 Analizando los resultados",
    "text": "1.3 Analizando los resultados\nLa primer figura del panel muestra los a priori, nuestra estimación de \\(\\theta\\) dado que no hemos realizado ningún experimento. Las sucesivas nueve figuras muestran las distribuciones a posteriori y se indica la cantidad de experimentos y de caras obtenidas. Además se puede ver un círculo negro de contorno blanco en 0.35, la cual representa el valor verdadero de \\(\\theta\\). Por supuesto que en problemas reales este valor es desconocido.\nEste ejemplo es realmente ilustrativo en varios aspectos.\n\nEl resultado de un análisis Bayesiano NO es un solo valor, si no una distribución (a posteriori) de los valores plausibles de los parámetros (dado los datos y el modelo).\nLa dispersión o ancho de las curvas es una medida de la incertidumbre sobre los valores.\nEl valor más probable viene dado por la moda de la distribución (el pico de la distribución).\nAún cuando \\(\\frac{2}{1} = \\frac{8}{4}\\) son numéricamente iguales tenemos menor incertidumbre en un resultado cuando el número de experimentos es mayor.\nDada una cantidad suficiente de datos los resultados tienden a converger sin importar el a priori usado.\nLa rapidez con la que los resultados convergen varía. En este ejemplo las curvas azul y turquesa parecen converger con tan solo 8 experimentos, pero se necesitan más de 50 experimentos para que las tres curvas se muestren similares. Aún con 150 experimentos se observan ligeras diferencias.\nPartiendo de los a priori uniforme (azul) o sesgado (turquesa) y habiendo realizado un solo experimento y observado una sola cara, lo más razonable es pensar que estamos frente a una moneda con dos caras!\nLa situación cambia drásticamente al ver por primera vez una moneda caer ceca. Ahora lo más probable (dado cualquiera de los tres a prioris) es inferir que \\(\\theta=0.5\\). Los valores de \\(\\theta\\) exactamente 0 o 1 se vuelven imposibles.\nEl a priori naranja es más informativo que los otros dos (la distribución esta más concentrada), por ello se requiere de un número mas grande de experimentos para “moverlo”.\nEl a priori uniforme (azul) es lo que se conoce como no informativo. El resultado de un análisis Bayesiano usando un a priori no-informativos en general coinciden con los resultados de análisis frecuentistas (en este caso el valor esperado de \\(\\theta = \\frac{y}{N}\\)).\n\n\n1.3.1 Influencia y elección del a priori\nDe los ejemplos anteriores debería quedar claro que los a priori influencian los resultados de nuestros cálculos. Esto tiene total sentido si no fuese así no haría falta incluirlos en el análisis y todo sería más simple (aunque nos perderíamos la oportunidad de usar información previa). De los ejemplos anteriores también debería quedar claro que a medida que aumentan los datos (como las tiradas de monedas) los resultados son cada vez menos sensibles al a priori. De hecho, para una cantidad infinita de datos el a priori no tiene ningún efecto. Exactamente cuantos datos son necesarios para que el efecto del a priori sea despreciable varía según el problema y los modelos usados. En el ejemplo de la moneda se puede ver que 50 experimentos bastan para hacer que dos de los resultados sean prácticamente indistinguibles, pero hacen falta más de 150 experimentos para que los 3 resultados se vuelvan practicamente independientes del a priori. Esto es así por que los dos primeros a prioris son relativamente planos, mientras que el tercer a priori concentra casi toda la probabilidad en una región relativamente pequeña. El tercer a priori no solo considera que el valor más probable de \\(\\theta\\) es 0.5, si no que considera que la mayoría de los otros valores son muy poco probables. ¿Cómo cambiarían los resultados si hubiéramos usado como a priori \\(\\operatorname{Beta}(\\alpha=2, \\beta=2)\\)?\nLa elección de los a priori puede poner nervioso a quienes se inician en el análisis Bayesiano (o a los detractores de este paradigma). ¡El temor es que los a prioris censuren a los datos y no les permitan hablar por sí mismos! Eso está muy bien, pero el punto es que los datos no saben hablar, con suerte murmuran. Los datos solo tienen sentido a la luz de los modelos (matemáticos y mentales) usados para interpretarlos, y los a prioris son parte de esos modelos.\nHay quienes prefieren usar a priori no-informativos (también conocidos como a priori planos, vagos, o difusos). Estos a priori aportan la menor cantidad posible de información y por lo tanto tienen el menor impacto posible en el análisis. Si bien es posible usarlos, en general hay razones prácticas para no preferirlos. En este curso usaremos a priori ligeramente informativos siguendo las recomendaciones de Gelman, McElreath, Kruschke, y otros. En muchos problemas sabemos al menos algo de los valores posibles que pueden tomar nuestros parámetros, por ejemplo que solo pueden ser positivos, o que están restringidos a sumar 1 o el rango aproximado, etc. En esos casos podemos usar a prioris que introduzcan esta ligera información. En estos casos podemos pensar que la función del a priori es la de mantener las inferencias dentro de límites razonables. Estos a priori se suelen llamar regularizadores.\nPor supuesto que también es posible usar a prioris informativos (o fuertes). Hacer esto es razonable solo si contamos con información previa confiable. Esto puede ser ventajoso en casos en que los datos contengan poca información sobre el problema. Si la información no viene por el likelihood (datos), entonces puede venir por el a priori. A modo de ejemplo, en bioinformática estructural es común usar toda la información previa posible (de forma Bayesiana y no-Bayesiana) para resolver problemas. Esto es posible por la existencia de bases de datos que almacenan los resultados de cientos o miles experimentos realizados a lo largo de décadas de esfuerzo (¡No usar esta información sería casi absurdo!). En resumen, si contás con información confiable no hay razón para descartarla, menos si el argumento es algo relacionado con pretender ser objetivo (¡No hay objetividad en negar lo que se sabe!).\nHasta ahora hemos visto que es posible clasificar, aunque sea de forma vaga o aproximada, a los a priori en función de la información que contienen. Pero saber esta clasificación no necesariamente hace las cosas más simples a la hora de elegir un a priori. ¿Acaso no sería mejor eliminar los a prioris de nuestro análisis? Eso haría el asunto mucho mas simple. Bueno, el punto es que desde una perspectiva Bayesiana todos los modelos tienen a prioris, aun cuando no sean explícitos. De hecho muchos resultados de la estadística frecuentista pueden considerarse casos especiales de modelos Bayesianos usando a prioris planos. Volviendo a la figura anterior se puede ver que la moda del a posteriori para la curva azul. Coincide con la estimación (puntual) frecuentista para el valor de \\(\\theta\\)\n\\[\n\\hat \\theta = {{y} \\over {N}}\n\\]\nNotar que \\(\\hat \\theta\\) es una estimación puntual (un número) y no una distribución.\nEste ejemplo nos muestra que no es posible hacer análisis estadísticos y sacarse los a prioris de encima. Un posible corolario es que es más flexible y transparente especificar los a prioris de forma explícita que esconderlos bajo la cama. Al hacerlo ganamos mayor control sobre nuestro modelo, mayor transparencia y por el mismo precio la estimación de la incertidumbre con la que se estima cada parámetro.\nPor último, hay que recordar que el modelado estadístico (como otras formas de modelado) es un proceso iterativo e interactivo. Nada nos impide usar más de un a priori (o un likelihood) si así lo quisiéramos. Una parte importante del modelado es la de cuestionar los supuestos y los a prioris son simplemente un tipo de supuestos (como lo son los likelihoods). Si tuviéramos más de un a priori razonable podríamos realizar un análisis de sensibilidad, es decir evaluar como cambian los resultados con los a prioris, podríamos llegar a la conclusión que para un rango amplio de a prioris ¡los resultados no varían! Más adelante veremos varias herramientas para comparar distintos modelos.\nDado que los a prioris tienen un papel central en la estadística Bayesiana, seguiremos discutiéndolos a medida que vayamos viendo problemas concretos. Por lo que si esta discusión no ha aclarado todas tus dudas y seguís algo confundido, mejor mantener la calma y no preocuparse demasiado, este tema ha sido motivo de discusión y confusión durante décadas ¡y la discusión todavía continua!\n\n\n1.3.2 Cuantificando el peso del a priori\nEn general la distribución más familiar para la mayoría de las personas es la distribución Gaussiana, como esta distribución está definida por dos parámetros, la media y la dispersión de ese valor medio, suele resultarnos natural pensar las distribuciones en esos términos. Además, resulta relativamente sencillo (o al menos más sencillo que otras alternativas) pensar en un valor medio y una desviación o ruido simétrico alrededor de esa media.\nSi queremos expresar la distribución Beta en función de la media y la dispersión podemos hacerlo de la siguiente forma:\n\\[\\begin{align}\n\\alpha &= \\mu \\kappa \\\\\n\\beta &= (1 - \\mu) \\kappa\n\\end{align}\\]\ndonde \\(\\mu\\) es la media y \\(\\kappa\\) es un parámetro llamado concentración. Por ejemplo si \\(\\mu=0.5\\) y \\(\\kappa=40\\), tenemos que:\n\\[\\begin{align}\n\\alpha = 0.5 \\times 40 &= 20 \\\\\n\\beta = (1-0.5) \\times 40 &= 20\n\\end{align}\\]\n\\(\\kappa\\) se puede interpretar como la cantidad de experimentos si/no que realizamos dándonos como resultado la media \\(\\mu\\). Es decir el a priori no sesgado (naranja) equivale a haber arrojado una moneda 40 veces y haber obtenido como media 0.5. Es decir que si usamos ese a priori recién al observar 40 experimentos si/no, los datos tendrán el mismo peso relativo que el a priori, por debajo de este número el a priori contribuye más que los datos al resultado final y por encima menos. El a priori azul (uniforme) equivale a haber observado a la moneda caer una vez cara y otra vez ceca (\\(\\kappa = 2\\)). Cuando \\(\\kappa &lt; 2\\), la cosa se pone un poco extraña, por ejemplo el a priori sesgado (turquesa) equivale a haber observado una sola moneda (\\(\\kappa = 1\\)) pero en una especie de, a falta de mejor analogía, ¡¿superposición cuántica de estados?!\n\n\n1.3.3 Resumiendo el a posteriori\nEl resultado de un análisis Bayesiano es siempre una distribución de probabilidad.\nA la hora de comunicar los resultados de un análisis Bayesiano, lo más informativo es reportar la distribución completa, aunque esto no siempre es posible o deseable, por ejemplo el a posteriori de una distribución multidimensional es imposible de visualizar de forma directa. Por lo tanto, es común recurrir a distintas medidas que resumen el a posteriori, por ejemplo la media, mediana, la desviación estándar, etc. También es común, e informativo, reportar un intervalo de credibilidad. Existen varios criterios para definir intervalos de credibilidad, el que usaremos en este curso (y que también es ampliamente usado en la literatura) es lo que se conoce como intervalo de más alta densidad y nos referiremos a él por su sigla en ingles, HDI (Highest Posterior Density interval). Un HDI es el intervalo, más corto, que contiene una porción fija de la densidad de probabilidad, generalmente el 95% (aunque otros valores como 90% o 50% son comunes). Cualquier punto dentro de este intervalo tiene mayor densidad que cualquier punto fuera del intervalo. Para una distribución unimodal, el HDI 95 es simplemente el intervalo entre los percentiles 2,5 y 97,5.\nArviZ es un paquete de Python para análisis exploratorio de modelos Bayesianos. ArviZ provee de funciones que facilitan analizar y resumir el a posteriori. Por ejemplo plot_posterior puede ser usado para generar un gráfico con la media y el HDI. En el siguiente ejemplo en vez de un a posteriori “real” estamos usando datos sintéticos generados de una distribución Beta.\n\nmock_posterior = pz.Beta(5, 11).rvs(size=1000)\naz.plot_posterior(mock_posterior, figsize=(8, 4));\n\n\n\n\n\n\n\n\nAhora que estamos aprendiendo que es un HDI por primera vez y antes de que automaticemos el concepto conviene aclarar un par de puntos.\n\nLa elección automática de 95% (o cualquier otro valor) es totalmente arbitraria. En principio no hay ninguna razón para pensar que describir el a posteriori con un HDI 95 sea mejor que describirlo con un HDI 98 o que no podamos usar valores como 87% o 66%. El valor de 95% es tan solo un accidente histórico. Como un sutil recordatorio de esto ArviZ usa por defecto el valor 94%!\nUn intervalo de credibilidad (que es Bayesiano) no es lo mismo que un intervalo de confianza (que es frecuentista). Un intervalo de confianza es un intervalo que se define según un nivel de confianza, en general del 95%. Un intervalo de confianza se construye de tal forma que si repitiéramos infinitas veces un experimento obtendríamos que la proporción de intervalos que contienen el valor verdadero del parámetro que nos interesa coincide con el nivel de confianza estipulado. Contra-intuitivamente esto no es lo mismo que decir que un intervalo en particular tiene una probabilidad \\(x\\) de contener el parámetro (esto sería la definición de un intervalo de credibilidad, que es Bayesiano). De hecho, un intervalo de confianza en particular contiene o no contiene al valor, la teoría frecuentista no nos deja hablar de probabilidades de los parámetros, ya que estos tienen valores fijos. Si no queda clara la diferencia no te hagas problema, la diferencia entre estos dos conceptos suele ser tan difícil de entender que en la práctica estudiantes y científicos por igual interpretan los intervalos de confianza (frecuentistas) como intervalos de credibilidad (Bayesianos).\n\n\nSi bien desde la perspectiva Bayesiana podemos afirmar que un intervalo de credibilidad nos permite asegurar que la probabilidad de un parámetro está acotado en cierto rango. Siempre hay que tener presente que dicha afirmación es correcta SOLO en sentido teórico. Es decir, solo si todos los supuestos contenidos en el modelo son ciertos. Una inferencia es siempre dependiente de los datos y modelos usados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#distribución-predictivas",
    "href": "01_Inferencia_Bayesiana.html#distribución-predictivas",
    "title": "1  Inferencia Bayesiana",
    "section": "1.4 Distribución predictivas",
    "text": "1.4 Distribución predictivas\nSi bien el objeto central de la estadística Bayesiana es la distribución a posteriori. Existen otras distribuciones muy importantes. Una de ellas es la distribución predictiva a posteriori, otra es la distribución predictiva a priori.\n\n1.4.1 Distribución predictivas a posteriori\nEsta distribución representa las predicciones \\(\\tilde{y}\\) de un modelo una vez obtenido el a posteriori. Se calcula de la siguiente manera:\n\\[\np(\\tilde{y}  \\mid  y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta\n\\]\nEs decir integramos \\(\\theta\\) de acuerdo a la distribución a posteriori.\nComputacionalmente podemos generar muestras de esta distribución según el siguiente procedimiento:\n\nElegimos un valor de \\(\\theta\\) de acuerdo a la distribución a posteriori \\(p(\\theta \\mid y)\\)\nFijamos \\(\\theta\\) en la distribución que usamos como likelihood \\(p(\\tilde{y} \\mid \\theta)\\) y generamos una muestra aleatoria\nRepetimos desde 1, tantas veces como muestras necesitemos\n\nLos datos generados son predictivos ya que son los datos que se esperaría ver por ejemplo en un futuro experimento, es decir son variables no observadas pero potencialmente observables. Como veremos en el siguiente capítulo un uso muy común para la distribución predictiva a posteriori es compararla con los datos observados y así evaluar si el posterior calculado es razonable.\n\n\n1.4.2 Distribución predictiva a priori\nAsi como es posible generar datos sintéticos desde el a posteriori. Es posible hacerlo desde el prior. En este caso la distribución se llama distribución predictiva a priori. Y representa los datos \\(p(y^\\ast)\\) que el modelo espera ver antes de haber visto los datos. O más formalmente antes de haber sido condicionado a los datos. Se calcula como:\n\\[\np(y^\\ast) =  \\int p(y^\\ast \\mid \\theta) \\; p(\\theta) \\; d\\theta\n\\]\nEs importante notar que la definición es muy similar a la distribución predictiva a posteriori, solo que ahora integramos a lo largo del prior en vez del posterior.\nLos datos generados son predictivos ya que son los datos que el modelo esperara ver, es decir son datos no observados pero potencialmente observables. Como veremos en el siguiente capítulo un uso muy común para la distribución predictiva a priori es compararla con nuestro conocimiento previo y así evaluar si el modelo es capaz de generar resultados razonable, incluso antes de haber incorporado los datos.\n\n\n1.4.3 Distribución predictiva a priori y a posterior para el problema de la moneda.\nEn el caso del modelo beta-binomial es posible obtener analíticamente tanto la distribución predictiva a priori como a posteriori y estas son:\n\\[\np(y^\\ast) \\propto \\operatorname{Beta-binomial}(n=N, \\alpha_{a priori}, \\beta_{a priori})\n\\]\n\\[\np(\\tilde{y}  \\mid  y)  \\propto \\operatorname{Beta-binomial}(n=N, \\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nOmitiremos la discusión de como se obtienen estas distribuciones\n\n\n1.4.4 Cuarteto Bayesiano\nEl siguiente bloque de código computa las distribuciones a priori, a posteriori, predictiva a priori y predictiva a posteriori. En vez de usar la distribución \\(\\operatorname{Beta-binomial}\\) para las distribuciones predictivas hemos optado por usar una aproximación más computacional y muestrear primero de la distribuciones beta y luego de la binomial. Esperamos que esta decisión contribuya a comprender mejor que representan estas distribuciones.\nEs importante notar que mientras la distribuciones a priori y a posteriori son distribución sobre los parámetros en un modelo, la distribución predictivas a priori y a posteriori son distribuciones sobre los datos (predichos).\n\nfig, axes = plt.subplots(2, 2, figsize=(10, 8), sharex=\"row\", sharey=\"row\")\naxes = np.ravel(axes)\ndist = pz.Beta\na_prior = 1\nb_prior = 1\nN = 12\ny = 3\neps = np.finfo(float).eps\nx = np.linspace(eps, 1-eps, 100)\n\n\nprior = dist(a_prior, b_prior).pdf(x)\naxes[0].fill_between(x, 0, prior)\naxes[0].set_title(\"Prior\")\naxes[0].set_yticks([])\n\n\nposterior = dist(a_prior + y, b_prior + N - y).pdf(x)\naxes[1].fill_between(x, 0, posterior)\naxes[1].set_title(\"Posterior\")\n\n\nprior = dist(a_prior, b_prior).rvs(500)\nprior_predictive = np.hstack([pz.Binomial(n=N, p=p).rvs(N) for p in prior])\naxes[2].hist(prior_predictive, bins=range(0, N+2), rwidth=0.9, align=\"left\", density=True)\naxes[2].set_xlim(-0.5, N+0.5)  \naxes[2].set_title(\"Predictiva a priori\")\n\nposterior = dist(a_prior + y, b_prior + N - y).rvs(500)\nprior_predictive = np.hstack([pz.Binomial(n=N, p=p).rvs(N) for p in posterior])\naxes[3].hist(prior_predictive, bins=range(0, N+2), rwidth=0.9, align=\"left\", density=True)\naxes[3].set_xlim(-0.5, N+0.5)  \naxes[3].set_title(\"Predictiva a posteriori\");\n\nfig.suptitle(\"Cuarteto Bayesiano\", fontweight=\"bold\", fontsize=16);",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "01_Inferencia_Bayesiana.html#ejercicios",
    "href": "01_Inferencia_Bayesiana.html#ejercicios",
    "title": "1  Inferencia Bayesiana",
    "section": "1.5 Ejercicios",
    "text": "1.5 Ejercicios\n\nEl estadístico Bruno de Finetti declaró que “Las probabilidades no existen”. Cómo se vincula este enunciado con el modelo BetaBinomial que hemos visto?\nEdwin Jaynes, físico, declaró que la teoría de probabilidad es la lógica de la ciencia. Discutí este enunciado.\nUsá pz.Beta().plot_interactive() para explorar distintas combinaciones de parámetros de la distribución Beta. Cuál es el efecto de los parámetros \\(\\alpha\\) y \\(\\beta\\)?\nInterpretá los parámetros de una distribución Beta, \\(\\alpha\\) y \\(\\beta\\) en términos de su PDF (probability density function). Analizá solo el caso de \\(\\alpha &gt;= 1\\) y \\(\\beta &gt;= 1\\)\nLa media de la distribución Beta es \\(\\frac{\\alpha}{\\alpha+\\beta}\\). Cuál es la media de la distribución a posteriori para un modelo Beta-Binomial, con prior Beta(2, 5) y 10 experimentos con 6 caras?\nLa varianza de la distribución Beta es \\(\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\\). Cuál es la varianza de la distribución a posteriori para un modelo Beta-Binomial, con prior Beta(2, 5) y 10 experimentos con 6 caras?\nContrastá los resultados de los puntos anteriores usando la función mean y var de la distribución Beta de PreliZ.\nPreliZ tiene una función llamada maxent. Explicá que hace.\nConocimiento experto indica que un parámetro debe ser positivo y que el 90% puede estar entre 2 y 20. Usá maxent para definir ese prior.\nConocimiento experto indica que un parámetro debe ser positivo con media 6 y 90% puede estar entre 2 y 20. Usá maxent para definir ese prior.\nUsá la siguiente función para explorar diversas combinaciones de priors y likelihoods. Enunciá las conclusiones que consideres más relevantes.\n\n\ndef a_posteriori_grilla(grilla=10, a=1, b=1, caras=6, tiradas=9):\n    grid = np.linspace(0, 1, grilla)\n    prior = pz.Beta(a, b).pdf(grid)\n    likelihood = pz.Binomial(n=tiradas, p=grid).pdf(caras)\n    posterior = likelihood * prior\n    posterior /= posterior.sum()\n    _, ax = plt.subplots(1, 3, sharex=True, figsize=(16, 4))\n    ax[0].set_title('caras = {}\\ntiradas = {}'.format(caras, tiradas))\n    for i, (e, e_n) in enumerate(zip([prior, likelihood, posterior], ['a priori', 'likelihood', 'a posteriori'])):\n        ax[i].set_yticks([])\n        ax[i].plot(grid, e, 'o-', label=e_n)\n        ax[i].legend(fontsize=14)\n\n\ninteract(a_posteriori_grilla, grilla=ipyw.IntSlider(min=2, max=100, step=1, value=15), a=ipyw.FloatSlider(min=1, max=7, step=1, value=1), b=ipyw.FloatSlider(\n    min=1, max=7, step=1, value=1), caras=ipyw.IntSlider(min=0, max=20, step=1, value=6), tiradas=ipyw.IntSlider(min=0, max=20, step=1, value=9));",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inferencia Bayesiana</span>"
    ]
  },
  {
    "objectID": "02_Programación_probabilística.html",
    "href": "02_Programación_probabilística.html",
    "title": "2  Programación probabilista",
    "section": "",
    "text": "2.1 Introducción a PyMC\nPyMC es un paquete para programación probabilística bajo Python. PyMC es lo suficientemente madura para resolver muchos problemas estadísticos. PyMC permite crear modelos probabilísticos usando una sintaxis intuitiva y fácil de leer que es muy similar a la sintaxis usada para describir modelos probabilísticos.\nLa mayoría de las funciones de PyMC están escritas en Python. Mientras que las partes computacionalmente demandantes están escritas en NumPy y PyTensor. Pytensor es una biblioteca de Python que permite definir, optimizar y evaluar expresiones matemáticas que involucran matrices multidimensionales de manera eficiente. PyTensor es hija de Theano una librería de Python originalmente desarrollada para deep learning (que es a su vez la antecesora de TensorFlow, PyTorch, etc).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programación probabilista</span>"
    ]
  },
  {
    "objectID": "02_Programación_probabilística.html#introducción-a-pymc",
    "href": "02_Programación_probabilística.html#introducción-a-pymc",
    "title": "2  Programación probabilista",
    "section": "",
    "text": "2.1.1 El problema de la moneda, ahora usando PyMC y ArviZ\nA continuación revistaremos el problema de la moneda visto en el capítulo anterior, usando esta vez PyMC para definir nuestro modelo y hacer inferencia. Luego usaremos ArviZ para analizar el a posterori.\nA continuación generaremos datos sintéticos, en este caso asumiremos que conocemos el valor the \\(\\theta\\) y lo llamaremos theta_real, y luego intentaremos averiguar este valor como si no lo conociéramos. En un problema real theta_real sería desconocido y realizaríamos un proceso de inferencia precisamente para averiguar su valor.\n\nn_experimentos = 4\ntheta_real = 0.35  # en una situación real este valor es desconocido\ndatos = pz.Binomial(n=1, p=theta_real).rvs(size=n_experimentos, random_state=123)\ndatos\n\narray([1, 0, 0, 0])\n\n\n\n\n2.1.2 Creación del modelo\nAhora que tenemos nuestros datos es necesario especificar el modelo. Para ello usaremos una distribución beta (con parámetros \\(\\alpha=\\beta=1\\)) como a priori y la distribución de Bernoulli como likelihood. Usando la notación usual en estadística tenemos:\n\\[\\begin{align}\n\\theta &\\sim \\operatorname{Beta}(\\alpha=1, \\beta=1)\\\\\nY &\\sim \\operatorname{Bin}(n=1, p=\\theta)\n\\end{align}\\]\n\nCada uno de los elementos del array datos es un experimento de Bernoulli, es decir un experimento donde solo es posible obtener dos valores (0 o 1) si en cambio tuviera el número total de “caras” obtenidas en varios experimentos de Bernoulli podríamos modelar el likelihood como una distribución Binomial.\n\nEsto modelo se traduce casi literalmente a PyMC, veamos:\n\nwith pm.Model() as nuestro_primer_modelo:\n    θ = pm.Beta(\"θ\", alpha=1, beta=1)  # a priori\n    y = pm.Bernoulli(\"y\", p=θ, observed=datos)  # likelihood\n    # y = pm.Binomial('y',n=n_experimentos, p=θ, observed=sum(datos))\n\nEn la primer linea hemos creado un nuevo objeto llamado nuestro_primer_modelo. Este objeto contiene información sobre el modelo y las variables que lo conforman. PyMC usa el bloque with para indicar que todas las lineas que están dentro de él hacen referencia al mismo modelo (que en este caso se llama nuestro_primer_modelo).\nLa segunda linea de código, especifica el a priori, como pueden ver la sintaxis sigue de cerca a la notación matemática, la única diferencia es que el primer argumento es siempre una cadena que especifica el nombre de la variable aleatoria (el nombre es usado internamente por PyMC), este nombre siempre deberá coincidir con el nombre de la variable de Python a la que se le asigna. De no ser así el código correrá igual, pero puede conducir a errores y confusiones al analizar el modelo.\n\nEs importante recalcar que las variables de PyMC, como \\(\\theta\\), no son números sino objetos que representan distribuciones. Es decir objetos a partir de los cuales es posible calcular probabilidades y generar números aleatorios.\n\nEn la tercer linea de código se especifica el likelihood, que como verán es similar a la linea anterior con la diferencia que hemos agregado un argumento llamado observed al cual le asignamos nuestros datos. Esta es la forma de indicarle a PyMC cuales son los datos. Los datos pueden ser números, listas de Python, arrays de NumPy o data_frames de Pandas.\n\n\n2.1.3 Inferencia\nNuestro modelo ya está completamente especificado, lo único que nos resta hacer es obtener el a posteriori. En el capítulo anterior vimos como hacerlo de forma analítica, ahora lo haremos con métodos numéricos.\nEn PyMC la inferencia se realiza escribiendo las siguientes lineas:\n\nwith nuestro_primer_modelo:\n    idata = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [θ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n\n\n\n\n\n\n\n\n\n\n\nPrimero llamamos al objeto que definimos como nuestro modelo (nuestro_primer_modelo), indicando de esta forma que es sobre ese objeto que queremos realizar la inferencia. En la segunda linea le indicamos a PyMC que deseamos 1000 muestras. Esta linea luce inocente, pero internamente PyMC está haciendo muchas cosas por nosotros. Algunas de las cuales son detalladas en el mensaje que se imprime en pantalla.\nVeamos este mensaje:\n\nLa primer linea indica que PyMC ha asignado el método de muestreo NUTS, el cual es un muy buen método para variables continuas.\nLa segunda linea nos da información sobre cómo se inicializaron los valores de NUTS. Un detalle que por ahora no nos preocupa.\nLa tercer linea indica que PyMC correrá cuatro cadenas en paralelo, es decir generará cuatro muestras independientes del a posteriori. Esta cantidad puede ser diferente en sus computadoras ya que es determinada automáticamente en función de los procesadores disponibles (que en mi caso, 4). sample tiene un argumento chains que permite modificar este comportamiento.\nLa cuarta linea indica qué variable ha sido asignada a cual método de muestreo. En este caso la información es redundante, ya que tenemos una sola variable, pero esto no siempre es así. PyMC permite combinar métodos de muestreo, ya sea de forma automática basado en propiedades de las variables a muestrear o especificado por el usuario usando el argumento step.\nLa quinta linea es una barra de progreso con varias métricas sobre la velocidad del muestreo, que en este caso (y para referencia futura) es muy alta. También indica la cantidad de cadenas usadas y la cantidad de divergencias. Tener 0 divergencias es ideal, más adelante discutiremos la razón.\nPor último tenemos un detalle de la cantidad de muestras generadas, aunque pedimos 1000 obtuvimos 8000, la razón es que es son 1000 por cadena (4 cadenas en mi caso), es decir 4000. Todavía nos queda explicar 4000 muestras extras, estas se corresponden a 1000 por cadena y son muestras que PyMC utiliza para auto-tunear el método de muestreo. Estás muestras son luego descartadas automáticamente ya que no son muestras representativas del posterior. La cantidad de pasos que se usan para tunear el algoritmo de muestreo se puede cambiar con el argumento tune de la función pm.sample(.).\n\n\n\n2.1.4 Resumiendo el a posteriori\nPor lo general, la primer tarea a realizar luego de haber realizado un muestreo es evaluar como lucen los resultados. La función plot_forestplot de ArviZ es muy útil para esta tarea.\n\naz.plot_forest(idata, combined=True, figsize=(6, 2));\n\n\n\n\n\n\n\n\nEl punto indica la media, la linea gruesa el rango intercuartil y las lineas finas el HDI 94%\n\nEs importante notar que la variable y es una variable observada, es decir conocida. Mientras que en el gráfico anterior estamos dibujando solo \\(\\theta\\) que es la única variables desconocida, y por lo tanto muestreada.\n\nSi quisiéramos un resumen numérico de los resultados podemos usar:\n\naz.summary(idata, kind=\"stats\")\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nθ\n0.347\n0.18\n0.038\n0.668\n\n\n\n\n\n\n\n\nComo resultado obtenemos un DataFrame con los valores de la media, la desviación estándar y el intervalo HDI 94% (hdi_3 hdi_97).\nOtra forma de resumir visualmente el a posteriori es usar la función plot_posterior que viene con ArviZ, ya hemos utilizado esta distribución en el capítulo anterior para un falso a posteriori. Vamos a usarlo ahora con un posterior real. Por defecto, esta función muestra un histograma para variables discretas y KDEs para variables continuas. También obtenemos la media de la distribución (podemos preguntar por la mediana o moda usando el argumento point_estimate) y el 94% HDI como una línea negra en la parte inferior de la gráfica. Se pueden establecer diferentes valores de intervalo para el HDI con el argumento hdi_prob. Este tipo de gráfica fue presentado por John K. Kruschke en su gran libro “Doing Bayesian Data Analysis”.\n\naz.plot_posterior(idata);\n\n\n\n\n\n\n\n\n\n\n2.1.5 Accidentes mineros\nEste ejemplo está tomado del tutorial de PyMC.\nEl problema es el siguiente, tenemos un registro del número de accidentes en minas de carbón, ubicadas en el Reino Unido, que ocurrieron entre 1851 y 1962 (Jarrett, 1979). Se sospecha que la aplicación de ciertas regulaciones de seguridad tuvo como efecto una disminución en la cantidad de catástrofes. Por lo tanto nos interesa averiguar el año en que la tasa cambió y nos interesa estimar ambas tasas.\nLos datos son los siguientes, por un lado tenemos la variable accidentes que contiene la cantidad de accidentes por año y por el otro la variable años conteniendo el rango de años para los cuales tenemos datos. accidentes es una serie de Pandas que contiene el valor especial NAN, este es el valor por defecto en Pandas para lidiar con datos faltantes.\nBien, pero para que molestarse con datos faltantes si en general es más fácil eliminarlos. una de las razones es que esto puede conducir a pérdida de información cuando por cada observación tenemos más de una variable o cantidad de interés. Por ejemplo si tenemos 50 sujetos a los que les hemos medido la presión, la temperatura y el ritmo cardíaco, pero sucede que para 4 de ellos no contamos con el datos de la presión (porque alguien se olvidó de medirlo o registrarlo, o porque el tensiómetro se rompió, o por lo que sea). Podemos eliminar esos cuatro sujetos del análisis y perder por lo tanto información sobre la presión y ritmo cardíaco, o podemos usar todos los datos disponibles y además estimar los valores de temperatura faltantes. En el contexto de la estadística Bayesiana los datos faltantes se tratan como un parámetro desconocido del modelo que puede ser estimado.\n\naccidentes = pd.Series([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n                       3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n                       2, 2, 3, 4, 2, 1, 3, np.nan, 2, 1, 1, 1, 1, 3, 0, 0,\n                       1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n                       0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n                       3, 3, 1, np.nan, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n                       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\naños = np.arange(1851, 1962)\n\n\nplt.plot(años, accidentes, \".\")\nplt.ylabel(\"Número de accidentes\")\nplt.xlabel(\"Año\");\n\n\n\n\n\n\n\n\nPara modelar los accidentes usaremos una distribución de Poisson. Como creemos que la cantidad media de accidentes es distinta antes y después de la introducción de regulaciones de seguridad usaremos dos valores de tasas medias de accidentes (\\(t_0\\) y \\(t_1\\)). Además deberemos estimar un punto de corte (\\(pc\\)) que dividirá los años para los cuales se aplica la tasa de accidentes \\(t_0\\) de los cuales se aplica la tasa \\(t_1\\):\n\\[\\begin{equation}\nA_t \\sim Poisson(tasa)\n\\end{equation}\\]\n\\[\\begin{equation}\ntasa = \\begin{cases}\nt_0, \\text{si } t \\ge pc,\\\\\nt_1, \\text{si } t \\lt pc\n\\end{cases}\n\\end{equation}\\]\nLos a prioris que usaremos serán:\n\\[\\begin{align}\nt_0 \\sim Expon(1) \\\\\nt_1 \\sim Expon(1) \\\\\npc \\sim U(A_0, A_1)\n\\end{align}\\]\nDonde la distribución uniforme es discreta y \\(A_0\\) y \\(A_1\\) corresponden al primer y último año considerado en el análisis respectivamente.\nGráficamente el modelo es:\n\n\nUna peculiaridad de la implementación de este modelo en PyMC es el uso de la función pm.switch (linea 10). Esta es en realidad una función de PyMC y equivale a un if else de Python. Si el primer argumento es True entonces devuelve el segundo argumento caso contrario el tercer argumento. Como resultado tenemos que tasa es un vector de longitud igual a la de años y cuyos elementos corresponden a una repetición \\(t_0\\) seguida de una repetición \\(t_1\\), la cantidad exacta de repeticiones de \\(t_0\\) y \\(t_1\\) está controlada por la condición \\(pc \\ge\\) años. De esta forma, podemos al muestrear \\(pc\\), modificar que años reciben cual tasa para el cálculo del likelihood.\n\nwith pm.Model() as modelo_cat:\n\n    pc = pm.DiscreteUniform(\"pc\", lower=años.min(), upper=años.max())\n\n    # Priors para las tasas antes y después del cambio.\n    t_0 = pm.Exponential(\"t_0\", 1)\n    t_1 = pm.Exponential(\"t_1\", 1)\n\n    # Asignamos las tasas a los años de acuerdo a pc\n    tasa = pm.Deterministic(\"tasa\", pm.math.switch(pc &gt;= años, t_0, t_1))\n\n    acc = pm.Poisson(\"acc\", tasa, observed=accidentes)\n    idata_cat = pm.sample(1000, random_seed=1791, idata_kwargs={\"log_likelihood\": True})\n\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pymc/model/core.py:1342: RuntimeWarning: invalid value encountered in cast\n  data = convert_observed_data(data).astype(rv_var.dtype)\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pymc/model/core.py:1356: ImputationWarning: Data in acc contains missing values and will be automatically imputed from the sampling distribution.\n  warnings.warn(impute_message, ImputationWarning)\nMultiprocess sampling (4 chains in 4 jobs)\nCompoundStep\n&gt;CompoundStep\n&gt;&gt;Metropolis: [pc]\n&gt;&gt;Metropolis: [acc_unobserved]\n&gt;NUTS: [t_0, t_1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n\n\n\n\n\nidata_cat\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 7MB\nDimensions:               (chain: 4, draw: 1000, acc_dim_0: 111,\n                           acc_unobserved_dim_0: 2, tasa_dim_0: 111)\nCoordinates:\n  * chain                 (chain) int64 32B 0 1 2 3\n  * draw                  (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\n  * acc_dim_0             (acc_dim_0) int64 888B 0 1 2 3 4 ... 107 108 109 110\n  * acc_unobserved_dim_0  (acc_unobserved_dim_0) int64 16B 0 1\n  * tasa_dim_0            (tasa_dim_0) int64 888B 0 1 2 3 4 ... 107 108 109 110\nData variables:\n    acc                   (chain, draw, acc_dim_0) int64 4MB 4 5 4 0 ... 0 1 0 1\n    acc_unobserved        (chain, draw, acc_unobserved_dim_0) int64 64kB 0 ... 2\n    pc                    (chain, draw) int64 32kB 1887 1887 1889 ... 1891 1891\n    t_0                   (chain, draw) float64 32kB 3.626 3.154 ... 2.858 3.064\n    t_1                   (chain, draw) float64 32kB 0.863 1.119 ... 1.074\n    tasa                  (chain, draw, tasa_dim_0) float64 4MB 3.626 ... 1.074\nAttributes:\n    created_at:                 2024-07-22T16:57:03.210354+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1\n    sampling_time:              2.1572232246398926\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000acc_dim_0: 111acc_unobserved_dim_0: 2tasa_dim_0: 111Coordinates: (5)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])acc_dim_0(acc_dim_0)int640 1 2 3 4 5 ... 106 107 108 109 110array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110])acc_unobserved_dim_0(acc_unobserved_dim_0)int640 1array([0, 1])tasa_dim_0(tasa_dim_0)int640 1 2 3 4 5 ... 106 107 108 109 110array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110])Data variables: (6)acc(chain, draw, acc_dim_0)int644 5 4 0 1 4 3 4 ... 0 0 1 0 0 1 0 1array([[[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]],\n\n       [[4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        ...,\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1],\n        [4, 5, 4, ..., 1, 0, 1]]])acc_unobserved(chain, draw, acc_unobserved_dim_0)int640 2 0 2 0 2 0 2 ... 6 2 5 2 5 2 6 2array([[[0, 2],\n        [0, 2],\n        [0, 2],\n        ...,\n        [1, 1],\n        [1, 1],\n        [1, 1]],\n\n       [[0, 0],\n        [0, 0],\n        [0, 0],\n        ...,\n        [2, 0],\n        [2, 0],\n        [2, 0]],\n\n       [[1, 1],\n        [1, 1],\n        [1, 1],\n        ...,\n        [4, 3],\n        [4, 4],\n        [2, 4]],\n\n       [[0, 3],\n        [0, 3],\n        [1, 3],\n        ...,\n        [5, 2],\n        [5, 2],\n        [6, 2]]])pc(chain, draw)int641887 1887 1889 ... 1892 1891 1891array([[1887, 1887, 1889, ..., 1889, 1889, 1889],\n       [1887, 1887, 1886, ..., 1893, 1893, 1890],\n       [1889, 1890, 1890, ..., 1890, 1892, 1894],\n       [1889, 1889, 1889, ..., 1892, 1891, 1891]])t_0(chain, draw)float643.626 3.154 3.215 ... 2.858 3.064array([[3.62609622, 3.15358938, 3.21504831, ..., 3.24213146, 3.24458059,\n        3.32619297],\n       [3.41140371, 2.96600758, 2.93413869, ..., 3.40462424, 2.40233718,\n        3.25590635],\n       [2.92708336, 2.75116042, 3.6619095 , ..., 3.15104363, 2.85371574,\n        2.82202577],\n       [3.04951578, 3.00911206, 3.27150806, ..., 2.85126572, 2.85814187,\n        3.06443812]])t_1(chain, draw)float640.863 1.119 1.038 ... 0.8535 1.074array([[0.86299821, 1.11937507, 1.03820933, ..., 1.08729406, 0.73449746,\n        0.81363484],\n       [0.94353549, 1.10934818, 1.00952674, ..., 0.83546158, 0.91014974,\n        0.94228058],\n       [0.88137241, 0.83087074, 1.05354979, ..., 1.1700208 , 0.74372701,\n        1.0046596 ],\n       [0.99897101, 1.00757965, 0.93265556, ..., 1.02012749, 0.85350861,\n        1.07387497]])tasa(chain, draw, tasa_dim_0)float643.626 3.626 3.626 ... 1.074 1.074array([[[3.62609622, 3.62609622, 3.62609622, ..., 0.86299821,\n         0.86299821, 0.86299821],\n        [3.15358938, 3.15358938, 3.15358938, ..., 1.11937507,\n         1.11937507, 1.11937507],\n        [3.21504831, 3.21504831, 3.21504831, ..., 1.03820933,\n         1.03820933, 1.03820933],\n        ...,\n        [3.24213146, 3.24213146, 3.24213146, ..., 1.08729406,\n         1.08729406, 1.08729406],\n        [3.24458059, 3.24458059, 3.24458059, ..., 0.73449746,\n         0.73449746, 0.73449746],\n        [3.32619297, 3.32619297, 3.32619297, ..., 0.81363484,\n         0.81363484, 0.81363484]],\n\n       [[3.41140371, 3.41140371, 3.41140371, ..., 0.94353549,\n         0.94353549, 0.94353549],\n        [2.96600758, 2.96600758, 2.96600758, ..., 1.10934818,\n         1.10934818, 1.10934818],\n        [2.93413869, 2.93413869, 2.93413869, ..., 1.00952674,\n         1.00952674, 1.00952674],\n...\n        [3.15104363, 3.15104363, 3.15104363, ..., 1.1700208 ,\n         1.1700208 , 1.1700208 ],\n        [2.85371574, 2.85371574, 2.85371574, ..., 0.74372701,\n         0.74372701, 0.74372701],\n        [2.82202577, 2.82202577, 2.82202577, ..., 1.0046596 ,\n         1.0046596 , 1.0046596 ]],\n\n       [[3.04951578, 3.04951578, 3.04951578, ..., 0.99897101,\n         0.99897101, 0.99897101],\n        [3.00911206, 3.00911206, 3.00911206, ..., 1.00757965,\n         1.00757965, 1.00757965],\n        [3.27150806, 3.27150806, 3.27150806, ..., 0.93265556,\n         0.93265556, 0.93265556],\n        ...,\n        [2.85126572, 2.85126572, 2.85126572, ..., 1.02012749,\n         1.02012749, 1.02012749],\n        [2.85814187, 2.85814187, 2.85814187, ..., 0.85350861,\n         0.85350861, 0.85350861],\n        [3.06443812, 3.06443812, 3.06443812, ..., 1.07387497,\n         1.07387497, 1.07387497]]])Indexes: (5)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))acc_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n      dtype='int64', name='acc_dim_0', length=111))acc_unobserved_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='acc_unobserved_dim_0'))tasa_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n      dtype='int64', name='tasa_dim_0', length=111))Attributes: (6)created_at :2024-07-22T16:57:03.210354+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :2.1572232246398926tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  log_likelihood\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3MB\nDimensions:             (chain: 4, draw: 1000, acc_observed_dim_0: 109)\nCoordinates:\n  * chain               (chain) int64 32B 0 1 2 3\n  * draw                (draw) int64 8kB 0 1 2 3 4 5 ... 994 995 996 997 998 999\n  * acc_observed_dim_0  (acc_observed_dim_0) int64 872B 0 1 2 3 ... 106 107 108\nData variables:\n    acc_observed        (chain, draw, acc_observed_dim_0) float64 3MB -1.652 ...\nAttributes:\n    created_at:                 2024-07-22T16:57:03.376720+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:chain: 4draw: 1000acc_observed_dim_0: 109Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])acc_observed_dim_0(acc_observed_dim_0)int640 1 2 3 4 5 ... 104 105 106 107 108array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108])Data variables: (1)acc_observed(chain, draw, acc_observed_dim_0)float64-1.652 -1.973 ... -1.074 -1.003array([[[-1.65152346, -1.97280472, -1.65152346, ..., -1.01034087,\n         -0.86299821, -1.01034087],\n        [-1.73747805, -2.19837467, -1.73747805, ..., -1.00660451,\n         -1.11937507, -1.00660451],\n        [-1.7217326 , -2.16332813, -1.7217326 , ..., -1.0007119 ,\n         -1.03820933, -1.0007119 ],\n        ...,\n        [-1.7152614 , -2.14846834, -1.7152614 , ..., -1.00360196,\n         -1.08729406, -1.00360196],\n        [-1.71469005, -2.14714186, -1.71469005, ..., -1.0430662 ,\n         -0.73449746, -1.0430662 ],\n        [-1.69693321, -2.10454272, -1.69693321, ..., -1.01987845,\n         -0.81363484, -1.01987845]],\n\n       [[-1.68096213, -2.0632762 , -1.68096213, ..., -1.00165679,\n         -0.94353549, -1.00165679],\n        [-1.79519421, -2.31741533, -1.79519421, ..., -1.00557556,\n         -1.10934818, -1.00557556],\n        [-1.80653673, -2.33956069, -1.80653673, ..., -1.00004509,\n         -1.00952674, -1.00004509],\n...\n        [-1.73816262, -2.19986683, -1.73816262, ..., -1.01299927,\n         -1.1700208 , -1.01299927],\n        [-1.83728192, -2.39809791, -1.83728192, ..., -1.03980824,\n         -0.74372701, -1.03980824],\n        [-1.85025966, -2.42224259, -1.85025966, ..., -1.00001082,\n         -1.0046596 , -1.00001082]],\n\n       [[-1.76763834, -2.26209344, -1.76763834, ..., -1.00000053,\n         -0.99897101, -1.00000053],\n        [-1.78058574, -2.28837861, -1.78058574, ..., -1.00002858,\n         -1.00757965, -1.00002858],\n        [-1.70855765, -2.13274451, -1.70855765, ..., -1.00237488,\n         -0.93265556, -1.00237488],\n        ...,\n        [-1.83826752, -2.39994242, -1.83826752, ..., -1.00019988,\n         -1.02012749, -1.00019988],\n        [-1.83550883, -2.39477502, -1.83550883, ..., -1.01190826,\n         -0.85350861, -1.01190826],\n        [-1.76303503, -2.25260871, -1.76303503, ..., -1.0026014 ,\n         -1.07387497, -1.0026014 ]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))acc_observed_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n        99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n      dtype='int64', name='acc_observed_dim_0', length=109))Attributes: (4)created_at :2024-07-22T16:57:03.376720+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 688kB\nDimensions:                (chain: 4, draw: 1000, accept_dim_0: 2,\n                            accepted_dim_0: 2, scaling_dim_0: 2)\nCoordinates:\n  * chain                  (chain) int64 32B 0 1 2 3\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\n  * accept_dim_0           (accept_dim_0) int64 16B 0 1\n  * accepted_dim_0         (accepted_dim_0) int64 16B 0 1\n  * scaling_dim_0          (scaling_dim_0) int64 16B 0 1\nData variables: (12/20)\n    accept                 (chain, draw, accept_dim_0) float64 64kB 1.0 ... 0...\n    acceptance_rate        (chain, draw) float64 32kB 0.9228 0.7767 ... 0.7077\n    accepted               (chain, draw, accepted_dim_0) float64 64kB 1.0 ......\n    diverging              (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 178.4 179.6 ... 180.3\n    energy_error           (chain, draw) float64 32kB 0.2636 ... -0.09946\n    ...                     ...\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    scaling                (chain, draw, scaling_dim_0) float64 64kB 3.221 .....\n    smallest_eigval        (chain, draw) float64 32kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 32kB 1.724 1.724 ... 0.9887\n    step_size_bar          (chain, draw) float64 32kB 1.139 1.139 ... 1.071\n    tree_depth             (chain, draw) int64 32kB 2 2 2 2 2 2 ... 2 2 2 1 2 2\nAttributes:\n    created_at:                 2024-07-22T16:57:03.221674+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1\n    sampling_time:              2.1572232246398926\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000accept_dim_0: 2accepted_dim_0: 2scaling_dim_0: 2Coordinates: (5)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])accept_dim_0(accept_dim_0)int640 1array([0, 1])accepted_dim_0(accepted_dim_0)int640 1array([0, 1])scaling_dim_0(scaling_dim_0)int640 1array([0, 1])Data variables: (20)accept(chain, draw, accept_dim_0)float641.0 1.0 1.0 ... 0.002307 0.2685array([[[1.00000000e+00, 1.00000000e+00],\n        [1.00000000e+00, 5.00000000e-01],\n        [1.07751160e+00, 5.00000000e-01],\n        ...,\n        [4.31940201e+00, 1.57423770e+00],\n        [3.05222576e-02, 5.00000000e-01],\n        [6.62027311e-02, 8.25523913e-03]],\n\n       [[9.59371929e-01, 0.00000000e+00],\n        [2.18259579e-04, 5.00000000e-01],\n        [8.95629042e-01, 6.13768590e-01],\n        ...,\n        [3.73227808e-01, 5.87822822e-01],\n        [7.08670033e-05, 5.00000000e-01],\n        [1.81159812e+00, 1.58759339e-02]],\n\n       [[2.30664222e+00, 4.06596957e-01],\n        [4.29372932e-01, 5.00000000e-01],\n        [1.83665422e-01, 5.57528849e-01],\n        ...,\n        [8.69336169e-02, 6.31549643e-01],\n        [3.71610466e-01, 6.46252600e-01],\n        [2.16412024e-01, 1.23676643e+00]],\n\n       [[9.18342500e-02, 3.33979313e-02],\n        [9.86860930e-03, 1.24871376e-01],\n        [5.31408122e-02, 1.00378983e+00],\n        ...,\n        [1.00000000e+00, 1.19264887e+00],\n        [2.23290367e+00, 1.70828896e-01],\n        [2.30698471e-03, 2.68531695e-01]]])acceptance_rate(chain, draw)float640.9228 0.7767 1.0 ... 1.0 0.7077array([[0.92277106, 0.7767203 , 1.        , ..., 0.8067856 , 0.72162054,\n        1.        ],\n       [1.        , 0.63276109, 1.        , ..., 0.81565131, 0.89756198,\n        0.7975073 ],\n       [1.        , 0.75852799, 0.85536921, ..., 0.85247546, 0.90929773,\n        0.91014643],\n       [1.        , 0.99101851, 0.41467517, ..., 0.86763111, 1.        ,\n        0.70774038]])accepted(chain, draw, accepted_dim_0)float641.0 1.0 1.0 0.5 ... 1.0 0.0 0.0 0.5array([[[1. , 1. ],\n        [1. , 0.5],\n        [1. , 0.5],\n        ...,\n        [1. , 1. ],\n        [0. , 0.5],\n        [0. , 0. ]],\n\n       [[1. , 0. ],\n        [0. , 0.5],\n        [1. , 0.5],\n        ...,\n        [1. , 0.5],\n        [0. , 0.5],\n        [1. , 0. ]],\n\n       [[1. , 0.5],\n        [1. , 0.5],\n        [0. , 0.5],\n        ...,\n        [0. , 1. ],\n        [1. , 1. ],\n        [1. , 1. ]],\n\n       [[0. , 0. ],\n        [0. , 0. ],\n        [0. , 1. ],\n        ...,\n        [1. , 0.5],\n        [1. , 0. ],\n        [0. , 0.5]]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float64178.4 179.6 177.1 ... 178.3 180.3array([[178.41143846, 179.59173694, 177.1351425 , ..., 176.89630037,\n        177.99667758, 177.18561892],\n       [176.84600092, 177.85074117, 176.9666878 , ..., 179.68836893,\n        180.14059585, 179.50668463],\n       [176.02268341, 177.38329427, 179.55032141, ..., 183.02157913,\n        182.60418822, 183.40238698],\n       [177.54752547, 177.45355953, 179.93278057, ..., 178.77479853,\n        178.2828962 , 180.28435945]])energy_error(chain, draw)float640.2636 -0.1333 ... -0.09946array([[ 0.26355783, -0.13330973, -0.26240448, ...,  0.24313167,\n         0.28330909, -0.24217744],\n       [-0.4273274 ,  0.32701495, -0.33620175, ...,  0.19996137,\n         0.36717857, -1.20664615],\n       [-0.20394846,  0.27637557,  0.44286054, ..., -0.26506457,\n         0.31760094, -0.77510954],\n       [-0.05506083,  0.02731414,  0.17298595, ...,  0.14198864,\n        -0.01235158, -0.09945761]])index_in_trajectory(chain, draw)int641 2 1 -1 2 1 -3 ... -3 2 0 -1 -1 2array([[ 1,  2,  1, ...,  2, -2, -1],\n       [-1, -3, -1, ...,  3,  2,  3],\n       [-1, -1, -2, ..., -2,  2,  3],\n       [-2,  1, -2, ..., -1, -1,  2]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-178.1 -177.4 ... -177.8 -178.5array([[-178.06471821, -177.36341404, -176.54725471, ..., -176.33919673,\n        -177.26311194, -176.26608141],\n       [-176.03730645, -177.00447731, -176.41281426, ..., -178.84693934,\n        -179.92107947, -176.03922263],\n       [-175.65859291, -177.35642617, -179.07588836, ..., -179.48487457,\n        -182.41992202, -181.79561482],\n       [-177.33561688, -177.40972276, -177.47033385, ..., -178.71915246,\n        -177.82876556, -178.52296286]])max_energy_error(chain, draw)float640.2636 0.5106 ... -0.07446 0.6935array([[ 0.26355783,  0.51057924, -0.38363035, ...,  0.36462813,\n         0.43043964, -0.24217744],\n       [-0.4273274 ,  0.70045505, -0.33620175, ...,  0.42551817,\n         0.36717857, -1.20664615],\n       [-0.20394846,  0.27637557,  0.44286054, ...,  0.56588886,\n        -0.60278095, -0.77510954],\n       [-0.08579607, -0.02907607,  2.02675312, ...,  0.14198864,\n        -0.07445566,  0.69349068]])n_steps(chain, draw)float643.0 3.0 3.0 3.0 ... 3.0 1.0 3.0 3.0array([[3., 3., 3., ..., 3., 3., 1.],\n       [1., 3., 1., ..., 3., 3., 3.],\n       [1., 1., 3., ..., 3., 3., 3.],\n       [3., 3., 3., ..., 1., 3., 3.]])perf_counter_diff(chain, draw)float640.0006533 0.0006227 ... 0.0003438array([[0.00065333, 0.00062266, 0.00061065, ..., 0.00038398, 0.00054344,\n        0.00020115],\n       [0.00024091, 0.00060407, 0.00024154, ..., 0.00072214, 0.00044918,\n        0.00047457],\n       [0.00041829, 0.00035076, 0.00040825, ..., 0.00036863, 0.00039605,\n        0.00038362],\n       [0.000577  , 0.00061123, 0.00058611, ..., 0.00017694, 0.00033391,\n        0.00034377]])perf_counter_start(chain, draw)float641.408e+03 1.408e+03 ... 1.409e+03array([[1407.93183186, 1407.93302818, 1407.93417483, ..., 1408.76806132,\n        1408.76879642, 1408.76969854],\n       [1407.81418664, 1407.81679154, 1407.81781985, ..., 1408.66162411,\n        1408.66308901, 1408.66392757],\n       [1407.92080993, 1407.9218606 , 1407.92261022, ..., 1408.73110886,\n        1408.7318262 , 1408.73256638],\n       [1407.88907368, 1407.89021411, 1407.89137256, ..., 1408.82789621,\n        1408.82838251, 1408.82904646]])process_time_diff(chain, draw)float640.0006535 0.0006232 ... 0.0003439array([[0.00065354, 0.00062324, 0.00061078, ..., 0.00038425, 0.00054381,\n        0.0002012 ],\n       [0.00024099, 0.00060454, 0.0002417 , ..., 0.00072257, 0.00044922,\n        0.00047477],\n       [0.00041827, 0.00035093, 0.00040842, ..., 0.0003688 , 0.00039615,\n        0.00038375],\n       [0.00057726, 0.00061175, 0.00058643, ..., 0.00017693, 0.00033399,\n        0.0003439 ]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])scaling(chain, draw, scaling_dim_0)float643.221 2.35 3.221 ... 3.221 2.536array([[[3.22102   , 2.3498805 ],\n        [3.22102   , 2.3498805 ],\n        [3.22102   , 2.3498805 ],\n        ...,\n        [3.22102   , 2.3498805 ],\n        [3.22102   , 2.3498805 ],\n        [3.22102   , 2.3498805 ]],\n\n       [[3.22102   , 2.6573415 ],\n        [3.22102   , 2.6573415 ],\n        [3.22102   , 2.6573415 ],\n        ...,\n        [3.22102   , 2.6573415 ],\n        [3.22102   , 2.6573415 ],\n        [3.22102   , 2.6573415 ]],\n\n       [[2.9282    , 2.53589441],\n        [2.9282    , 2.53589441],\n        [2.9282    , 2.53589441],\n        ...,\n        [2.9282    , 2.53589441],\n        [2.9282    , 2.53589441],\n        [2.9282    , 2.53589441]],\n\n       [[3.22102   , 2.53589441],\n        [3.22102   , 2.53589441],\n        [3.22102   , 2.53589441],\n        ...,\n        [3.22102   , 2.53589441],\n        [3.22102   , 2.53589441],\n        [3.22102   , 2.53589441]]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float641.724 1.724 1.724 ... 0.9887 0.9887array([[1.72357069, 1.72357069, 1.72357069, ..., 1.72357069, 1.72357069,\n        1.72357069],\n       [1.2359314 , 1.2359314 , 1.2359314 , ..., 1.2359314 , 1.2359314 ,\n        1.2359314 ],\n       [1.3423228 , 1.3423228 , 1.3423228 , ..., 1.3423228 , 1.3423228 ,\n        1.3423228 ],\n       [0.98866571, 0.98866571, 0.98866571, ..., 0.98866571, 0.98866571,\n        0.98866571]])step_size_bar(chain, draw)float641.139 1.139 1.139 ... 1.071 1.071array([[1.13858127, 1.13858127, 1.13858127, ..., 1.13858127, 1.13858127,\n        1.13858127],\n       [1.15412385, 1.15412385, 1.15412385, ..., 1.15412385, 1.15412385,\n        1.15412385],\n       [1.13254671, 1.13254671, 1.13254671, ..., 1.13254671, 1.13254671,\n        1.13254671],\n       [1.07082605, 1.07082605, 1.07082605, ..., 1.07082605, 1.07082605,\n        1.07082605]])tree_depth(chain, draw)int642 2 2 2 2 2 2 2 ... 2 2 2 2 2 1 2 2array([[2, 2, 2, ..., 2, 2, 1],\n       [1, 2, 1, ..., 2, 2, 2],\n       [1, 1, 2, ..., 2, 2, 2],\n       [2, 2, 2, ..., 1, 2, 2]])Indexes: (5)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))accept_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='accept_dim_0'))accepted_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='accepted_dim_0'))scaling_dim_0PandasIndexPandasIndex(Index([0, 1], dtype='int64', name='scaling_dim_0'))Attributes: (6)created_at :2024-07-22T16:57:03.221674+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :2.1572232246398926tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 2kB\nDimensions:             (acc_observed_dim_0: 109)\nCoordinates:\n  * acc_observed_dim_0  (acc_observed_dim_0) int64 872B 0 1 2 3 ... 106 107 108\nData variables:\n    acc_observed        (acc_observed_dim_0) int64 872B 4 5 4 0 1 ... 0 0 1 0 1\nAttributes:\n    created_at:                 2024-07-22T16:57:03.225029+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:acc_observed_dim_0: 109Coordinates: (1)acc_observed_dim_0(acc_observed_dim_0)int640 1 2 3 4 5 ... 104 105 106 107 108array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n        42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n        98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108])Data variables: (1)acc_observed(acc_observed_dim_0)int644 5 4 0 1 4 3 4 ... 0 0 1 0 0 1 0 1array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3,\n       1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 1, 1, 1, 1,\n       3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0,\n       1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 2, 1, 1, 1, 1, 2,\n       4, 2, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])Indexes: (1)acc_observed_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n        99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n      dtype='int64', name='acc_observed_dim_0', length=109))Attributes: (4)created_at :2024-07-22T16:57:03.225029+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\nax = az.plot_posterior(idata_cat, var_names=[\"~tasa\", \"~acc\"], figsize=(12, 6));\n\n\n\n\n\n\n\n\n\naz.summary(idata_cat, var_names=[\"~tasa\", \"~acc\"])\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nacc_unobserved[0]\n2.074\n1.799\n0.000\n5.000\n0.098\n0.069\n322.0\n472.0\n1.02\n\n\nacc_unobserved[1]\n0.986\n1.028\n0.000\n3.000\n0.041\n0.029\n662.0\n883.0\n1.01\n\n\npc\n1889.783\n2.406\n1886.000\n1894.000\n0.159\n0.113\n218.0\n493.0\n1.04\n\n\nt_0\n3.088\n0.283\n2.552\n3.606\n0.006\n0.004\n2261.0\n2316.0\n1.00\n\n\nt_1\n0.929\n0.116\n0.712\n1.149\n0.002\n0.002\n2801.0\n2797.0\n1.00\n\n\n\n\n\n\n\n\n\ntasa_mean = idata_cat.posterior[\"tasa\"].mean((\"chain\", \"draw\"))\ntasa_hdi = az.hdi(idata_cat.posterior[\"tasa\"].values)\npc_hdi = az.hdi(idata_cat.posterior[\"pc\"])[\"pc\"]\n\n_, ax = plt.subplots(figsize=(10, 5), sharey=True)\nax.plot(años, accidentes, \".\")\n\nax.set_ylabel(\"Número de accidentes\")\nax.set_xlabel(\"Año\")\n\nax.vlines(\n    idata_cat.posterior[\"pc\"].mean((\"chain\", \"draw\")),\n    accidentes.min(),\n    accidentes.max(),\n    color=\"C1\",\n    lw=2,\n)\n\n\nax.fill_betweenx(\n    [accidentes.min(), accidentes.max()], pc_hdi[0], pc_hdi[1], alpha=0.3, color=\"C1\"\n)\nax.plot(años, tasa_mean, \"k\", lw=2)\nax.fill_between(años, tasa_hdi[:, 0], tasa_hdi[:, 1], alpha=0.3, color=\"k\")\n\n\nfaltante0 = (\n    idata_cat.posterior[\"acc_unobserved\"].sel(acc_unobserved_dim_0=0).mean((\"chain\", \"draw\"))\n)\nfaltante1 = (\n    idata_cat.posterior[\"acc_unobserved\"].sel(acc_unobserved_dim_0=1).mean((\"chain\", \"draw\"))\n)\n\nax.plot(años[np.isnan(accidentes)], [faltante0, faltante1], \"C2s\");",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programación probabilista</span>"
    ]
  },
  {
    "objectID": "02_Programación_probabilística.html#comparando-grupos",
    "href": "02_Programación_probabilística.html#comparando-grupos",
    "title": "2  Programación probabilista",
    "section": "2.2 Comparando grupos",
    "text": "2.2 Comparando grupos\nUna tarea común al analizar datos es comparar grupos. Podríamos estar interesados en analizar los resultados de un ensayo clínico donde se busca medir la efectividad de una droga, o la reducción de la cantidad de accidentes de tránsito al introducir un cambio en las regulaciones de tránsito, o el desempeño de estudiantes bajo diferentes aproximaciones pedagógicas, etc. Este tipo de preguntas se suele resolver en el marco de lo que se conoce como pruebas de hipótesis que busca declarar si una observación es estadísticamente significativa o no. Nosotros tomaremos una ruta alternativa.\nAl comparar grupos debemos decidir que característica(s) vamos a usar. Una característica común es la media de cada grupo. En ese caso podemos calcular la distribución a posteriori de la diferencia entre medias. Para ayudarnos a entender este posterior usaremos 3 herramientas:\n\nUn posteriorplot con un valor de referencia\nUna medida llamada d de Cohen\nLa probabilidad de superioridad\n\nEn el capítulo anterior ya vimos un ejemplo de cómo usar posteriorplot con un valor de referencia, pronto veremos otro ejemplo. Las novedades aquí son el d de Cohen y la probabilidad de superioridad, dos maneras populares de expresar el tamaño del efecto.\n\n2.2.1 d de Cohen\nUna medida muy común, al menos en ciertas disciplinas, para cuantificar el tamaño del efecto es el d de Cohen\n\\[\n\\frac{\\mu_2 - \\mu_1}{\\sqrt{\\frac{\\sigma_2^2 + \\sigma_1^2}{2}}}\n\\]\nDe acuerdo con esta expresión, el tamaño del efecto es la diferencia de las medias con respecto a la desviación estándar combinada de ambos grupos. Ya que es posible obtener una distribución a posteriori de medias y de desviaciones estándar, también es posible calcular una distribución a posteriori de los valores d de Cohen. Por supuesto, si sólo necesitamos o queremos una estimación puntual, podríamos calcular la media de esa distribución a posteriori. En general, al calcular una desviación estándar combinada, se toma en cuenta el tamaño de la muestra de cada grupo explícitamente, pero la ecuación de d de Cohen omite el tamaño de la muestra, la razón es que tomamos estos valores del posterior (por lo que ya estamos considerando la incertidumbre de las desviaciones estándar).\n\nUn d de Cohen es una forma de medir el tamaño del efecto donde la diferencia de las medias se estandariza al considerar las desviaciones estándar de ambos grupos.\n\nCohen introduce la variabilidad de cada grupo al usar sus desviaciones estándar. Esto es realmente importante, una diferencia de 1 cuando la desviación estándar es de 0.1 es muy grande en comparación con la misma diferencia cuando la desviación estándar es 10. Además, un cambio de x unidades de un grupo respecto del otro podría explicarse por cada punto desplazándose exactamente x unidades o la mitad de los puntos sin cambiar mientras la otra mitad cambia 2x unidades, y así con otras combinaciones. Por lo tanto, incluir las variaciones intrínsecas de los grupos es una forma de poner las diferencias en contexto. Re-escalar (estandarizar) las diferencias nos ayuda a dar sentido a la diferencia entre grupos y facilita evaluar si el cambio es importante, incluso cuando no estamos muy familiarizados con la escala utilizada para las mediciones.\nUn d de Cohen se puede interpretar como un Z-score. Un Z-score es la cantidad de desviaciones estándar que un valor difiere del valor medio de lo que se está observando o midiendo, puede ser positivo o negativo dependiendo de si la diferencia es por exceso o por defecto. Por lo tanto, un d de Cohen de -1.2, indica que la media de un grupo está 1.2 desviación estándar por debajo de la media del otro grupo.\nIncluso con las diferencias de medias estandarizadas, puede ser necesario tener que calibrarnos en función del contexto de un problema determinado para poder decir si un valor de d de Cohen es grande, pequeño, mediano, importante, despreciable, etc. Afortunadamente, esta calibración se puede adquirir con la práctica, a modo de ejemplo si estamos acostumbrados a realizar varios análisis para más o menos el mismo tipo de problemas, podemos acostumbrarnos a un d de Cohen de entre 0.8 y 1.2, de modo que si obtenemos un valor de 2 podría ser que estamos frente a algo importante, inusual (¡o un error!). Una alternativa es consultar con expertos en el tema.\nUna muy buena página web para explorar cómo se ven los diferentes valores de Cohen’s es http://rpsychologist.com/d3/cohend. En esa página, también encontrarán otras formas de expresar el tamaño del efecto; algunas de ellos podrían ser más intuitivas, como la probabilidad de superioridad que analizaremos a continuación.\n\n\n2.2.2 Probabilidad de superioridad\nEsta es otra forma de informar el tamaño del efecto y se define como la probabilidad que un dato tomado al azar de un grupo tenga un valor mayor que un punto tomado al azar del otro grupo. Si suponemos que los datos que estamos utilizando se distribuyen de forma Gaussiana, podemos calcular la probabilidad de superioridad a partir de la d de Cohen usando la expresión:\n\\[\\begin{equation} \\label{eq_ps}\nps = \\Phi \\left ( \\frac{\\delta}{\\sqrt{2}} \\right)\n\\end{equation}\\]\nDonde \\(\\Phi\\) es la distribución normal acumulada y \\(\\delta\\) es el d de Cohen. Podemos calcular una estimación puntual de la probabilidad de superioridad (lo que generalmente se informa) o podemos calcular la distribución a posteriori. Si no estamos de acuerdo con la suposición de normalidad, podemos descartar esta fórmula y calcularla directamente a partir del posterior sin necesidad de asumir ninguna distribución. Esta es una de las ventajas de usar métodos de muestreo para estimar el a posteriori, una vez obtenidas las muestras lo que podemos hacer con ellas es muy flexible.\n\n\n2.2.3 El conjunto de datos propinas\nPara explorar el tema de esta sección, vamos a usar el conjunto de datos tips (propinas). Estos datos fueron informados por primera vez por Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics.\nQueremos estudiar el efecto del día de la semana sobre la cantidad de propinas en un restaurante. Para este ejemplo, los diferentes grupos son los días. Comencemos el análisis cargando el conjunto de datos como un DataFrame de Pandas usando solo una línea de código. Si no está familiarizado con Pandas, el comando tail se usa para mostrar las últimas filas de un DataFrame:\n\ntips = pd.read_csv(\"datos/propinas.csv\")\ntips.tail()\n\n\n\n\n\n\n\n\n\ntotal_cuenta\npropina\ngenero\nfumador\ndia\ntiempo\ncantidad\n\n\n\n\n239\n29.03\n5.92\nHombre\nNo\nSab\nCena\n3\n\n\n240\n27.18\n2.00\nMujer\nSi\nSab\nCena\n2\n\n\n241\n22.67\n2.00\nHombre\nSi\nSab\nCena\n2\n\n\n242\n17.82\n1.75\nHombre\nNo\nSab\nCena\n2\n\n\n243\n18.78\n3.00\nMujer\nNo\nJue\nCena\n2\n\n\n\n\n\n\n\n\nPara este ejemplo solo vamos a usar las columnas dia y propina y vamos a usar la función plot_forest de ArviZ. Aún cuando ArviZ está pensado para análisis de modelos Bayesianos algunos de sus funciones pueden ser útiles para analizar datos.\n\naz.plot_forest(\n    tips.pivot(columns=\"dia\", values=\"propina\").to_dict(\"list\"),\n    kind=\"ridgeplot\",\n    hdi_prob=1,\n    figsize=(12, 4),\n);\n\n\n\n\n\n\n\n\nA fin de simplificar el análisis vamos a crear 2 variables: * La variable categories contiene los nombres de los días (abreviados) * La variable idx codifica los días de la semana como enteros entre 0 y 3.\n\ncategories = np.array([\"Jue\", \"Vie\", \"Sab\", \"Dom\"])\n\ntip = tips[\"propina\"].values\nidx = pd.Categorical(tips[\"dia\"], categories=categories).codes\n\nEl modelo para este problema es basicamente igual a model_g, con la diferencia que \\(\\mu\\) y \\(\\sigma\\) ahora serán vectores en vez de escalares. La sintáxis de PyMC es super-útil para estos caso, en vez de usar for loops escribimos el modelo de forma vectorizada, para ello especificamos el argumento shape para los priors \\(\\mu\\) y \\(\\sigma\\) y para el likelihood usamos la variable idx para indexar de forma adecuada \\(\\mu\\) y \\(\\sigma\\) para asegurar que usamos los parámetros correctos para cada grupo. En este ejemplo un \\(\\mu\\) para jueves, otra para viernes, otra para sábado y una cuarta para domingo, y lo mismo para \\(\\sigma\\).\n    with pm.Model() as comparing_groups:\n        μ = pm.Normal('μ', mu=0, sigma=10, shape=4)\n        σ = pm.HalfNormal('σ', sigma=10, shape=4)\n\n        y = pm.Normal('y', mu=μ[idx], sigma=σ[idx], observed=tip)\nPyMC provee una sintaxis alternativa, la cual consisten en especificar coordenadas y dimensiones. La ventaja de esta alternativa es que permite una mejor integración con ArviZ.\nVeamos, en este ejemplo tenemos 4 valores para las medias y 4 para las desviaciones estándar, y por eso usamos shape=4. El InferenceData tendrá 4 indices 0, 1, 2, 3 correspondientes a cada uno de los 4 días. Pero es trabajo del usuario asociar esos indices numéricos con los días.\nAl usar coordenadas y dimensiones nosotros podremos usar los rótulos 'Jue', 'Vie', 'Sab', 'Dom' para referirnos a los parámetros relacionados con cada uno de estos días. ArviZ también podrá hacer uso de estos rótulos. Vamos a especificar dos coordenadas dias con las dimensiones 'Jue', 'Vie', 'Sab', 'Dom' y dias_flat que contendrá los mismo rótulos pero repetidos según el orden y longitud que corresponda con cada observación. Esto último será útil para poder obtener pruebas predictivas a posteriori para cada día.\n\ncoords = {\"dias\": categories, \"dias_flat\": categories[idx]}\n\nwith pm.Model(coords=coords) as comparing_groups:\n    μ = pm.HalfNormal(\"μ\", sigma=5, dims=\"dias\")\n    σ = pm.HalfNormal(\"σ\", sigma=1, dims=\"dias\")\n\n    y = pm.Gamma(\"y\", mu=μ[idx], sigma=σ[idx], observed=tip, dims=\"dias_flat\")\n\n    idata_cg = pm.sample()\n    idata_cg.extend(pm.sample_posterior_predictive(idata_cg))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nSampling: [y]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUna vez obtenido un a posteriori podemos hacer todos los análisis que creamos pertinentes con el. Primero hagamos una prueba predictiva a posteriori. Vemos que en general somos capaces de capturar la forma general de las distribuciones, pero hay detalles que se nos escapan. Esto puede deberse al tamaño relativamente pequeño de la muestra, a que hay otros factores además del día que tienen influencia en las propinas o una combinación de ambas. Por ahora seguiremos con el análisis considerando que el modelo es lo suficientemente bueno\n\n_, axes = plt.subplots(2, 2)\naz.plot_ppc(\n    idata_cg,\n    num_pp_samples=100,\n    coords={\"dias_flat\": [categories]},\n    flatten=[],\n    ax=axes,\n);\n\n\n\n\n\n\n\n\nPodemos ver la distribución de cada uno de los parámetros haciendo\n\naz.plot_posterior(idata_cg, var_names=\"μ\", figsize=(12, 3));\n\n\n\n\n\n\n\n\nLa figura anterior es bastante informativa, por ejemplo vemos que los valores medios de las propinas difieren en solo unos pocos centavos y que para los domingos el valor es ligeramente más alto que para el resto de los días analizados.\nPero quizá consideramos que puede ser mejor mostrar los datos de otra forma. Por ejemplo podemos calcular todas las diferencias de medias a posteriori entre si. Además podríamos querer usar alguna medida del tamaño del efecto que sea popular entre nuestra audiencia, como podrían ser la probabilidad de superioridad o d de Cohen.\nCohen’s d\n\\[\n\\frac{\\mu_2 - \\mu_1}{\\sqrt{\\frac{\\sigma_1^2 + \\sigma_2^2}{2}}}\n\\]\n\nSe puede interpretar como un z-score. Cuántas desviaciones estándar una media de un grupo está por encima (o por debajo) de la media del otro grupo\nEjemplo interactivo\n\nProbabilidad de superioridad\n\nLa probabilidad que un dato tomado de un grupo sea mayor que la de un dato tomado del otro grupo.\nSi suponemos que los datos se distribuyen normalmente, entonces:\n\n\\[\n\\text{ps} = \\Phi \\left ( \\frac{\\delta}{\\sqrt{2}} \\right)\n\\]\n\\(\\Phi\\) es la cdf de una distribución normal \\(\\delta\\) es el valor del d de Cohen.\nCon el siguiente código usamos plot_posterior para graficar todas las diferencias no triviales o redundantes. Es decir evitamos las diferencias de un día con sigo mismo y evitamos calcular ‘Vie - Jue’ si ya hemos calculado ‘Jue - Vie’. Si lo viéramos como una matriz de diferencias solo estaríamos calculando la porción triangular superior.\n\ncg_posterior = az.extract(idata_cg)\n\ndist = pz.Normal(0, 1)\n\ncomparisons = [(categories[i], categories[j]) for i in range(4) for j in range(i+1, 4)]\n\n_, axes = plt.subplots(3, 2, figsize=(13, 9), sharex=True)\n\nfor (i, j), ax in zip(comparisons, axes.ravel()):\n    means_diff = cg_posterior[\"μ\"].sel(dias=i) - cg_posterior['μ'].sel(dias=j)\n    \n    d_cohen = (means_diff /\n               np.sqrt((cg_posterior[\"σ\"].sel(dias=i)**2 + \n                        cg_posterior[\"σ\"].sel(dias=j)**2) / 2)\n              ).mean().item()\n    \n    ps = dist.cdf(d_cohen/(2**0.5))\n    az.plot_posterior(means_diff.values, ref_val=0, ax=ax)\n    ax.set_title(f\"{i} - {j}\")\n    ax.plot(0, label=f\"Cohen's d = {d_cohen:.2f}\\nProb sup = {ps:.2f}\", alpha=0)\n    ax.legend(loc=1)\n\n\n\n\n\n\n\n\nUna forma de interpretar estos resultados es comparando el valor de referencia con el intervalo HDI. De acuerdo con la figura anterior, tenemos solo un caso cuando el 94% HDI excluye el valor de referencia de cero, la diferencia en las propinas entre el jueves y el domingo. Para todos los demás ejemplos, no podemos descartar una diferencia de cero (de acuerdo con los criterios de superposición de valores de referencia de HDI). Pero incluso para ese caso, ¿es una diferencia promedio de ≈0.5 dólares lo suficientemente grande? ¿Es suficiente esa diferencia para aceptar trabajar el domingo y perder la oportunidad de pasar tiempo con familiares o amigos? ¿Es suficiente esa diferencia para justificar promediar las propinas durante los cuatro días y dar a cada mozo/a la misma cantidad de dinero de propina? Este tipo de preguntas es crucial para interpretar los datos y/o tomar decisiones, pero las respuestas no las puede ofrecer la estadística de forma automática (ni ningún otro procedimiento). La estadística solo pueden ayudar en la interpretación y/o toma de decisiones.\nNota: Dependiendo del público el gráfico anterior puede que esté demasiado “cargado”, quizá es útil para una discusión dentro del equipo de trabajo, pero para un público en general quizá convenga sacar elementos o repartir la información entre una figura y una tabla o dos figuras.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programación probabilista</span>"
    ]
  },
  {
    "objectID": "02_Programación_probabilística.html#resumen",
    "href": "02_Programación_probabilística.html#resumen",
    "title": "2  Programación probabilista",
    "section": "2.3 Resumen",
    "text": "2.3 Resumen\nAunque la estadística Bayesiana es conceptualmente simple, los modelos probabilísticos a menudo conducen a expresiones analíticamente intratables. Durante muchos años, esta fue una gran barrera que obstaculizó la adopción amplia de métodos Bayesianos. Afortunadamente, la matemática, la física y la informática vinieron al rescate en forma de métodos numéricos capaces, al menos en principio, de resolver cualquier inferencia. La posibilidad de automatizar el proceso de inferencia ha llevado al desarrollo de los lenguajes de programación probabilista que permiten una clara separación entre la definición del modelo y la inferencia.\nPyMC es una librería de Python para programación probabilística con una sintaxis simple, intuitiva y fácil de leer que también está muy cerca de la sintaxis estadística utilizada para describir modelos probabilísticos. En este capítulo introducimos PyMC revisando el problema de la moneda que vimos en el capítulo anterior. La diferencia es que no tuvimos que derivar analíticamente la distribución a posteriori. Los modelos en PyMC se definen dentro de un bloque with; para agregar una distribución de probabilidad a un modelo, solo necesitamos escribir una línea de código. Las distribuciones se pueden combinar y se pueden usar como priors (variables no observadas) o likelihoods (variables observadas). En la sintaxis de PyMC la única diferencia entre ambas es que para esta última debemos pasar los datos usando el argumento observed. Si todo va bien las muestras generadas por PyMC serán representativas de la distribución a posteriori y por lo tanto serán una representación de las consecuencias lógicas del modelo y los datos.\nArviZ es una librería que nos ayuda a explorar los modelos definidos por PyMC (u otras librerías como PyStan, TFP, BeanMachine, etc). Una forma de usar el posterior para ayudarnos a tomar decisiones es comparando la ROPE con el intervalo HDI.\nFinalizamos comparando medias entre grupos, una tarea común en análisis de datos. Si bien esto a veces se enmarca en el contexto de las pruebas de hipótesis, tomamos otra ruta y trabajamos este problema como una inferencia del tamaño del efecto.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programación probabilista</span>"
    ]
  },
  {
    "objectID": "02_Programación_probabilística.html#ejercicios",
    "href": "02_Programación_probabilística.html#ejercicios",
    "title": "2  Programación probabilista",
    "section": "2.4 Ejercicios",
    "text": "2.4 Ejercicios\n\nUsando PyMC reproducí los resultados del primer capítulo para el problema de la moneda. Usar los 3 priors usados en ese capítulo Beta(1, 1), Beta(0.5, 0.5), Beta(20, 20).\nReemplazá la distribución Beta por una uniforme en el intervalo [0, 1] ¿Cómo cambia la velocidad del muestreo? ¿Y si se usas un intervalo más ámplio, como [-3, 3]?\nPara el modelo_g. Usá una Gaussiana para la media, centrada en la media empírica. Probá modificar la desviación estándard de ese prior ¿Cuán robusto/sensible son los resultados a la elección del prior?\nLa Gaussiana es una distribución sin límites es decir es válida en el intervalo \\((-\\infty, \\infty)\\), en el ejemplo anterior la usamos para modelar datos que sabemos tienen límites ¿Qué opinás de esta elección?\nCalculá la probabilidad de superioridad directamente a partir de las muestras del posterior, es decir sin la expresión analítica. Cómo se comparan los resultados con los valores obtenidos analíticamente.\nAplicá al menos uno de los modelos vistos en este capítulo a datos propios o de tu interés.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Programación probabilista</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html",
    "href": "03_Modelos_jerárquicos.html",
    "title": "3  Modelado Jerárquico",
    "section": "",
    "text": "3.1 Jerarquías en los datos\nAl analizar datos es común encontrarse con situaciones como las siguientes:\nEn todos estos casos lo que tenemos es una agrupamiento o jerarquía “natural”. Los datos están agrupados en diferentes niveles. En el caso de los estudiantes, los datos están agrupados por escuela, ciudad y provincia. En el caso de los pacientes, los datos están agrupados por hospital. En el caso de los corredores tenemos mediciones repetidas de un mismo individuo a lo largo del tiempo, es decir los datos están agrupados por corredor.\nEs muy común que al analizar estos datos ignoremos la estructura jerárquica de los datos y decidamos o bien agrupar los datos (ej, todos los corredores en un mismo grupo) o bien analizarlos por separado (cada corredor, independiente del resto). Agrupar todos los datos nos permite obtener estimaciones más precisas, el costo es que perdemos los detalles de cada grupo. Al agrupar datos también corremos el riesgo de opacar diferencias o incluso obtener conclusiones diametralmente opuestas (ver paradoja de Simpson). Tratar a cada grupo por separado tiene la ventaja que podemos capturar las particularidades de cada grupo, pero las estimaciones de los parámetros serán menos precisas y corremos el riesgo de sobre-ajuste.\n¿Es posible construir un modelo que contemple que los datos están formados por grupos diferentes, pero que al mismo tiempo comparten información?\nSi, y ese es precisamente el tema principal de este capítulo. Este tipo de modelos se conocen como modelos jerárquicos. En la literatura es posible encontrar el mismo concepto bajo diferentes nombres; modelos multinivel, modelos de efectos mixtos, modelos de efectos aleatorios o modelos anidados. Lamentablemente algunos autores utilizan estos términos de forma intercambiable, mientras que otros los utilizan para marcar algunas diferencias. Nosotros utilizaremos el término modelo jerárquico para referirnos a cualquier modelo que contemple la estructura jerárquica de los datos.\nUn modelo jerárquico se construye asignado distribuciones a priori a las distribuciones a priori! Este nivel superior de distribuciones a priori se suelen denominar hiper-priors. Conceptualmente al utilizar un hiper-prior, estamos asumiendo que los priors de cada grupo no son nesariamente idénticos, pero si están vinculados al provenir de una población (o mecanismo generarador de datos) común. La siguiente figura muestra un diagrama con las diferencias entre un modelo agrupado (un solo grupo), un modelo no agrupado (todos los grupos separados) y un modelo jerárquico.\nEl introducir hiper-priors induce una distribución a posteriori donde las estimaciones de cada grupo estarán parcialmente agrupadas, es decir en algún punto entre el modelo agrupado y el modelo no agrupado. Para generar intuición sobre este punto construyamos un modelo no-jerarquico y uno jerárquico y compararemos los resultados.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#jerarquías-en-los-datos",
    "href": "03_Modelos_jerárquicos.html#jerarquías-en-los-datos",
    "title": "3  Modelado Jerárquico",
    "section": "",
    "text": "Datos de desempeño deportivo. Por ejemplo datos de los mismos corredores en diferentes años.\nDatos de salud. Por ejemplo datos de pacientes en diferentes hospitales.\nDatos de rendimiento escolar. Podríamos tener información sobre el rendimiento de los estudiantes en diferentes escuelas, de diferentes ciudades y en diferentes provincias.\n\n\n\n\n\n\n\n\n\nDiagrama que muestra las diferencias entre un modelo agrupado, un modelo no agrupado y un modelo jerárquico.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#desplazamientos-jerárquicos",
    "href": "03_Modelos_jerárquicos.html#desplazamientos-jerárquicos",
    "title": "3  Modelado Jerárquico",
    "section": "3.2 Desplazamientos jerárquicos",
    "text": "3.2 Desplazamientos jerárquicos\nLas proteínas son moléculas formadas por 20 unidades, llamadas amino ácidos, cada amino ácido puede aparecer en una proteína 0 o más veces. Así como una melodía está definida por una sucesión de notas musicales, una proteína está definida por una sucesión de amino ácidos. Algunas variaciones de notas pueden dar como resultados pequeñas variaciones sobre la misma melodía, otras variaciones pueden resultar en melodías completamente distintas, algo similar sucede con las proteínas. Una forma de estudiar proteínas es usando resonancia magnética nuclear (la misma técnica usada para imágenes médicas). Esta técnica permite medir diversos observables, uno de ellos se llama desplazamiento químico y para simplificar diremos que podemos medir tantos desplazamientos químicos como amino ácidos tenga una proteína. Los aminoácidos son una familia de compuestos químicos por lo que tendría sentido tratarlos a todos de igual forma, pero al mismo tiempo tienen diferentes propiedades químicas, las cuales de hecho son relevantes para comprender como funcionan las proteínas! Por lo que también tiene sentido tratarlos por separado. Como ya vimos una alternativa es construir un modelo jerárquico y hacer algo a mitad de camino.\nEl siguiente conjunto de datos contiene valores de desplazamientos químicos para un conjunto de proteínas. Si inspeccionan el DataFrame cs_data verán que tiene 4 columnas:\n\nLa primera es un código que identifica a la proteína (si tienen curiosidad pueden ingresar el identificador en esta base de datos https://www.rcsb.org).\nLa segunda columna tiene el nombre del amino ácido (pueden corroborar que hay tan solo 20 nombres únicos).\nLa tercera contiene valores teóricos de desplazamientos químicos (calculados usando métodos cuánticos).\nLa cuarta tiene valores experimentales.\n\nLa motivación de este ejemplo es comparar las diferencias entre valores teóricos y experimentales, entre otras razones para evaluar la capacidad de los métodos teóricos para reproducir valores experimentales.\n\ncs_data = pd.read_csv('datos/chemical_shifts_theo_exp.csv')\ndiff = cs_data.theo - cs_data.exp\ncat_encode = pd.Categorical(cs_data['aa'])\nidx = cat_encode.codes\ncoords = {\"aa\": cat_encode.categories}\n\nPara resaltar la diferencia entre un modelo jerárquico y uno no-jerárquico vamos a construir ambos. Primero el no-jerárquico. Este modelo es equivalente a haber ajustado cada uno de los aa grupos por separado.\n\nwith pm.Model(coords=coords) as cs_nh:         \n    μ = pm.Normal('μ', mu=0, sigma=1, dims=\"aa\") \n    σ = pm.HalfNormal('σ', sigma=2, dims=\"aa\") \n \n    y = pm.Normal('y', mu=μ[idx], sigma=σ[idx], observed=diff) \n     \n    idata_cs_nh = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n\n\n\n\nY ahora la novedad. El modelo jerárquico.\nEste modelo tiene un hiper-prior para la media de \\(\\mu\\) (μ_mu) y otro para la desviación estándar de \\(\\mu\\) (μ_sd). Para \\(\\sigma\\) no usamos un hiper-prior, asumimos un valor común del parámetro para todos los grupos. Esto es una decisión de modelado. En este caso la justificación es mantener el ejemplo simple, pero en principio no sería problemático usar un hiper-prior también para \\(\\sigma\\).\n\nwith pm.Model(coords=coords) as cs_h:\n    # hyper_priors\n    μ_mu = pm.Normal('μ_mu', mu=0, sigma=2)\n    μ_sd = pm.HalfNormal('μ_sd', 2)\n\n    # priors\n    μ = pm.Normal('μ', mu=μ_mu, sigma=μ_sd, dims=\"aa\") \n    σ = pm.HalfNormal('σ', sigma=2, dims=\"aa\") \n\n    y = pm.Normal('y', mu=μ[idx], sigma=σ[idx], observed=diff) \n\n    idata_cs_h = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ_mu, μ_sd, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n\n\n\n\nAntes de observar los resultados, comparemos gráficamente ambos modelos, para estar seguros que entendemos en qué difieren. La siguiente figura muestra una representación gráfica de los modelos cs_nh (no-jerárquico) y cs_h (jerárquico). Se puede ver como el modelo jerárquico tiene un nivel más.\n\n\n\nAhora que tenemos más claras las diferencias a nivel del modelo, vamos a explorar las consecuencias de esas diferencias. Para ello vamos a comparar los resultados usando un forest plot. ArviZ nos ofrece la función plot_forest que permite pasar más de un modelo, esto es útil cuando queremos comparar los valores de parámetros equivalentes entre modelos como en el presente ejemplo. Por defecto, plot_forest grafica las cadenas de MCMC por separado, esto no es relevante en este caso por lo que vamos a combinarlas usando combined=True. Los invito a explorar, por su cuenta, el significado del resto de los argumentos que pasamos en la siguiente celda.\n\naxes = az.plot_forest([idata_cs_nh, idata_cs_h], model_names=['no_jerárquico', 'jerárquico'],\n                      var_names='μ', combined=True, r_hat=False, ess=False, figsize=(10, 7),\n                      colors='cycle')\ny_lims = axes[0].get_ylim()\naxes[0].vlines(idata_cs_h.posterior['μ_mu'].mean(), *y_lims, color=\"k\", ls=\":\");\n\n\n\n\n\n\n\n\nBien, tenemos un gráfico para 38 valores medios estimados, uno por aminoácido (19 en este conjunto de datos) y esto duplicado ya que tenemos dos modelos. También tenemos los intervalos de credibilidad del 94% y el rango intercuartil (el intervalo que contiene el 50% central de la distribución). La línea vertical es la media parcialmente agrupada, es decir la media según el modelo jerárquico. El valor es cercano a cero, esto es parte de lo que esperaríamos ver si los valores teóricos son buenos reproduciendo los valores experimentales.\nLa parte más relevante de este gráfico es que las estimaciones del modelo jerárquico son atraídas hacia la media parcialmente agrupada o, de forma equivalente, se contraen con respecto a las estimaciones no agrupadas. Este efecto es más notorio para los grupos más alejados de la media (como PRO), además la incertidumbre es igual o menor que la del modelo no jerárquico. Decimos que las estimaciones están parcialmente agrupadas porque tenemos una estimación para cada grupo, pero las estimaciones para cada grupo se informan mutuamente mediante el hiper prior. Por lo tanto, se obtiene una situación intermedia entre tener un solo grupo (la media global), todos los aminoácidos juntos, y tener 20 grupos separados, uno por aminoácido (el modelo no jerárquico).\n\n\n\n\n\n\nNota\n\n\n\nEn un modelo jerárquico, los grupos que comparten un hiperprior común comparten información a través de ese hiperprior. Esto da como resultado una contracción de las estimaciones, respecto del modelo desagrupado. Es decir, las estimaciones individuales se contraen hacia la media común. Al agrupar parcialemente las estimaciones, estamos modelando los grupos en algún punto medio entre grupos independientes unos de otros y un solo gran grupo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#es-deseable-tener-contracción",
    "href": "03_Modelos_jerárquicos.html#es-deseable-tener-contracción",
    "title": "3  Modelado Jerárquico",
    "section": "3.3 Es deseable tener contracción?",
    "text": "3.3 Es deseable tener contracción?\nUn modelo jerárquico ofrece estimaciones más conservadoras y más robustas. Por ejemplo, si un grupo tiene un tamaño de muestra pequeño, la estimación de ese grupo será más incierta que la de un grupo con un tamaño de muestra grande. En un modelo jerárquico, la información de los grupos con mayor tamaño de muestra se comparte con los grupos con menor tamaño de muestra, lo que resulta en una estimación más precisa para los grupos con menor tamaño de muestra. La cantidad exacta de contracción dependerá de varios factores (ver ejercicios), pero en general, la contracción es deseable ya que reduce la varianza de las estimaciones y reduce las posibilidades de sobreajuste.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#intercambiabilidad",
    "href": "03_Modelos_jerárquicos.html#intercambiabilidad",
    "title": "3  Modelado Jerárquico",
    "section": "3.4 Intercambiabilidad",
    "text": "3.4 Intercambiabilidad\nUna secuencia, finita o infinita de variables aleatorias \\(X_1, X_2, X_3, \\dots X_j\\) es intercambiable si su distribución de probabilidad conjunta no se ve modificada por permutaciones de los indices \\((1, \\dots, J)\\).\nUn ejemplo típico de variables intercambiables es el siguiente:\nTenemos una bolsa con una bola blanca y una negra. La probabilidad de sacar cualquiera de ellas es de 0.5. Si \\(Y_i = 1\\) indica que la iésima bola es blanca y muestreando sin reemplazo, tendremos que:\n\\[P(X_1=1, X_2=0) = 0.5\\] \\[P(X_1=0, X_2=1) = 0.5\\]\nEs decir la probabilidad de tomar primero la blanca y luego la negra es igual a tomar primero la blanca y luego la negra. Es decir \\(X_1\\) e \\(X_2\\) son intercambiables.\nAhora bien también es cierto que:\n\\[0 = P(X_2=1 \\mid X_1=1) \\not= P(X_2=1) = 0.5\\]\nEs decir la probabilidad marginal de que la segunda bola sea blanca no es la misma que la probabilidad (condicional) de que la segunda sea blanca dado que ya obtuvimos una blanca. Es decir \\(X_1\\) e \\(X_2\\) no son independientes.\n\nToda secuencia iid es también intercambiable, pero una secuencia intercambiable no es necesariamente iid. La condición de intercambialidad es más general (o menos estricta) que la de independencia.\n\nEste enunciado se puede demostrar de la siguiente forma:\nSea \\(x_i \\mathop{\\sim}\\limits^{iid} p(x)\\), tenemos que la probabilidad conjunta se calcula como el producto de las probabilidades marginales:\n\\[p(x_i, \\dots , x_n) = \\prod_i^n p(x_i)\\]\nDado que el producto es commutativo, tenemos que el resultado es invariante a permutaciones.\nOK, todo muy lindo, pero y que tiene que ver esto con modelos jerárquicos? Por ahora parece que nada, pero avancemos un poco más.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#teorema-de-de-finetti",
    "href": "03_Modelos_jerárquicos.html#teorema-de-de-finetti",
    "title": "3  Modelado Jerárquico",
    "section": "3.5 Teorema de De Finetti",
    "text": "3.5 Teorema de De Finetti\nUna secuencia de variables aleatorias es intercambiable si y solo si para todo \\(n\\) podemos escribir:\n\\[p(X_1, X_2,  \\dots , X_n) = \\int \\prod_i^n p(X_i \\mid \\theta) \\; p(\\theta)\\]\nEs decir, que un conjunto de variable aleatorias puede ser descrito por:\n\nun parámetro \\(\\theta\\)\nun likelihood \\(p(X \\mid \\theta)\\)\nun prior \\(p(\\theta)\\)\n\nEntonces podemos ver al teorema de De Finetti como una justificación de la estadística Bayesiana y como una garantía de que si tenemos una secuencia de observaciones/variables aleatorias intercambiables entoces podremos describirlas adecuadamente usando estadística Bayesiana. La trampa, por que siempre hay una trampa, es que el teorema no nos dice nada sobre como elegir ni el parámetro, ni el likelihood ni el prior. Existen algunas justificaciones teóricas para elegir estos elementos, pero no lo discutiremos en este curso, principalmente por su limitada utilidad práctica.\nSupongamos ahora que \\(\\theta\\) representa un conjunto de parámetros, \\(\\theta = (\\theta_1, \\theta_2,  \\dots , \\theta_n)\\) y que este conjunto de parámetros es intercambiable. Entonces podemos escribir:\n\\[(\\theta_1, \\theta_2,  \\dots , \\theta_n) = \\int \\prod_i^n p(\\theta_i \\mid \\psi) \\; p(\\psi)\\]\nObteniendo un modelo jerárquico que podríamos reescribir como:\n\\[\\begin{align*}\nX_{ij} &\\sim p(X \\mid \\theta_i) \\\\\n\\theta_i &\\sim p(\\theta \\mid \\psi)  \\\\\n\\psi &\\sim p(\\psi)\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#intercambiabilidad-e-inferencia",
    "href": "03_Modelos_jerárquicos.html#intercambiabilidad-e-inferencia",
    "title": "3  Modelado Jerárquico",
    "section": "3.6 Intercambiabilidad e inferencia",
    "text": "3.6 Intercambiabilidad e inferencia\nYo he seleccionado 10 valores de desplazamientos químicos \\(y_1, \\dots, y_{10}\\). Qué me pueden decir del valor \\(y_4\\)? Sin conocer algo de la química de aminoácidos es dificil arriesgar un rango razonable para \\(y_4\\), pero si asumen intercambialidad podrían decir \\(y_4\\) debe parecerse a los demás valores, ya que no hay razón para pensar que \\(y_4\\) sea especial, por ejemplo para decir algo como \\(y_4 &gt; y_3\\) necesitarían información adicional o supuestos adicionales, como asumir un orden dado. Es decir intercambialidad, implica cierto grado de ignorancia.\nBien, ahora supongamos que les muestro 9 valores, excepto \\(y_4\\), qué pueden decir de \\(y_4\\)?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(y_1\\)\n\\(y_2\\)\n\\(y_3\\)\n\\(y_5\\)\n\\(y_6\\)\n\\(y_7\\)\n\\(y_8\\)\n\\(y_9\\)\n\\(y_{10}\\)\n\n\n\n\n58.27\n56.18\n56.84\n54.64\n54.2\n57.51\n44.45\n61.46\n54.45\n\n\n\nPodrían decir que es posible que \\(y_4\\) esté comprendido en ese rango y si están dispuestos a asumir normalidad, entonces pueden decir algo más como que es probable que \\(y_4\\) tenga una valor de 54.9 (la media de los otros valores) y sería extraño que tenga una valor inferior a \\(\\approx 41\\) y superior a \\(\\approx 68\\) (\\(54.9 \\pm 3 \\text{ desvíos estándar}\\)). Esta estimación es válida incluso si reordenamos los valores de la tabla anterior. Estamos asumiendo que \\(y_4\\) es intercambiable, pero no independiente, ya que de alguna forma el valor de \\(y_4\\) está “informado” por los otros valores.\nAlguien podría objetar que este análisis no es válido, ya que existen distintos tipos de aminoácidos y en algunos casos los desplazamientos pueden ser muy diferentes para estos distintos tipos. En ese caso podemos responder de al menos 2 formas.\n\nSi solo tenemos los valores pero no los “rótulos” (es decir no sabemos a que aminoácido corresponde cada valor), entonces no tenemos otra opción que asumir intercambialidad.\nSi tenemos los rótulos, entonces podemos incorporar esa información y hacer un análisis jerárquico.\n\nAmbas opciones están justificadas teóricamente. La diferencia es la información disponible.\nLuego de estas discusión teórica y conceptual veamos algunos otros ejemplos prácticos de modelos jerárquicos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#renacuajos-multinivel",
    "href": "03_Modelos_jerárquicos.html#renacuajos-multinivel",
    "title": "3  Modelado Jerárquico",
    "section": "3.7 Renacuajos multinivel",
    "text": "3.7 Renacuajos multinivel\nEste ejemplo está tomado de statistical rethinking\n\nTenemos 48 tanques llenos de renacuajos\nQueremos modelar la probabilidad de supervivencia de los renacuajos\nLas condiciones como la temperatura, el pH, la luz, etc. varían ligeramente entre los tanques (pero no los estamos teniendo en cuenta explícitamente)\nPodemos pensar en cada tanque como un grupo\n\n\nd = pd.read_csv('datos/renacuajos.csv', sep=\",\")\ncoords = {\"tanks\": list(d.index)}\nd.head()\n\n\n\n\n\n\n\n\n\ndensity\npred\nsize\nsurv\npropsurv\n\n\n\n\n0\n10\nno\nbig\n9\n0.9\n\n\n1\n10\nno\nbig\n10\n1.0\n\n\n2\n10\nno\nbig\n7\n0.7\n\n\n3\n10\nno\nbig\n10\n1.0\n\n\n4\n10\nno\nsmall\n9\n0.9\n\n\n\n\n\n\n\n\n\nwith pm.Model(coords=coords) as modelo_renacuajos:\n    # Hiperpriors\n    μ = pm.Normal('μ', 0., 2.)\n    σ = pm.HalfNormal('σ', 2.)\n    # Prior\n    α_tanque = pm.Normal('α_tanque', μ, σ, dims=\"tanks\")\n    p = pm.Deterministic('p', pm.math.sigmoid(α_tanque))  # transformación logística\n    #likelihood\n    surv = pm.Binomial('surv', n=d.density, p=p, observed=d.surv)\n    \n    idata_renacuajos = pm.sample(2000, tune=2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ, α_tanque]\nSampling 4 chains for 2_000 tune and 2_000 draw iterations (8_000 + 8_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\npm.model_to_graphviz(modelo_renacuajos)\n\n\n\n\n\n\n\n\nEn la siguiente figura se muestran las proporciones empíricas de sobrevivientes en cada tanque de renacuajos (puntos azules) y las proporciones estimadas por el modelo (puntos turquesa). La línea discontinua indica la proporción promedio de sobrevivientes teniendo en cuenta todos los tanques. Las lineas verticales dividen los tanques de acuerdo a las diferentes densidades iniciales de renacuajos: tanques pequeños (10), tanques medianos (25) y tanques grandes (35). En cada tanque, la media a posteriori del modelo multinivel está más cerca de la línea punteada que la proporción empírica. Esto refleja la información compartida entre tanques y el efecto de contracción.\n\n_, ax = plt.subplots(1, 1, figsize=(12, 5))\n\npost_r = az.extract(idata_renacuajos)\n\nax.scatter(np.arange(0, 48), d.propsurv, color='C0')\nax.scatter(np.arange(0, 48), post_r['p'].mean(\"sample\"), color='C1')\nax.hlines(logistic(post_r['μ'].median(\"sample\")), -1, 49, linestyles='--')\n\nidx = d.density[d.density.diff() &gt; 0].index\nax.vlines(idx + 0.5, -.05, 1.05, lw=.5)\nfor i, t in zip(np.linspace(0, 48, 7)[1::2], ('pequeño', 'mediano', 'grande')):\n    ax.text(i, 0, t, horizontalalignment='center')\nax.set_xlabel('tanques')\nax.set_ylabel('proporción de survivencia')\nax.set_xlim(-1, 48)\nax.set_xticks([])\nax.set_ylim(-.05, 1.05)\nax.grid(False)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#jerarquías-futboleras",
    "href": "03_Modelos_jerárquicos.html#jerarquías-futboleras",
    "title": "3  Modelado Jerárquico",
    "section": "3.8 Jerarquías futboleras",
    "text": "3.8 Jerarquías futboleras\nVarias estructuras de datos se prestan a descripciones jerárquicas que pueden abarcar múltiples niveles. Por ejemplo, jugadores profesionales de fútbol. Como en muchos otros deportes, los jugadores tienen diferentes posiciones dentro de la cancha. Es posible que nos interese estimar algunas métricas de habilidad para cada jugador, para las posiciones y para el grupo general de jugadores de fútbol profesional. Este tipo de estructura jerárquica también se puede encontrar en muchos otros dominios, como:\n\nInvestigación médica: Supongamos que estamos interesados en estimar la eficacia de diferentes fármacos para el tratamiento de una determinada enfermedad. Podemos categorizar a los pacientes según su información demográfica, la gravedad de la enfermedad y otros factores relevantes y construir un modelo jerárquico para estimar la probabilidad de curación o el éxito del tratamiento para cada subgrupo. Luego podemos usar los parámetros de la distribución de subgrupos para estimar la probabilidad general de curación o éxito del tratamiento para toda la población de pacientes.\nCiencias ambientales: Supongamos que estamos interesados en estimar el impacto de un determinado contaminante en un ecosistema particular. Podemos categorizar diferentes hábitats dentro del ecosistema (p. ej., ríos, lagos, bosques, humedales) y construir un modelo jerárquico para estimar la distribución de los niveles de contaminantes dentro de cada hábitat. Luego podemos usar los parámetros de la distribución del hábitat para estimar la distribución general de los niveles de contaminantes dentro del ecosistema.\nInvestigación de mercado: supongamos que estamos interesados en comprender el comportamiento de compra de los consumidores de un producto en particular en diferentes regiones. Podemos categorizar a los consumidores según su información demográfica (por ejemplo, edad, sexo, ingresos, educación) y construir un modelo jerárquico para estimar la distribución del comportamiento de compra para cada subgrupo. Luego podemos usar los parámetros de la distribución del subgrupo para estimar la distribución del comportamiento de compra para el grupo general de consumidores.\n\nVolviendo a nuestros jugadores de fútbol, hemos recopilado datos de la Premier League, Ligue 1, Bundesliga, Serie A y La Liga, en el transcurso de cuatro años (2017 a 2020). Supongamos que estamos interesados en la métrica de goles por tiro. Esto es lo que los estadísticos suelen llamar tasa de éxito, y podemos estimarlo con un modelo Binomial donde el parámetro \\(n\\) es el número de tiros y las observaciones \\(y\\) es el número de goles. Esto nos deja con un valor desconocido para \\(p\\), en ejemplos anteriores hemos estado llamando a este parámetro \\(\\theta\\) y hemos usado una distribución Beta para modelarlo. Haremos lo mismo ahora, pero jerárquicamente. \\(\\theta\\) representa la “tasa de éxito” de cada jugador y, por lo tanto, es un vector de tamaño n_jugadores. Usamos una distribución Beta para modelar \\(\\theta\\). Los hiperparámetros de la distribución Beta serán los vectores \\(\\mu_p\\) y \\(\\nu_p\\), que son vectores de tamaño 4, que representan las cuatro posiciones en nuestro conjunto de datos (defensor DF, mediocampista MF, delantero FW y arquero GK). Tendremos que indexar correctamente los vectores \\(\\mu_p\\) y \\(\\nu_p\\) para que coincidan con el número total de jugadores. Finalmente, tendremos dos parámetros globales, \\(\\mu\\) y \\(\\nu\\), que representan a los futbolistas profesionales.\nEl modelo PyMC se define en el siguiente bloque de código. El pm.Beta('mu', 1.7, 5.8) fue elegido con la ayuda de PreliZ como prior con el 90% de la masa entre 0 y 0.5. Este es un ejemplo de un prior poco informativo, ya que no hay duda de que una tasa de éxito de 0,5 es un valor alto. Las estadísticas deportivas están bien estudiadas y hay mucha información previa que podría usarse para definir priors más fuertes. Para este ejemplo, nos conformaremos con este prior. Una justificación similar se puede hacer para el prior pm.Gamma('nu', mu=125, sigma=50), que definimos como la distribución Gamma de máxima entropía con el 90% de la masa entre 50 y 200.\n\nfutbol = pd.read_csv(\"datos/futbol.csv\", dtype={'posición':'category'})\npos_idx = futbol.posición.cat.codes.values\npos_codes = futbol.posición.cat.categories\nn_pos = pos_codes.size\nn_jugadores = futbol.index.size\n\n\ncoords = {\"pos\": pos_codes}\nwith pm.Model(coords=coords) as modelo_futbol:\n    # Hiper-parámetros\n    μ = pm.Beta('μ', 1.7, 5.8) \n    ν = pm.Gamma('ν', mu=125, sigma=50)\n\n    \n    # Parámetros por posición\n    μ_p = pm.Beta('μ_p',\n                       mu=μ,\n                       nu=ν,\n                       dims = \"pos\")\n    \n    ν_p = pm.Gamma('ν_p', mu=125, sigma=50, dims=\"pos\")\n \n    # Parámetros por jugador\n    θ = pm.Beta('θ', \n                    mu=μ_p[pos_idx],\n                    nu=ν_p[pos_idx])\n    \n    _ = pm.Binomial('gs', n=futbol.tiros.values, p=θ, observed=futbol.goles.values)\n\n    idata_futbol = pm.sample(4000, target_accept=0.98)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, ν, μ_p, ν_p, θ]\nSampling 4 chains for 1_000 tune and 4_000 draw iterations (4_000 + 16_000 draws total) took 258 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n\n\n\n\n\npm.model_to_graphviz(modelo_futbol)\n\n\n\n\n\n\n\n\nEn el panel superior de la siguiente figura tenemos la distribución a posteriori del parámetro global \\(\\mu\\). La distribución a posteriori es cercana a 0.1. Lo que significa que, en general, para un jugador de fútbol profesional, la probabilidad de hacer un gol es en promedio del 10%. Este es un valor razonable, ya que hacer goles no es una tarea fácil y no estamos discriminando posiciones, es decir, estamos considerando jugadores cuyo papel principal no es el de hacer goles. En el panel central, tenemos el valor estimado de \\(mu_p\\) para la posición de defensa, como es de esperar, es más alto que el parámetro global \\(\\mu\\). En el panel inferior, tenemos el valor estimado de \\(\\theta\\) para Lionel Messi, con un valor de 0.17, que es más alto que el parámetro global \\(\\mu\\) y el valor de la posición delantera \\(\\mu_p\\). Esto también es de esperarse, ya que Lionel Messi es el mejor jugador de fútbol del mundo, y su rol principal es hacer goles.\n\n_, ax = plt.subplots(3, 1, figsize=(12, 7), sharex=True)\naz.plot_posterior(idata_futbol, var_names='μ', ax=ax[0])\nax[0].set_title(r\"Global mean\")\naz.plot_posterior(idata_futbol.posterior.sel(pos=\"FW\"), var_names='μ_p', ax=ax[1])\nax[1].set_title(r\"Forward position mean\")\naz.plot_posterior(idata_futbol.posterior.sel(θ_dim_0=1457), var_names='θ', ax=ax[2])\nax[2].set_title(r\"Messi mean\");\n\n\n\n\n\n\n\n\nLa siguiente figura muestra un forest plot para la distribución a posteriori del parámetro \\(\\mu_p\\). La distribución a posteriori para delanteros se centra en torno a 0.13, como ya vimos, y es la más alta de las cuatro. Esto tiene sentido ya que el papel de los jugadores en una posición delantera es hacer goles y asistencias. El valor más bajo de \\(\\mu_p\\) es para la posición de arquero. Esto esperable, ya que la función principal es evitar que el equipo contrario haga goles. El aspecto interesante es que la incertidumbre es muy alta, esto se debe a que tenemos muy pocos arqueros haciendo goles en nuestro conjunto de datos, 3 para ser precisos. Las distribuciones a posteriori para las posiciones de defensa y mediocampo están en el medio, siendo ligeramente más altas para los mediocampistas. Podemos explicar esto porque el papel principal de un mediocampista es defender y atacar, y por lo tanto la probabilidad de marcar un gol es mayor que la de un defensor pero menor que la de un delantero.\n\naz.plot_forest(idata_futbol, var_names=['μ_p'], combined=True, figsize=(12, 3));",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#resumen",
    "href": "03_Modelos_jerárquicos.html#resumen",
    "title": "3  Modelado Jerárquico",
    "section": "3.9 Resumen",
    "text": "3.9 Resumen\nEn este capítulo hemos descrito uno de los conceptos más importantes de este curso: los modelos jerárquicos. Podemos construir modelos jerárquicos cada vez que podamos identificar subgrupos en nuestros datos. En tales casos, en lugar de tratar los subgrupos como entidades separadas o ignorar los subgrupos y tratarlos como un solo gran-grupo, podemos construir un modelo para agrupar-parcialmente la información entre los grupos.\nEl principal efecto de este agrupamiento-parcial es que las estimaciones de cada subgrupo estarán sesgadas por las estimaciones del resto de los subgrupos. Este efecto se conoce como contracción y, en general, es un truco muy útil que ayuda a mejorar las inferencias haciéndolas más conservadoras (ya que cada subgrupo informa a los demás acercando el resto de las estimaciones hacia él) y más informativas, obtenemos estimaciones a nivel de subgrupo y el nivel del grupo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#para-seguir-leyendo",
    "href": "03_Modelos_jerárquicos.html#para-seguir-leyendo",
    "title": "3  Modelado Jerárquico",
    "section": "3.10 Para seguir leyendo",
    "text": "3.10 Para seguir leyendo\n\nCapítulo 5 de Bayesian Data Analysis de Gelman et al. BDA3\nBernardo, J. M. (1996). The concept of exchangeability and its applications. Far East J. Mathematical Sciences 4, 111-121. Exchangeability",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "03_Modelos_jerárquicos.html#ejercicios",
    "href": "03_Modelos_jerárquicos.html#ejercicios",
    "title": "3  Modelado Jerárquico",
    "section": "3.11 Ejercicios",
    "text": "3.11 Ejercicios\n\n(Borrador). Escribir el teorema de bayes para un modelo jerárquico. La idea es que escriban, likelihood, prior e hyperprior.\nDescrí un ejemplo donde un modelo jerárquico sería más adecuado que un modelo simple. Explica cómo se estructuraría el modelo jerárquico, incluyendo los niveles de la jerarquía y las dependencias entre los parámetros.\n(Borrador) Tenés datos de ventas mensuales de diferentes sucursales de una cadena de supermercados. El objetivo es construir un modelo jerárquico para predecir las ventas futuras y entender la variabilidad entre tiendas. Realizá un esquema de como podría ser un modelo de ese tipo\n(Borrador). Escribir enunciado tuberías jerarquicas (ver ejemplo en repo privado).\n(Borrador, este ejericio asume que ya vimos el ejemplo de las propinas, si no es así podríamos introducir el ejemplo y pedir que ajusten el modelo jerarquico y no jerarquico). Creá una versión jerárquica para el ejemplo de las propinas agrupando parcialmente los días de la semana.\n(Borrador), Cuando se utilizan distribuciones a priori débilmente informativos, las predicciones medias a posteriori de un modelo normal-normal jerárquico son (aproximadamente) promedios pesado de la siguiente forma $ _{} + _j$. Donde \\(\\overline{y}_{\\text{global}}\\) es la media de todas las observaciones, \\(\\overline{y}_j\\) es la media de las observaciones en el grupo \\(j\\), \\(n_j\\) es el número de observaciones en el grupo \\(j\\), \\(\\sigma^2_y\\) es la varianza de las observaciones y \\(\\sigma^2_\\mu\\) es la varianza de las medias de los grupos. Indique en que condiciones las prediccions a nivel individual se contraeran más hacia la predicción global.\nAplicá al menos uno de los modelos visto en este capítulo a datos propios o de tu interés.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelado Jerárquico</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html",
    "href": "04_Flujo_de_trabajo_bayesiano.html",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "",
    "text": "4.1 De datos y suposiciones a insights\nUsamos datos para comprender el mundo que nos rodea, lo que podría consistir en revelar el origen del universo, predecir cuándo debemos plantar y cuándo cosechar, o cómo hacer sugerencias de productos útiles para mantener a los clientes interesados y comprando nuestros productos. Sin embargo, el mundo suele ser un lugar complejo y, por lo tanto, los datos deben procesarse e interpretarse para que sean útiles. Una forma de interpretar los datos es construir modelos. Los modelos son útiles porque nos permiten incorporar suposiciones y evaluarlas.\nLos modelos funcionan como ficciones científicas; mapas que nos ayudan a navegar relaciones complejas. Por lo general (aunque no siempre), los modelos no son el objeto de interés principal, sino que son andamios que proporcionan un marco estructurado para comprender e interpretar datos.\nAl discutir estadística Bayesiana se suele hacer en torno a modelos de probabilidad. Tomamos algunos priors, algunos likelihoods, que luego mezclamos con datos siguiendo como receta el Teorema de Bayes, y Voila!, somos Bayesianos!\nEsta descripción no es incorrecta, simplemente no refleja muchos de los aspectos prácticos de la estadística Bayesiano (o del modelado en general). Lo que sucede es que muchos de esos aspectos prácticos no han sido completamente formalizados (como sí lo ha sido el proceso de inferencia). Incluso para varios de esos aspectos, no tenemos aún buenas herramientas o incluso no tenemos aún buenos marcos conceptuales.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#el-flujo-de-trabajo-bayesiano",
    "href": "04_Flujo_de_trabajo_bayesiano.html#el-flujo-de-trabajo-bayesiano",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.2 El flujo de trabajo bayesiano",
    "text": "4.2 El flujo de trabajo bayesiano\nLa siguiente figura muestra un esquema de un flujo de trabajo Bayesiano. Podemos ver que hay muchos pasos. Necesitamos todos estos pasos porque los modelos son sólo elucubraciones de nuestra mente sin garantía de ayudarnos a comprender los datos. Primero debemos ser capaces de construir un modelo y luego comprobar su utilidad y, si no es lo suficientemente útil, seguir trabajando o, a veces, dejar de intentarlo. Es posible que también hayas notado el paso “evaluar muestras”. Necesitamos esto porque, normalmente, utilizamos métodos computacionales para resolver modelos Bayesianos, los cuales solos proveen garantías asintóticas.\n\n\n\nPrincipales elementos de un flujo de trabajo Bayesiano.\n\n\nDiseñar un modelo adecuado para una tarea de análisis de datos determinada generalmente requiere una combinación de experiencia estadística, conocimiento del dominio, comprensión de las herramientas computacionales y usualmente mucha perseverancia. Rara vez obtenemos el modelo queremos en un solo paso. Es similar a escribir un programa de computadora. Difícilmente no cometamos errores. Incluso los programas muy cortos requieren algo de prueba y error. Por lo general, es necesario probar, depurar y perfeccionar y, a veces, cambiar de enfoque . Lo mismo ocurre con los modelos estadísticos; después de todo, podemos ver los modelos estadísticos como software generador de datos.\nEn las siguientes secciones vamos a discutir algunos de los pasos del flujo de trabajo Bayesiano. Y al final vamos a describir un resumen de un trabajo Bayesiano. La mejor forma de lograr familiaridad con el flujo de trabajo Bayesiano y los sub-flujos es resolviendo problemas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#pruebas-predictivas-a-priori",
    "href": "04_Flujo_de_trabajo_bayesiano.html#pruebas-predictivas-a-priori",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.3 Pruebas predictivas a priori",
    "text": "4.3 Pruebas predictivas a priori\nLa distribución predictiva a priori se define como:\n\\[\np(y^\\ast) =  \\int_{\\Theta} p(y^\\ast \\mid \\theta) \\; p(\\theta) \\; d\\theta\n\\]\ndonde \\(y^\\ast\\) representa datos no observados pero potencialmente observables, al menos de acuerdo a nuestro modelo. Los datos generados son predictivos ya que son los datos que el modelo esperara ver, es decir son datos no observados pero potencialmente observables.\nLo que estamos haciendo es marginalizando el likelihood al integrar sobre todos los valores posibles del prior. Por lo tanto, desde la perspectiva de nuestro modelo, estamos describiendo la distribución marginal de los datos, es decir independientemente de los parámetros. En otros palabras estamos generando predicciones del modelo “antes” de ver los datos. Esta distribución representa lo que el modelo “cree” sobre la cantidad modelada.\nObtener esta distribución de forma analítica no siempre es sencillo, pero si lo es computacionalmente, siempre y cuando podamos escribir un modelo en un PPL. Podemos generar muestras de esta distribución según el siguiente procedimiento:\n\nElegimos un valor de \\(\\theta\\) de acuerdo a la distribución a priori \\(p(\\theta \\mid y)\\)\nFijamos \\(\\theta\\) en la distribución que usamos como likelihood \\(p(y^\\ast \\mid \\theta)\\) y generamos una muestra aleatoria\nRepetimos desde 1, tantas veces como muestras necesitemos\n\nUno de los usos prácticos de esta distribución es evaluar el modelo. A grandes rasgos esto se puede realizar generando datos a partir de la distribución predictiva a priori y comparándolos con nuestro conocimiento de domino. Es común que las comparaciones sean visuales y semi-cuantitativas, es decir buscamos acuerdos razonables. Por ejemplo podemos hacernos preguntas como ¿La mayor parte de la distribución simulada está en un rango razonable? ¿Existen valores extremos? Es recomendable NO comparar con los datos observados, en cambio usar valores de referencia. Los valores de referencia son datos empíricos u observaciones históricas, normalmente serán valores mínimos, máximos o esperados.\n\n4.3.1 Predadores y presas\nEstamos interesados en modelar la relación entre las masas de organismos que son presas y organismos que son predadores, como las masas varían en órdenes de magnitud desde una célula de 1e-14 gramos a una ballena azul de 1.5e8 gramos, es conveniente trabajar en una escala logarítmica. Entonces un modelo podría ser\n\\[\\begin{align}\n    \\mu =& Normal(\\cdots, \\cdots) \\\\\n    \\sigma =& HalfNormal(\\cdots) \\\\\n    log(masas) =& Normal(\\mu, \\sigma)\n\\end{align}\\]\nPara definir los valores del prior, podríamos definir el modelo con algunos priors y ver que implican estos priors en la escala de los datos. Para muestrear de la predictiva a priori usamos pm.sample_prior_predictive() en vez de sample y necesitamos definir observaciones “dummy”. Esto es necesario para indicar cual es el likelihood y para controlar el tamaño de cada distribución predicha.\n\npp_mass = pd.read_csv(\"datos/pp_mass.csv\")\npp_mass[\"predator_log\"] = np.log(pp_mass[\"predator\"])\npp_mass[\"prey_log\"] = np.log(pp_mass[\"prey\"])\n\n# valores de referencia en escala log\nrefs = {\"Planeta Tierra\":np.log(5.97e+27),\n        \"Ballena Azul\":np.log(1.5e8), \n        \"Célula más pequeña\":np.log(1e-14)}\n\n\nwith pm.Model() as model:\n    α = pm.Normal(\"α\", 0, 100)\n    β = pm.Normal(\"β\", 0, 100)\n    σ = pm.HalfNormal(\"σ\", 5)\n    presa = pm.Normal(\"presa\", α + β * pp_mass[\"prey_log\"], σ, observed=pp_mass[\"predator_log\"])\n    idata = pm.sample_prior_predictive(samples=100)\n\nSampling: [presa, α, β, σ]\n\n\nPodemos ver que el idata no tiene grupo posterior, pero si tiene prior y prior_predictive\n\nidata\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  prior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:  (chain: 1, draw: 100)\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 800B 0 1 2 3 4 5 6 7 8 ... 91 92 93 94 95 96 97 98 99\nData variables:\n    α        (chain, draw) float64 800B -2.124 -68.39 187.4 ... 70.34 -68.94\n    β        (chain, draw) float64 800B 48.4 -208.6 64.61 ... -75.42 -3.393 5.3\n    σ        (chain, draw) float64 800B 0.8148 3.467 3.605 ... 6.172 2.439 5.546\nAttributes:\n    created_at:                 2024-07-22T17:11:02.761618+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:chain: 1draw: 100Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])Data variables: (3)α(chain, draw)float64-2.124 -68.39 ... 70.34 -68.94array([[-2.12412977e+00, -6.83897076e+01,  1.87381731e+02,\n        -2.27509066e+01, -6.23616211e+01,  8.89621284e+00,\n         2.20355443e+01,  4.88725407e+01, -1.25672401e+02,\n         5.97970095e+01,  1.15673392e+02,  1.29983312e+02,\n        -1.75802842e+02,  2.31710688e+01,  8.78086705e+01,\n        -1.53942523e+01,  5.63941328e+01, -1.39750605e+02,\n         9.70808737e+01,  5.08763714e+01, -1.47758701e+02,\n        -2.90883820e+01, -8.77625851e+01, -2.07583157e+01,\n         2.69776146e+01,  8.06293697e+01,  4.84698500e+01,\n        -2.41184512e+01, -7.37015211e+01,  2.00247449e+02,\n         4.11860853e+01, -1.46670523e+02, -1.14267363e+02,\n         1.29125357e+02, -1.86666239e+02, -2.03868952e+02,\n         1.04998686e+02, -5.86365673e+01,  8.34084474e+01,\n        -5.01877791e+01,  2.83222760e+02, -1.96979317e+01,\n        -2.20125374e+01,  1.25861934e+02, -1.09790466e+02,\n         8.83709261e+01, -2.45703635e+02,  3.15030634e+01,\n        -1.01417588e+02,  6.16300062e+01,  2.43925974e+02,\n         1.51107343e+01,  1.57359195e-01,  6.25557555e+01,\n        -9.57191585e+01, -2.70747370e+01,  1.92229853e+02,\n        -9.67613997e+01,  1.49990079e+01, -1.45690322e+02,\n         4.57865422e+01, -1.01912985e+02,  4.59366052e+01,\n         6.03821689e+01,  1.17257417e+02,  1.71332685e+02,\n        -2.05566943e+01, -2.02362168e+02, -5.76453273e+01,\n         3.58880789e+01,  4.42529782e+01,  1.84679108e+02,\n         1.54783295e+02, -1.12250198e+02, -8.53103230e+01,\n         4.83735186e+00, -2.53524579e+01,  1.09798862e+02,\n        -1.07433006e+00, -8.35736182e+01,  7.94248964e+00,\n         1.85462513e+02,  8.86020376e+01, -4.02734232e+01,\n        -5.98767230e+01, -4.42178017e+01, -1.16136322e+02,\n         3.56396410e+01, -4.66719085e+01, -1.06664479e+02,\n        -1.73528861e+02, -8.30496274e+01, -4.21101546e+01,\n        -4.14606514e+01, -6.05027369e+01,  4.18292527e+01,\n        -1.29130438e+01,  1.50017716e+01,  7.03444261e+01,\n        -6.89354115e+01]])β(chain, draw)float6448.4 -208.6 64.61 ... -3.393 5.3array([[ 4.83952075e+01, -2.08592477e+02,  6.46122098e+01,\n         8.23922577e+01,  8.89027974e+01, -8.68759316e+01,\n         7.79996037e+01,  2.99336099e+02,  1.75675891e+02,\n        -2.74571976e+01, -2.97144625e+01,  1.00421762e+02,\n         7.60175146e+01, -5.29221062e+01,  4.27298191e+01,\n        -2.29528716e+02,  1.10591147e+02,  1.28746542e+02,\n         1.56604015e+02,  6.98636865e+01, -1.05505332e+02,\n        -9.31878215e+01,  4.06747834e+01, -9.12698705e+00,\n        -8.13247564e+01, -8.94306533e+01,  5.57371372e+01,\n        -1.49573359e+02, -1.70387542e+01,  1.09876715e+01,\n        -2.15983237e+01, -4.28065787e+01, -3.57035951e+01,\n         4.84614496e+01, -7.02016448e+01, -4.17749657e+01,\n        -9.85563447e+01,  1.24964358e+02,  1.63314154e+02,\n         1.14004380e-02, -5.69410468e+01, -2.63699285e+01,\n        -1.90262170e+02, -1.34583971e+02, -6.89686822e+01,\n        -4.79990225e+01,  7.33475953e+01,  3.61439799e+00,\n        -1.29846462e+02,  6.92080046e+01, -4.59562921e+01,\n         1.19253004e+02, -1.50521049e+02,  7.93202505e+01,\n         1.06209778e+02,  1.90007901e+01, -1.66207803e+02,\n        -1.58588767e+02, -8.17188661e+01, -1.33616911e+02,\n        -2.88975087e+01, -1.76442570e+02, -1.30939419e+02,\n         1.29101486e+01, -1.38127844e+02,  9.90712711e+01,\n         5.70419744e+01, -1.03183992e+02, -1.36043282e+02,\n         2.45109803e+01,  2.21599510e+01, -5.26495774e+01,\n        -5.78703078e+01, -2.12115606e+01, -2.27638224e+00,\n        -2.12144410e+02,  1.18768829e+01, -1.26288076e+02,\n        -1.67826125e+02,  7.13319990e+01, -7.97026125e+00,\n        -4.46950166e+01,  5.87528095e+01, -4.16510945e+01,\n        -1.70627823e+02, -2.00240634e+02,  2.98073504e+01,\n         6.78344029e-01, -2.13548150e+02,  3.58254492e+00,\n        -1.89481552e+01, -4.51218638e+01,  8.63386208e+00,\n         9.71484148e+01,  1.10069541e+02,  6.04590425e+01,\n        -9.73598900e+01, -7.54241033e+01, -3.39302253e+00,\n         5.30031334e+00]])σ(chain, draw)float640.8148 3.467 3.605 ... 2.439 5.546array([[ 0.81477172,  3.46674519,  3.60482506,  5.50691442,  2.7744022 ,\n         2.16423172,  2.58509262,  7.49669781,  2.58854522,  0.85866756,\n         2.96715133,  0.37031874,  9.41992658, 16.36969789,  4.38939271,\n         5.33569986,  3.01638423,  1.25211518,  3.49410376,  2.29507129,\n         3.49628586,  0.82158435,  1.9361587 ,  6.60345178,  2.04892918,\n         3.84130375,  7.8464228 ,  3.00666454,  4.59837038,  2.53572456,\n         1.05011842,  4.43712234,  3.17820739,  2.58893885,  0.78558407,\n         1.72055203,  0.68798629,  4.39995446,  2.00805081, 10.83939596,\n         5.27228333,  3.91531973,  0.29031789,  7.20273663,  1.84853735,\n         4.54926084,  1.12000363,  9.827529  ,  0.62825311,  1.85735073,\n         3.63378055,  6.96421866,  2.13670951,  1.05469796,  2.90851408,\n         0.8896554 ,  0.51789003,  4.12546164,  6.4556614 ,  1.55517591,\n         0.73707132,  1.78904655,  5.76805814,  1.82236649,  2.22306525,\n         2.07604734,  3.90652454,  0.70690197,  4.380674  ,  0.40295826,\n         5.14595712,  4.1447829 ,  2.67636501,  1.43864716,  7.84310928,\n         5.56460084,  1.98840893,  7.42065799,  6.16893226,  3.01261542,\n         0.13591495,  0.69858417,  1.47455044,  8.05402488,  4.47130217,\n         4.31870206,  6.72091241,  0.43903588,  4.11323736,  0.61332962,\n         4.05815731,  1.92796519,  2.59540031,  2.91973262,  0.61083135,\n         3.40184664,  0.24785771,  6.17180495,  2.43926933,  5.54573403]])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='draw'))Attributes: (4)created_at :2024-07-22T17:11:02.761618+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n            \n                  \n                  prior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 11MB\nDimensions:      (chain: 1, draw: 100, presa_dim_0: 13085)\nCoordinates:\n  * chain        (chain) int64 8B 0\n  * draw         (draw) int64 800B 0 1 2 3 4 5 6 7 8 ... 92 93 94 95 96 97 98 99\n  * presa_dim_0  (presa_dim_0) int64 105kB 0 1 2 3 4 ... 13081 13082 13083 13084\nData variables:\n    presa        (chain, draw, presa_dim_0) float64 10MB -447.4 110.0 ... -52.88\nAttributes:\n    created_at:                 2024-07-22T17:11:02.764142+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:chain: 1draw: 100presa_dim_0: 13085Coordinates: (3)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 94 95 96 97 98 99array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])presa_dim_0(presa_dim_0)int640 1 2 3 ... 13081 13082 13083 13084array([    0,     1,     2, ..., 13082, 13083, 13084])Data variables: (1)presa(chain, draw, presa_dim_0)float64-447.4 110.0 ... -48.95 -52.88array([[[-447.38074126,  110.00869171, -448.03754426, ...,\n           93.01651713,  172.25865378,  147.02512297],\n        [1857.02958777, -550.28748601, 1859.40347202, ...,\n         -475.1893734 , -826.81184586, -711.06414276],\n        [-403.26088213,  340.81368153, -409.53350679, ...,\n          317.8908905 ,  416.4677049 ,  375.03966841],\n        ...,\n        [ 705.71562209, -157.13723904,  719.41979747, ...,\n         -122.32687389, -261.55804793, -206.91024166],\n        [ 101.9948571 ,   58.03589736,  100.82080828, ...,\n           62.2650152 ,   61.38144153,   57.08682074],\n        [-110.96230245,  -60.99538226, -114.68073057, ...,\n          -57.51996222,  -48.95335016,  -52.87568837]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n      dtype='int64', name='draw'))presa_dim_0PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084],\n      dtype='int64', name='presa_dim_0', length=13085))Attributes: (4)created_at :2024-07-22T17:11:02.764142+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 209kB\nDimensions:      (presa_dim_0: 13085)\nCoordinates:\n  * presa_dim_0  (presa_dim_0) int64 105kB 0 1 2 3 4 ... 13081 13082 13083 13084\nData variables:\n    presa        (presa_dim_0) float64 105kB -18.42 2.303 -9.21 ... 6.544 6.044\nAttributes:\n    created_at:                 2024-07-22T17:11:02.764876+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:presa_dim_0: 13085Coordinates: (1)presa_dim_0(presa_dim_0)int640 1 2 3 ... 13081 13082 13083 13084array([    0,     1,     2, ..., 13082, 13083, 13084])Data variables: (1)presa(presa_dim_0)float64-18.42 2.303 -9.21 ... 6.544 6.044array([-18.42068074,   2.30258509,  -9.21034037, ...,   5.36933899,\n         6.54377083,   6.04402043])Indexes: (1)presa_dim_0PandasIndexPandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n       ...\n       13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084],\n      dtype='int64', name='presa_dim_0', length=13085))Attributes: (4)created_at :2024-07-22T17:11:02.764876+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nNuestro modelo tiene priors tan vagos que todos los valores que ni siquiera podemos distinguir nuestro valores de referencia.\n\nax = az.plot_ppc(idata, group=\"prior\", kind=\"cumulative\", mean=False, legend=False)\n\nfor key, val in refs.items():\n    ax.axvline(val, ls=\"--\", color=\"0.5\")\n    ax.text(val-7, 0.5-(len(key)/100), key, rotation=90)\n\n\n\n\n\n\n\n\n\nwith pm.Model() as model:\n    α = pm.Normal(\"α\", 0, 1)\n    β = pm.Normal(\"β\", 0, 1)\n    σ = pm.HalfNormal(\"σ\", 5)\n    presa = pm.Normal(\"presa\", α + β * pp_mass[\"prey_log\"], σ, observed=pp_mass[\"predator_log\"])\n    idata = pm.sample_prior_predictive(samples=100)\n\nSampling: [presa, α, β, σ]\n\n\nCon estos nuevos priors todavía tenemos algunos valores sin sentido, pero al menos la mayor parte de la masa de nuestras predicciones está dentro de rangos razonables.\n\nax = az.plot_ppc(idata, group=\"prior\", kind=\"cumulative\", mean=False, legend=False)\n\nfor key, val in refs.items():\n    ax.axvline(val, ls=\"--\", color=\"0.5\")\n    ax.text(val-7, 0.5-(len(key)/100), key, rotation=90)\n\n\n\n\n\n\n\n\nPreliZ nos permite hacer algo similar pero de forma interactiva\n\ndef pp_model(α_μ=0, α_σ=100, β_μ=0, β_σ=100, σ_σ=5):\n    α = pz.Normal(α_μ, α_σ).rvs()\n    β = pz.Normal(β_μ, β_σ).rvs()\n    σ = pz.HalfNormal(σ_σ).rvs()\n    prey = pz.Normal(α + β * pp_mass.predator_log, σ).rvs()\n    return prey\n\nrefs = {\"Earth\":np.log(5.97e+27), \"Blue whale\":np.log(1.5e8), \"Smallest cell\":np.log(1e-14)}\npz.predictive_explorer(pp_model, references=refs)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#pruebas-predictivas-a-posteriori",
    "href": "04_Flujo_de_trabajo_bayesiano.html#pruebas-predictivas-a-posteriori",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.4 Pruebas predictivas a posteriori",
    "text": "4.4 Pruebas predictivas a posteriori\nSe define como\n\\[\np(\\tilde{y}  \\mid  y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta\n\\]\ndonde \\(\\tilde{y}\\) representa los datos generados por un modelo una vez obtenido el a posteriori. Es decir, las predicciones del modelo. Es similar a la distribución predictiva a priori, pero esta vez integramos sobre los valores a posteriori de \\(\\theta\\)\nComputacionalmente podemos generar muestras de esta distribución según el siguiente procedimiento:\n\nElegimos un valor de \\(\\theta\\) de acuerdo a la distribución a posteriori \\(p(\\theta \\mid y)\\)\nFijamos \\(\\theta\\) en la distribución que usamos como likelihood \\(p(\\tilde{y} \\mid \\theta)\\) y generamos una muestra aleatoria\nRepetimos desde 1, tantas veces como muestras necesitemos\n\nLas pruebas predictivas a posteriori son usadas de forma muy extendida para evaluar un modelo. En este caso SI es común compara contra los datos observados. Al comparar con los datos que se usaran para ajustar el modelo este tipo de pruebas son una forma de evaluación de la consistencia interna de un modelo. Es decir, de mínima esperamos que un modelo sea capaz de reproducir los datos usados para ajustarlo.\n\naccidentes = pd.Series([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n                       3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n                       2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n                       1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n                       0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n                       3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n                       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\naños = np.arange(1851, 1962)\n\n\nwith pm.Model() as modelo_cat:\n    pc = pm.DiscreteUniform(\"pc\", lower=años.min(), upper=años.max())\n\n    t_0 = pm.Exponential(\"t_0\", 1)\n    t_1 = pm.Exponential(\"t_1\", 1)\n\n    tasa = pm.Deterministic(\"tasa\", pm.math.switch(pc &gt;= años, t_0, t_1))\n\n    acc = pm.Poisson(\"acc\", tasa, observed=accidentes)\n    idata_cat = pm.sample(1000, random_seed=1791, progressbar=False)\n    idata_cat.extend(pm.sample_posterior_predictive(idata_cat, progressbar=False))\n\nMultiprocess sampling (4 chains in 4 jobs)\nCompoundStep\n&gt;Metropolis: [pc]\n&gt;NUTS: [t_0, t_1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nSampling: [acc]\n\n\n\nax = az.plot_ppc(idata_cat, figsize=(10, 3), num_pp_samples=200)\nax.set_xlabel(\"acc\");",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#valores-p-bayesianos",
    "href": "04_Flujo_de_trabajo_bayesiano.html#valores-p-bayesianos",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.5 Valores p Bayesianos",
    "text": "4.5 Valores p Bayesianos\nUn valor-p Bayesiano se define como:\n\\[\n\\text{valor-p Bayesiano} \\triangleq p(T_{\\text{sim}} \\le T_{\\text{obs}} \\mid \\tilde y)\n\\]\nDonde \\(T\\) es un estadístico sumario como la media, mediana, desviación estándar o lo que se desee comparar, que se calcula para los datos observados \\(T_{\\text{obs}}\\) y para los datos simulados \\(T_{\\text{sim}}\\).\nSi los valores observados coinciden con los predichos, el valor esperado será 0,5. Es decir, la mitad de las predicciones estarán por debajo de las observaciones y la otra mitad por encima.\n\nPara aquellos que están familiarizados con los valores p y su uso en estadística frecuentista, hay un par de aclaraciones. Lo que hay de Bayesiano en estos valores p es que NO estamos utilizando una distribución muestral sino la distribución predictiva posterior. Además, no estamos haciendo una prueba de hipótesis nula ni tratando de declarar que una diferencia es “significativa”.\n\n\n_, ax = plt.subplots(1, 3, figsize=(12, 3))\n\ndef iqr(x, a=-1):\n    \"\"\"interquartile range\"\"\"\n    return np.subtract(*np.percentile(x, [75, 25], axis=a))\n\naz.plot_bpv(idata_cat, kind=\"t_stat\", t_stat=\"mean\", ax=ax[0])\naz.plot_bpv(idata_cat, kind=\"t_stat\", t_stat=\"median\", ax=ax[1])\naz.plot_bpv(idata_cat, kind=\"t_stat\", t_stat=iqr, ax=ax[2])\nax[0].set_title(\"media\")\nax[1].set_title(\"mediana\")\nax[2].set_title(\"Rango inter-cuartil\");\n\n\n\n\n\n\n\n\nUn caso especial se da al comparar si los valores simulados son menores que los observados, es decir\n\\[\np(\\tilde y \\le y_{\\text{obs}} \\mid y)\n\\]\n\naz.plot_bpv(idata_cat, kind=\"p_value\");\n\n\n\n\n\n\n\n\nOtra posibilidad es realizar la comparación por observación.\n\\[\np(\\tilde y_i \\le y_i \\mid y)\n\\]\nEsto se suele llamar valor-p marginal y la distribución ideal es uniforme estándar.\nLa linea blanca en la siguiente figura representa el valor ideal y la banda gris la desviación esperada dado el tamaño de los datos. Los valores de x se pueden interpretar como cuantiles, es decir los valores centrales representan el “seno” de la distribución y los valores extremos las “colas”.\n\naz.plot_bpv(idata_cat);\n\n\n\n\n\n\n\n\nPor qué esperamos una distribución uniforme? Debido a una propiedad llamada transformada integral de probabilidad (PIT por su sigla en inglés). También llamada a veces universalidad de la uniforme.\nDada una variable aleatoria continua \\(X\\) y CDF \\(F_X\\) podemos computar una variable aleatoria \\(Y\\) con distribución uniforme estándar haciendo.\n\\[\nY = F_X (X)\n\\]\nEs decir si tomamos una variable aleatoria \\(X\\) y le aplicamos su propia CDF, la transformamos en \\(Y \\sim \\mathcal{U}[0, 1]\\). Empíricamente podemos ver esto haciendo:\n\ndist = pz.Normal(0, 1)  # Probar con otras distribuciones\nplt.hist(dist.cdf(dist.rvs(1000)), bins=\"auto\");\n\n\n\n\n\n\n\n\nSi desconocemos \\(F_X\\), pero contamos con muestras de \\(X\\), podemos usar la CDF empírica que es lo que estamos haciendo al calcular el valor-p marginal.\n\ndist = pz.Normal(0, 1)  # Probar con otras distribuciones\npred_f = np.exp(dist.rvs(1000))**0.3\nobs_f = np.exp(dist.rvs(1000))**0.3\n\n\npit = []\nfor m in obs_f:\n    pit.append(np.mean(pred_f &lt;= m))\n    \nplt.hist(pit);",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#comparación-de-modelos",
    "href": "04_Flujo_de_trabajo_bayesiano.html#comparación-de-modelos",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.6 Comparación de modelos",
    "text": "4.6 Comparación de modelos\n\n4.6.1 El equilibro entre simplicidad y exactitud\nAl elegir entre explicaciones alternativas, existe un principio conocido como la navaja de Occam. En lineas muy generales este principio establece que dadas dos o más explicaciones equivalentes para el mismo fenómeno, la más simple es la explicación preferida. Un criterio común de simplicidad es la cantidad de parámetros de un modelo.\nOtro factor que generalmente debemos tener en cuenta al comparar modelos es su exactitud, es decir, qué tan bueno es un modelo ajustando los datos. Según este criterio si tenemos dos (o más) modelos y uno de ellos explica los datos mejor que el otro, entonces ese es el modelo preferido.\nIntuitivamente, parece que al comparar modelos, tendemos a preferir aquellos que mejor ajusten los datos y aquellos que sean más simples. ¿Pero que hacer si estos dos principios se contraponen? O de forma más general, ¿Existe una forma cuantitativa de contemplar ambas contribuciones? La respuesta corta es que si. De hecho hay más de una forma de hacerlo. Pero antes veamos un ejemplo a fin de generar mayor intuición.\n\n\n4.6.2 Muchos parámetros (pueden) conducir a sobreajuste\nVamos a comenzar por combinar polinomios cada vez más complejos en un conjunto de datos muy simple. En lugar de utilizar la maquinaria Bayesiana, usaremos la aproximación de mínimos cuadrados para ajustar modelos lineales.\n\n\nMostrar Código\n_, ax = plt.subplots(1, 1, figsize=(12, 4))\n\n\nx0 = np.array([4., 5., 6., 9., 12, 14.])\ny0 = np.array([4.2, 6.1, 5., 10., 10, 14.])\n\norder = [0, 1, 5]\nax.plot(x0, y0, 'ko', zorder=3)\n\n\nax.set_yticks([])\nax.set_xticks([])\n\nx_n = np.linspace(x0.min(), x0.max(), 100)\nps = []\nfor i in order:\n    p = np.polynomial.Polynomial.fit(x0, y0, deg=i)\n    ps.append(p)\n    yhat = p(x0)\n    ybar = np.mean(y0)\n    ss_regression = np.sum((yhat-y0)**2)\n    ss_total = np.sum((ybar-y0)**2)\n    r2 = 1 - ss_regression / ss_total\n    ax.plot(x_n, p(x_n), label=f'orden {i}, $R^2$= {r2:.3f}')\n\n    \nax.legend(loc=2);\n\n\n\n\n\n\n\n\n\nDe la figura anterior podemos ver que el aumento de la complejidad del modelo se acompaña de una mayor exactitud reflejada en el coeficiente de determinación R². De hecho, podemos ver que el polinomio de orden 5 se ajusta perfectamente a los datos, obteniendo un R²=1.\n¿Por qué el polinomio de grado 5 puede capturar los datos sin perder uno solo de ellos? La razón es que tenemos el mismo número de parámetros que de datos es decir 6. Por lo tanto, el modelo está actuando como una forma alternativa de expresar los datos. El modelo no está aprendiendo algo sobre los datos, ¡Está memorizando los datos! A partir de este simple ejemplo, podemos ver que un modelo con mayor ajuste no siempre es lo ideal.\nAhora agregaremos dos datos nuevos y sin volver a ajustar los modelos veremos como cambia el R². Se puede ver que al modelo lineal le va mejor en este caso que al polinomial.\n\n\nMostrar Código\n_, ax = plt.subplots( figsize=(12, 4))\nx_ = np.array([6.5, 10])\ny_ = np.array([7, 10])\n\nax.plot(x0, y0, 'ko', zorder=3)\nax.plot(x_, y_, 'ks', zorder=3)\n\nax.set_yticks([])\nax.set_xticks([])\n\nx1 = np.concatenate((x0, x_))\ny1 = np.concatenate((y0, y_))\n\nfor idx, i in enumerate(order):\n    yhat = ps[idx](x1)\n    ybar = np.mean(y1)\n    ss_regression = np.sum((yhat-y1)**2)\n    ss_total = np.sum((ybar-y1)**2)\n    r2 = 1 - ss_regression / ss_total\n    ax.plot(x_n, ps[idx](x_n), label=f'orden {i}, $R^2$= {r2:.3f}')\n\n    \nax.legend(loc=2, fontsize=12);\n\n\n\n\n\n\n\n\n\nCuando un modelo ajusta muy bien, el conjunto de datos utilizado para aprender los parámetros de ese modelo, pero muy mal otros conjuntos de datos, decimos que tenemos sobreajuste (overfitting). Este es un problema muy común al analizar datos.\nUna forma muy útil de pensar el sobreajuste es considerar que un conjunto de datos tiene dos componentes; la señal y el ruido. La señal es lo que queremos capturar (o aprender) de los datos. Si usamos un conjunto de datos es porque creemos que hay una señal allí, de lo contrario será un ejercicio fútil. El ruido, en cambio, no es útil y es el producto de los errores de medición, las limitaciones en la forma en que se generaron o capturaron los datos, la presencia de datos corruptos, etc. Un modelo sobreajusta cuando es tan flexible (para un conjunto de datos) que es capaz de aprender el ruido. Esto tiene como consecuencia que la señal queda oculta.\nEsta es una justificación práctica para la navaja de Occam. Y nos advierte que al menos en principio, siempre es posible crear un modelo tan complejo que explique todos los detalles, incluso los más irrelevantes. Tal como en el Imperio descrito por Borges, donde los cartógrafos alcanzaron tal nivel de sofisticación que crearon un mapa del Imperio cuyo tamaño era el del propio Imperio, y que coincidía punto por punto con él.\n\n\n4.6.3 Muy pocos parámetros conducen a un subajuste\nContinuando con el mismo ejemplo pero en el otro extremo de complejidad, tenemos el modelo de orden 0. Este modelo es simplemente una Gaussiana disfrazada de modelo lineal. Este modelo solo es capaz de capturar el valor de la media de \\(y\\), y es por lo tanto totalente indiferente a los valores de \\(x\\). Decimos que este modelo ha subajustado los datos.\n\n\n4.6.4 Medidas de exactitud predictiva\nTodo debe hacerse tan simple como sea posible, pero no más simple es una cita que a menudo se atribuye a Einstein. Al igual que en una dieta saludable, al modelar tenemos que mantener un balance. Idealmente, nos gustaría tener un modelo que ni sub-ajuste ni sobre-ajuste los datos. De alguna forma hay que balancear simplicidad y bondad de ajuste.\nEn el ejemplo previo, es relativamente fácil de ver que el modelo de orden 0 es demasiado simple mientras que el modelo de orden 5 es demasiado complejo. Pero que podemos decir de los otros dos modelos? Cómo podríamos establecer un ranking numérico de estos modelos? Para poder hacer esto necesitamos formalizar nuestra intuición sobre este balance entre simplicidad y exactitud\nVeamos un par de términos que nos serán de utilidad.\n\nExactitud dentro de la muestra (within-sample accuracy). La exactitud medida con los mismos datos usado para ajustar el modelo.\nExactitud fuera de la muestra (out-of-sample accuracy). La exactitud medida con datos no usados para ajustar el modelo.\n\nLa exactitud dentro de la muestra será, en promedio, mayor a la exactitud fuera de la muestra. Es por ello que usar la exactitud dentro de la muestra para evaluar un modelo en general conducirá a pensar que tenemos un mejor modelo de lo que realmente es. Utilizar la exactitud fuera de la muestra es por lo tanto una mejor idea para evitar engañarnos a nosotros mismos. Sin embargo, esta aproximación requiere dejar datos fuera del ajuste, lo cual es un lujo que en general no nos podemos dar. Ya que este es un problema central en el análisis de datos existen varias propuestas para abordarlo. Dos aproximaciones muy populares son:\n\nValidación cruzada: esta es una estrategia empírica basada en dividir los datos disponibles en subconjuntos separados que se utilizan para ajustar y evaluar de forma alternativa\nCriterios de información: este es un término general usado para referirse a varias expresiones que aproximan la exactitud fuera de la muestra como la exactitud dentro de la muestra más un término que penaliza la complejidad del modelo.\n\n\n\n4.6.5 Validación cruzada\nLa validación cruzada es una solución simple y, en la mayoría de los casos, efectiva para comparar modelos. Tomamos nuestros datos y los dividimos en K porciones. Intentamos mantener las porciones más o menos iguales (en tamaño y, a veces, también en otras características, como, por ejemplo, un número igual de clases). Luego usamos K-1 porciones para entrenar el modelo y el resto para evaluarlo. Este proceso se repite sistemáticamente dejando, por cada iteración, una porción diferente fuera del conjunto de entrenamiento y usando esa porción como el conjunto de evaluación. Esto se repite hasta que hayamos completado K rondas de ajuste-evaluación. La exactitud del modelo será la del promedio a lo largo de las K rondas. Esto se conoce como validación cruzada K-fold. Por último, una vez que hemos realizado la validación cruzada, usamos todos los datos para ajustar por última vez nuestro modelo y este es el modelo que se utiliza para hacer predicciones o para cualquier otro fin.\n\nCuando K es igual a la cantidad de puntos de datos, obtenemos lo que se conoce como validación cruzada dejando uno afuera (LOOCV del inglés leave-one-out cross-validation).\nLa validación cruzada es una práctica de rutina en machine learning. Y apenas hemos descripto los aspectos más esenciales de esta práctica. Para mayor información pueden leer The Hundred-Page Machine Learning Book o Python Machine Learning, by Sebastian Raschka, o Python Data Science Handbook by Jake Vanderplas.\nLa validación cruzada es una idea muy simple y útil, pero para algunos modelos o para grandes cantidades de datos, el costo computacional de la validación cruzada puede estar más allá de nuestras posibilidades. Muchas personas han tratado de encontrar cantidades más simples de calcular que se aproximen a los resultados obtenidos con la validación cruzada o que funcionen en escenarios donde la validación cruzada no puede ser tan fácil de realizar. Y ese es el tema de la siguiente sección.\n\n\n4.6.6 Criterios de información\nLos criterios de información son una colección de herramientas estrechamente relacionadas que se utilizan para comparar modelos en términos de la bondad del ajuste y de la complejidad del modelo. En otras palabras, los criterios de información formalizan la intuición que desarrollamos al comienzo del capítulo. La forma exacta en que se derivan estas cantidades tiene que ver con un campo conocido como Teoría de la Información.\nUna forma intuitiva de medir qué tan bien un modelo se ajusta a los datos es calcular el error cuadrático medio entre los datos y las predicciones realizadas por el modelo:\n\\[\n\\frac{1}{N} \\sum_i^N  (y_i - \\operatorname{E} (y_i \\mid \\theta))^2\n\\]\n\\(\\operatorname{E} (y_i \\mid \\theta)\\) es el valor predicho dados los parámetros estimados. Es importante notar que esto es esencialmente el promedio de la diferencia entre los datos observados y los predichos. Tomar el cuadrado de los errores asegura que las diferencias no se cancelen y enfatiza grandes errores comparado con otros alternativas como por ejemplo calcular el valor absoluto.\nEl error cuadrático medio, puede resultarnos familiar ya que es muy popular. Pero si nos detenemos a reflexionar sobre esta cantidad veremos que en principio no tiene nada de especial y bien podríamos idear otras expresiones similares. Intentemos encontrar una métrica más general y compatible con la aproximación probabilista de este curso.\n\n\n4.6.7 Entropia\nFor a probability distribution with \\(N\\) possible different events which each possible event having probability \\(p_i\\), the entropy is defined as:\n\\[\nH(p) = - \\mathbb{E}[\\log{p}] = -\\sum_i^N p_i \\log{p_i}\n\\]\nLa entropía es una medida de la incertidumbre de una distribución. En este sentido podemos decir que la incertidumbre contenida en una distribución es el logaritmo de la probabilidad promedio de un evento. Si solo un evento es posible la entropía será 0, si todos los eventos tienen la misma probabilidad la entropía será máxima. El concepto de entropía se puede extender a distribuciones continuas, pero no vamos a entrar en esos detalles.\n\n_, axes = plt.subplots(2, 2, sharex=True, sharey=True)\n\nfor p, ax in zip([0.5, 0.1, 0.9, 0.0001], axes.ravel()):\n    dist = pz.Bernoulli(p=p)\n    dist.plot_pdf(ax=ax, legend=False)\n    ax.set_title(f\"Entropy={dist.entropy():.2f}\")\n    ax.set_ylim(-0.05, 1.05)\n\n\n\n\n\n\n\n\nEl concepto de entropía aparece muchas veces en estadística. Puede ser útil, por ejemplo al definir priors. En general queremos utilizar un prior que sea de máxima entropía dado nuestro conocimiento (ver por ej funcion maxent de PreliZ). Y también a la hora de comparar modelos. Veamos.\nSupongamos que tenemos una distribución objetivo \\(p\\), con la cual no podemos trabajar de forma directa y solo tenemos acceso a \\(q\\). Queremos evaluar que tan bien \\(q\\) approxima a \\(p\\), o si \\(q\\) es una familia paramétrica encontrar que parámetros hacen que \\(q\\) sea lo más cercana a \\(p\\) que sea posible. Una forma de hacer esto es medir la divergencia de Kulback-Leibler:\n\\[\n\\mathbb{KL}(p \\parallel q) =  \\overbrace{-\\sum_i^N p_i \\log{q_i}}^{H(p, q)} -  \\overbrace{\\left(-\\sum_{i}^n p_i \\log{p_i}\\right)}^{H(p)}\n\\]\nFijense que tiene dos componentes la entropia de \\(p\\), \\(H(p)\\) y la entropía cruzada \\(H(p, q)\\), es decir la entropía de \\(q\\) pero evaluada según \\(p\\). Esto puede parecer algo abstracto, pero si pensamos que tenemos \\(N\\) muestras que asumimos provienen de una distribución \\(p\\) desconocida y tenemos un modelo descripto por \\(q(y \\mid \\theta)\\), entonces veremos que estamos describiendo una situación típica en análisis de datos.\nSegún esta expresión la divergencia de KL representa la entropía “extra” que introducimos al aproximar \\(p\\) por \\(q\\). Es común encontrarla escrita de otras formas, como:\n\\[\n\\mathbb{KL}(p \\parallel q) \\quad=\\quad- \\sum_i^N p_i (\\log{q_i} - \\log{p_i}) \\quad=\\quad \\mathbb{E}_p[\\log{p}] - \\mathbb{E}_p[\\log{q}] \\quad=\\quad \\sum_i^N p_i \\log{\\frac{p_i}{q_i}}\n\\]\nTodas formas equivalentes y útiles depediendo en contexto. Algo común en todas estas expresiones es que no podemos aplicar de forma directa si \\(p\\) es desconocida. Por ejemplo si \\(p\\) representa el proceso generador de datos o la población o la distribución verdadera, estamos perdidos… Pero, si lo que nos interesa es comparar modelos veremos que NO es necesario el cálculo directo, la razón es que aún cuando desconozcamos \\(p\\) su entropía es un término constante.\n\\[\n\\begin{split}\n        \\mathbb{KL}(p \\parallel q_0) =&\\; \\mathbb{E}[\\log{p}] - \\mathbb{E}[\\log{q(y \\mid \\theta_0)}] \\\\\n        \\mathbb{KL}(p \\parallel q_1) =&\\; \\mathbb{E}[\\log{p}] - \\mathbb{E}[\\log{q(y \\mid \\theta_1)}] \\\\\n        &\\cdots \\\\\n        \\mathbb{KL}(p \\parallel q_2) =&\\; \\mathbb{E}[\\log{p}] - \\mathbb{E}[\\log{q(y \\mid \\theta_2)}]\n\\end{split}\n\\]\nSi comparamos modelos entonces el mejor modelo, dado el conjunto de modelos comparados, será aquel que tenga un valor más grande de verosimilitud. En otras palabras mimimizar la divergencia de KL es proporcional a maximizar la verosimilitud (likelihood).\nEn la práctica tampoco tenemos acceso a \\(\\mathbb{E}[\\log{q}]\\), lo que podemos hacer es estimar esta cantidad a partir de una muestra, pero como ya sabemos usar una muestra para estimar los parámetros de un modelo y usar la misma muestra para evaluarlo introduce un sesgo, que de alguna manera debemos corregir. Una forma de corregir este sesgo viene dada por los criterior de información.\n\n4.6.7.1 Criterio de información de Akaike\nEste es un criterio de información muy conocido y ampliamente utilizado fuera del universo Bayesiano y se define como:\n\\[\nAIC = -2 \\sum_i^N \\log p(y_i \\mid \\hat{\\theta}_{mle}) + 2 k\n\\]\nDonde, \\(k\\) es el número de parámetros del modelo y \\(\\hat{\\theta}_{mle}\\) es la estimación por máxima verosimilitud para \\(\\theta\\). Para el resto de nuestra discusión vamos a omitir la constante -2 y escribir\n\\[\nAIC = \\sum_i^N \\log p(y_i \\mid \\hat{\\theta}_{mle}) - k\n\\]\nDe esta forma es más fácil ver que el criterio de Akaike es una maxima-verosimilitud penalizada (se hace más chica, se minimiza) mientras más parámetros tenga un modelo.Además, esta versión sin el -2 tiene una correspondencia más clara con otras expresiones que veremos a continuación.\nQué el número de parámetros sea un criterio válido de penalización es intuitivo, ya que como vimos en el ejemplo anterior con los polinomios, un modelo con mayor número de parámetros es, en general, más flexible. Pero es importante destacar que el criterio de Akaike tiene una justificación teórica, no es que Akaike simplemente pensó que usar \\(k\\) era buena idea.\nEl criterio de AIC es muy útil, pero presenta problemas para modelos Bayesianos. Una de las razones es que no utiliza la distribución a posteriori de \\(\\theta\\) y, por lo tanto, descarta información. Además AIC, desde una perspectiva Bayesiana, asume que los priors son planos y, por lo tanto, AIC es incompatible con priors informativos y/o ligeramente informativos. Además, la cantidad de parámetros de un modelo no es una buena medida de la complejidad del mismo cuando se usan priors informativos o estructuras como la jerárquica. Agregar información a un modelo en su estructura, equivale a reducir la cantidad efectiva de parámetros, algo también conocido como regularización.\nPodemos encontrar una expresión equivalente, pero mejor ajustada a modelos Bayesianos?\n\n\n\n4.6.8 WAIC\nComo ya vimos en el criterio de Akaike, la bondad del ajuste viene dada por:\n\\[\n\\sum_i^N \\log p(y_i \\mid \\hat{\\theta}_{mle})\n\\]\nPero en estadística Bayesiana, NO tenemos una estimación puntual de \\(\\theta\\). Tenemos una distribución, por lo que deberíamos hacer:\n\\[\n\\sum_i^N \\log\n    \\int \\ p(y_i \\mid \\theta) \\; p(\\theta \\mid y) d\\theta\n\\]\nComo en general no tenemos una expresión analítica para el posterior, \\(p(\\theta \\mid y)\\), pero tenemos unas serie de muestras (como las obtenidas por MCMC), entonces podemos aproximar la integral por:\n\\[\n\\sum_i^N \\log \\left(\\frac{1}{S} \\sum_{j}^S p(y_i \\mid \\theta^j) \\right)\n\\]\nLLamaremos a esta cantidad ELPD, que es la sigla en inglés para valor esperado de la densidad log-predictiva.\nOK, ya tenemos como medir la bondad de ajuste. Ahora necesitamos un término que penalice la complejidad del modelo. Encontrar la expresión correcta para esto, requiere de trabajo, asi que la vamos a presentar sin justificar. Este nuevo criterio (la versión Bayesiana de Akaike) se llama Widely applicable information criterion:\n\\[\nWAIC = \\sum_i^N \\log \\left(\\frac{1}{S} \\sum_{j}^S p(y_i \\mid \\theta^j) \\right) - \\sum_i^N  \\left( V_{j}^S \\log p(y_i \\mid \\theta^j) \\right)\n\\]\nDonde el término de penalización viene dado por la varianza de los log-likelihoods sobre las \\(S\\) muestras del posterior. Intuitivamente el término penaliza modelos que tengan mucha variabilidad en sus predicciones. Veamos como ejemplo un modelo lineal:\n\\[\nY = \\alpha + \\beta X\n\\]\nUn modelo donde \\(\\beta=0\\) será menos flexible, ya que equivale a un modelo que solo tiene un parámetro, \\(\\alpha\\). De forma un poco más sutil un modelo donde \\(\\beta\\) varía en un rango estrecho será menos flexible (más regularizado), que un modelo donde \\(\\beta\\) puede tomar cualquier valor.\n\n\n4.6.9 LOO y la validación cruzada (aproximada)\nExiste otra alternativa para penalizar el término\n\\[\n\\sum_i^N \\log \\left(\\frac{1}{S} \\sum_{s=1}^S p(y_i \\mid \\theta^s) \\right)\n\\]\nY es calcular\n\\[\n\\sum_i^N \\log\n    \\left( \\frac{1}{S}\\sum_j^S \\mathbin{\\color{#E9692C}{p(y_i \\mid \\theta_{-i}^j)}} \\right)\n\\]\ndonde \\(_{-i}\\) quiere decir que dejamos la observación \\(i\\) afuera. Una implementación Naive de esta estimación requiere que estimemos tantas distribuciones a posteriori como datos tengamos, ya que para cada una de ellas eliminaremos una observación. Sin embargo, esto no es necesario ya que es posible estiamar \\(\\color{#E9692C}{p(y_i \\mid \\theta_{-i}^j})\\) usando Muestreo de Importancia (importance sampling).\nAntes de seguir con nuestra agenda, necesitamos hacer un pequeño detour.\n\n4.6.9.1 Muestreo de importancia\nEsta es una técnica para estimar propiedades de una distribución de interés \\(f\\), dado que solo tenemos muestras de una distribución \\(g\\). Usar el muestreo de importancia tiene sentido, por ejemplo, cuando es más simple muestrear \\(g\\) y no \\(f\\).\nSi tenemos un conjunto de muestras de la variable aleatoria \\(X\\) y podemos evaluar \\(g\\) y \\(f\\) puntualmente, podemos calcular los pesos de importancia como:\n\\[\\begin{equation}\n     w_i = \\frac{f(x_i)}{g(x_i)}\n\\end{equation}\\]\nComputacionalmente queda de la siguiente manera:\n\nExtraer \\(N\\) muestras \\(x_i\\) de \\(g\\)\nCalcular la probabilidad de cada muestra \\(g(x_i)\\)\nEvaluar \\(f\\) sobre las \\(N\\) muestras \\(f(x_i)\\)\nCalcular los pesos de importancia \\(w_i = \\frac{f(x_i)}{g(x_i)}\\)\n\nUna vez obtenidos los pesos \\(w_i\\), podemos usarlos para estimar propiedades de \\(f\\), su densidad, momentos, cuantiles, etc.\nA continuación se muestre un bloque de código donde \\(g\\) es una Normal y \\(f\\) una Gamma y usamos muestreo de importancia para estimar la PDF de \\(f\\). Este es solo un ejemplo didáctico, ya que en realidad sabemos como calcular la PDF de una Gamma. Pero en la práctica \\(f\\) puede ser un objeto mucho más complejo.\n\ng = pz.Normal(0, 10)\nsamples = g.rvs(1000)\nf = pz.Gamma(mu=4, sigma=1.5)\n\nw = f.pdf(samples) / g.pdf(samples)\n\nplt.hist(samples, bins=100, density=True, weights=w, alpha=0.6, color='C1', label='Weighted samples')\nplt.xlim(0, 15)\n\n\nf.plot_pdf();\n\n\n\n\n\n\n\n\nAl hacer muestreo de importancia mientras más similares sean \\(g\\) y \\(f\\) mejor serán los resultados. En la práctica las inferencias son más confiables cuando \\(g\\) tiene un soporte mayor que \\(f\\), es decir cuando es más “ancha”, intuitivamente necesitamos que las muestras de \\(g\\) cubran todo el soporte de \\(f\\) (o al menos las regiones de densidad alta).\n\n\n\n4.6.10 Retomando\nAhora que tenemos una mejor idea de muestreo por importancia veamos como podemos usarlo. La distribución que conocemos es la distribución a posteriori, y la que queremos aproximar por muestreo de importancia es la distribución a posteriori dejando uno afuera \\(p(y_i \\mid \\theta_{-i}^j)\\). Por lo que los pesos de importancia que nos interesa calcular son:\n\\[\nw_i^j = \\frac{p(\\theta^j \\mid y_{-i} )}{p(\\theta^j \\mid y)} \\propto \\frac{p(\\theta) \\prod_{i\\not=-i}^n p(y_i \\mid \\theta)}{p(\\theta) \\prod_i^n p(y_i \\mid \\theta)} \\propto \\frac{1}{p(y_i \\mid \\theta^j)}\n\\]\nEs decir los términos comunes (y que por lo tanto se cancelan) entre numerador y denominador son todos menos el likelihood para la observación que queremos remover. Nótese que los pesos son proporcionales y no están normalizados, pero esto no es un problema ya que se pueden normalizar simplemente dividiendo cada peso por la suma total de los pesos.\nEste resultado es una gran noticia, porque nos dice que es posible calcular el ELPD por validación cruzada dejando uno afuera, a partir de un solo ajuste de los datos! y que solo necesitamos los valores de los log-likelihoods, cuyo costo computacional es, en general, muy bajo.\nLa trampa, por que siempre hay una trampa, es que es esperable que \\(p(\\theta^j \\mid y_{-i} )\\) sea más “ancha” que \\(p(\\theta^j \\mid y)\\), ya que es una distribución a posteriori estimada con una observación menos. Esto es lo contrario al caso ideal en muestreo por importancia. Para muchos casos puede que la diferencia no sea relevante, ya que eliminar una observación puede conducir a una distribución a posteriori prácticamente equivalente. Pero en algunos casos la diferencia puede ser relativamente grande. Cuándo? Pues, mientras más “influyente” sea la observación. En términos de importance sampling esto se traduce en pesos con mayor importancia relativa y que por lo tanto tienen a dominar la estimación.\nUna forma de corregir esto problema es simplemente truncando los pesos “demasiado altos”, pero esto trae otros problemas que no vamos a discutir. Otra forma consiste en respaldarse en la teoría. La teoría indica que bajo ciertas condiciones los pesos altos se distribuyen según una Pareto. Por lo que en vez de truncarlos podemos ajustarlos a una distribución de Pareto y luego remplazarlos por valores obtenidos de esa distribución. Esto es una forma de suavizado que, dentro de cierto rango, permite estabilizar la estimación por muestreo de importancia, ya que hará que alguno valores “muy grandes” no lo sean tanto.\nCuando combinamos todas estas ideas obtenemos un método llamado Pareto-Smooth Importance Sampling Leave-One-Out Cross Validation, que se abrevia como PSIS-LOO-CV. Dado que el nombre y la sigla son horriblemente largo y difíciles de pronunciar nosotros lo llamaremos LOO (pronunciado como “lu”).\n\n\n4.6.11 LOO y WAIC\nAsintóticamente LOO y WAIC convergen, y además funcionan bajo el mismo conjunto de supuestos. Por lo que teóricamente son equivalentes. Sin embargo en la práctica LOO es más robusto, y además nos ofrece un diagnóstico que indica cuándo podría estar fallando (esto gracias al ajuste de Pareto). Por lo que en la práctica preferimos LOO.\n\n\n4.6.12 Calculando LOO\nLuego de toda esta introducción calcular LOO, puede parecer algo decepcionante. Solo tenemos que llamar a la función loo de ArviZ y pasarle un objeto InfereceData que contenga el grupo log-likelihood. Por defecto PyMC NO agrega este grupo al llamar a pm.sample. Podemos calcularlo junto con el posterior si hacemos pm.sample(., )\n\nwith modelo_cat:\n    pm.compute_log_likelihood(idata_cat,\n                              extend_inferencedata=True,  # actualizamos \"in-place\"\n                              progressbar=False,\n                             )  \n\n\nloo_p = az.loo(idata_cat)\nloo_p\n\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/arviz/stats/stats.py:792: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\nComputed from 4000 posterior samples and 111 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -171.18     7.90\np_loo        2.92        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.70]   (good)      108   97.3%\n   (0.70, 1]   (bad)         1    0.9%\n   (1, Inf)   (very bad)    2    1.8%\n\n\nPodemos ver que obtenemos el valor del ELPD estimado usando LOO y su error estándar. p_loo se puede interpretar aproximadamente como el número efectivo de parámetros. De hecho, si cuentan el número de parámetros de modelo_cat verán que es efectivamente 3.\nLuego podemos ver una tabla con los “Valor del diagnóstico de Pareto k”. Ya algo adelantamos sobre esto. Dijimos que usábamos una Pareto para regularizar la estimación de los pesos de importancia. Uno de los parámetros de ese ajuste se llama k. Como tenemos un ajuste de Pareto por observación tenemos un valor k por observación. Este parámetro es útil por que nos indica dos caras de una misma moneda, nos dice cuando una observación es “muy influyente” y nos indica que la aproximación empleada por LOO podría estar fallando para esa observación (lean el mensaje de advertencia con fondo rosa).\nComo regla general si k es menor a 0.7 no hay problemas, si estamos entre 0.7 y 1 es muy probable que estemos en problemas y si el mayor a 1, estamos perdidos. El valor corte 0.7 no es fijo, estrictamente puede ser menor y depende del número total de muestras de la distribución a posteriori, 4000, en este ejemplo. Pero cuando el número es un poco mayor a 2000 ya estamos casi en 0.7. En la práctica es común usar valores de muestras de 2000 o mayores. Incrementar el número de muestras (draws en la función pm.sample) puede reducir el valor de k y por lo podríamos remover algunas de estas advertencias, pero en general el número necesario podría ser demasiado grande como para que tenga sentido práctico.\nEs posible visualizar los valores de k, usando plot_khat\n\naz.plot_khat(loo_p, threshold=0.7);\n\n\n\n\n\n\n\n\nSi bien la función principal de LOO es comparar modelos, los valores de k puede ser útiles incluso si solo tenemos uno. Por ejemplo podríamos tener conocimiento extra que nos indique por qué estas observaciones son influyentes, quizá hubo un problema en la toma de datos y los valores son incorrectos. O quizá los valores son correctos pero desde la perspectiva de nuestro modelo son influyentes, “extraños”, “sorprendentes”.\nSi k &gt; 0.7, el valor de p_loo puede darnos algo más de información. Siendo \\(p\\) es el número total de parámetros en un modelo.\n\nSi p_loo &lt;&lt; p entonces el modelo debe estar mal-especificado. Esto debería verse también en las pruebas predictivas a posteriori. Una solución es usar un modelo sobredispersado (como cambiar una Poisson por una NegativaBinomial o por una ZeroInflatedPoisson o HurdlePoisson, o cambiar una Normal por una T de Student, etc). O es probable que el modelo necesite más estructura o complejidad, quizá necesitamos un término no-lineal, etc\nSi p_loo &lt; p y las observaciones son relativamente pocas comparadas con \\(p\\), (digamos p&gt;N/5). Es probable que tengamos un modelo demasiado flexible y/o priors demasiado vagos. Esto puede pasar para modelos jerárquicos con muy pocas observaciones por grupo o por ejemplo para splines con muchos nudos o Procesos Gaussianos con valores de escala muy cortos\nIf p_loo &gt; p, entonces el modelo tiene problemas muy serios. Si p&lt;&lt;N, entonces las pruebas predictivas a posterior también deberían reportar problemas. Si en cambio p es relativamente grande (digamos p&gt;N/5). Entonces es posible que las pruebas predictivas a posteriori no reflejen problemas.\n\nPor último, otra forma de usar LOO incluso en ausencia de otro modelo es mediante plot_loo_pit. Si el gráfico luce similar al que vimos para los valores p-Bayesianos marginales, es por que estamos haciendo lo mismo. Pero esta vez al usar LOO, estamos considerando:\n\\[\np(\\tilde y_i \\le y_i \\mid y_{-i})\n\\]\nEs decir estamos evaluando, de forma aproximada, la capacidad del modelo de predecir una observación cuando removemos esa observación de los datos observados.\n\naz.plot_loo_pit(idata_cat, y=\"acc\", use_hdi=True)\n\n\n\n\n\n\n\n\n\n4.6.12.1 Otros criterios de información\nOtro criterio de información muy usado es DIC, si usamos el bayesómetro™, DIC es más bayesiano que AIC pero menos que WAIC. Aunque aún es popular, WAIC y principalmentete LOO han demostrado ser más útiles tanto teóricamente como empíricamente que DIC. Por lo cual NO recomendamos su uso.\nOtro criterio muy usado es BIC (del inglés Bayesian Information Criteria), al igual que la regresión logística y la sopa seca de mi madre, este nombre puede ser engañoso. BIC se propuso como una forma de corregir algunos de los problemas con AIC y el autor propuso una justificación Bayesiana para ello. Pero BIC no es realmente Bayesiano en el sentido que al igual que AIC asume priors planos y utiliza una estimación por máxima verosimilitud.\nPero lo que es más importante, es que BIC difiere de AIC y WAIC en su objetivo. AIC y WAIC intentan reflejar cuál modelo generaliza mejor a otros datos (exactitud predictiva) mientras que BIC intenta identificar cuál es el modelo correcto y por lo tanto está más relacionado a los factores de Bayes que con WAIC. Más adelante discutiremos Factores de Bayes y veremos cómo se diferencia de criterios como WAIC y LOO.\n\ntarget = pz.StudentT(nu=4, mu=0, sigma=1).rvs(200)\n\nwith pm.Model() as modelo_n:\n    μ = pm.Normal(\"μ\", 0, 1)\n    σ = pm.HalfNormal(\"σ\", 1)\n    pm.Normal(\"y\", μ, σ, observed=target)\n    idata_n = pm.sample(idata_kwargs={\"log_likelihood\":True})\n    \nwith pm.Model() as modelo_t:\n    μ = pm.Normal(\"μ\", 0, 1)\n    σ = pm.HalfNormal(\"σ\", 1)\n    ν = pm.Exponential(\"ν\", scale=30)\n    pm.StudentT(\"y\", nu=ν, mu=μ, sigma=σ, observed=target)\n    idata_t = pm.sample(idata_kwargs={\"log_likelihood\":True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ, ν]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncmp_df = az.compare({'modelo_n':idata_n, 'modelo_t':idata_t})\ncmp_df\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmodelo_t\n0\n-317.983410\n3.276837\n0.000000\n1.000000e+00\n14.069689\n0.000000\nFalse\nlog\n\n\nmodelo_n\n1\n-329.414153\n3.630109\n11.430743\n2.717826e-13\n16.903472\n6.613548\nFalse\nlog\n\n\n\n\n\n\n\n\nEn las filas tenemos los modelos comparados y en la columnas tenemos\n\nrank : el orden de los modelos (de mejor a peor)\nelpd : la estimación puntual del elpd usando\np : los parámetros efectivos\nelpd_diff : la diferencia entre el ELPD del mejor modelo y los demás modelos\nweight : el peso relativo de cada modelo. Si quisieramos hacer predicciones combinando los distintos modelos, en vez de elegir uno solo, este sería el peso que deberíamos asignar a cada modelo. En este caso vemos que model_t se lleva todo el peso.\nse : el error estándard del ELPD\ndse : el error estándard de las diferencias\nwarning : una advertencia sobre si hay almenos un valor k alto\nscale : la escala en la que se calcula el ELPD\n\nTambién podemos obtener más o menos la misma información de forma gráfica usando la función `az.compareplot\n\naz.plot_compare(cmp_df, plot_ic_diff=False);\n\n\n\n\n\n\n\n\n\nLos círculos vacíos representan los valores del ELPD y líneas negras el error estándar.\nEl valor más alto del ELPD se indica con una línea gris discontinua vertical para facilitar la comparación con otros valores.\nPara todos los modelos, excepto el mejor, también obtenemos un triángulo que indica el valor de la diferencia del ELPD entre cada modelo y el mejor modelo. La barra de error gris que indica el error estándar de las diferencias entre las estimaciones puntuales.\n\nLa forma más sencilla de utilizar los criterios de información es elegir un único modelo. Simplemente elija el modelo con el valor más alto de ELPD. Si seguimos esta regla tendremos que aceptar que el modelo cuadrático es el mejor. Incluso si tenemos en cuenta los errores estándar podemos ver que estos no se solapan. Lo que nos da cierta seguridad que efectivamente los modelos son diferentes entre si. Si, en cambio, los errores estándar se superpusieran, deberíamos proporcionar una respuesta más matizada.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#métodos-numéricos-de-inferencia-bayesiana",
    "href": "04_Flujo_de_trabajo_bayesiano.html#métodos-numéricos-de-inferencia-bayesiana",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.7 Métodos numéricos de Inferencia Bayesiana",
    "text": "4.7 Métodos numéricos de Inferencia Bayesiana\nLa estadística Bayesiana es una técnica flexible y poderosa que ofrece un marco conceptual unificado para el análisis de datos. Lamentablemente esta formulación conduce a expresiones que no siempre tienen solución analítica por lo que se requiere de métodos numéricos de inferencia. Los lenguajes de programación probabilista (lpp) han sido propuestos como una forma de superar estas limitaciones técnicas y facilitar la creación de modelos probabilistas. El objetivo de los lpp es unificar los lenguajes de programación general con el modelado probabilista, permitiendo que estudiantes, investigadores y practicantes se focalicen en crear e interpretar modelos en vez de tener que lidiar con detalles computacionales y/o matemáticos. La posibilidad de aplicar métodos Bayesianos a una amplia variedad de problemas sin requerir, por parte del analista, de avanzados conocimientos matemáticos y computacionales es relativamente reciente. Este hito descansa, principalmente, en el aumento de poder de cálculo y en el desarrollo de métodos de inferencia automática. Para entender donde radica la dificultad de la inferencia Bayesiana podemos revisitar el teorema de Bayes.\n\\[\n\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} = \\frac{\\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}}{\\underbrace{{p(\\boldsymbol{Y})}}_{\\text{marginal likelihood}}}\n\\]\nEl teorema de Bayes, tiene una formulación que a primera vista parece muy inocente. Pero el diablo está en los detalles. El likelihood marginal toma la forma de una integral.\n\\[\n{p(\\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta}}\n\\]\nEsta integral suele ser difícil de resolver. Veamos, esta expresión nos dice que debemos evaluar el likelihood para cada uno de los posibles valores del prior \\(\\theta\\). En la práctica esa tarea no siempre es sencilla o barata de realizar. Si \\(\\theta\\) representa un solo parámetro desconocido (como en el modelo beta-binomial) entonces solo hay que resolver una integral 1D, pero si \\(\\theta\\) representa dos parámetros (como en el modelo Gaussiano) entonces la integral será doble. En definitiva la integral tendrá tantas dimensiones como parámetros el modelo. En general las integrales en grandes dimensiones no son simples de resolver.\nPara obtener una buena aproximación de la distribución a posteriori podemos concentrarnos en las regiones donde tanto la contribución del prior como del likelihood son relativamente grandes (área gris en la siguiente figura), en general esto es lo que hacen métodos numéricos como MCMC, encontrar de forma automática la regiones de mayor densidad de probabilidad. Esa misma aproximación puede conducir a errores gruesos en el cálculo del likelihood marginal\n\n\n\nPara algunos problemas es posible calcular la distribución a posteriori de forma analítica. Esto ya lo vimos para el modelo beta-binomial donde la distribución a posteriori es:\n\\[\np(\\theta \\mid y) \\propto \\operatorname{Beta}(\\alpha_{a priori} + y, \\beta_{a priori} + N - y)\n\\]\nPara esos casos suele ser posible también calcular el marginal likelihood de forma analítica.\nPero en general no tenemos expresiones analíticas y entonces debemos confiar en métodos numéricos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#calculando-la-distribución-a-posteriori",
    "href": "04_Flujo_de_trabajo_bayesiano.html#calculando-la-distribución-a-posteriori",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.8 Calculando la distribución a posteriori",
    "text": "4.8 Calculando la distribución a posteriori\nHay muchas formas de calcular la distribución a posteriori\n\n Conjugación \n Método de Laplace \n Aproximación de Laplace Anidada Integrada (INLA) \n Inferencia Variacional (VI) \nMarkov Chain Monte Carlo (MCMC)\n Sequential Monte Carlo \n…\n\nPor ahora solo hablaremos de los métodos MCMC ya que, por el momento, son los métodos más generales. Pero para entender de forma más simple que es lo que hacen estos métodos conviene empezar desde otro método, conocido como método de la grilla.\n\n4.8.1 Markov Chain Monte Carlo (MCMC)\nEsta es una familia muy extensa de métodos utilizados para resolver muchos problemas, entre los que se encuentra el cálculo de la distribución a posteriori. Conceptualmente se puede pensar a estos métodos como generalizaciones del método de la grilla, ya que también se basan en la posibilidad de realizar evaluaciones punto a punto del prior y likelihood. La diferencia crucial es que en vez de utilizar una grilla predefinida el método realiza evaluaciones que progresivamente se concentran en regiones de alta probabilidad. No solo eso si no que eventualmente el método devolverá muestras de forma proporcional a la probabilidad a posteriori. Es decir si una región es 3 veces más probable que otra obtendremos 3 veces más muestras de esa región que de la otra.\nA muy grandes rasgos, y dado un punto inicial arbitrario, los métodos MCMC, constan de dos pasos.\n\nGenerar un nuevo punto a partir de perturbar uno preexistente.\nAceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.\n\nEsta es esencialmente la receta, la forma exacta en que hacemos cada uno de estos pasos define los distintos métodos dentro de la familia MCMC. Veamos uno de los más sencillos de entender y de implementar.\n\n\n4.8.2 Metropolis-Hastings\nMetropolis-Hastings no es un algoritmo muy moderno o particularmente eficiente, pero Metropolis-Hastings es simple de entender y también proporciona una base para comprender métodos más sofisticados y poderosos.\nEl algoritmo Metropolis-Hasting se define de la siguiente manera:\n\nInicialice el valor del parámetro \\(\\boldsymbol{X}\\) en \\(x_i\\)\nUtilice una distribución de propuesta \\(q(x_{i + 1} \\mid x_i)\\) para generar un nuevo valor \\(x_{i + 1}\\)\nCalcule la probabilidad de aceptar el nuevo valor como:\n\n\\[\np_a (x_{i + 1} \\mid x_i) = \\min \\left(1, \\frac{p(x_{i + 1}) \\; q(x_i \\mid x_{i + 1})} {p(x_i) \\; q (x_{i + 1} \\mid x_i)} \\right)\n\\]\n\nSi \\(p_a &gt; R\\) donde \\(R \\sim \\mathcal{U}(0, 1)\\), guarde el nuevo valor; de lo contrario, guarde el anterior.\nIterar de 2 a 4 hasta que se haya generado una muestra suficientemente grande\n\nEl algoritmo Metropolis es muy general y se puede usar en aplicaciones no Bayesianas, pero para la presente discusión, \\(p(x_i)\\) es la densidad del posterior evaluada en el valor del parámetro \\(x_i\\). Una forma de simplificar un poco el método es notar que si \\(q\\) es una distribución simétrica, los términos \\(q(x_i \\mid x_{i + 1})\\) y \\(q(x_{i + 1} \\mid x_i)\\) se cancelarán (conceptualmente significa que es igualmente probable que vayamos de \\(x_{i+1}\\) a \\(x_i\\) o de \\(x_{i}\\) a \\(x_{i+1}\\)), dejando solo un cociente entre el posterior evaluado en dos puntos. Este algoritmo siempre aceptará moverse de una región de baja probabilidad a una más alta y aceptará probabilísticamente moverse de una región de alta a una baja probabilidad.\n¡Otra observación importante es que el algoritmo Metropolis-Hastings no es un método de optimización! No nos importa encontrar el valor del parámetro con la máxima probabilidad, queremos explorar la distribución \\(p\\). Intuitivamente esto es posible ya que en general el sistema puede moverse de una región de alta probabilidad a una región de menor probabiliad. Estrictamente MH cumple con la condición de balance detallado, que se describe como:\n\\[\np_i t_{ij} = p_j t_{ji}\n\\]\nEn palabras, la probabilidad de estar en un estado \\(i\\) por la probabilidad de moverse del estado \\(i\\) al \\(j\\) es igual que la probabilidad de estar en el estado \\(j\\) y moverse del \\(j\\) al \\(i\\).\nLa condición de balance detallado es suficiente para garantizar que un algoritmo de MCMC es capaz de muestrear de forma correcta de una distribución arbitraria dada una cantidad infinita de pasos. Entonces una forma de probar que un algortimo de muestre es teóricamente válido es demostrar que cumple con el balance detallado.\nPara hacer las cosas más concretas, intentemos resolver el modelo Beta-Binomial.\n\\[\\begin{aligned}\n    \\theta \\sim &\\; \\text{Beta}(\\alpha, \\beta) \\\\\n    Y \\sim &\\; \\text{Bin}(n=1, p=\\theta)\n\\end{aligned}\\]\nEste modelo tiene solución analítica. Pero supongamos que no sabemos cómo calcularla, y por lo tanto, implementaremos el algoritmo Metropolis-Hastings usando Python.\n\ndef post(θ, Y, α=1, β=1):\n    if 0 &lt;= θ &lt;= 1:\n        prior = pz.Beta(α, β).pdf(θ)\n        like  = pz.Bernoulli(θ).pdf(Y).prod()\n        prob = like * prior\n    else:\n        prob = -np.inf\n    return prob\n\nTambién necesitamos datos, por lo que generaremos algunos datos falsos aleatorios para este propósito.\n\nY = pz.Bernoulli(0.7).rvs(20, random_state=123)\n\nY finalmente ejecutamos nuestra implementación del algoritmo Metropolis-Hastings:\n\nn_iters = 1000\ncan_sd = 0.05\nα = β =  1\nθ = np.array([0.5]) \ntrace = {\"θ\":np.zeros(n_iters)}\np2 = post(θ, Y, α, β)\n\nfor iter in range(n_iters):\n    θ_can = pz.Normal(θ, can_sd).rvs(1)\n    p1 = post(θ_can, Y, α, β)  \n    pa = p1 / p2\n\n    if pa &gt; pz.Uniform(0, 1).rvs(1):\n        θ = θ_can\n        p2 = p1\n\n    trace[\"θ\"][iter] = θ.item()\n\nEn la línea 9 del bloque de código anterior generamos una propuesta muestreando una distribución Normal con desviación estándar can_sd. En la línea 10 evaluamos el posterior en el nuevo valor generado θ_can y en la línea 11 calculamos la probabilidad de aceptación. En la línea 17 guardamos un valor de θ en el array trace. Dependiendo del resultado de la comparación en la línea 13, el valor guardado será nuevo o repetiremos el anterior.\nEl primer panel de la siguiente figura muestra cada valor muestreado en cada paso, y el panel de la derecha el histograma de esos valores. El resultado parece razonable. Nada mal para unas pocas lineas de código!\n\n_, axes = plt.subplots(1, 2, figsize=(10, 2), sharey=True)\naxes[0].plot(trace['θ'])\naxes[0].set_ylabel('θ', rotation=0, labelpad=15)\naxes[1].hist(trace['θ'], orientation=\"horizontal\", density=True)\naxes[1].set_xticks([]);\n\n\n\n\n\n\n\n\nAcá pueden ver una versión interactiva de un Metropolis-Hastings\n\n\n4.8.3 MH adaptativo\nLas garantías teóricas de MH y otros MCMC son válidas cuando la cantidad de pasos tiende a infinito. Si tomáramos infinitas muestras, cualquier distribución de propuesta nos conduciría al mismo resultado. Tampoco importaría el punto inicial.\nSin embargo, no podemos tomar infinitas muestras y por lo tanto la eficiencia puede cambiar drásticamente de acuerdo a la distribución de propuesta que utilicemos y en menor medida al punto inicial. Además, la eficiencia de una distribución de propuesta dada dependerá de la geometría de la distribución a posteriori. Por ejemplo, si la distribución a posteriori es muy alargada en una dirección y muy angosta en otra, una distribución de propuesta que isotrópica será ineficiente. Es decir no existe una única distribución de propuesta que sea eficiente para todos los problemas.\nVarios estudios teóricos muestran que bajos ciertas condiciones la tasa de aceptación óptima para MH es de 0.4 para distribuciones a posterirori unidimensionales y \\(\\approx 0.234\\) en el límite de dimensión infinita. En la práctica “infinito suele ser \\(\\lessapprox 10\\)”. Estos resultados teóricos proporcionan una guía para diseñar métodos adatativos. Es decir podemos agregar al algortimo una primer fase the ajuste (tuning) donde se modifica algún aspecto de la distribución de propuesta de forma tal de lograr tasas de aceptación entre 0.23 y 0.4.\nExisten muchos esquemas de ajuste uno común es usar como distribución de propuesta una gaussiana multivariada y ajustar la varianza de forma adaptativa. Muchas veces la matriz de covarianza usada es diagonal y se ajusta por separado cada componente. Estos esquemas adaptativos permiten que MH sea aplicado a una gran cantidad de problemas sin necesidad de realizar modificaciones al método.\nAl usar métodos adaptativos hay que tomar alguno recaudos. Principalmente es importante destacar que las muestras generadas durante el ajuste no son muestras válidas. Esencialmente al cambiar lo hiper-parámetros del método, perdemos las garantías teóricas que aseguran que un MCMC sea valido. Es por ello que en la práctica se suele descartar las muestras generadas durante el ajuste. Vale aclarar que es posible diseñar esquemas de ajuste que no requieran descartar muestras, pero estos son más complejos y no son tan comunes.\nEs posible tener que un algoritmo MCMC sea eficiente sin fase de ajuste, pero oso implica mucha suerte o que alguien se tomó el trabajo de ajusar el algoritmo a un caso particular.\nEn resumen, la fase de ajuste permite que el método MCMC se adapte a la geometría de la distribución a posteriori y por lo tanto permite generalizar estar métodos a una amplia variedad de problemas. Es por ello que los métodos MCMC a veces reciben el nombre de “motores de inferencia universal”. El nombre es bastante rimbomante pero refleja el hecho, de que al menos en teoría, es posible escribir un modelo Bayesiano arbitrario y resolverlo. Esta separación entre modelo e inferencia es un aspecto central de la programación probabilista, ya que saca el foco del proceso de inferencia en si y pone todo el peso en el modelado. En la realidad esto es una verdad a medias, o si se quiere una promesa. En la práctica los métodos de MCMC son muy útiles hasta que dejan de serlo. Por ello es que necesitamos de métodos de diagnóstico del muestreo.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#diagnóstico-del-muestreo",
    "href": "04_Flujo_de_trabajo_bayesiano.html#diagnóstico-del-muestreo",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.9 Diagnóstico del muestreo",
    "text": "4.9 Diagnóstico del muestreo\nUn método de diagnóstico, evalua alguna propiedad esperada de una muestra y nos indica sobre posibles desviaciones entre lo observado y lo predicho por la teoría. Si el diagnóstico encuentra un problema, en general es que hay un problema. Pero si el diagnóstico no encuentra un problema, no quiere decir, estrictamente, que este no exista. Además, como veremos no existe un criterio claro de demarcación. Es el problema del pelado. Se estima que un humano tienen alrededor de 150000 cabellos en su cabeza. Alguien con 0 pelos es claramente un pelado. Pero es dificil establecer un número único y no arbitrario que divida pelados de no pelados.\n\n4.9.1 Trace plots\nEste es un gráfico muy común. Para cada parámetro graficamos su valor (eje-y) en cada iteración (eje-x). Lo esperable es no ver ningún patrón, solo ruido como en primer panel de la siguiente figura (marco turquesa).\n\n\n\nEn cambio los otros tres paneles (marco magenta) muestran problemas. De izquierda a derecha y arriba a abajo:\n\nEl segundo panel muestra que el muestreo es “pegajoso”, le toma muchos pasos a la cadena moverse de valores altos a valores bajos, es difícil predecir que sucedería si seguimos corriendo, la cadena se movería hacia arriba nuevamente, se estabilizaría en valos bajos, continuaría bajando aún más?\nEl tercer panel muestra una cadena menos “pegajosa”, pero también daría la impresión que aún no ha terminado de estabilizarse\nEl último panel, en cambio, muestra que hay una región donde el sampler se mueve bien, pero cada tanto “salta” a estados donde se queda atascado. Quizá esto se deba a una distribución a posteriori multimodal o dificultades en el sampler para explorar regiones con distinta curvatura.\n\nEn general combine correr más de una cadena de MCMC empezando de puntos distintos. Lo esperable es que no podamos distinguir diferencias entre cadenas. Un traceplot con 4 cadenas superpuestas se ve así lo cual es un poco dificil de interpretar.\n\n\n\nArviZ permite graficar trace-plots usando la función az.plot_trace(). Por defecto obtenemos el trace a la derecha y un KDE (para variables continuas) y un histograma (para discretas) a la izquierda\n\n\n\nEl KDE o histograma, también nos puedo ayudar a interpretar si hay problemas. Ya que esperamos que las distribuciones sean similares, más allá de un poco de ruido producto del número finito de muestras.\n\n\n4.9.2 Rank plots\nLos trace plots son muy comunes, pero existe una alternativa más moderna llamada rank plots. La idea básica es la siguiente. Para un parámetro tomamos todas las cadenas y ordenamos los valores de menor a mayor y les asignamos un rango es decir al valor más bajo le ponemos 0, al que sigue 1 y así hasta llegar a un número que será igual a la cantidad de muestras totales (cantidad de cadenas multiplicado por la cantidad de muestras por cadena). Luego reagrupamos los rankings según las cadenas que les dieron origen y para cada cadena hacemos un histograma. Si las cadenas fuesen indistinguibles esperaríamos que los histogramas sean uniformes. Ya que no hay razón para que una cadena tenga más rankings bajos (o medios o altos) que el resto.\nLa siguiente figura muestra 4 ejemplos, donde solo uno (marco cyan) no muestra problemas\n\n\n\nEn ArviZ los rank plots se pueden obtener con la función az.plot_rank o pasando un argumento a plot_trace az.plot_trace(⋅, kind=\"rank_bars\")\n\n\n4.9.3 \\(\\hat R\\) (R sombrero)\nLos gráficos suelen ser útiles para descubrir patrones, pero a veces queremos números, por ejemplo al evaluar rápidamente una lista de cientos, o miles, de parámetros. \\(\\hat R\\) es la respuesta a la pregunta ¿Lograron las cadenas mezclarse adecuadamente?\nEn la literatura podrán encontrar que hay varias versiones de este diagnóstico, en texto viejos puede aparecer como Gelman-Rubin, por los nombres de los autores de la primer versión de este diagnóstico. Pero hoy en día contamos con versiones más modernas y más robustas y generales de las versiones anteriores. La versión implementada en ArviZ es la última versión de este diagnóstico y su cálculo tiene varios pasos. Pero la idea central es que compara la varianza entre cadenas con la varianza dentro de cada cadena. Si las cadenas provienen de la misma distribución entonces \\(\\hat R = 1\\). En la práctica se suele considerar que \\(\\hat R \\lessapprox 1.01\\) son seguros. Pero acá retomamos el problema del pelado. El valor de corte es arbitrario, tiene cierto sustento empírico pero es arbitrario. Por ejemplo en la primer fase de modelado valores más altos como \\(\\hat R \\approx 1.1\\) pueden estár bien. Además el valor de \\(\\hat R \\lessapprox 1.01\\) es razonable cuando tenemos unos pocos parámetros pero es esperable que si tenemos muchos paramétros varios de ellos tengan valores de \\(\\hat R\\) mayores a 1.01. Un caso particular que veremos más adelante es el de BART, un método no paramétrico de regresión. Es conocido que BART suele generar valores de \\(\\hat R\\) relativamente alto y aún ser útil.\nLa siguiente animación muestra, en el panel superior, 4 cadenas que progresivamente se van haciendo más similares. En el panel inferior tenemos 2 Gaussianas centradas en 0, una de ellas con las varianza intra cadena o y la otra entre cadenas.\n\n\n\nUsando ArviZ podemos obtener \\(\\hat R\\) usando az.rhat(⋅), az.summary(⋅) y az.plot_forest(⋅, r_hat=True)\n\n\n4.9.4 Gráfico de autocorrelación\nIdealmente, nos gustaría poder trabajar con muestras independientes e idénticamente distribuidas (iid). Por construcción, las muestras MCMC están correlacionadas, ya que la probabilidad de aceptar el paso \\(i\\) depende del paso \\(i-1\\). En la práctica, queremos muestras con baja autocorrelación.\nEn ArviZ obtenemos este gráfico con la función az.plot_autocorr()\n\ncadenas_defectuosas = {\"cadenas_defectuosas\": np.linspace(0, 1, 1000).reshape(2, -1)}\naz.plot_autocorr(cadenas_defectuosas);\n\n\n\n\n\n\n\n\n\ncadenas_adecuadas = {\"cadena_adecuadas\": pz.Uniform(0, 1).rvs(size=(2, 500))}\naz.plot_autocorr(cadenas_adecuadas);\n\n\n\n\n\n\n\n\n\n\n4.9.5 Tamaño de muestra efectivo (ESS)\nComo las muestras de un MCMC están correlacionadas la cantidad de información “útil” es menor que una muestra del mismo tamaño pero iid.\nLa siguiente figura muestra la distribución correcta como una linea punteada y un histograma de muestras que sucesivamente van aumento. Podemos ver que en el panel de arriba, donde la muestra no están correlacionadas, obtenemos una mejor representación de la distribución real con un menor número de muestras que en el panel inferior donde las muestras si lo están.\n \n\n\n\nPodemos estimar el tamaño de muestra efectivo (ESS), es decir, el tamaño de una muestra con la cantidad equivalente de información pero sin autocorrelación. Esto es útil para determinar si el tamaño de muestra que tenemos es lo suficientemente grande. Se recomienda que el ESS sea superior a 100 por cadena. Es decir para para 4 cadenas queremos un mínimo de 400.\nCon ArviZ podemos obtenerlo az.ess(⋅), az.summary(⋅) y az.plot_forest(⋅, ess=True)\n\npd.concat((az.ess(cadenas_defectuosas).to_pandas(),\n           az.ess(cadenas_adecuadas).to_pandas()))\n\ncadenas_defectuosas       2.282878\ncadena_adecuadas       1229.613734\ndtype: float64\n\n\nVemos que az.summary(⋅) devuelve dos valores de ESS, ess_bulk y ess_tail. Esto se debe a que, distintas regiones del espacio de los parámetros pueden tener distinto valor de ESS, ya que no todas las regiones son muestreadas con la misma eficiencia. Intuitivamente uno puede pensar que al muestrear una distribución como una Gaussiana es más fácil obtener mejor calidad de muestra alrededor de la media que de las colas, simplemente por que tenemos más muestras de esa región.\n\npd.concat([az.summary(cadenas_adecuadas, kind=\"diagnostics\"),\n           az.summary(cadenas_defectuosas, kind=\"diagnostics\")])\n\n\n\n\n\n\n\n\n\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ncadena_adecuadas\n0.008\n0.006\n1230.0\n1028.0\n1.00\n\n\ncadenas_defectuosas\n0.198\n0.165\n2.0\n11.0\n3.05\n\n\n\n\n\n\n\n\nSi las muestras de MCMC las vamos a usar para calcular valores centrales como medias o medianas entonces tenemos que asegurarnos que el ess_bulk sea lo suficientemente algo, en cambio, si queremos calcular intervalos como un HDI 95% hay que asegurarse que ess_tail sea adecuado.\nArviZ ofrece varias funciones vinculadas al ESS. Por ejemplo si queremos evaluar el desempeño del sampler para varias regiones al mismo tiempo podemos usar az.plot_ess.\n\n_, axes = plt.subplots(1, 2, figsize=(10,4), sharey=True)\naz.plot_ess(cadenas_adecuadas, ax=axes[0])\naz.plot_ess(cadenas_defectuosas, ax=axes[1]);\n\n\n\n\n\n\n\n\nUna forma simple de aumentar el ESS es aumentar la cantidad de muestras, pero podría darse el caso que el ESS crezca muy lento con el número de muestras, por lo que aún si aumentáramos 10 veces la cantidad de muestras estaríamos por debajo de lo requerido. Una forma de estimar “cuanto nos falta” es usar az.plot_ess(⋅, kind=\"evolution\"). Este gráfico nos muestra como fue cambiando el ESS con cada muestra, lo que nos permite hacer proyecciones. En el siguiente ejemplo vemos que para cadenas_adecuadas el ESS crece linealmente con el número de muestras mientras que para cadenas_defectuosas no crece para nada. Este último caso no hay esperanzas de mejorar el ESS simplemente aumentando la cantidad de muestras.\n\n_, axes = plt.subplots(1, 2, figsize=(10,4), sharey=True)\naz.plot_ess(cadenas_adecuadas, kind=\"evolution\", ax=axes[0])\naz.plot_ess(cadenas_defectuosas,  kind=\"evolution\", ax=axes[1]);\n\n\n\n\n\n\n\n\n\n\n4.9.6 Error estándar del Monte Carlo (MCSE)\nUna ventaja del ESS es que no tiene escala, da igual si un parámetro varía entre 0.1 y 0.2 y otro entre -2000 y 5000, un ESS de 400 tiene el mismo significado en ambos casos. En modelos con muchos parámetros rápidamente podemos indentificar cuales parámetros son más problemáticos. Sin embargo, a la hora de reportar resultados no es muy informativo saber si el ESS fue de 1372 o 1501. Por que a la hora de reportar resultados la escala si es relevant. Por ejemplo, digamos que necesitamos estimar una variación de temperatura, una diferencia de 1 grado podría considerarse pequeña en un sistema de calefacción doméstico y muy, muy pequeña cuando se cocina en un pollo al horno, pero ese mismo valor es enorme si hablamos del aumento esperado de la temperatura en la Tierra en los próximos 50 años.\n¿Podemos conocer el error de un método MCMC? Si podemos. El teorema del límite central proporciona una primera pista. En términos generales, este teorema nos dice que el error es \\(\\frac{\\sigma}{\\sqrt{N}}\\) donde \\(\\sigma\\) es la desviación estándar a posteriori de un parámetro dado y \\(N\\) es el número de muestras de MCMC. Para simplificar las cosas, digamos que \\(\\sigma=1\\), esto nos dice que si tenemos 100 muestras, el error estándar será \\(\\frac{1}{\\sqrt{100}} = 0.1\\) y si, en cambio, tenemos 1000 muestras, entonces \\(\\frac{1}{\\sqrt{1000}} = 0,03\\). Observe que aumentamos el número de muestras 10 veces, pero el error disminuyó solo en un factor de \\(\\approx 3\\). Esto explica por qué si tenemos un problema de muestreo con un método MCMC aumentar el número de muestras sólo ayudara con problemas leves. No es que aumentar la cantidad de muestras no funcione en absoluto, es que pasado cierto punto el beneficio obtenido vs la cantidad de recursos se vuelve prácticamente nulo. Además para calcular el MCSE debemos considerar la correlación en el muestreo, es decir no tenemos \\(N\\) si no \\(ESS\\).\nA la hora de reportar resultados el MCSE nos brinda un límite a la precisión que podremos reportar. Es decir si para un parámetro el MCSE es 0.1, no tiene sentido reportar que la media de ese parámetro es 3.15. Ya que tranquilamente el valor correcto podría estar entre 3.4 y 2.8.\nUna de las cantidades devueltas por az.summary(⋅) es mc_error.\n\n\n4.9.7 Incremento de temperatura en kilpisjärvi\nEste ejemplo está adaptado de https://avehtari.github.io/casestudies/Digits/digits.html y https://www.youtube.com/watch?v=V6dgfckhezQ y lo vamos a usar para discutir algunas sutilezas que es importante considerar al momento de presentar resultados.\nKilpisjärvi es un lugar en el noroeste de Finlandia. Queremos evaluar si la temperatura durante los veranos está aumentando. Para ello vamos a analizar la temperatura media de los meses de junio, julio y agosto. Nuestros datos van desde 1952 hasta 2013.\n\n\nMostrar Código\nkilpisjärvi = pd.read_csv(\"datos/kilpisjärvi.csv\")\nkilpisjärvi.plot(\"year\", \"temperature\", kind=\"scatter\", figsize=(10, 4));\n\nx = kilpisjärvi.year - kilpisjärvi.year.mean()\ny = kilpisjärvi.temperature\n\n\n\n\n\n\n\n\n\nVamos a ajustar el modelo usando una regresión lineal Bayesiana. Para este ejemplo los detalles del modelo no son el foco de nuestro interés.\n\n\nMostrar Código\nwith pm.Model() as model_k:\n    α = pm.Normal(\"α\", y.mean(), 1)\n    β = pm.Normal(\"β\", 0, 0.1/3)\n    σ = pm.HalfNormal(\"σ\", 1)\n    μ = pm.Deterministic(\"μ\", α + β*x)\n    _ = pm.Normal(\"obs\", μ, σ, observed=y)\n    idata_k = pm.sample(random_seed=125)\n\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(idata_k, var_names=\"~μ\")\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nα\n9.310\n0.140\n9.045\n9.560\n0.002\n0.001\n5107.0\n3191.0\n1.0\n\n\nβ\n0.019\n0.008\n0.005\n0.034\n0.000\n0.000\n5349.0\n3001.0\n1.0\n\n\nσ\n1.118\n0.104\n0.924\n1.303\n0.002\n0.001\n4670.0\n3019.0\n1.0\n\n\n\n\n\n\n\n\nUsando az.summary() podemos ver que tenemos un bajo valor para \\(\\hat R\\) y elevado para ESS. Nos vamos a concentrar en reportar un valor para \\(\\beta\\), la pendiente de la regresión. Primero vamos a multiplicar el resultado por 100, de esta forma \\(\\beta\\) representará el aumento de temperatura por cada 100 años (según el modelo).\n\naz.summary(idata_k, kind=\"stats\", var_names=\"β\", round_to=5)*100\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nβ\n1.921\n0.786\n0.477\n3.376\n\n\n\n\n\n\n\n\nPor defecto ArviZ usa 0.94 como valor para el HDI. Este valor es arbitrario y podemos elegir el que consideremos conveniente. Por ej, si usáramos 0.8 obtendríamos:\n\naz.summary(idata_k, kind=\"stats\", var_names=\"β\", round_to=5, hdi_prob=0.8)*100\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_10%\nhdi_90%\n\n\n\n\nβ\n1.921\n0.786\n1.003\n2.98\n\n\n\n\n\n\n\n\nPor lo que redondeando podríamos reportar esto como un incremento medio de 2 grados con un 80% de probabilidad de que sea entre 1 y 3 grados. Fijensé que estamos exagerando ligeramente la temperatura media y el valor superior del intervalo, pero la diferencia es pequeña y esto nos deja con número redondos que son fáciles de discutir, comunicar, recordar, etc.\nOK, veamos que pasa con el MCSE\n\n(az.summary(idata_k, kind=\"all\", var_names=\"β\", round_to=5, hdi_prob=0.8)*100)[\"mcse_mean\"]\n\nβ    0.011\nName: mcse_mean, dtype: float64\n\n\n\n{\"β_mcse_mean\": f\"{az.mcse(idata_k)['β'].item()*100:.3f}\",\n \"β_mcse_10%\": f\"{az.mcse(idata_k, method='quantile', prob=0.1)['β'].item()*100:.3f}\",\n \"β_mcse_90%\": f\"{az.mcse(idata_k, method='quantile', prob=0.9)['β'].item()*100:.3f}\"}\n\n{'β_mcse_mean': '0.011', 'β_mcse_10%': '0.031', 'β_mcse_90%': '0.030'}\n\n\nEl MCSE para la estimación media es aproximadamente 0,01 y para los percentiles del 10% y 90% aproximadamente 0,03. Si los multiplicamos por 2 (solo por que es “común” usar dos desvíos estándard), el rango probable de variación debido al muestreo es ±0,02 para la media y ±0,06 para el intervalo.\nDe esto podemos esperar que la media probablemente varíe de 1,92 ±0,02, por lo tanto, de 1,90 a 1,94. Por lo tanto, es seguro informar que la media es 2. Podemos hacer un cálculo similar para el límite superior e inferior y veremos que reportar el intervalo como 1-3, es razonable.\nComo alternativa o de forma complementaria podríamos estar interesados en reportar la probilidad de que exista un aumento, es decir la probabilidad que \\(\\beta\\) sea positivo.\n\n{\"mean\":f\"{np.mean(idata_k.posterior['β'] &gt; 0).item()*100:.1f}\",\n \"mcse\":f\"{az.mcse(idata_k.posterior['β'] &gt; 0)['β'].item()*100:.1f}\"}\n\n{'mean': '99.2', 'mcse': '0.1'}\n\n\nEsto lo podríamos reportar como\n\nExiste entre un 98.7% a un 99.5% de posibilidad que la temperatura se haya incrementado\nExiste un 99% de chance que la temperatura se haya incrementado\nEstamos bastante seguros que la temperatura se ha incrementado\n\nLos 3 enunciados son correctos, cual usar dependerá de cual sea nuestra audiencia.\n\n\n4.9.8 Montecarlo Hamiltoniano (HMC)\nSupongamos que queremos simular el movimiento de una partícula sobre una superficie. Si queremos que nuestra simulación sea fidedigna necesitamos describirla usando las leyes de la física. Una forma de describir el movimiento de la partícula es utilizando lo que se conoce como mecánica Hamiltoniana. Sin entrar en detalles diremos que un Hamiltonianio es una descripción de la energía total de un sistema físico. Si asumimos que no hay fricción ni ninguna otra forma de “disipar” energía podemos describir el compartamiento de partícula sobre una superficie con solo 2 componentes. La energía cinética y la potencial.\nLa energía cinética es la energía asociada al movimiento de la partícula y la potencial es la energía asociada a la posición de la partícula. Supongamos que nuestra superficie tiene una forma de U. Y nuestra partícula está en la parte más baja. Esa partícula tendrá energía potencial 0 y si está quieta energía cinética 0. Nuestra simulación será terriblemente aburrida, ya que la partícula permanecerá en esa posición para siempre. Para ponerle algo de diversión podemos empujar la partícula, es decir le impartimos momentum, la partícula se moverá hacia arriba perdiendo cada vez más energía cinética (cada vez se moverá más lento) y ganando potencial, hasta que llegue a un punto en que se detenga, en ese punto toda la energía cinética se habrá convertido en potencial y la partícula comenzara a caer y la energía potencial se convertirá en cinética. Como no hay fricción la energía total del sistema se mantiene constante. Y todo los cambios en la energía cinética son compensados por cambios en la energía potencial.\nPara un sistema como el que acabamos de describir la energía total será:\n\\[\n\\underbrace{H(\\overbrace{\\mathbf{q}}^{\\text{posición}}, \\overbrace{\\mathbf{p}}^{\\text{momemtum}})}_{\\text{Hamiltoniano}}  = \\underbrace{K(\\mathbf{p}, \\mathbf{q})}_{\\text{Energía cinética}} + \\underbrace{V(\\mathbf{q})}_{\\text{Energía potencial}}\n\\]\nDesde un punto de vista matemático da igual si la superficie es una U, una montaña rusa, un satélite en órbita o incluso una distribución a posteriori. En todos estos casos podemos describir el movimiento de la partícula usando un Hamiltoniano.\nLa siguiente figura muestra un ejemplo de un distribución a posteriori 2D y multiples trayectorias de una partícula. En la figura se puede ver que iniciamos una simulación, la detenemos, marcamos un punto y empezamos desde ese punto empujando de vuelta la particula con una fuerza y direcciones arbitrarias.\n\n\n\nEn el caso de la distribución a posteriori la posición de la particula son los valores de los parámetros. La energía potencial vendrá dada por la densidad de probabilidad a posteriori, estrictamente por el menos logaritmo de esa densidad. Y el momentum es una variable auxiliar. Es decir una variable completamente inventada, pero útil por que nos permite calcular el hamiltoniano.\n\\[\nH(\\mathbf{q}, \\mathbf{p}) = \\overbrace{-\\log p(\\mathbf{p} \\mid \\mathbf{q})}^{K(\\mathbf{p}, \\mathbf{q})} \\overbrace{- \\log p(\\mathbf{q})}^{ + V(\\mathbf{q})}\n\\]\nFijensé que en este punto no estamos haciendo ninguna analogía, estrictamente un Hamiltonian MonteCarlo es un método que simula el movimiento de una partícula en un espacio de parámetros.\nA grandes rasgos un HMC tiene dos pasos que se repiten hasta obtener la cantidad de muestras necesarias:\n\nGenerar un nuevo punto a partir del hamiltoniano\nAceptar o rechazar ese nuevo punto según el criterio de metropolis.\n\nPara generar mejor intuición recomiendo jugar con ese demo\n\n\n4.9.9 Propuestas aleatorias vs hamiltonianos\nPor qué es buena idea usar el Hamiltoniano? Porque estamos explorando la distribución a posteriori siguiendo una representación fidedigna de la misma. OK, esto es cierto pero no genera demasiada intuición. Veamos un par de enfoques alternativos.\nEn un MH la propuesta es aleatoria, es como querer encontrar algo en una habitación desconocida a oscuras, hay que ir a tientas. Si la habitación es pequeña y simple (cuadrada, con pocos muebles, escaleras etc) hacerlo a ciegas no será tarea demasiado compleja. Sin embargo con el Hamiltoniano es como tener una linterna, ahora podemos ver, al menos localmente, que hay en la habitación, por lo que recorrerla será más eficiente.\nVamos con otra explicación, para resolver un hamiltoniano necesitamos calcular derivadas, las derivadas nos dan información sobre la curvatura de una función, por ejemplo el cálculo de la primer derivada en un punto nos dice hacia donde (de)crece una función. Si siguiéramos la derivada hacia donde crece la función, eventualmente llegaríamos a un máximo (asumiendo que este existe). Esto se llama maximizar una función y de hecho muchos métodos de minimización de funciones como los encontrados en SciPy.optimize utilizan derivadas. Al agregar el momemtum podemos hacer algo más interesante, no solo podemos encontrar máximos, también podemos escapar de ellos. Esto nos permite obtener puntos de toda la distribución a posteriori de forma eficiente. Esto es importante en estadística Bayesiana, ya que no solo queremos el máximo, si no una descripción de toda la distribución a posteriori.\n\n\n\n\n\n4.9.10 HMC dinámico y adaptativo\nUn HMC tiene varios hipeparámetros, por ejemplo para simular una trayectoria tenemos que hacerlo de a pasos discretos, mientras más pequeños los pasos más fidedigna la simulación, pero también más costosa. Otro hiperparámetro es la longitud de cada simulación si esta es muy corta demoraremos mucho tiempo en explorar la distribución a posteriori, pero si está es muy larga corremos el riesgo de retornar al punto de partida, o sus inmediaciones, es decir habremos gastado un montón de recursos para terminar en el mismo lugar.\nEn la siguiente figura se muestran tres ejemplos. A la izquierda el paso es muy corto, por lo que la exploración no es eficiente, en el centro tenemos un mejor paso pero simulamos durante tanto tiempo que terminamos regresando al punto de partida. Finalmente y a la derecha tanto el paso como el tiempo de simulación son adecuados. Decimos que es adecuado, ya que logramos genear un nuevo punto que simultaneamente está alejado en el espacio de los parámetros, pero con alta probabilidad de aceptación. De hecho en este ejemplo la probabilidad de aceptación es 1, ya que el valor de la pdf es el mismo para el punto de partida y para el punto final.\n\n\n\nEste es otro ejemplo, en cada caso se muestra una densidad de probabilidad que va de más probable (amarillo) a menos probable (violeta), las flechas naranjas indican la trayectoria calculada de a pasos. En en el primer caso vemos una trayectoria elíptica tan larga que vuelve al punto de partida. En el segundo ejemplo vemos que el paso no es adecuado, esto produce una simulación inestable que se manifiesta en divergencias de la trayectoria correcta. En este último caso, y como en el ejemplo anterior, vemos que tanto el paso como el tiempo de simulación son adecuamos y la propuesta genera un punto alejado en el espacio de los parámetros, pero con alta probabilidad de aceptación (1 en este caso).\n\n\n\nLas divergencias ocurren cuando hay cambios de “curvatura” demasiado bruscos. Es decir cuando la partícula pasa de zonas de baja densidad de probabilidad a zonas de alta densidad o viceversa. En estos casos el método de integración numérica que se utiliza para resolver el hamiltoniano no es suficientemente preciso. PyMC registra cuando las divergencias ocurren y como veremos más adelante, es posible utilizar las divergencias para diagnosticar problemas con el método de muestreo.\nAl igual que en un MH adaptativo, en un HMC también necesitamos ajustar la matriz de covarianza, usualmente llamada Matriz de Masa (mass matrix). En HMC esta matriz es la que determina el momemtum.\nCuando los hiper-parámetros de un HMC son adecuados, el muestreo es muy eficiente. De hecho es mucho más eficiente que un MH. Los valores de los hiper-parámetros dependen esencialmente de la geometría de la distribución a posteriori, por lo que no existe un solo conjunto de hiper-parámetros mejor que los demás. Es por ello que en la práctica estos se calculan de forma adaptativa corriendo una cantidad de pasos de HMC los cuales se utilizan para ajustar eso hiper-parámetros automáticamente y luego se descartan.\nNUTS (No U-Turn sampler), el sampler por defecto en PyMC es un HMC dinámico y adaptativo. El nombre proviene de una rutina del método que evita que las trayectorias den vueltas en U. Este método detecta en cada paso de si estamos retornando el punto de partida, de ser así detiene el paso, evalúa si aceptar o no y comienza un nuevo paso. Al evitar trayectoria que vuelven al punto de partida, NUTS es capaz de explorar la distribución a posteriori de forma más eficiente.\n\n\n4.9.11 Diagnóstico de algoritmos basados en gradiente\nDebido a su funcionamiento interno, algoritmos como NUTS ofrecen algunas pruebas específicas que no están disponibles para otros métodos. Generalmente estas pruebas son muy sensibles\nPara ejemplificar esto vamos a cargar dos InferenceData de modelos pre-calculados. Los detalles de como se generaron estos idatas no son relevantes por el momento. Solo diremos que son dos modelos que son matemáticamente equivalente pero parametrizados de formas distintas. En este caso la parametrización afecta la eficiencia del sampler. El modelo centrado es muestreado de forma más eficiente que el modelo no centrado.\n\nidata_cm = az.load_arviz_data(\"centered_eight\")\nidata_ncm = az.load_arviz_data(\"non_centered_eight\")\n\n\n\n4.9.12 Divergencias\nUna ventaja de NUTS es que falla con el estilo. Esto sucede por ejemplo al intentar pasar de regiones de baja curvatura a regiones de alta curvatura. En estos casos las trayectorias numéricas pueden divergir. En esencia esto sucede porque en esos casos no existe un único conjunto de hiper-parámetros que permita el muestreo eficiente de ambas regiones. Por lo que una de la regiones es muestreada adecuandamente y cuando el sampler se mueve hacia la otra región falla. Las trayectorias numéricas divergentes son identificadores extremadamente sensibles de vecindarios patológicos.\nEl siguiente ejemplo muestra dos cosas el modelo no centrado muestra varias divergencias (círculos turquesas) agrupados en una región. En el modelo centrado, que no tiene divergencias, se puede ver que alrededor de esa misma región hay muestras para valores más pequeños de tau. Es decir el modelo no centrado falla en muestrear una región, pero al menos avisa que está teniendo problemas en muestrear esa región!\n\n_, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5), constrained_layout=True)\n\n\nfor ax, idata, nombre in zip(axes.ravel(), (idata_cm, idata_ncm), (\"centrado\", \"no_centrado\")):\n    az.plot_pair(idata, var_names=['theta', 'tau'], coords={'school':\"Choate\"}, kind='scatter',\n                 divergences=True, divergences_kwargs={'color':'C1'},\n                 ax=ax)\n    ax.set_title(nombre)\n\n\n\n\n\n\n\n\n\naz.plot_parallel(idata_cm, figsize=(12, 4));",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#qué-hacer-cuando-los-diagnósticos-no-dan-bien",
    "href": "04_Flujo_de_trabajo_bayesiano.html#qué-hacer-cuando-los-diagnósticos-no-dan-bien",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.10 Qué hacer cuando los diagnósticos no dan bien?",
    "text": "4.10 Qué hacer cuando los diagnósticos no dan bien?\n\n\n Más muestras o más pasos de tuning. Esto solo suele ser útil cuando los problemas son menores\n Burn-in. Los métodos MCMC, pueden demorar un tiempo en converger. En estos casos una solución simple es eliminar la primer porción de muestras, lo que se llama burnin. Software moderno como PyMC utiliza una cantidad de muestras para ajustar los hiper-parámetros de los métodos de muestreo. Por defecto esas muestras son eliminadas, por lo que en general no es necesario hacer burn-in manualmente. Pero lo mencionamos, ya que es una práctica que suele mencionarse en la literatura.\n Cambiar el método de muestreo! \nReparametrizar el modelo\n Mejorar las distribuciones a priori \n\nEl teorema popular de la estadística computacional: Cuando tienes problemas computacionales, a menudo hay un problema con tu modelo. La recomendación NO es cambiar la distribución a priori para mejorar la calidad del muestreo. La recomendación es que si el muestreo es malo, quizá el modelo también lo sea. En ese caso, podemos pensar en mejorar el modelo, una forma de mejorarlo es usar conocimiento previo para mejorar las distribuciones a priori.\n\nAlgunos modelos pueden expresarse en más de una forma, todas matemáticamente equivalentes. En esos casos, algunas parametrizaciones pueden ser más eficientes que otras. Por ejemplo, como veremos más adelante con modelos lineales jerárquicos.\nEn el caso de las divergencias, estas suelen eliminarse aumentando la tasa de aceptación (pm.sample(..., target_accept=x) x&gt;0.8)\nLeer los mensajes de advertencia y sugerencias de PyMC! ;-)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#una-hoja-de-ruta-para-el-bayesian-workflow",
    "href": "04_Flujo_de_trabajo_bayesiano.html#una-hoja-de-ruta-para-el-bayesian-workflow",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.11 Una hoja de ruta para el Bayesian workflow",
    "text": "4.11 Una hoja de ruta para el Bayesian workflow\nA continuación se describen una serie de consejos y recomendaciones a modo de referencia rápida, sobre como encarar un análisis de datos y modelado. Las recomendaciones están orientadas a estadística Bayesiana en particular, pero pueden ser útiles al utilizar otro tipo de herramientas y modelos.\nLas recomendaciones están escritas de forma lineal, pero en la práctica, es posible que debas retroceder uno o más pasos y, a veces, omitir pasos. Piensa en estas notas, no como una partitura de una pieza clásica que un violinista tiene que seguir exactamente, sino como la partitura que sigue un bajista de Jazz, eres libre de improvisar, reorganizar algunas partes y omitir otras, e incluso puedes agregar tus propias notas!\n\n4.11.1 Resume el problema\nResuma los puntos clave de su problema y lo que le gustaría aprender de los datos. Piensa también en los demás, en lo que a tu jefe, cliente o colega le gustaría saber o aprender. No es necesario que esto sea muy completo; puedes revisar los objetivos más adelante, pero pueden ayudarte a organizar tus esfuerzos de modelado y evitar desviaciones excesivas.\nComuníquese con las partes interesadas cuando surjan dudas. Una respuesta de la persona adecuada, puede ahorrarnos horas de trabajo.\nA veces no tendrás una idea clara de como enfocar un análisis; tu única expectativa podría ser obtener “algo útil” de un conjunto de datos, y eso está bien. Pero otras veces puede que incluso sepas qué tipo de modelo quieres, tal vez tu jefe te pidió explícitamente que ejecutaras tal o cual análisis. Si ya sabe qué tipo de modelo o herramienta es necesaria, pero no está muy familiarizado con el enfoque, busque qué métodos, métricas o visualizaciones son comunes para ese problema/datos y pida consejo a otros. Esto es más importante cuanto menos familiarizado esté con ese tipo de problema/datos. Si está familiarizado, es posible que ya sepa qué métodos, visualizaciones y resúmenes desea utilizar u obtener.\nEscriba todos estos elementos preliminares como una lista de puntos a tener en cuenta o una hoja de ruta a seguir, en problemas complejos es fácil perder el foco. Esta lista puede ser revisada y actualizada de ser necesario, pero es importante establecer expectativas preliminares de lo que es deseable e ir actualizándolas según lo que sea posible. Quizá los datos no sirvan para contestar lo que nos interesa, o quizá necesitamos información extra o incluso puede que hayamos encontrado algo aún mas importante que lo que queríamos originalmente.\n\n\n4.11.2 Familiarízate con los datos\nSiempre es una buena idea realizar un análisis exploratorio de los datos. Modelar ciegamente tus datos te lleva a todo tipo de problemas. Tomarse el tiempo de mirar los datos es rara vez una pérdida de tiempo y al contrario suele ahorrarnos tiempo y proporcionar ideas útiles. A veces un buen resumen de los datos puede ser suficiente para nuestro propósito y hacer innecesarias otras aproximaciones más complejas como modelos estadísticos o de otros tipos.\nLa exploración de los datos debe conducir al entendimiento de los mismos. La forma exacta de lograr esto puede variar mucho de un conjunto de datos a otro y de un análisis a otro. Pero hay comprobaciones que suelen ser útiles, como comprobar si hay valores faltantes o errores en los datos. Es importantes considerar el contexto. Una valor de 200 es razonable si se refiere al peso en gramo de frutas, pero problemático si se refiere a registros de clima en el planeta Tierra. ¿Son correctos los tipos de datos? ¿Todos los valores que deberían ser números, son realmente números (generalmente enteros o flotantes) o son cadenas? ¿Qué variables son categóricas? ¿Cuáles son continuos? En esta etapa, es posible que deba realizar una limpieza de sus datos. Esto le ahorrará tiempo en el futuro. Y es posible que sea necesario comunicarse con quien generó o proveyó los datos, para asegurarse que estamos interpretando de forma correcta los datos y que cualquier procesamiento de los mismos es correcto.\nPor lo general, también nos gustaría hacer algunos gráficos, histogramas, diagramas de caja, diagramas de dispersión, matrices de correlaciones, etc. Además de los gráficos, también calcule resúmenes numéricos, medias y medianas, para todos los datos, o agrupando los datos, etc.\nAcá es importante llevar registro de lo que se va observando. Cualquier cosa que resulte llamativa, inesperada o que consideremos relevante para análisis posteriores. En esta etapa los gráficos y análisis no tienen que ser extremadamente prolijos. Después de todo es un análisis preliminar, pero mantener cierto orden es de utilidad. Un análisis más o menos ordenado puede ser suficiente para compartir en una discusión técnica con colegas o clientes. Incluso puede ser muy útil para nuestros yo futuro, nada tan frustrante como retomar un análisis luego de un par de meses y no entender que fue lo que nosotros mismos hicimos!\n\n\n4.11.3 Cuente una historia para los datos\nA menudo resulta útil pensar en cómo se podrían haber generado los datos. Esto suele denominarse proceso generador de datos o mecanismo de generación de datos. No necesitamos descubrir el mecanismo verdadero, muchas veces sólo necesitamos pensar en mecanismos plausibles.\nHaz dibujos y trata de ser muy esquemático, garabatos y figuras geométricas deberían ser suficientes a menos que seas un buen dibujante. Este paso puede ser complicado, así que usemos un ejemplo. Digamos que estás estudiando los niveles de agua de un lago, piensa en qué hace que el agua aumente; lluvia, ríos, etc, y lo que la hace disminuir; evaporación, animales bebiendo agua, producción de energía, etc. Intenta pensar cuáles de estos elementos pueden ser relevantes y cuáles podrían ser insignificantes. Utilice todo el contexto que tenga para su problema.\nIntente mantenerlo simple pero no más simple. Por ejemplo, un mecanismo podría ser “El peso de los cerdos aumenta cuando se les dá mayor cantidad de maíz”, ese es un buen mecanismo si todo lo que necesita predecir son sus ganancias por la venta de cerdos. Pero será un mecanismo demasiado simplista si se estudia la absorción intestinal a nivel celular.\nSi se te ocurren historias alternativas y no sabes decidir cuál es mejor. ¡No te preocupes, enuméralas todos! ¡Quizás podamos usar los datos para decidir!\n\n\n4.11.4 Escribe un modelo\nIntente traducir el proceso generador de datos a un modelo. Si te sientes cómodo con las matemáticas, úsalas. Si prefiere una representación visual como un modelo gráfico, úsela. Si te gusta el código, hazlo. Los modelos incompletos están bien como primer paso. Por ejemplo, si usa código, siéntase libre de usar pseudocódigo o agregar comentarios para señalar los elementos que faltan mientras piensa en el modelo. Puedes refinarlo más tarde.\nIntente comenzar de manera simple, no use jerarquías, preferible empezar con priors unidimensionales e independientes, omita interacciones para modelos lineales, etc. Si por alguna razón el punto de partida es un modelo complejo, está bien, puede pensar en formas de simplificarlo.\nA veces, es posible que puedas utilizar un modelo de libro de texto estándar o algo que hayas visto en una publicación de blog o en una charla. Es común que para ciertos problemas la gente tienda a utilizar ciertos modelos “predeterminados”. Puede que sea un buen comienzo, o quizá todo lo que necesite. Mantenga las cosas simples, a menos que necesite algo más.\nEste es un buen paso para pensar en tus antecedentes, no solo qué familia vas a utilizar, sino qué parámetros específicos. Si no tienes ni idea, utiliza un previo vago. Pero si tienes alguna información úsala. Intente codificar información muy general, como que este parámetro no puede ser negativo, o es probable que este parámetro sea más pequeño que esto o esté dentro de este rango. Busque la fruta madura, normalmente eso será suficiente. La excepción será cuando tengas suficiente información de buena calidad para definir un previo muy preciso, pero incluso entonces, eso es algo que puedes agregar más adelante.\n\n\n4.11.5 Implementar el modelo\nEscriba el modelo en un lenguaje de programación probabilístico. Si usó código en el ejemplo anterior, la línea entre este paso y el anterior puede ser difusa, está bien. Intente mantener el modelo simple al principio; agregaremos más capas más adelante a medida que sigamos iterando el flujo de trabajo. Empezar de forma sencilla normalmente le ahorra tiempo a largo plazo. Los modelos simples son más fáciles de depurar y depurar un problema a la vez es generalmente menos frustrante que tener que solucionar varios problemas antes de que nuestro modelo se ejecute.\nUna vez que tenga un modelo, verifique que el modelo se compile y/o ejecute sin errores. Al depurar un modelo, especialmente en una etapa inicial del análisis, es posible que desee trabajar con un conjunto de datos reducido, por ej un 50% o 10% si el conjunto de datos es demasiado grande, o tal vez comenzar con solo unas pocas covariables, y luego agrega el resto. Esto puede ayudar a acelerar el modelo, para que pueda cambiarlo e iterar más rápido. Esto tiene la desventaja de que es posible que se pierdan los datos necesarios para descubrir algún patrón relevante, pero podría estar bien al principio, cuando suele ser el momento en el que cometerá la mayoría de los errores o tendrá mayores dudas sobre lo que está haciendo. En las primeras etapas, también puede reducir la cantidad de pasos de ajuste y muestreo.\n\n\n4.11.6 Evaluar la distribución predictiva a priori\nGeneralmente es una buena idea generar datos a partir de la distribución predictiva a priori y compararlos con su conocimiento previo. ¿Está la mayor parte de la distribución simulada dentro de un rango razonable? ¿Existen valores extremos? Utilice valores de referencia como guía. Los valores de referencia son datos empíricos u observaciones históricas, normalmente serán valores mínimos, máximos o esperados. Evite comparar con los datos observados, ya que eso puede generar problemas si no es lo suficientemente cuidadoso.\n\n\n4.11.7 Calcular la distribución a posteriori\nHay muchas formas de calcular el a posteriori; en esta serie de recomendaciones asumimos el uso de métodos MCMC, ya que son los métodos más generales y más usados.\n\n\n4.11.8 Evaluar muestras\nCuando utilizamos métodos MCMC, debemos comprobar que las muestras sean lo suficientemente buenas. Para ello, necesitamos calcular diagnósticos como \\(\\hat R\\) (r-hat) y el tamaño de muestra efectivo (ESS). Y evalúe gráficos como traceplot y rank-plots. No es necesario que los diagnósticos sean tan buenos en las primeras etapas del flujo de trabajo. Al mismo tiempo, un diagnóstico muy malo podría ser una señal de un problema con nuestro(s) modelo(s).\n\n\n4.11.9 Validar el modelo\nHay muchas formas de validar su modelo, como una prueba predictiva a posteriori, valores p Bayesianos, análisis de residuos, recuperación de parámetros a partir de datos sintéticos. O una combinación de todo esto. A veces es posible que puedas utilizar un conjunto de extra de datos para evaluar el rendimiento predictivo de tu modelo. El objetivo principal aquí es encontrar si el modelo es lo suficientemente bueno para su propósito y qué limitaciones puede tener. Todos los modelos tendrán limitaciones, pero algunas limitaciones pueden ser irrelevantes en el contexto de su análisis, algunas pueden valer la pena eliminarlas mejorando los modelos y otras simplemente vale la pena saber que existen.\n\n\n4.11.10 Comparar modelos\nSi logras conseguir más de un modelo (normalmente es una buena idea), es posible que tengas que definir cuál te gustaría conservar (suponiendo que sólo necesitas uno). Para comparar modelos se pueden utilizar validación cruzada (incluido LOO) y/o criterios de información. Pero también puedes utilizar los resultados del paso anterior (validación del modelo). A veces comparamos modelos para mantener un solo modelo, la comparación de modelos también puede ayudarnos a comprender mejor un modelo, sus fortalezas y limitaciones, y también puede ser una motivación para mejorar un modelo o probar uno nuevo. El promediado de modelos, es decir, la combinación de varios modelos en uno solo, suele ser una estrategia sencilla y eficaz para mejorar el rendimiento predictivo.\n\n\n4.11.11 Resumir resultados\nResuma los resultados de una manera que le ayude a alcanzar sus objetivos. ¿Logró responder las preguntas clave? ¿Es esto algo que convencerá a tu jefe o al departamento de marketing? Piense en formas efectivas de mostrar los resultados. Si su audiencia es muy técnica, haga un resumen técnico, pero si su audiencia solo se preocupa por maximizar ganancias, concéntrese en eso. Intenta utilizar resúmenes que sean fáciles de entender sin ocultar detalles valiosos, no querrás engañar a tu audiencia.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#comentarios-finales",
    "href": "04_Flujo_de_trabajo_bayesiano.html#comentarios-finales",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.12 Comentarios finales",
    "text": "4.12 Comentarios finales\nEn conclusión, el flujo de trabajo Bayesiano no es un conjunto rígido de instrucciones sino un enfoque de modelado dinámico y en evolución. Piense en ello como un marco conceptual que guía sus pensamientos y acciones en la búsqueda de mejores modelos y análisis.\nLos métodos, herramientas y prácticas para el análisis Bayesiano mejorarán con el tiempo. A medida que avance la tecnología, es esperable una mayor automatización y mejorar en las herramientas de software y esta guía evolucionará en consecuencia.\nAdemás, el flujo de trabajo Bayesiano subraya la importancia de valorar tanto el viaje como el destino. Fomenta una comprensión más profunda del problema y mejora las habilidades aplicables en diversos dominios. En última instancia, el flujo de trabajo Bayesiano representa un compromiso con el aprendizaje y el refinamiento continuos en el modelado y el análisis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "04_Flujo_de_trabajo_bayesiano.html#ejercicios",
    "href": "04_Flujo_de_trabajo_bayesiano.html#ejercicios",
    "title": "4  Flujo de trabajo Bayesiano",
    "section": "4.13 Ejercicios",
    "text": "4.13 Ejercicios\n\n(Borrador, Está bien esto como ejercicio o lo demostramos en el texto?) Demuestre que la transformada integral de probabilidad es cierta.\n(Borrador) Usando la transformada integral de probabilidad describa una método general para generar muestreas aleatorias de cualquier distribución a partir de una distribución uniforme.\n(Borrador) deberíamos tener una serie de ejercicios donde calculen los valores-p marginales para distribuciónes sintéticas, por tomar una Gaussiana de base y comparar con una gaussian más ancha, otra más angosta y otra desplazada y ver en cada caso como la distribución se desvía de la uniforme.\n(Borrador) correr los dignósticos de convergencia en algún modelo anterior y escribir un breve reporte?\n(Borrador) deberíamos tener un ejemplo donde comparen un par de modelos\n(Borrador) deberíamos tener un ejemplo donde reporten un resultado teniendo en cuenta el MCSE.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Flujo de trabajo Bayesiano</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html",
    "href": "05_GLMS.html",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "",
    "text": "5.1 La idea central en regresión lineal\nAnteriormente vimos el modelo normal, que (omitiendo las distribuciones a priori) definimos como:\n\\[\nY \\sim \\mathcal{N}(\\mu, \\sigma)\n\\]\nLa idea central de la regresión lineal es extender este modelo, agregando una variable predictora \\(X\\) a la estimación de la media \\(\\mu\\):\n\\[\n\\begin{aligned}\n\\mu &= \\alpha + \\beta X  \\\\\nY &\\sim \\mathcal{N}(\\mu, \\sigma)\n\\end{aligned}\n\\]\nEste modelo dice que existe una relación lineal entre la variable \\(X\\) y la variable \\(Y\\). Pero esta relación solo es válida en promedio, por lo que agregamos un término de error o ruido \\(\\sigma\\). Además, el modelo dice que la media de \\(Y\\) es una función lineal de \\(X\\), con intercepto \\(\\alpha\\) y pendiente \\(\\beta\\). El intercepto nos dice el valor de \\(Y\\) cuando \\(X=0\\), la pendiente nos dice el cambio en \\(Y\\) por unidad de cambio en \\(X\\). Debido a que no conocemos los valores de \\(\\alpha\\), \\(\\beta\\) o \\(\\sigma\\), debemos determinar una distribución a priori para estos parámetros.\nUna suposición típica cuando se establecen priors para modelos lineales es suponer que son independientes. Esta suposición simplifica enormemente la elección de priors, ya que en vez de definir una distribución conjunta para los 3 parámetros, podemos definir 3 distribuciones por separado. Al menos en principio, \\(\\alpha\\) y \\(\\beta\\) pueden tomar cualquier valor en los reales, por lo que es común usar a prioris normales para ellos. En cambio \\(\\sigma\\) debe ser un número positivo, por lo que es común usar distribuciónes como seminormal, exponencial, gamma-inversa, etc.\nLos valores que puede tomar el intercepto pueden variar mucho de un problema a otro. Por ejemplo, yo solía trabajar con problemas donde era esperable que \\(\\alpha\\) estuviera alrededor de cero y con una desviación estándar muy por debajo de 1. Pero esta experiencia (casi anecdótica) es dificil de trasladar a cualquier otro problema. Con respecto a la pendiente (\\(\\beta\\)), puede ser más fácil tener una noción informada. Usualmente tenemos una idea del signo de la pendiente, por ejemplo esperamos que el peso de un animal aumente, en promedio, con la variable largo (o altura). Para \\(\\sigma\\), podemos establecerlo en un valor grande en la escala de la variable \\(Y\\), por ejemplo, 2 veces el valor de su desviación estándar. Debemos tener cuidado al usar los datos observados para estimar a prioris, por lo general, está bien si los datos se usan para evitar el uso de a prioris muy restrictivos. Si no tenemos demasiado conocimiento del parámetro, tiene sentido asegurarse que la distribución a priori sea realmente vaga. En cambio, si queremos definir distribuciones a priori más informativas, entonces no deberíamos obtener esa información de los datos observados, sino que deberíamos obtenerla de nuestro conocimiento del dominio.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#bicicletas-lineales",
    "href": "05_GLMS.html#bicicletas-lineales",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.2 Bicicletas lineales",
    "text": "5.2 Bicicletas lineales\nAhora que tenemos una idea general de cómo luce un modelo lineal Bayesiano, tratemos de cimentar esta idea con un ejemplo.\nVamos a empezar muy sencillo, tenemos un registro de temperaturas y del número de bicicletas alquiladas en una ciudad. Queremos modelar la relación entre la temperatura y el número de bicicletas alquiladas. Usaremos bike-sharing dataset del repositorio UCI Machine Learning Repository. El conjunto de datos original contiene 17379 registros, cada registro tiene 17 variables, pero para este ejemplo usaremos tan solo 348 registros y dos variables temperatura y alquiladas. La variable ‘temperatura’ es la temperatura en Celsius y ‘alquiladas’ es el número de bicicletas alquiladas.\nCarguemos los datos y grafiquémoslos\n\nbicis = pd.read_csv(\"datos/bicis.csv\")\n\nbicis.plot(x=\"temperatura\", y=\"alquiladas\", kind=\"scatter\");\n\n\n\n\n\n\n\n\nConstruyamos un modelo lineal bayesiano para estos datos. La temperatura será nuestra variable independiente (nuestra “X”) y el número de bicicletas alquiladas será nuestra variable dependiente (nuestra “Y”). Vamos a utilizar el siguiente modelo:\n\nwith pm.Model() as modelo_bl:\n    α = pm.Normal('α', mu=0, sigma=100)\n    β = pm.Normal('β', mu=0, sigma=10)\n    σ = pm.HalfCauchy('σ', 10)\n    μ = pm.Deterministic('μ', α + β * bicis.temperatura)\n    _ = pm.Normal('y_pred', mu=μ, sigma=σ, observed=bicis.alquiladas)\n\npm.model_to_graphviz(modelo_bl)\n\n\n\n\n\n\n\n\nAntes de calcular la distribución a posteriori tomemos un momento para leer el código línea por línea y asegurarnos de entender lo que está pasando. Comparemos el código con la representación visual del modelo.\nComo ya dijimos, este modelo es similar a un modelo normal, la diferenciea principal es que la media se modela como una función lineal de la temperatura. El intercepto es \\(\\alpha\\) y la pendiente es \\(\\beta\\). El término de ruido es \\(\\sigma\\) y la media es \\(\\mu\\).\nAlgo importante a notar es que la variable \\(\\mu\\) es una variable determinista (pm.Deterministic). Le llamamos así ya que una vez conocidos los valores de \\(\\alpha\\) y \\(\\beta\\), el valor de \\(\\mu\\) queda determinado. En vez que μ = pm.Deterministic('μ', α + β * bikes.temperatura) podríamos haber escrito μ = α + β * bicicletas.temperatura o incluso _ = pm.Normal('y_pred', mu=α + β * bicicletas.temperatura, sigma=ϵ, observado=bicicletas.alquiladas) y el modelo sería el mismo. La única razón de usar pm.Deterministic, es que de esta forma le pedimos a PyMC que guarde los valores de \\(\\mu\\) en el InferenceData.\n\nwith modelo_bl:\n    idata_bl = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n\n\n\n\nVeamos un trace plot de idata_bl combinando todas las cadenas en una sola curva\n\naz.plot_trace(idata_bl, combined=True);  \n\n\n\n\n\n\n\n\nAlgo que suele resultar confuso o inesperado para muchos estudiantes es la gráfica para \\(\\mu\\), por qué hay tantas curvas? Porque a cada observaciones le corresponde una curva, para cáda valor de \\(X\\), hacemos\n\\[\n\\mu_i = \\alpha + \\beta + x_i\n\\]\nEs decir un valor de \\(\\mu\\) por cada valor de \\(X\\), además como \\(\\alpha\\) y \\(\\beta\\) son distribuciones. Entonces cada \\(\\mu_i\\) es también una distribución.\nPodemos comprobar que hay 348 distribuciones para \\(\\mu\\) inspeccionado el InfereceData, por ejemplo:\n\ncadenas, muestras, mus = idata_bl.posterior[\"μ\"].shape\nf\"{cadenas=}, {muestras=}, {mus=}\"\n\n'cadenas=4, muestras=1000, mus=348'\n\n\n\n5.2.1 Interpretando la media a posteriori\nHabiendo aclarado este punto vamos a focalizarnos en intepretar los parámetros del modelo, pero omitiendo μ. Hagamos un gráfico de las distribuciones a posteriori marginales para \\(\\alpha\\), \\(\\beta\\) y \\(\\sigma\\),\n\naz.plot_posterior(idata_bl, var_names=['~μ'], figsize=(10, 3));\n\n\n\n\n\n\n\n\nSi solo leemos las medias de cada distribución podemos decir que \\(\\mu = 69 + 7,9 X\\). Con esta información podemos decir que el valor esperado de bicicletas alquiladas cuando la temperatura es 0 es de 69 y por cada grado de temperatura el número de bicicletas alquiladas aumenta en 7,9. Así que para una temperatura de 28 grados esperamos alquilar \\(69 + 7.9 * 28 \\approx 278\\) bicicletas. Este es nuestro valor esperado, pero la distribución a posteriori también nos informa sobre la incertidumbre en torno a esta estimación. Por ejemplo, el HDI 94% para \\(\\beta\\) es (6,1, 9,7), por lo que por cada grado de temperatura el número de bicicletas alquiladas podría aumentar de 6 a unas 10.\nIncluso si omitimos la incertidumbre a posteriori, y solo prestaramos atención a las medias, tenemos incertidumbre sobre el número de bicicletas alquiladas debido al valor de \\(\\sigma\\) de 170. Entonces, si decimos que para una temperatura de 28 grados, esperamos alquilar 278 bicicletas, no debería sorprendernos que el número real resulte estar entre \\(\\approx 100\\) y \\(\\approx 500\\) bicicletas.\nAhora vamos a crear algunas gráficas que nos ayudarán a visualizar la incertidumbre combinada de estos parámetros. En una primer lectura recomiendo saltearse el código y focalizarse en las figuras y su interpretación.\nLa siguiente figura tiene dos paneles. Ambos muestran del número medio de bicicletas alquiladas en función de la temperatura. La diferencia está en como se representa la incertidumbre. Para el panel izquierdo, tomamos 50 muestras de la distribución a posteriori de \\(\\mu\\) y las dibujamos como líneas individuales. Para el panel derecho tomamos todas las muestras a posteriori de \\(\\mu\\) y las usamos para calcular el HDI 94%.\n\nposterior = az.extract(idata_bl, num_samples=50)\nx_plot = xr.DataArray(np.linspace(bicis.temperatura.min(), bicis.temperatura.max(), 50), dims=\"plot_id\")\nlinea_media = posterior['α'].mean() + posterior['β'].mean() * x_plot\nlineas = posterior['α'] + posterior['β'] * x_plot\nhdi_lines = az.hdi(idata_bl.posterior['μ'])\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\naxes[0].plot(bicis.temperatura, bicis.alquiladas,  '.', color=\"0.75\",  zorder=-3)\nlines_ = axes[0].plot(x_plot, lineas.T, c='C1', alpha=0.5, label='lineas')\nplt.setp(lines_[1:], label=\"_\")\naxes[0].plot(x_plot, linea_media, c='C0', label='linea media')\naxes[0].set_xlabel('temperatura')\naxes[0].set_ylabel('bicis alquiladas')\naxes[0].legend()\n\naxes[1].plot(bicis.temperatura, bicis.alquiladas, '.', color=\"0.75\",  zorder=-3)\nidx = np.argsort(bicis.temperatura.values)\naxes[1].fill_between(bicis.temperatura[idx], hdi_lines[\"μ\"][:,0][idx], hdi_lines[\"μ\"][:,1][idx],\n                     color=\"C1\", label='HDI', alpha=0.5)\naxes[1].plot(x_plot, linea_media, c='C0', label='linea media')\naxes[1].set_xlabel('temperatura')\naxes[1].legend();\n\n\n\n\n\n\n\n\nAmbos paneles transmiten esencialmente la misma información, si volvemos a correr el código para generar el gráfico, las lineas serán diferentes, porque las 50 muestras serán distintas cada vez (salvo que fijemos una semilla). Sin embargo, el área sombreada será la misma, porque estamos utilizando todas las muestras ya calculadas. Si reajustamos el modelo (sin fijar una semillar), no solo obtendremos líneas diferentes, sino que el área sombreada también podría cambiar, pero la diferencia debería ser muy pequeña, caso contrario es probable que necesitemos más muestras (incrementar la candidad de draws en pm.sample(.))\nOK, pero ¿Por qué mostramos dos gráficos ligeramente diferentes si transmiten la misma información? Bueno, por un lado para resaltar que hay diferentes formas de representar la incertidumbre. ¿Cuál es mejor? Como de costumbre, eso depende del contexto, el área sombreada es una buena opción, es muy común y es simple de calcular e interpretar. Pero pueden darse situaciones donde nos interese mostrar muestras individuales de la distribución a posteriori, por ejemplo, la mayoría de las líneas podrían abarcar una determinada región, pero algunas podrían tener una pendiente muy alta. Un área sombreada podría opacar esta información. Al mostrar muestras individuales, puede ser una buena idea animarlas si las está mostrando en una presentación o en un video (ver Hypothetical Outcome Plots para obtener más información al respecto).\nOtra razón para mostrar estas figuras es que vean diferentes formas de extraer información de la distribución a posteriori. Si prestamos atención al código veremos que en la primera línea usamos az.extract toma la dimensión chain y draw y las apila en una sola dimensión sample, que puede ser útil para el procesamiento posterior. Además, usamos el argumento num_samples para solicitar una submuestra de la distribución a posteriori. Por defecto az.extract opera sobre el grupo posterior de un InferenceData. Si deseamos extraer información de otro grupo, podemos usar el argumento group. En la segunda línea, definimos un DataArray llamado x_plot, con valores igualmente espaciados empezando por la temperatura mínima observada y terminado en la máxima observada. La razón para crear un DataArray es poder usar las capacidades de alineación automática de Xarray (esto lo hacemos en las próximas dos líneas). Si usaramos un arreglo NumPy necesitariamos agregar dimensiones adicionales, lo que puede resultar confuso, la mejor manera de entender completamente lo que quiero decir es definir x_plot = np.linspace(bikes.temperature.min(), bikes.temperature.max()) e intentar rehacer el gráfico. En la tercer y cuarta línea de código, calculamos la media del posterior de \\(\\mu\\) para cada valor de x_plot las líneas individuales, respectivamente. Podríamos haber usado posterior['μ'], pero en su lugar reescribimos explícitamente el modelo lineal, lo hacemos para ser explícitos y con la esperanza de que te ayude a obtener más intuición sobre los modelos lineales.\n\n\n5.2.2 Interpretando las predicciones a posteriori\n¿Qué pasa si no solo estamos interesados en el valor esperado (promedio), sino que queremos pensar en términos de predicciones, es decir, en términos de bicicletas alquiladas? Bueno, para eso podemos usar la distribución predictiva a posteriori. Después de ejecutar la siguiente línea de código idata_lb contendrá un nuevo grupo posterior_predictive con una variable y_pred que representa la distribución predictiva a posteriori para el número de bicicletas alquiladas.\n\npm.sample_posterior_predictive(idata_bl, model=modelo_bl, extend_inferencedata=True, random_seed=123)\n\nSampling: [y_pred]\n\n\n\n\n\n\n\n\n\n\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 11MB\nDimensions:  (chain: 4, draw: 1000, μ_dim_0: 348)\nCoordinates:\n  * chain    (chain) int64 32B 0 1 2 3\n  * draw     (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\n  * μ_dim_0  (μ_dim_0) int64 3kB 0 1 2 3 4 5 6 7 ... 341 342 343 344 345 346 347\nData variables:\n    α        (chain, draw) float64 32kB 62.5 47.79 81.1 ... 85.27 59.62 78.58\n    β        (chain, draw) float64 32kB 8.966 8.725 6.576 ... 7.612 7.999 6.555\n    μ        (chain, draw, μ_dim_0) float64 11MB 91.9 58.21 ... 100.1 130.9\n    σ        (chain, draw) float64 32kB 168.5 172.8 168.4 ... 163.7 159.4 178.3\nAttributes:\n    created_at:                 2024-07-22T17:15:59.387370+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1\n    sampling_time:              2.4274613857269287\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000μ_dim_0: 348Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])μ_dim_0(μ_dim_0)int640 1 2 3 4 5 ... 343 344 345 346 347array([  0,   1,   2, ..., 345, 346, 347])Data variables: (4)α(chain, draw)float6462.5 47.79 81.1 ... 59.62 78.58array([[ 62.49743693,  47.7851502 ,  81.0967781 , ...,  74.92214114,\n         72.11017461,  68.94318738],\n       [ 74.62738274,  65.09123583,  32.61590784, ...,  59.77707482,\n         70.46653223,  75.8109043 ],\n       [ 65.74894981, 101.60876086,  86.60738904, ...,  91.21114365,\n        105.73948633,  57.62041875],\n       [ 85.79646577,  63.45579066,  41.66613253, ...,  85.26761107,\n         59.62264272,  78.57622637]])β(chain, draw)float648.966 8.725 6.576 ... 7.999 6.555array([[8.96576975, 8.72454039, 6.57649715, ..., 7.00435197, 7.70277124,\n        7.38297283],\n       [7.47514547, 8.26584494, 9.8874908 , ..., 8.68137832, 7.90494386,\n        6.78427703],\n       [8.50475798, 6.08482785, 7.30749554, ..., 5.78038701, 6.04893982,\n        8.94044506],\n       [6.63157403, 8.43311569, 9.00526467, ..., 7.61183246, 7.9991286 ,\n        6.55513651]])μ(chain, draw, μ_dim_0)float6491.9 58.21 83.47 ... 100.1 130.9array([[[ 91.89583584,  58.20927992,  83.47443449, ..., 100.3321058 ,\n          91.89143947, 134.05391293],\n        [ 76.39256772,  43.6123686 ,  68.19774917, ...,  84.60185483,\n          76.38828964, 117.4163567 ],\n        [102.66084811,  77.95136469,  96.48365156, ..., 108.84895096,\n         102.65762333, 133.58429155],\n        ...,\n        [ 97.88912994,  71.57209291,  91.31005632, ..., 104.47981939,\n          97.88569535, 130.82439581],\n        [ 97.36725215,  68.42608575,  90.1321647 , ..., 104.61511368,\n          97.3634751 , 133.58656549],\n        [ 93.15165878,  65.41205201,  86.21695277, ..., 100.09860853,\n          93.14803854, 127.86724334]],\n\n       [[ 99.1380845 ,  71.05216295,  92.11680223, ..., 106.17176335,\n          99.13441906, 134.28707533],\n        [ 92.19460939,  61.13783953,  84.430636  , ...,  99.97229065,\n          92.19055624, 131.06155978],\n        [ 65.03659306,  27.8869092 ,  55.74943415, ...,  74.34014914,\n          65.03174473, 111.52870819],\n...\n        [110.16480048,  88.44649457, 104.73537721, ..., 115.6038098 ,\n         110.16196607, 137.34484278],\n        [125.57371706, 102.84639355, 119.8920465 , ..., 131.26541902,\n         125.57075096, 154.01652547],\n        [ 86.93577905,  53.34437406,  78.53816476, ...,  95.34821994,\n          86.9313951 , 128.97477657]],\n\n       [[107.54113068,  82.62471014, 101.31220131, ..., 113.78105769,\n         107.53787889, 138.72355196],\n        [ 91.10763833,  59.42239195,  83.18655024, ...,  99.04271168,\n          91.10350315, 130.76111499],\n        [ 71.19403372,  37.35908585,  62.73553542, ...,  79.66746611,\n          71.18961799, 113.53782047],\n        ...,\n        [110.226504  ,  81.62701649, 103.07683386, ..., 117.3887974 ,\n         110.22277154, 146.01821276],\n        [ 85.85146411,  55.79681177,  78.33801303, ...,  93.37818074,\n          85.84754174, 123.4642837 ],\n        [100.0702557 ,  75.44102935,  93.91312285, ..., 106.23825943,\n         100.06704139, 130.89325896]]])σ(chain, draw)float64168.5 172.8 168.4 ... 159.4 178.3array([[168.5193324 , 172.75449318, 168.38667999, ..., 163.14853048,\n        160.84224916, 164.20176184],\n       [167.5906032 , 180.49112665, 169.93434131, ..., 152.39144481,\n        184.39053547, 187.05346251],\n       [169.08284223, 175.7237506 , 165.40491574, ..., 167.8089673 ,\n        166.59478807, 178.89837676],\n       [161.26600918, 172.03105632, 173.81270242, ..., 163.72896967,\n        159.42143163, 178.33931821]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))μ_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       338, 339, 340, 341, 342, 343, 344, 345, 346, 347],\n      dtype='int64', name='μ_dim_0', length=348))Attributes: (6)created_at :2024-07-22T17:15:59.387370+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :2.4274613857269287tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 11MB\nDimensions:       (chain: 4, draw: 1000, y_pred_dim_2: 348)\nCoordinates:\n  * chain         (chain) int64 32B 0 1 2 3\n  * draw          (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * y_pred_dim_2  (y_pred_dim_2) int64 3kB 0 1 2 3 4 5 ... 343 344 345 346 347\nData variables:\n    y_pred        (chain, draw, y_pred_dim_2) float64 11MB -6.052 50.2 ... 143.3\nAttributes:\n    created_at:                 2024-07-22T17:16:10.668979+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:chain: 4draw: 1000y_pred_dim_2: 348Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])y_pred_dim_2(y_pred_dim_2)int640 1 2 3 4 5 ... 343 344 345 346 347array([  0,   1,   2, ..., 345, 346, 347])Data variables: (1)y_pred(chain, draw, y_pred_dim_2)float64-6.052 50.2 64.69 ... 184.3 143.3array([[[-6.05155896e+00,  5.02047422e+01,  6.46926080e+01, ...,\n          3.76660321e+02,  3.28003382e+02, -2.50354642e+01],\n        [ 1.50492591e+02,  1.09691254e+02,  3.60819245e+02, ...,\n          1.47698056e+02, -3.67746203e+01,  9.18606093e+01],\n        [ 9.01975360e+01, -2.91342775e+02,  2.93138046e+02, ...,\n         -2.45628211e+02, -9.99494724e+01,  1.04579562e+02],\n        ...,\n        [ 1.90613993e+02, -1.83680288e+02,  2.26622238e+02, ...,\n          2.05949234e+02,  3.38825827e+02,  3.20729070e+02],\n        [-1.21152826e+02,  8.14465864e+01,  1.35818644e+02, ...,\n         -2.22302294e+02, -6.82669221e+01,  2.70600533e+02],\n        [ 2.71909184e+01, -2.91668328e+01,  8.93924135e+01, ...,\n          2.74103924e+02, -7.81866064e+01, -1.53368671e+02]],\n\n       [[ 4.39810655e+01,  1.23604195e+02,  3.15248981e+02, ...,\n         -3.09305335e+01,  3.42710548e+02,  7.73660265e+01],\n        [-1.66827808e+02, -7.14719365e+00,  1.49014032e+02, ...,\n          9.57363142e+01,  2.67616367e+02,  3.55588690e+01],\n        [ 2.21255761e+02,  1.20934237e+02,  3.83859099e+00, ...,\n          1.21233965e+02, -2.67192256e+02,  8.96933872e+01],\n...\n        [-9.73001731e+01,  1.22065471e+02, -7.01086631e+01, ...,\n          3.46960801e+02,  2.16748755e+02,  3.28927890e+02],\n        [ 3.75171296e+02,  2.31616710e+02,  3.20900178e+02, ...,\n         -3.88860388e+01,  2.33705523e+01,  8.36921175e+01],\n        [-2.25927075e+01,  3.72281197e+01, -1.66667266e+02, ...,\n          2.95374716e+02,  2.18755971e+02,  3.15278589e+02]],\n\n       [[ 2.23214995e+02,  1.95613273e+00,  6.26998927e+01, ...,\n          5.46011703e+01, -1.35335488e+02,  1.65455692e+02],\n        [ 2.38825080e+02,  4.02976096e+00, -6.26069488e+01, ...,\n          2.08303225e+02,  3.19734445e+01, -2.63227241e+02],\n        [-3.00792851e+01,  2.07819559e+01,  2.56357878e+02, ...,\n          1.25024308e+02, -5.97975929e+01, -1.06019622e+02],\n        ...,\n        [ 1.76273949e+02, -1.17196334e+00,  1.28180064e+02, ...,\n          1.50507543e+02,  8.52055432e+01,  7.13830106e+01],\n        [ 3.12623456e+02, -3.43460967e-01,  6.56571721e+01, ...,\n          1.21679028e+02, -3.86687805e+01,  1.20966016e+02],\n        [ 7.01281216e+01, -7.83165070e+00, -2.16394678e+02, ...,\n          4.31197787e+02,  1.84307685e+02,  1.43264069e+02]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))y_pred_dim_2PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       338, 339, 340, 341, 342, 343, 344, 345, 346, 347],\n      dtype='int64', name='y_pred_dim_2', length=348))Attributes: (4)created_at :2024-07-22T17:16:10.668979+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 496kB\nDimensions:                (chain: 4, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 32B 0 1 2 3\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/17)\n    acceptance_rate        (chain, draw) float64 32kB 0.7564 0.8197 ... 0.7183\n    diverging              (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 2.292e+03 ... 2.294e+03\n    energy_error           (chain, draw) float64 32kB 0.4801 -0.2678 ... 0.5114\n    index_in_trajectory    (chain, draw) int64 32kB 1 2 -3 -2 -3 ... -2 0 -2 -4\n    largest_eigval         (chain, draw) float64 32kB nan nan nan ... nan nan\n    ...                     ...\n    process_time_diff      (chain, draw) float64 32kB 0.0003078 ... 0.0006075\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    smallest_eigval        (chain, draw) float64 32kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 32kB 0.5204 0.5204 ... 0.5206\n    step_size_bar          (chain, draw) float64 32kB 0.5068 0.5068 ... 0.5639\n    tree_depth             (chain, draw) int64 32kB 2 2 3 3 3 3 ... 3 3 3 1 3 3\nAttributes:\n    created_at:                 2024-07-22T17:15:59.398088+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1\n    sampling_time:              2.4274613857269287\n    tuning_steps:               1000xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (17)acceptance_rate(chain, draw)float640.7564 0.8197 0.8515 ... 1.0 0.7183array([[0.75635563, 0.81967172, 0.8515365 , ..., 0.89163324, 0.56127166,\n        0.42770019],\n       [1.        , 0.80732849, 0.71814044, ..., 0.98528259, 0.99898804,\n        0.80181998],\n       [0.99105692, 0.97253908, 0.67635143, ..., 0.75383604, 0.95766215,\n        0.92824628],\n       [0.99672972, 0.9016479 , 0.86364315, ..., 0.25422238, 1.        ,\n        0.71827462]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float642.292e+03 2.293e+03 ... 2.294e+03array([[2292.49667558, 2292.66198725, 2293.53496919, ..., 2293.87381972,\n        2293.84069071, 2292.95133406],\n       [2291.82346937, 2293.57630663, 2296.54998371, ..., 2296.11555248,\n        2297.81123818, 2297.12009399],\n       [2291.83189635, 2294.18917652, 2295.39044244, ..., 2295.38070214,\n        2294.45185538, 2295.49584313],\n       [2293.31220759, 2293.16420825, 2294.62537468, ..., 2293.89873468,\n        2293.38079253, 2294.1485723 ]])energy_error(chain, draw)float640.4801 -0.2678 ... -0.0812 0.5114array([[ 0.48011874, -0.26779274,  0.33163064, ...,  0.17124502,\n        -0.43563145,  0.42704104],\n       [-0.15384544,  0.14513703, -0.13887986, ..., -0.15512917,\n        -0.16025993,  0.46059285],\n       [ 0.01888158, -0.00671088, -0.09329776, ...,  0.53555502,\n        -0.56831456,  0.10863194],\n       [-0.2550174 , -0.15052447,  0.21794821, ...,  0.        ,\n        -0.08119834,  0.51139737]])index_in_trajectory(chain, draw)int641 2 -3 -2 -3 4 ... -2 -1 -2 0 -2 -4array([[ 1,  2, -3, ...,  1, -3, -2],\n       [ 1,  2, -2, ...,  2, -7,  1],\n       [-4, -4, -5, ...,  4,  1,  4],\n       [-7,  4, -1, ...,  0, -2, -4]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-2.292e+03 ... -2.294e+03array([[-2292.1150571 , -2292.0410545 , -2292.42477831, ...,\n        -2292.30515483, -2291.80771532, -2291.87697076],\n       [-2291.13076956, -2292.6492259 , -2293.30543439, ...,\n        -2295.18386224, -2293.68808697, -2295.6995725 ],\n       [-2291.37285478, -2293.33695976, -2291.72605722, ...,\n        -2294.16204339, -2293.30043937, -2292.79231182],\n       [-2292.7062563 , -2291.31543857, -2292.62358171, ...,\n        -2292.17071093, -2292.615977  , -2293.70146615]])max_energy_error(chain, draw)float640.4801 0.4125 ... -0.3926 0.8692array([[ 0.48011874,  0.41252217,  0.33283552, ...,  0.48701634,\n         1.7745814 ,  1.23766289],\n       [-0.15384544,  0.2938744 ,  0.85348546, ..., -0.43798004,\n        -0.25531883,  0.5353822 ],\n       [-0.09070367,  0.10372755,  0.8146555 , ...,  0.57776326,\n        -0.56831456,  0.16845522],\n       [-0.45834808,  0.36422584,  0.29924066, ...,  1.36954587,\n        -0.39259843,  0.86917849]])n_steps(chain, draw)float643.0 3.0 7.0 7.0 ... 7.0 1.0 7.0 7.0array([[ 3.,  3.,  7., ...,  7.,  3.,  3.],\n       [ 7.,  7.,  7., ...,  3.,  7.,  7.],\n       [ 7.,  7.,  7., ...,  7.,  3., 11.],\n       [15.,  7.,  7., ...,  1.,  7.,  7.]])perf_counter_diff(chain, draw)float640.0003078 0.0003006 ... 0.0006072array([[0.00030781, 0.0003006 , 0.00057401, ..., 0.00082419, 0.00039798,\n        0.00041605],\n       [0.00060114, 0.0006144 , 0.00061627, ..., 0.00029955, 0.00056821,\n        0.00055532],\n       [0.00082267, 0.00064485, 0.00062062, ..., 0.00059669, 0.00029769,\n        0.00084636],\n       [0.0018366 , 0.00092547, 0.00090717, ..., 0.00020601, 0.00057097,\n        0.00060724]])perf_counter_start(chain, draw)float642.544e+03 2.544e+03 ... 2.545e+03array([[2544.38488424, 2544.38526362, 2544.38563142, ..., 2545.04110478,\n        2545.04200902, 2545.04250536],\n       [2544.2286101 , 2544.22929216, 2544.22998741, ..., 2544.93774749,\n        2544.93811563, 2544.93875243],\n       [2544.49499104, 2544.49596298, 2544.49668508, ..., 2545.19857197,\n        2545.19923763, 2545.19960468],\n       [2544.52858074, 2544.53052761, 2544.53155778, ..., 2545.2439378 ,\n        2545.24422037, 2545.24486053]])process_time_diff(chain, draw)float640.0003078 0.0003007 ... 0.0006075array([[0.00030784, 0.00030066, 0.00057414, ..., 0.00082458, 0.00039829,\n        0.00041636],\n       [0.00060119, 0.00061446, 0.00061642, ..., 0.00029967, 0.00056835,\n        0.0005554 ],\n       [0.00082305, 0.00064517, 0.00062082, ..., 0.00059686, 0.00029782,\n        0.00084665],\n       [0.00183679, 0.00092302, 0.00090734, ..., 0.00020617, 0.0005712 ,\n        0.0006075 ]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.5204 0.5204 ... 0.5206 0.5206array([[0.52044606, 0.52044606, 0.52044606, ..., 0.52044606, 0.52044606,\n        0.52044606],\n       [0.57077188, 0.57077188, 0.57077188, ..., 0.57077188, 0.57077188,\n        0.57077188],\n       [0.53340825, 0.53340825, 0.53340825, ..., 0.53340825, 0.53340825,\n        0.53340825],\n       [0.52058287, 0.52058287, 0.52058287, ..., 0.52058287, 0.52058287,\n        0.52058287]])step_size_bar(chain, draw)float640.5068 0.5068 ... 0.5639 0.5639array([[0.50678698, 0.50678698, 0.50678698, ..., 0.50678698, 0.50678698,\n        0.50678698],\n       [0.54682871, 0.54682871, 0.54682871, ..., 0.54682871, 0.54682871,\n        0.54682871],\n       [0.52497026, 0.52497026, 0.52497026, ..., 0.52497026, 0.52497026,\n        0.52497026],\n       [0.56387316, 0.56387316, 0.56387316, ..., 0.56387316, 0.56387316,\n        0.56387316]])tree_depth(chain, draw)int642 2 3 3 3 3 2 3 ... 3 3 3 3 3 1 3 3array([[2, 2, 3, ..., 3, 2, 2],\n       [3, 3, 3, ..., 2, 3, 3],\n       [3, 3, 3, ..., 3, 2, 4],\n       [4, 3, 3, ..., 1, 3, 3]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (6)created_at :2024-07-22T17:15:59.398088+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :2.4274613857269287tuning_steps :1000\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 6kB\nDimensions:       (y_pred_dim_0: 348)\nCoordinates:\n  * y_pred_dim_0  (y_pred_dim_0) int64 3kB 0 1 2 3 4 5 ... 343 344 345 346 347\nData variables:\n    y_pred        (y_pred_dim_0) float64 3kB 16.0 3.0 115.0 ... 13.0 271.0 102.0\nAttributes:\n    created_at:                 2024-07-22T17:15:59.401126+00:00\n    arviz_version:              0.19.0\n    inference_library:          pymc\n    inference_library_version:  5.15.1xarray.DatasetDimensions:y_pred_dim_0: 348Coordinates: (1)y_pred_dim_0(y_pred_dim_0)int640 1 2 3 4 5 ... 343 344 345 346 347array([  0,   1,   2, ..., 345, 346, 347])Data variables: (1)y_pred(y_pred_dim_0)float6416.0 3.0 115.0 ... 13.0 271.0 102.0array([ 16.,   3., 115.,  73.,  82.,  51.,  15.,  16.,  61., 152.,  30.,\n         2.,  16.,  64.,  52.,  78.,  84.,  78.,  16.,   1., 256.,  86.,\n       191., 146.,   4.,  11.,  59.,  78.,  68., 164.,  54.,  18.,   1.,\n       241.,  88., 173., 226., 135.,  33.,  20.,   8.,  92.,  87., 124.,\n       112.,  25., 236., 103., 104.,  33.,  13.,   6.,  11., 353.,  92.,\n       223., 238., 271., 520., 219., 116.,  44.,  52.,   6., 101., 517.,\n       305., 170., 189., 402., 249., 256., 171.,  29.,   7.,   4.,  14.,\n       486., 121., 420., 175., 258., 452., 213., 134.,  68.,  69.,   5.,\n       118., 182., 117., 174., 265., 317., 530., 237., 125.,  28.,   7.,\n        10., 100., 437., 163., 370., 148., 298., 292., 285., 171., 128.,\n         8.,   7., 105., 186.,  93.,  32.,  43.,  72.,  69., 360., 189.,\n       277., 482., 180., 148.,  52., 106.,   8., 111.,  67., 101., 214.,\n       256., 470., 539., 181., 166.,  31.,   1.,   8., 285., 240., 168.,\n       345., 186., 498., 204., 139.,  66.,  54.,   7.,  13., 216., 138.,\n        32., 175., 314., 416., 190., 102.,  24.,   6.,   2.,  10., 400.,\n       109., 244., 137., 101.,  95.,  19.,  10.,   6.,   5., 354.,  86.,\n       376.,  50., 134., 206.,  72.,  17.,  11.,   2.,  89., 530., 191.,\n       134., 192., 311., 181., 190.,  84.,  24.,   3.,  20.,  41., 143.,\n       190.,  94., 287., 306., 126.,  72.,   4.,   2.,  12., 281., 220.,\n       260., 554., 750., 586., 104.,  48.,  33.,  31., 110., 684., 238.,\n       457., 224., 656., 459., 271.,  70.,  88.,   1.,  24., 315., 185.,\n       229., 265., 541., 769.,  98., 270.,  74.,  21.,  14.,   8., 324.,\n       301., 520., 556., 275., 227., 453., 283., 177., 116.,  12.,  40.,\n        78., 250., 188., 300., 487., 900., 571., 213., 102.,  30.,  31.,\n        28., 497., 414., 451., 221., 292., 241., 582., 397., 189.,  19.,\n         7.,  37.,  68., 327., 260., 569., 274., 851., 491., 190., 136.,\n        42.,  53.,  42., 532., 237., 459., 234., 331., 671., 596., 317.,\n       229.,   5.,   6.,  17., 530., 334., 361., 594., 209., 901., 341.,\n       151., 136., 146.,   4.,  41., 154., 269., 253., 313., 711.,  24.,\n       357., 217., 216., 182., 605., 551., 267., 162.,  27.,   8.,   4.,\n        11., 500., 163., 509., 268., 605., 352.,  96.,  64.,  26.,  38.,\n        36., 350.,  90., 135.,  13., 271., 102.])Indexes: (1)y_pred_dim_0PandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       338, 339, 340, 341, 342, 343, 344, 345, 346, 347],\n      dtype='int64', name='y_pred_dim_0', length=348))Attributes: (4)created_at :2024-07-22T17:15:59.401126+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nEn la siguiente figura la línea azul es la media del número de bicicletas alquiladas, esto es lo mismo que ya vimos en la figura anterior. Los nuevos elementos son la banda turquesa oscuro, que representa el 50% central (cuartiles 0,25 y 0,5) para las bicicletas alquiladas y la banda turquesa claro, que representa el 94% central (cuartiles 0,03 y 0,97).\nPodemos notar que nuestro modelo predice un número negativo de bicicletas, lo cual no tiene sentido para nuestro problema, ya que no estemas modelando robo o pérdida de bicicletas. Pero detengamonos un momento a reflexionar sobre nuestro modelo. Tiene sentido, según el modelo, que tengamos valores negativos de bicicletas?\nSi, esto debería esperarse ya que usamos una distribución Normal como likelihood en modelo_bl. Una solución muy sucia podría ser recortar las predicciones para valores inferiores a cero, pero eso es feo, feo. En la siguiente sección, veremos que podemos mejorar fácilmente este modelo para evitar predicciones sin sentido.\n\nlinea_media = idata_bl.posterior['μ'].mean((\"chain\", \"draw\"))\nidx = np.argsort(bicis.temperatura.values)\nx = np.linspace(bicis.temperatura.min(), bicis.temperatura.max(), 15)\ny_pred_q = idata_bl.posterior_predictive['y_pred'].quantile([0.03, 0.97, 0.25, 0.75], dim=['chain', 'draw'])\ny_hat_bounds = iter([PchipInterpolator(bicis.temperatura.values[idx], y_pred_q[i][idx])(x) for i in range(4)])\n\n_, ax = plt.subplots(figsize=(12, 5))\nax.plot(bicis.temperatura, bicis.alquiladas, '.', color=\"0.75\",  zorder=-3)\nax.plot(bicis.temperatura[idx], linea_media[idx], c='C0')\n\nfor lb, ub in zip(y_hat_bounds, y_hat_bounds): \n    ax.fill_between(x,\n                    lb, ub,\n                    color=\"C1\", alpha=0.5)\n\n\nax.set_xlabel('temperatura')\nax.set_ylabel('bicis alquiladas');",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#generalizando-el-modelo-lineal",
    "href": "05_GLMS.html#generalizando-el-modelo-lineal",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.3 Generalizando el modelo lineal",
    "text": "5.3 Generalizando el modelo lineal\nEl modelo lineal que hemos estado usando es un caso especial de un modelo más general, el modelo lineal generalizado (GLM, por su sigla en inglés). El GLM es una generalización del modelo lineal que nos permite utilizar diferentes distribuciones para el likelihood. De forma general (y omitiendo priors), podemos escribir un GLM como:\n\\[\n\\begin{aligned}\n\\mu &= \\alpha + \\beta X \\\\\nY &\\sim \\phi(f(\\mu), \\theta)\n\\end{aligned}\n\\]\ndonde \\(\\phi\\) es una distribución arbitraria algunos casos comunes son Normal, Student’s T, Gamma, NegativeBinomial, pero podemos usar otras. \\(\\theta\\) representa cualquier parámetro auxiliar o ruido que pueda tener la distribución, por ejemplo \\(\\sigma\\) para la distribución Normal. También tenemos \\(f\\), generalmente llamada función de enlace inverso. Cuando \\(\\phi\\) es Normal, entonces \\(f\\) es la función identidad. Para distribuciones como Gamma y NegativeBinomial, \\(f\\) suele ser la función exponencial. ¿Por qué necesitamos \\(f\\)? Porque \\(\\mu\\) generalmente tomará valores en los reales, para una distribución como la Normal esto es correcto ya que la media está definida en los reales, pero esto no es necesariamente así para otras distribuciones. Por ejemplo, el parámetro \\(\\mu\\) de la Negativa Binomial se define solo para números positivos, por lo que necesitamos una transformación que nos lleve de los reales a los positivos. La función exponencial es un buen candidato para esta transformación. Vamos a explorar varios GLM, un buen ejercicio es crear una tabla y cada vez que veamos una un nuevo GLM, agregar una línea que indique qué es \\(\\phi\\), \\(\\theta\\), \\(f\\) y tal vez algunas notas sobre cuándo se usa este GLM. Bien, comencemos con nuestro primer ejemplo concreto de un GLM.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#generalizando-el-modelo-lineal-para-datos-de-conteo",
    "href": "05_GLMS.html#generalizando-el-modelo-lineal-para-datos-de-conteo",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.4 Generalizando el modelo lineal para datos de conteo",
    "text": "5.4 Generalizando el modelo lineal para datos de conteo\n¿Cómo podemos cambiar modelo_bl para acomodar mejor los datos de las bicicletas? Hay dos cosas a tener en cuenta, el número de bicicletas alquiladas es discreto y está acotado en cero. Esto generalmente se conoce como datos de conteo. Se les llama así porque son el resultado de contar algo. Los datos de conteo a veces se modelan usando una distribución continua como una Normal, especialmente cuando el número de conteos es grande. Pero a menudo es una buena idea usar una distribución discreta. Dos opciones comunes son la distribución de Poisson y el NegativaBinomial. La principal diferencia es que, para la distribución de Poisson, la media y la varianza son iguales y están controladas por un mismo parámetro. Asumir que la media y la varianza son idénticas puede no ser adecuado. En esos casos es común tomar como alternativa la distribución NegativaBinomial, ya que permite que la media y la varianza sean diferentes. Ante la duda es posible generar dos modelos y evaluar si una Poisson o una NegativaBinomial es más adecuada. Más adelante veremos algunos criterios para comparar modelos, por ahora vamos a usar la distribución NegativaBinomial.\nEl modelo de PyMC es muy similar al anterior, pero con dos diferencias principales. Primero, usamos pm.NegativeBinomial en lugar de pm.Normal para el likelihood. La distribución NegativaBinomial tiene dos parámetros, la media \\(\\mu\\) y un parámetro de dispersión \\(\\alpha\\). La varianza de la NegativaBinomial es \\(\\mu + \\frac{\\mu^2}{\\alpha}\\). Entonces, cuanto mayor sea el valor de \\(\\alpha\\), mayor será la varianza. La segunda diferencia es que \\(\\mu\\) es pm.math.exp(α + β * bikes.temperatura) en lugar de solo α + β * bikes.temperatura, como ya explicamos, esto es necesario para transformar los realaes a valores positivos.\n\nwith pm.Model() as modelo_neg:\n    α = pm.Normal('α', mu=0, sigma=100)\n    β = pm.Normal('β', mu=0, sigma=10)\n    σ = pm.HalfCauchy('σ', 10)\n    μ = pm.Deterministic('μ', pm.math.exp(α + β * bicis.temperatura))\n    y_pred = pm.NegativeBinomial('y_pred', mu=μ, alpha=σ, observed=bicis.alquiladas)\n    idata_neg = pm.sample(random_seed=123)\n    idata_neg.extend(pm.sample_posterior_predictive(idata_neg, random_seed=123))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\nSampling: [y_pred]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa distribución predictiva a posteriori para modelo_neg se muestra en la siguiente figura. Podemos ver que ya no predecimos valores negativos y que la varianza de las predicciones aumenta con la media. Esto es de esperar ya que la varianza de la NegativaBinomial es \\(\\mu + \\frac{\\mu^2}{\\alpha}\\).\n\nlinea_media = idata_neg.posterior['μ'].mean((\"chain\", \"draw\"))\nidx = np.argsort(bicis.temperatura.values)\nx = np.linspace(bicis.temperatura.min(), bicis.temperatura.max(), 15)\ny_pred_q = idata_neg.posterior_predictive['y_pred'].quantile([0.03, 0.97, 0.25, 0.75], dim=['chain', 'draw'])\ny_hat_bounds = iter([PchipInterpolator(bicis.temperatura.values[idx], y_pred_q[i][idx])(x) for i in range(4)])\n\n_, ax = plt.subplots(figsize=(12, 5))\nax.plot(bicis.temperatura, bicis.alquiladas, '.', color=\"0.75\", zorder=-3)\nax.plot(bicis.temperatura[idx], linea_media[idx], c='C0')\n\nfor lb, ub in zip(y_hat_bounds, y_hat_bounds): \n    ax.fill_between(x,\n                    lb, ub,\n                    color=\"C1\", alpha=0.5)\n\nax.set_xlabel('temperatura')\nax.set_ylabel('bicis alquiladas');\n\n\n\n\n\n\n\n\nEn la siguiente figura tenemos una prueba predictiva a posteriori para modelo_bl a la izquierda y modelo_neg a la derecha. Podemos ver que cuando se usa una Normal, la discrepancia más grande es que el modelo predice valores negativos para las bicicletas alquiladas, pero incluso para los valores positivos vemos que el el ajuste no es tan bueno. Por otro lado, el modelo con la distribución NegativaBinomial ajusta mejor los datos. Aunque el ajuste no es del todo perfecto, vemos que la cola de la distribución es más pesada para las predicciones que para las observaciones, pero también observamos que la probabilidad de esta demanda tan alta es baja. Entonces, en general, reafirmamos que el modelo NegativoBinomial es mejor que el Normal.\n\n_, ax = plt.subplots(1, 2, figsize=(12, 4))\naz.plot_ppc(idata_bl,  num_pp_samples=200,  alpha=0.1, colors=[\"C1\", \"C0\", \"C0\"], ax=ax[0], mean=False)\naz.plot_ppc(idata_neg, num_pp_samples=200,  alpha=0.1, colors=[\"C1\", \"C0\", \"C0\"], ax=ax[1], mean=False)\nax[0].set_title(\"Normal\")\nax[1].set_title(\"NegativaBinomial\");",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-robusta",
    "href": "05_GLMS.html#regresión-robusta",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.5 Regresión robusta",
    "text": "5.5 Regresión robusta\nUna vez estaba ejecutando una simulación compleja de un sistema molecular. En cada paso de la simulación, necesitabamos calcular una regresión lineal como paso intermedio. Teníamos razones teóricas y empíricas para pensar que nuestra “Y” era condicionalmente normal dada nuestra “X”, por lo que la regresión lineal simple debía funcionar. Pero de vez en cuando la simulación generaba algunos valores de “Y” muy por encima o por debajo de la del grueso de los datos, esto arruinaba completamente nuestra simulación y tenáimos que reiniciarla. Estos valores muy diferentes al grueso de los datos se denominan valores atípicos o aberrantes. El motivo del fracaso de nuestras simulaciones era que los valores atípicos estaban tirando de la línea de regresión hacia valores que daban un muy mal ajuste para el grueso de los datos y cuando pasabamos de esta estimación al siguiente paso de la simulación, todo se detenía. Resolvimos esto con la ayuda de nuestra buena amiga, la distribución T de Student, que como vimos anteriormente, tiene colas más pesadas que la distribución Normal. Esto significa que los valores atípicos tienen menos influencia en el resultado final, que se asemeja más al resultado que hubieramos obtenido en ausencia de los valores atípicos. Esto es un ejemplo de una regresión robusta.\nPara ejemplificar la robustez que la distribución T de Student aporta a la regresión lineal, vamos a utilizar un conjunto de datos muy simple. Una versión ligeramente modificada del tercer grupo de datos del cuarteto de Anscombe.\nEn el siguiente modelo, estamos usando una exponencial desplazada (le sumamos 1) para evitar valores cercanos a cero. La distribución exponencial (no desplazada) pone demasiado peso en los valores cercanos a cero. En mi experiencia, esto está bien para datos con valores atípicos “moderados”, pero en algunos conjuntos de datos pequeños como este, es mejor evitar valores tan bajos. Esta recomendación, como otras, hay que tomarlas con una pizca de sal. Los valores por defecto son buenos puntos de partida, pero no es necesario ceñirse a ellos. Otro priors comunes para Gamma(2, 0.1) o Gamma(mu = 20, sd = 15).\n\nans = pd.read_csv('datos/anscombe_3.csv')\nans.plot(\"x\", \"y\", kind=\"scatter\");\n\n\n\n\n\n\n\n\n\nwith pm.Model() as modelo_t:\n    α = pm.Normal('α', mu=ans.y.mean(), sigma=1)\n    β = pm.Normal('β', mu=0, sigma=1)\n    σ = pm.HalfNormal('σ', 5)\n    ν_ = pm.Exponential('ν_', 1/29)\n    ν = pm.Deterministic('ν', ν_ + 1)\n    μ = pm.Deterministic('μ', α + β * ans.x)\n    _ = pm.StudentT('y_pred', mu=μ, sigma=σ, nu=ν, observed=ans.y)\n    idata_t = pm.sample(2000, random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ, ν_]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 4 seconds.\nThere were 1 divergences after tuning. Increase `target_accept` or reparameterize.\n\n\n\n\n\n\n\n\n\n\n\nEn la siguiente figura podemos ver el ajuste robusto, según model_t, y el ajuste no robusto, según linregress de SciPy (esta función está haciendo una regresión por mínimos cuadrados).\nMientras que el ajuste no robusto trata de comprometerse e incluir todos los puntos, el ajuste Bayesiano robusto, model_t, automáticamente descarta (o le reduce peso) a un punto y ajusta una línea que pasa más cerca de todos los puntos restantes\n\nbeta_c, alpha_c, *_ = linregress(ans.x, ans.y)\n\n_, ax = plt.subplots()\nax.plot(ans.x, (alpha_c + beta_c * ans.x), 'C0:', label='non-robust')\nax.plot(ans.x, ans.y, 'C0o')\nalpha_m = idata_t.posterior['α'].mean((\"chain\", \"draw\"))\nbeta_m = idata_t.posterior['β'].mean((\"chain\", \"draw\"))\n\nx_plot = xr.DataArray(np.linspace(ans.x.min(), ans.x.max(), 50), dims=\"plot_id\")\nax.plot(x_plot, alpha_m + beta_m * x_plot, c='C0', label=\"robust\")\naz.plot_hdi(ans.x, az.hdi(idata_t.posterior['μ'])['μ'].T, ax=ax)\nax.set_xlabel('x')\nax.set_ylabel('y', rotation=0)\nax.legend(loc=2);\n\n\n\n\n\n\n\n\nEn la siguiente figura podemos ver que obtenemos una muy buena coincidencia. También podemos ver que nuestro modelo predice valores alejados del grueso de los datos hacia ambos lados.\n\npm.sample_posterior_predictive(idata_t, model=modelo_t, random_seed=2, extend_inferencedata=True)\nax = az.plot_ppc(idata_t, num_pp_samples=200, figsize=(12, 6),  colors=[\"C1\", \"C0\", \"C1\"])\n\nSampling: [y_pred]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-logística",
    "href": "05_GLMS.html#regresión-logística",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.6 Regresión logística",
    "text": "5.6 Regresión logística\nLa regresión logistica es la generalización del modelo de regresión simple para cuando la variable dependiente es binaria. Esta generalización se logra en dos pasos. Primero utilizamos la funcion logística como función inversa de enlace:\n\\[ \\text{logística}(z) = \\frac{1}{1 + e^{-z}} \\]\nUsamos esta función por que una de sus propiedades es que no importa el valor del argumento \\(z\\), el resultado siempre será un valor en el intervalo [0, 1]. La función logística es conocida también como función sigmoide, por su aspecto típico de S como se puede ver al ejecutar la siguiente celda:\n\nz = np.linspace(-6, 6)\nlogística = 1 / (1 + np.exp(-z))\nplt.plot(z, logística)\nplt.xlabel('z')\nplt.ylabel('logística(z)');\n\n\n\n\n\n\n\n\nEl segundo paso consiste en usar como likelihood una distribución binomial y no una Gaussiana. De esta forma el modelo queda expresado como:\n\\[\n\\begin{aligned}\n\\theta &= \\text{logística}(\\alpha + \\beta X) \\\\\nY &\\sim \\text{Bern}(\\theta)\n\\end{aligned}\n\\]\nEsto modelo se puede explicar de la siguiente forma. Si nuestros datos son binarios \\(y \\in \\{0, 1\\}\\), como con el ejemplo de la moneda, vemos que tiene sentido usar una distribución Bernoulli. Esta distribución está parametrizada por un único parámetro en el intervalo [0, 1], el cual puede ser generado desde un modelo lineal siempre y cuando los valores generados por el modelo lineal sean comprimidos al intervalo [0, 1], algo que puede ser obtenido al emplear una función logística.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris.",
    "href": "05_GLMS.html#el-modelo-logístico-aplicado-al-conjunto-de-datos-del-iris.",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.7 El modelo logístico aplicado al conjunto de datos del iris.",
    "text": "5.7 El modelo logístico aplicado al conjunto de datos del iris.\nVamos a aplicar una regresión logística al conjunto de datos Iris. Este es un conjunto de datos clásico que contiene información sobre flores de 3 especies estrechamente relacionadas: setosa, virginica y versicolor. Estas serán nuestras variables dependientes, las clases que queremos predecir. Tenemos 50 individuos de cada especie y para cada individuo el conjunto de datos contiene cuatro variables que vamos a usar como variables independientes. Estas son el largo del pétalo, el ancho del pétalo, el largo del sépalo y el ancho del sépalo. Por si se lo están preguntando, los sépalos son hojas modificadas cuya función está generalmente relacionada con la protección de las flores en la yema.\n\niris = pd.read_csv('datos/iris.csv')\niris.head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\nVamos a comenzar con la regresión logística más simple posible: dos clases, setosa y versicolor, y solo una variable independiente, la longitud del sépalo. Como se hace normalmente, vamos a codificar las variables categóricas setosa y versicolor con los números 0 y 1. Usando Pandas podemos hacer:\n\ndf = iris.query(\"species == ('setosa', 'versicolor')\")\ny_0 = pd.Categorical(df['species']).codes\nx_n = 'sepal_length' \nx_0 = df[x_n].values\nx_c = x_0 - x_0.mean()\n\nAl igual que con otros modelos lineales, centrar los datos puede ayudar con el muestreo. Ahora que tenemos los datos en el formato adecuado, finalmente podemos construir el modelo con PyMC.\nObserve cómo la primera parte del siguiente modelo se asemeja a un modelo de regresión lineal. Este modelo tiene dos variables deterministas: θ ybd. θ es la salida de la función logística aplicada a la variable μ y bd es límite de decisión (el cual explicaremos más adelante). Otro punto que vale la pena mencionar es que en lugar de escribir explícitamente la función logística estamos usando pm.math.sigmoid.\n\nwith pm.Model() as modelo_rl:\n    α = pm.Normal('α', mu=0, sigma=1)\n    β = pm.Normal('β', mu=0, sigma=5)\n    \n    μ = α + β * x_c   \n    θ = pm.Deterministic('θ', pm.math.sigmoid(μ))\n    bd = pm.Deterministic('bd', -α/β)\n    \n    yl = pm.Bernoulli('yl', p=θ, observed=y_0)\n\n    idata_rl = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(idata_rl, var_names='~θ')\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbd\n-0.050\n0.059\n-0.160\n0.064\n0.001\n0.001\n3673.0\n2726.0\n1.0\n\n\nα\n0.265\n0.307\n-0.294\n0.852\n0.005\n0.004\n3615.0\n2750.0\n1.0\n\n\nβ\n5.187\n1.012\n3.462\n7.241\n0.018\n0.014\n3180.0\n2344.0\n1.0\n\n\n\n\n\n\n\n\nAhora vamos a graficar los datos junto con la curva sigmoide ajustada:\n\nposterior = idata_rl.posterior\ntheta = posterior[\"θ\"].mean((\"chain\", \"draw\"))\nidx = np.argsort(x_c)\n\n_, ax = plt.subplots()\n\nax.plot(x_c[idx], theta[idx], color='C0', lw=2)\nax.vlines(posterior['bd'].mean((\"chain\", \"draw\")), 0, 1, color='C1', zorder=0)\nbd_hdi = az.hdi(posterior['bd'])\nax.fill_betweenx([0, 1], bd_hdi[\"bd\"][0], bd_hdi[\"bd\"][1], color='C1', alpha=0.6, lw=0)\nax.scatter(x_c, np.random.normal(y_0, 0.02), marker='.', color=[f'{0.5*x}' for x in y_0])\naz.plot_hdi(x_c, posterior['θ'], color='C0', ax=ax, fill_kwargs={\"lw\": 0})\nax.set_xlabel(x_n)\nax.set_ylabel('θ', rotation=0)\n# usar escala original para los xticks\nlocs, _ = plt.xticks()\nax.set_xticks(locs, np.round(locs + x_0.mean(), 1));\n\n\n\n\n\n\n\n\nLa figura anterior muestra la longitud del sépalo para las especies (setosa = 0, versicolor = 1). Para mitigar la superposición de los datos, hemos agregado ruido (jitter) a las variable-respuesta que es binaria. Una línea azul en forma de S representa el valor medio de \\(\\theta\\). Esta línea se puede interpretar como la probabilidad que una flor sea versicolor dado el valor de longitud del sépalo. La banda azul semitransparente es el HDI 94%.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#clasificación-con-regresión-logística",
    "href": "05_GLMS.html#clasificación-con-regresión-logística",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.8 Clasificación con regresión logística",
    "text": "5.8 Clasificación con regresión logística\nMi madre prepara un plato delicioso llamado sopa seca, que básicamente es una receta a base de tallarines y que prácticamente no tienen agua. Si bien puede parecer un nombre inapropiado, el nombre del plato cobra total sentido cuando aprendemos cómo se cocina, una parte del agua que se agrega inicialmente se pierde por evaporación y la otra es absorvida por los fideos. Algo similar sucede con la regresión logística. Es usual que este modelo se muestre como un método de clasificación (y no de regresión). Veamos la fuente de esta dualidad.\nLos problemas de regresión consisten en predecir un valor continuo para una variable de salida dados los valores de una o más variables de entrada. Y una clasificación es un problema de asignación de valores discretos a una variable de salida dadas unas variables de entrada. Por ejemplo, asignar la clases versicolor dada la longitud de su sépalo.\nEntonces, ¿la regresión logística es una regresión o un método de clasificación? La respuesta es que es un método de regresión, solo que la regresión se hace sobre la probabilidad de pertenecer a una de dos clases. Pero también es posible usar una regresión logística como clasificador. Lo único que necesitamos es una regla de decisión. Por ej asignár la clase versicolor si \\(\\theta \\ge 0.5\\) y setosa en caso contrario.\nLa línea vertical en la figura anterior es el límite de decisión, y se define como el valor de la variable independiente que hace que la probabilidad de la clase 1 (versicolor en nuestro ejemplo) sea igual a 0,5. Para este modelo podemos calcular este valor analíticamente y es \\(-\\frac{\\alpha}{\\beta}\\).\nA partir de la definición del modelo tenemos la relación:\n\\[\\theta = \\text{logística}(\\alpha + x \\beta)\\]\nY a partir de la definición de la función logística tenemos que \\(\\theta = 0.5\\), cuando el argumento de la regresión logística es 0, es decir:\n\\[0.5 = \\text{logística}(\\alpha + x_i \\beta) \\Leftrightarrow 0 = \\alpha + x_i \\beta\\]\nReordenando encontramos que el valor de \\(x_i\\), para el cual, \\(\\theta = 0.5\\) corresponde a la expresión:\n\\[x_i = - \\frac{\\alpha}{\\beta}\\]\nResumiendo los puntos más importantes hasta el momento:\n\nEl valor de \\(\\theta\\) es, en términos generales, \\(p(y= 1 \\mid x)\\). En este sentido, la regresión logística es en realidad una regresión, solo que estamos regresionando la probabilidad que una observación pertenezca a la clase 1.\nEstamos modelando la media de una variable dicotómica, es decir, un número en el intervalo [0-1]. Luego, introducimos una regla para convertir esta probabilidad en una asignación de dos clases. En este caso, si \\(p(y = 1) &gt;= 0.5\\) asignamos clase 1, de lo contrario clase 0.\nNo hay nada especial en el valor 0.5, aparte de que es el número en el medio entre 0 y 1. Podemos argumentar que este límite solo es razonable si estamos de acuerdo en cometer un error en una u otra dirección. En otras palabras, si es lo mismo para nosotros clasificar erróneamente una setosa como versicolor o una versicolor como setosa. Resulta que este no es siempre el caso, y el costo asociado a la clasificación errónea no tiene por qué ser simétrico.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#interpretación-de-los-coeficientes-de-una-regresión-logística",
    "href": "05_GLMS.html#interpretación-de-los-coeficientes-de-una-regresión-logística",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.9 Interpretación de los coeficientes de una regresión logística",
    "text": "5.9 Interpretación de los coeficientes de una regresión logística\nDebemos tener cuidado al interpretar los coeficientes \\(\\beta\\) de una regresión logística. La interpretación no es tan sencilla como con los modelos lineales en el capítulo anterior. La función logística introduce una no linearidad, que debemos tener en cuenta. Si \\(\\beta\\) es positivo, aumentar \\(x\\) aumentará \\(p(y = 1)\\) en cierta cantidad, pero la cantidad no es una función lineal de \\(x\\), es en cambio una función no-lineal de \\(x\\). Podemos visualizar este hecho en la figura 4.4, en lugar de una línea con una pendiente constante, tenemos una línea en forma de S con una pendiente que cambia en función de \\(x\\). Un poco de álgebra nos puede dar una idea de cuánto cambia \\(p(y=1)\\) con \\(\\beta\\):\nEl modelo logístico básico es:\n\\[\\theta = logistic (\\alpha + X \\beta) \\]\nEl inverso de la logística es la función logit, que es:\n\\[ logit(z) = log \\left (\\frac{z}{1-z} \\right)\\]\nPor lo tanto, si tomamos la primera ecuación en esta sección y aplicamos la función logit a ambos términos, obtenemos:\n\\[ logit(\\theta) = \\alpha + X \\beta\\]\nO equivalente:\n\\[ log \\left (\\frac{\\theta} {1-\\theta} \\right) = \\alpha + X \\beta\\]\nRecuerden que \\(\\theta\\) en nuestro modelo era la probabilidad de \\(y = 1\\), por lo tanto:\n\\[ log \\left(\\frac {p(y = 1)} {1-p (y = 1)} \\right) = \\alpha + X \\beta \\]\nLa cantidad \\[\\frac{p (y = 1)} {1-p (y = 1)}\\] se conoce como odds. Los odds a favor se definen como la relación entre la probabilidad de éxito y la probabilidad de no éxito. Mientras que la probabilidad de obtener 2 tirando un dado es 1/6, los odds para el mismo evento son \\(\\frac{1/6}{5/6} = 0.2\\) o dicho de otra forma 1 evento favorable frente a 5 eventos desfavorables. Mientras las probabilidades toman valores en el intervalo [0, 1], los odds lo hacen en \\([0, \\infty)\\). Veamos otro ejemplo, si la probabilidad de lluvia mañana es \\(\\frac{3}{4}\\), entonces la probabilidad de que no llueva es \\(\\frac{1}{4}\\) y entonces el odds será de 3. Es decir es tres veces más probable que llueva respecto de que no llueva. Si en cambio la probabilidad fuese \\(\\frac{1}{2}\\) entonces el odds sería 1. Es tan probable que llueva como que no lo haga. Los odds suelen ser utilizadas por los apostadores ya que proporcionan una herramienta más intuitiva que las probabilidades en bruto cuando se piensa en la forma correcta de apostar.\n\nEn una regresión logística, el coeficiente \\(\\beta\\) codifica el aumento en unidades de log-odds por unidad de aumento de la variable \\(x\\).\n\nLa transformación de probabilidad a odds es una transformación monotónica, lo que significa que las probabilidades aumentan a medida que aumenta la probabilidad. Mientras que las probabilidades están restringidas al intervalo \\([0, 1]\\), los odds viven en el intervalo \\([0, \\infty]\\). El logaritmo es otra transformación monótonica y los log-odds están en el intervalo \\([-\\infty, \\infty]\\). La siguiente figura muestra cómo la probabilidad está relacionada con los odds y los log-odds.\n\nprobability = np.linspace(0.01, 1, 100)\nodds = probability / (1 - probability)\n\n_, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax1.plot(probability, odds, 'C0')\nax2.plot(probability, np.log(odds), 'C2')\n\nax1.set_xlabel('probabilidad')\nax1.set_ylabel('odds', color='C0')\nax2.set_ylabel('log-odds', color='C2');\n\n/tmp/ipykernel_12140/2677285095.py:2: RuntimeWarning: divide by zero encountered in divide\n  odds = probability / (1 - probability)\n\n\n\n\n\n\n\n\n\nEntonces averigüemos cuantas veces más probable es que una flor sea versicolor por unidad del largo del sépalo",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#varianza-variable",
    "href": "05_GLMS.html#varianza-variable",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.10 Varianza variable",
    "text": "5.10 Varianza variable\nHemos estado usando el modelo lineal para modelar la media de una distribución, dejando la varianza de lado. En caso que consideremos que el supuesto de varianza constante no tiene sentido podemos considerar la varianza como una función (lineal) de la variable dependiente.\nLa Organización Mundial de la Salud y otras instituciones de salud de todo el mundo recopilan datos para recién nacidos y diseñan estándares de crecimiento. Estas tablas son un componente esencial del conjunto de herramientas pediátricas y también como una medida del bienestar general de las poblaciones con el fin de formular políticas de salud, planificar intervenciones y controlar su eficacia. Un ejemplo de tales datos son la longitud (alturas) de las niñas recién nacidas en función de la edad (en meses):\n\ndata = pd.read_csv('datos/babies.csv')\ndata.plot.scatter('Meses', 'Longitud');\n\n\n\n\n\n\n\n\nPara modelar estos datos, presentaremos 3 elementos nuevos en comparación con los modelos anteriores:\n\n\\(\\sigma\\) ahora es una función lineal de \\(x\\), y para hacer esto agregamos dos nuevos parámetros \\(\\gamma\\) y \\(\\delta\\), estos son análogos directos de \\(\\alpha\\) y \\(\\beta\\).\nEl modelo lineal para la media es una función de \\(\\sqrt{x}\\), esto es solo un truco simple para ajustar un modelo lineal a una curva.\nHemos definido una variable compartida x_shared, esto nos permitirá cambiar los valores de la variable \\(x\\) (Meses en este ejemplo) sin la necesidad de volver a muestrear el modelo. Esto quedará más claro con el ejemplo.\n\n\nwith pm.Model() as model_vv:\n    x_shared = pm.MutableData(\"x_shared\", data.Meses.values.astype(float))\n    α = pm.Normal('α', sigma=10)\n    β = pm.Normal('β', sigma=10)\n    γ = pm.HalfNormal('γ', sigma=10)\n    δ = pm.HalfNormal('δ', sigma=10)\n\n\n    μ = pm.Deterministic('μ', α + β * x_shared**0.5)\n    σ = pm.Deterministic('σ', γ + δ * x_shared)\n    \n    y_pred = pm.Normal('y_pred', mu=μ, sigma=σ, observed=data.Longitud)\n    \n    idata_vv = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, γ, δ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.\n\n\n\n\n\n\n\n\n\n\n\nLa siguiente figura muestra el resultado de nuestro modelo. La media de \\(\\mu\\) es representada con una curva negra, y las dos bandas turquesa semitransparentes representan 1 y 2 desviaciones estándar.\n\n_, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].plot(data.Meses, data.Longitud, 'C0.', alpha=0.1);\n\nposterior = az.extract(idata_vv)\n\nμ_m = posterior['μ'].mean(\"sample\").values\nσ_m = posterior['σ'].mean(\"sample\").values\n\naxes[0].plot(data.Meses, μ_m, c='k')\naxes[0].fill_between(data.Meses, μ_m + 1 * σ_m, μ_m - 1 * σ_m, alpha=0.6, color='C1')\naxes[0].fill_between(data.Meses, μ_m + 2 * σ_m, μ_m - 2 * σ_m, alpha=0.4, color='C1')\n\naxes[0].set_xlabel('Meses')\naxes[0].set_ylabel('Longitud');\n\n\naxes[1].plot(data.Meses, σ_m)\naxes[1].set_xlabel('Meses');\naxes[1].set_ylabel(r'$\\bar ϵ$', rotation=0);\n\n\n\n\n\n\n\n\nAhora que tenemos ajustado el modelo podríamos querer usar el modelo para averiguar cómo se compara la longitud de una niña en particular respecto de la distribución. Una forma de responder a esta pregunta es preguntarle al modelo por la distribución de la variable longitud para bebas de digamos de 0.5 meses. Usando PyMC podemos hacer estas preguntas con la función pm.sample_posterior_predictive, ya que esto arrojará muestras de \\(\\tilde y\\) es decir los valores predichos considerando la incertidumbre de los parámetros. El único problema es que, por defecto, esta función devolverá valores de \\(\\tilde y\\) para los valores observados de \\(x\\), es decir los valores usando para ajustar el modelo. Pero que pasa si queremos obtener predicciones para que el modelo no vio? Como 0,5 meses que no es parte de los datos originales. La manera más fácil de obtener predicciones para valores no observados es definir una variable compartida (x_shared en el ejemplo) y luego actualizar el valor de la variable compartida justo antes del muestreo de la distribución predictiva a posteriori.\n\nwith model_vv:\n    pm.set_data({\"x_shared\": [0.5]})\n    ppc = pm.sample_posterior_predictive(idata_vv, random_seed=123)\n    y_ppc = ppc.posterior_predictive['y_pred'].stack(sample=(\"chain\", \"draw\"))\n\nSampling: [y_pred]\n\n\n\n\n\n\n\n\n\n\n\nAhora podemos graficar la distribución esperada de las longitudes para las bebas con 2 semanas de vida y calcular cantidades adicionales, por ejemplo, el percentil de una niña de esa longitud:\n\nref = 52.5\ngrid, pdf = az.stats.density_utils._kde_linear(y_ppc.values)\nplt.plot(grid, pdf)\npercentile = int((y_ppc &lt;= ref).mean() * 100)\nplt.fill_between(grid[grid &lt; ref], pdf[grid &lt; ref], label='percentil = {:2d}'.format(percentile))\nplt.xlabel('longitud')\nplt.yticks([])\nplt.legend();",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-por-cuantiles",
    "href": "05_GLMS.html#regresión-por-cuantiles",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.11 Regresión por cuantiles",
    "text": "5.11 Regresión por cuantiles\nEn los ejemplos anteriores nos focalizamos en usar un modelo lineal para estimar la media de la variable respuesta, también vimos que es posible usar la misma idea para estimar la varianza. Además, aprendimos que usar un likelihood Normal es solo una de muchas opciones, como Binomial, Negativa Binomial, t de Student, etc.\nEn esta sección vamos a discutir un modelo lineal, cuyo objetivo no es la estimación de media o varianza, en cambio la estimación de cuantiles. Cuando el cuantil a estimar es la mediana, la motivación suele ser la necesidad de una regresión robusta. Así como la mediana es un estimador de la media, robusto a valores extremos, una regresión mediana será también robusta. En ese caso la regresión por cuantiles cumpliría una función similar al modelo robusto que vimos anteriormente usando una distribución t de Student. Otras veces, la motivación está en modelar cuantiles específicos por que estos son “intrínsecamente” de interés. Esto sucede por ejemplo cuando nos interesa modelador valores en los extremos de una distribución. Por ejemplo podríamos estar interesados en modelar temperaturas altas, o eventos de lluvia intensos. A veces también se usa para explorar relaciones entre variables cuando no hay relación entre las medias de dichas variables, o cuando esta es muy débil. Una disciplina donde las regresiones por cuantiles son frecuentes es la ecología. Esto se debe posiblemente, a que la existencia de complejas interacciones entre variables, donde el efecto de una variable sobre otra es distinto para distintos rangos de la variable.\nPara hacer regresiones por cuantiles utilizamos la distribución asimétrica de Laplace como likelihood. Esta distribución la podemos pensar como dos distribuciones exponenciales espalda-con-espalda. La distribución tiene 3 parámetros \\(\\mu\\) controla la localización, \\(\\sigma\\) la escala y \\(q\\) la asimetría. \\(q\\) varía entre [0, 1], cuando \\(q=0.5\\) la distribución asimétrica de Laplace es en realidad simétrica. Este caso especial es conocido también como distribución de Laplace. Cuando hacemos regresión por cuantiles, podemos pensar a \\(q\\) como los cuantiles que nos interesa asociar con la variable respuesta. Por ejemplo, si \\(q=0.5\\) estamos modelando la mediana, si \\(q=0.25\\) estamos modelando el primer cuartil, etc.\nLa siguiente figuras muestras tres distribuciones de esta familia.\n\nq = np.array([0.05, 0.5, 0.95])\nfor q_i, mu in zip(q, [0, 0, -1]):\n    pz.AsymmetricLaplace(mu=mu, b=1, q=q_i).plot_pdf(support=(-6, 6))\n\n\n\n\n\n\n\n\nQuiere decir esto que al hacer una regresión por cuantiles estamos asumiendo que la variable respuesta se distribuye (condicionalmente) como una Asimétrica de Laplace? No necesariamente.\nUna forma alternativa de pensar el likelihood, es como una función de error (o de diferencia) entre el ajuste lineal y los datos. Al elegir una distribución determinada estamos, indirectamente, eligiendo como penalizaremos esa diferencia y al hacer inferencia estámos encontrando la distribución de parámetros que reducen esa diferencia. Usando esta lógica podemos pensar que una gaussiana le asigna un determinado peso a valores alejados de la media y una t de Student le asigna un menor peso, y por ende terminamos teniendo un ajuste más robusto. De la misma forma una asimétrica de Laplace le asigna una determinado peso a estas diferencias de forma tal que el resultado final es ajustar cuantiles en vez de medias. Si esto les suena extraño es por que están prestando atención.\n\nPara ejemplificar la regresión por cuantiles vamos a usar el dataset de las longitudes de bebés que usamos anteriormente. Vamos a ajustar 3 cuantiles al mismo tiempo, 0.05, 0.5, 0.95. Esto nos va a permitir ver como cambia la relación entre las variables a medida que nos movemos de los cuantiles bajos a los altos. Para esto vamos a “apilar” el dataset 3 veces, una para cada cuantil.\n\ny_con = np.stack([data.Longitud.values]* 3).T\nx_con = np.stack([data.Meses.values]* 3).T\n\n\nwith pm.Model() as model_q:\n    α = pm.Normal('α', 50, 3, shape=3)\n    β = pm.Normal('β', 0, 5, shape=3)\n    σ = pm.HalfNormal('σ', 5)\n\n    μ = pm.Deterministic('μ', α + β * x_con**0.5)\n    \n    y_pred = pm.AsymmetricLaplace('y_pred',  mu=μ, b=σ, q=q, observed=y_con)\n    \n    idata_q = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 11 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot(data.Meses, data.Longitud, \".\", color=\"0.5\")\nfor idx, label in enumerate((\"q=0.1\", \"q=0.5\", \"q=0.9\")):\n    plt.plot(data.Meses.values, idata_q.posterior[\"μ\"].mean((\"chain\", \"draw\"))[:,idx],\n            label=label, lw=3);\n    \nplt.legend();\n\n\n\n\n\n\n\n\nPara que sea más claro que estámos haciendo al hacer una regresión por cuantiles, comparemos el resultado con una regresión “normal”.\n\nwith pm.Model() as model_n:\n    α = pm.Normal('α', 50, 3)\n    β = pm.Normal('β', 0, 5)\n    σ = pm.HalfNormal('σ', 5)\n\n    μ = pm.Deterministic('μ', α + β * data.Meses.values**0.5)\n    \n    y_pred = pm.Normal('y_pred',  μ, σ, observed=data.Longitud.values)\n    \n    idata_n = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(data.Meses, data.Longitud, \".\", color=\"0.8\")\nlines = []\nfor idx, label in enumerate([f\"{q_i=:}\" for q_i in q]):\n    line, = ax.plot(data.Meses,\n                   idata_q.posterior[\"μ\"].mean((\"chain\", \"draw\"))[:,idx],\n                   label=label)\n    lines.append(line)\n    \nq_legend = ax.legend(handles=lines, loc='upper left', title=\"Regresión por cuantiles\")\n\n# aproximamos los cuantiles de la distribución posterior\nq_95 = (idata_n.posterior[\"μ\"] + idata_n.posterior[\"σ\"]*1.65).mean((\"chain\", \"draw\"))\nq_05 = (idata_n.posterior[\"μ\"] - idata_n.posterior[\"σ\"]*1.65).mean((\"chain\", \"draw\"))\n\nline0, = ax.plot(data.Meses, q_05, \"C0\", label=\"μ - 1.65σ\", ls=\"--\")\nline1, = ax.plot(data.Meses, idata_n.posterior[\"μ\"].mean((\"chain\", \"draw\")), \"C1\", label=\"μ\", ls=\"--\")\nline2, = ax.plot(data.Meses, q_95, \"C2\", label=\"μ + 1.65σ\", ls=\"--\");\n\nax.add_artist(q_legend)\n\nax.legend(handles=[line0, line1, line2], loc='lower right', title=\"Regresión normal\");\n\n\n\n\n\n\n\n\nPodemos ver que al usar una distribución Normal y a partir de ella computar los cuantiles, q=0.1 (\\(\\mu - 1.65\\sigma\\)) y q=0.9 (\\(\\mu + 1.65\\sigma\\)) estos son simétricos respecto de la media \\(\\mu\\). Además podemos ver que la forma de la curva es esencialmente la misma para los 3 casos, solo que desplazada hacia arriba o abajo. Además las curvas generadas al usar la distribución asimétrica de Laplace permite acomodarse a la varianza no constante, vean como las curvas empiezan muy cerca en el mes cero y se van separando a medida que pasan los meses.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-lineal-jerárquica",
    "href": "05_GLMS.html#regresión-lineal-jerárquica",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.12 Regresión lineal jerárquica",
    "text": "5.12 Regresión lineal jerárquica\nHace dos capítulos, aprendimos los rudimentos de los modelos jerárquicos. Este mismo concepto se puede aplicar a las regresiones lineales. Esto permite que los modelos realicen inferencias a nivel de subgrupo y a nivel global. Como ya vimos, esto se hace incluyendo hiperpriors.\nVamos a crear ocho grupos de datos relacionados, incluido un grupo con un solo dato\n\nN = 20\ngrupos = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\nM = len(grupos)\nidx = np.repeat(range(M - 1), N)\nidx = np.append(idx, 7)\nnp.random.seed(314)\nalpha_real = np.random.normal(2.5, 0.5, size=M)\nbeta_real = np.random.beta(6, 1, size=M)\neps_real = np.random.normal(0, 0.5, size=len(idx))\ny_m = np.zeros(len(idx))\nx_m = np.random.normal(0, 1, len(idx))\ny_m = alpha_real[idx] + beta_real[idx] * x_m + eps_real\n_, ax = plt.subplots(2, 4, figsize=(10, 5), sharex=True, sharey=True)\nax = np.ravel(ax)\nj, k = 0, N\nfor i, g in enumerate(grupos):\n    ax[i].scatter(x_m[j:k], y_m[j:k], marker=\".\")\n    ax[i].set_title(f\"grupo {g}\")\n    j += N\n    k += N\n\n\n\n\n\n\n\n\nVeamos un posible modelo para estos datos:\n\ncoords = {\"grupo\": grupos}\n\nwith pm.Model(coords=coords) as modelo_jerárquico:\n    # hyper-priors\n    α_μ = pm.Normal(\"α_μ\", mu=y_m.mean(), sigma=1)\n    α_σ = pm.HalfNormal(\"α_σ\", 5)\n    β_μ = pm.Normal(\"β_μ\", mu=0, sigma=1)\n    β_σ = pm.HalfNormal(\"β_σ\", sigma=5)\n\n    # priors\n    α = pm.Normal(\"α\", mu=α_μ, sigma=α_σ, dims=\"grupo\")\n    β = pm.Normal(\"β\", mu=β_μ, sigma=β_σ, dims=\"grupo\")\n    σ = pm.HalfNormal(\"σ\", 5)\n    _ = pm.Normal(\"y_pred\", mu=α[idx] + β[idx] * x_m, sigma=σ, observed=y_m)\n\n    idata_mj = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α_μ, α_σ, β_μ, β_σ, α, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 8 seconds.\nThere were 172 divergences after tuning. Increase `target_accept` or reparameterize.\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n\n\n\n\nVemos que obtenemos un mesaje de advertencia indicando divergencias y dos sugerencias para solucionar el problema. La primera es incrementar target_accept la segunda reparametrizar. Este mensaje indica que las muestras generadas por PyMC pueden no ser confiables, esto se vincula a los diagnósticos que vimos en el capítulo anterior.\nLa primer sugerencias es aumentar target_accept, que es un argumento de pm.sample() que por defecto toma el valor 0.8 y puede tomar valores en el intervalo (0, 1). Si ves divergencias, como en este caso, cambiar el valor por defecto a valores tales como 0.85, 0.9 o incluso más puede ayudar. En algunos casos incluso valores altos como 0.99 no serán de ayuda. Un efecto adverso de aumentar target_accept es que el sampler suele demorar más en generar una misma cantidad de muestras.\nSi las divergencias no desaparecen al cambiar target_accept, en general la única solución es reparametrizar. ¿Qué es esto? Reparametrizar es escribir un modelo de una manera diferente, pero matemáticamente equivalente a su versión original. Muchos modelos (por no decir todos) se pueden escribir de formas alternativas. A veces, la reparametrización puede tener un efecto positivo en la eficiencia del método de muestreo o en la interpretabilidad del modelo. Por ejemplo, al reparametrizar podemos eliminar las divergencias.\nSi prueban volver a correr modelo_jerárquico pero con valores más altos de target_accept verán que las divergecias disminuyen pero no desaparecen. Lamentablemente esto es algo común con modelos lineales jerárquicos, lo bueno es que existe una reparametrización que suele solucionar el problema. La reparametrización consiste en reescribir el modelo de la siguiente forma:\nEn vez definir \\(\\beta \\mathcal{N}(\\beta_\\mu, \\beta_\\sigma)\\) como en modelo_jerárquico vamos a escribir \\(\\beta = \\beta_\\mu + \\beta_\\text{offset} * \\beta_\\sigma\\). Donde \\(\\beta_\\text{offset}\\) es una distribución normal con media 0 y desviación estándar 1. Conceptualmente la diferencia es que en el primer caso estamos modelando la pendiente de cada grupo de forma explícita, mientras que en el segundo caso lo estamos haciendo como una desviación respecto de un valor común (\\(\\beta_\\mu\\)). A la primer versión se la suele llamar centrada y a la segunda no-centrada. Veamos como queda el modelo no-centrado en PyMC:\n\nwith pm.Model(coords=coords) as jerárquico_no_centrado:\n    # hyper-priors\n    α_μ = pm.Normal(\"α_μ\", mu=y_m.mean(), sigma=1)\n    α_σ = pm.HalfNormal(\"α_σ\", 5)\n    β_μ = pm.Normal(\"β_μ\", mu=0, sigma=1)\n    β_σ = pm.HalfNormal(\"β_σ\", sigma=5)\n\n    # priors\n    α = pm.Normal(\"α\", mu=α_μ, sigma=α_σ, dims=\"grupo\")\n\n    β_offset = pm.Normal(\"β_offset\", mu=0, sigma=1, dims=\"grupo\")\n    β = pm.Deterministic(\"β\", β_μ + β_offset * β_σ, dims=\"grupo\")\n\n    σ = pm.HalfNormal(\"σ\", 5)\n    _ = pm.Normal(\"y_pred\", mu=α[idx] + β[idx] * x_m, sigma=σ, observed=y_m)\n\n    idata_ncen = pm.sample(target_accept=0.85, random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α_μ, α_σ, β_μ, β_σ, α, β_offset, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 10 seconds.\n\n\n\n\n\n\n\n\n\n\n\nAl correr jerárquico_no_centrado sin modificar target_accept verán todavía quedan unas pocas divergencias. 2 en mi caso, un número tan bajo no suele ser problemático. Pero para estar seguros podemos aumentar target_accept a 0.85, como en el bloque de código anterior. Al hacer eso veremos que no hay divergencias y podremos seguir con nuestro análisis. Pero antes de hacer eso veamos que es lo que estamos haciendo al reparametrizar.\nLa siguiente figura muestra muestra dos paneles, a la izquierda tenemos un gráfico de dispersión entre los valores de \\(\\log \\beta_\\sigma\\) (el logaritmo de la desviación estándar global) y \\(\\beta_B\\). A la derecha entre \\(\\log \\beta_\\sigma\\) y la pendiente del grupo H. Los puntos negros representan divergencias. En ambos casos se observa una forma de “embudo” más ancha arriba y más angosta abajo (esto es más acentuado en el panel de la derecha). En ambos casos a medida que \\(\\beta_\\sigma\\) aumenta el embudo se ensancha, ya que la dispersión de \\(\\beta\\) aumenta. Esto es razonable ya que precisamente \\(\\beta_\\sigma\\) controla cuan variable puede ser \\(\\beta\\) respecto de su media. En si mismo esto no es un problema, es simplemente una consecuencia directa del modelo. Pero si es un problema para el método de muestreo, como vimos en el capítulo anterior, para obtener un método eficiente el método de muestreo debe “aprender” ciertos hiper-parámetros. El problema que en una geometría como el embudo, no hay un solo conjunto de hiper-parámetros que sean lo suficientemente buenos para muestrear tanto la boca del embudo como su pico. En general el método “aprende” a muestrear la parate ancha y cuando se aproxima a la parte angosta la trayectoria “diverge” de la correcta. Es como si usáramos los cálculos para poner un satélite en orbita de la tierra, para ponerlo en órbita de la luna, perderíamos el satélite en el espacio.\nNota: Para la figura usamos \\(\\log \\beta_\\sigma\\) en vez de \\(\\beta_\\sigma\\), por que esto es lo que “ve” el sampler. Por qué? Por que internamente PyMC muestrea los parámetros en un espacio sin “bordes” para eso convierte distribuciones como la Beta que tienen soporte en el intervalo (0, 1) a una distribución que tiene soporte en todo el espacio real. Lo mismo hace con distribuciones como la media-normal. En el caso de esta última la transformación es logarítmica. Una vez terminado el muestreo PyMC invierte la trasformación quedando los parámetros en la escala original y por eso nosotros vemos los valores de \\(\\beta_\\sigma\\) y no \\(\\log \\beta_\\sigma\\). Pero el sampler ve \\(\\log \\beta_\\sigma\\) por eso es conveniente graficar en esa escala.\n\nidata_mj.posterior[\"log(β_σ)\"] = np.log(idata_mj.posterior[\"β_σ\"])\n\n_, axes = plt.subplots(1, 2, sharey=\"row\", sharex=\"col\", figsize=(10, 4))\n\nvars = [\"log(β_σ)\", \"log(β_σ)\"]\nglabel = [\"B\", \"H\"]\nfor ax, var, gl in zip(axes.ravel(), vars, glabel):\n    az.plot_pair(\n        idata_mj,\n        var_names=[\"β\", var],\n        coords={\"grupo\": [gl]},\n        divergences=True,\n        scatter_kwargs={\"color\": \"C2\"},\n        divergences_kwargs={\"color\": \"k\", \"marker\": \".\", \"mec\": None},\n        ax=ax,\n    )\n\n\n\n\n\n\n\n\nAhora bien, que pasa cuando usamos un modelo jerárquico no centrado? Veamos la siguiente figura:\nAhora tenemos 4 paneles, en la primer fila vemos \\(\\log \\beta_\\sigma\\) vs \\(\\log \\beta_{text{offset}}\\), que es la nueva variable que introdujimos en la versión no centrada. Ahora vemos que el posterior es más “esférico” o al menos que la forma de embudo es mucho menos pronunciada. Esta geométrica es mucho más simple de muestrear que la anterior y por eso no observamos divergencias.\nEn la segunda fila vemos \\(\\log \\beta_\\sigma\\) vs \\(\\beta\\), ahora vemos que el embudo es aún más acentuado que en la figura anterior. Esto no debería ser aún más problemático? En realidad no, esto no es un problema para el sampler por que el sampler nunca “ve” este embudo ya que \\(\\beta\\) lo obtenemos al combinar \\(\\beta_\\text{offset}\\), \\(\\beta_\\sigma\\) y \\(\\beta_\\mu\\). Es decir con la reparametrización logramos obtener un embudo más “profundo”, pero sin muestrearlo directamente!\nAhora que quiere decir que ahora el embudo sea “más profundo”? Quiere decir que ahora somos capaces de muestrear una región de la distribución a posteriori que antes no podíamos. En la versión centrada del modelo el sampler divergía antes de poder encontrar la zona angosta y por lo tanto esa zona NO estaba presente en la distribución a posteriori. Nos estábamos perdiendo parte de la distribución a posteriori, que si no fuera por las divergencias no sabríamos que existe y estaríamos trabajando con una distribución a posteriori sesgada sin siquiera saberlo.\n\nidata_ncen.posterior[\"log(β_σ)\"] = np.log(idata_ncen.posterior[\"β_σ\"])\n\n_, axes = plt.subplots(2, 2, sharey=\"row\", sharex=\"col\", figsize=(10, 6))\n\nvars = np.repeat([\"β_offset\", \"β\"], 2)\nglabel = [\"B\", \"H\"] * 2\n\nfor ax, var, gl in zip(axes.ravel(), vars, glabel):\n    az.plot_pair(\n        idata_ncen,\n        var_names=[var, \"log(β_σ)\"],\n        coords={\"grupo\": [gl]},\n        divergences=True,\n        scatter_kwargs={\"color\": \"C2\"},\n        divergences_kwargs={\"color\": \"k\", \"marker\": \".\", \"mec\": None},\n        ax=ax,\n    )\n\n\n\n\n\n\n\n\nAhora que nuestras muestras están libres de divergencias, podemos continuar con el análisis de los resultados. La siguiente figura muestra los valores estimados para \\(\\alpha\\) y \\(\\beta\\). Podemos ver como las estimaciones para el grupo H son las de mayor incertidumbre. Lo cual es razonable dado que tenemos un solo punto.\n\naz.plot_forest(idata_ncen, var_names=['α', 'β'], figsize=(10, 4), combined=True);\n\n\n\n\n\n\n\n\nLa siguiente figura muestra las líneas ajustadas para cada uno de los ocho grupos. Podemos ver que logramos ajustar una línea a un solo punto. Al principio, esto puede sonar extraño o incluso sospechoso, pero es solo una consecuencia de la estructura del modelo jerárquico. Cada línea está informada por las líneas de los otros grupos, por lo que no estamos realmente ajustando una línea a un solo punto. En cambio, estamos ajustando una línea que ha sido informada por los puntos en los otros grupos a un solo punto.\n\n_, ax = plt.subplots(2, 4, figsize=(12, 5), sharex=True, sharey=True)\nax = np.ravel(ax)\nj, k = 0, N\nx_range = np.linspace(x_m.min(), x_m.max(), 10)\nposterior = az.extract(idata_ncen)\n\nfor i, g in enumerate(grupos):\n    ax[i].scatter(x_m[j:k], y_m[j:k], marker=\".\")\n    ax[i].set_xlabel(\"$x_{}$\".format(i))\n    ax[i].set_ylabel(\"$y_{}$\".format(i), labelpad=10, rotation=0)\n    alfas = posterior[\"α\"].sel(grupo=g)\n    betas = posterior[\"β\"].sel(grupo=g)\n    alfa_m = alfas.mean(\"sample\").item()\n    beta_m = betas.mean(\"sample\").item()\n    ax[i].plot(x_range, alfa_m + beta_m * x_range, c=\"k\")\n    az.plot_hdi(x_range, alfas + betas * xr.DataArray(x_range).transpose(), ax=ax[i])\n    plt.xlim(x_m.min() - 1, x_m.max() + 1)\n    plt.ylim(y_m.min() - 1, y_m.max() + 1)\n    j += N\n    k += N",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-lineal-múltiple",
    "href": "05_GLMS.html#regresión-lineal-múltiple",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.13 Regresión lineal múltiple",
    "text": "5.13 Regresión lineal múltiple\nHasta ahora, hemos estado trabajando con una variable dependiente y una variable independiente. Sin embargo, no es inusual tener varias variables independientes que queremos incluir en nuestro modelo. Algunos ejemplos podrían ser:\n\nCalidad percibida del vino (dependiente) y acidez, densidad, grado alcohólico, azúcar residual y contenido de sulfatos (variables independientes)\nCalificaciones promedio de un estudiante (dependiente) e ingreso familiar, distancia del hogar a la escuela y nivel de educación de la madre (variable categórica)\n\nPodemos extender fácilmente el modelo de regresión lineal simple para tratar con más de una variable independiente. Llamamos a este modelo regresión lineal múltiple o menos a menudo regresión lineal multivariable (que no debe confundirse con la regresión lineal multivariable, el caso en el que tenemos múltiples variables dependientes).\nEn un modelo de regresión lineal múltiple, modelamos la media de la variable dependiente de la siguiente manera:\n\\[\n\\mu = \\alpha + \\beta_1 X_{1} + \\beta_2 X_{2} + \\dots + \\beta_k X_{k}\n\\]\nUsando notación de álgebra lineal, podemos escribir una versión más corta:\n\\[\n\\mu = \\alpha + \\mathbf{X} \\beta\n\\]\ndonde \\(\\mathbf{X}\\) es una matriz de tamaño \\(n \\times k\\) con los valores de las variables independientes y \\(\\beta\\) es un vector de tamaño \\(k\\) con los coeficientes de las variables independientes, y $n $ es el número de observaciones.\nSi estás un poco oxidado con respecto al álgebra lineal, podés consultar el artículo de Wikipedia sobre el producto escalar entre dos vectores y su generalización a la multiplicación de matrices. Pero básicamente, lo que necesitás saber es que solo estamos usando una forma más corta y conveniente de escribir nuestro modelo:\n\\[\n\\mathbf{X} \\beta = \\sum_i^n \\beta_i X_{i} = \\beta_1 X_{1} + \\beta_2 X_{2} + \\dots + \\beta_k X_{k}\n\\]\nUsando el modelo de regresión lineal simple, encontramos una línea recta que (con suerte) explica nuestros datos. Bajo el modelo de regresión lineal múltiple encontramos, en cambio, un hiperplano de dimensión \\(k\\). Por lo tanto, el modelo de regresión lineal múltiple es esencialmente el mismo que el modelo de regresión lineal simple, con la única diferencia de que ahora \\(\\beta\\) es un vector y \\(\\mathbf{X}\\) es una matriz.\nPara ver un ejemplo de un modelo de regresión lineal múltiple, volvamos al ejemplo de las bicicletas. Usaremos la temperatura y la humedad del día para predecir el número de bicicletas alquiladas.\n\nwith pm.Model() as model_mlb:\n    α = pm.Normal(\"α\", mu=0, sigma=1)\n    β0 = pm.Normal(\"β0\", mu=0, sigma=10)\n    β1 = pm.Normal(\"β1\", mu=0, sigma=10)\n    σ = pm.HalfNormal(\"σ\", 10)\n    μ = pm.Deterministic(\"μ\", pm.math.exp(α + β0 * bicis.temperatura + β1 * bicis.hora))\n    _ = pm.NegativeBinomial(\"y_pred\", mu=μ, alpha=σ, observed=bicis.alquiladas)\n\n    idata_mlb = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [α, β0, β1, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 7 seconds.\n\n\n\n\n\n\n\n\n\n\n\nTomemos un momento para comparar model_mlb que tiene dos variables independientes temperatura y hora con model_neg que solo tiene una variable independiente temperatura. La única diferencia es que ahora tenemos dos coeficientes \\(\\beta\\), uno para cada variable independiente. El resto del modelo es el mismo. Podríamos haber escrito β = pm.Normal(\"β1\", mu=0, sigma=10, shape=2) y luego usar β1[0] y β1[1] en la definición de \\(\\mu\\). Yo suelo hacer eso, pero acá por ser el primer modelo de regresión múltiple, me pareció más claro escribirlo de esta manera.\nPodemos ver que escribir un modelo de regresión múltiple no es tan diferente de escribir un modelo de regresión simple. Sin embargo, interpretar los resultados puede ser más desafiante. Por ejemplo, el coeficiente de temperatura ahora es \\(\\beta_0\\) y el coeficiente de hora es \\(\\beta_1\\). Todavía podemos interpretar los coeficientes como el cambio en la variable dependiente por cambio unitario en la variable independiente. Pero ahora debemos tener cuidado de especificar de qué variable independiente estamos hablando. Por ejemplo, podemos decir que por una unidad de aumento en la temperatura, el número de bicicletas alquiladas aumenta en \\(\\beta_0\\) unidades, manteniendo constante la hora. O podemos decir que por una unidad de aumento en la hora, el número de bicicletas alquiladas aumenta en \\(\\beta_1\\) unidades, manteniendo la temperatura constante. Pero tenemos que entender que dado que las variables participan todas del mismo modelo, no podemos hablar de sus coeficientes de forma aislada. Esto lo podemos ver en la siguiente figura, que muestra los coeficientes \\(\\beta\\) para los modelos model_neg (solo temperatura) y para el modelo model_mld (temperatura y hora).\n\n# Para hacer comparables los coeficientes los escalamos respecto de su correspondiente desviación estándar\nidata_neg.posterior[\"β0_scaled\"] = idata_neg.posterior[\"β\"] * bicis.temperatura.std()\n\nidata_mlb.posterior[\"β0_scaled\"] = idata_mlb.posterior[\"β0\"] * bicis.temperatura.std()\nidata_mlb.posterior[\"β1_scaled\"] = idata_mlb.posterior[\"β1\"] * bicis.hora.std()\n\n\naz.plot_forest([idata_neg, idata_mlb], model_names=[\"model_neg\", \"model_mlb\"], var_names=[\"β0_scaled\", \"β1_scaled\"], figsize=(10, 3), combined=True)\n\narray([&lt;Axes: title={'center': '94.0% HDI'}&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\nEn la figura anterior podemos ver que el coeficiente \\(\\beta_0\\), que se corresponde con la temperatura es diferente en ambos modelos. Esto se debe a que el efecto de la hora ya explica algunas de las variaciones en el número de bicicletas alquiladas que anteriormente solo se explicaban por la temperatura. En casos extremos, la adición de una nueva variable puede llevar el coeficiente a cero o incluso cambiar el signo. Hablaremos más de esto en el próximo capítulo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#bambi-una-sintaxis-para-gobernarlos-a-todos",
    "href": "05_GLMS.html#bambi-una-sintaxis-para-gobernarlos-a-todos",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.14 Bambi: una sintaxis para gobernarlos a todos",
    "text": "5.14 Bambi: una sintaxis para gobernarlos a todos\nPyMC tiene una sintaxis muy simple y expresiva, que nos permite construir modelos arbitrarios, esta capacidad puede ser vista como una bendición, pero también como una carga. Bambi, en cambio, se centra en modelos de regresión; esta restricción conduce a una sintaxis más focalizada y características que serían difíciles de implementar en paquetes más generales.\nBambi utiliza una sintaxis de fórmula de Wilkinson similar a la utilizada por muchos paquetes de R como nlme, lme4 o brms. Supongamos que tenemos un DataFrame como el siguiente:\n\nSIZE = 117\ndatos = pd.DataFrame(\n    {\n        \"y\": np.random.normal(size=SIZE),\n        \"x\": np.random.normal(size=SIZE),\n        \"z\": np.random.normal(size=SIZE),\n        \"g\": [\"Group A\", \"Group B\", \"Group C\"] * 39,\n    }\n)\ndatos.head()\n\n\n\n\n\n\n\n\n\ny\nx\nz\ng\n\n\n\n\n0\n0.407373\n0.926419\n0.363536\nGroup A\n\n\n1\n-0.077750\n-2.315925\n-1.165464\nGroup B\n\n\n2\n0.459236\n1.177808\n0.422089\nGroup C\n\n\n3\n1.117329\n1.772152\n0.682265\nGroup A\n\n\n4\n-0.788372\n1.089291\n0.375650\nGroup B\n\n\n\n\n\n\n\n\nUsando estos datos queremos construir un modelo lineal que prediga y a partir de x. Usando PyMC haríamos algo como:\nwith pm.Model() as lm:\n    Intercept = pm.Normal(\"Intercept\", 0, 1)\n    x = pm.Normal(\"x\", 0, 1)\n    y_sigma = pm.HalfNormal(\"sigma\", 1)\n    y_mean = Intercept + x * data[\"x\"]\n    y = pm.Normal(\"y\", y_mean, y_sigma, observed=data[\"y\"])\nUsando la sintaxis de Bambi, podemos escribir el mismo modelo como:\n\nun_modelo = bmb.Model(\"y ~ x\", datos)\n\nEn el lado izquierdo de ~ tenemos la variable dependiente y en el lado derecho la(s) variable(s) independiente(s). Con esta sintaxis, solo estamos especificando la media (\\(\\mu\\) en el modelo lm de PyMC). De forma predeterminada, Bambi asume que el likelihood es una Normal. Esto se puede cambiar con el argumento family. Esta sintáxis solo especifica cómo se relacionan las variables dependientes e independiente, pero no especifica las distribuciones a priori. Bambi internamente define distribuciones a priori debilmente informativas. Al imprimir un modelo de Bambi obtenemos mucha información útil sobre su especificación.\n\nun_modelo\n\n       Formula: y ~ x\n        Family: gaussian\n          Link: mu = identity\n  Observations: 117\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0108, sigma: 2.6365)\n            x ~ Normal(mu: 0.0, sigma: 2.4114)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.0541)\n\n\nLa primera línea muestra la fórmula que usamos para definir el modelo y la segunda línea es el likelihood. En Bambi, usamos el argumento family para especificar el . La tercera línea es la función de enlace. Por defecto cada familia tiene asociada una función de enlace, por ej la Gaussiana se asocia a la función identidad. Luego tenemos el número de observaciones utilizadas para ajustar el modelo, y lo siguiente nos dice que estamos modelando linealmente el parámetro \\(\\mu\\) de la Gaussiana. Luego, en las siguientes líneas tenemos la estructura del modelo. La primera parte muestra los efectos de nivel común, en este caso, el intercepto y el coefficiente de regressión (la “pendiente”) asociado a x. En la segunda parte se muestran los parámetros auxiliares, es decir, todos los parámetros no modelados linealmente, en este caso, la desviación estándar.\nSi querés omitir el intercepto, tenés dos opciones:\n\nno_intercepto_1 = bmb.Model(\"y ~ 0 + x\", datos)\nno_intercepto_1\n\n       Formula: y ~ 0 + x\n        Family: gaussian\n          Link: mu = identity\n  Observations: 117\n        Priors: \n    target = mu\n        Common-level effects\n            x ~ Normal(mu: 0.0, sigma: 2.4114)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.0541)\n\n\n\nno_intercepto_2 = bmb.Model(\"y ~ -1 + x\", datos)\nno_intercepto_2\n\n       Formula: y ~ -1 + x\n        Family: gaussian\n          Link: mu = identity\n  Observations: 117\n        Priors: \n    target = mu\n        Common-level effects\n            x ~ Normal(mu: 0.0, sigma: 2.4114)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.0541)\n\n\nCon Bambi también podemos incluir efectos a nivel de grupo (es decir jerarquías), por ejemplo, si queremos usar la variable g para agrupar parcialmente las estimaciones de x podemos hacerlo así:\n\nmodelo_h = bmb.Model(\"y ~ x + z + (x | g)\", datos)\n\nPara obtener una representación gráfica de la estructura de un modelo de Bambi podemos usar el método .graph(), esto requiere que previamente hayamos usado el método .build() para construir el modelo. O el método .fit() para ajustar el modelo (calcular la distribución posterior de los parámetros). Veamos como lucen un_modelo y modelo_h:\n\nun_modelo.build()\nun_modelo.graph()\n\n\n\n\n\n\n\n\n\nmodelo_h.build()\nmodelo_h.graph()\n\n\n\n\n\n\n\n\nLa sintaxis de la fórmula es muy simple, pero también muy poderosa. Acabamos de arañar la superficie de lo que podemos hacer con él. En lugar de describir la sintaxis de una vez, la mostraremos mediante ejemplos. Así que comencemos ajustando el modelo de bicicleta del capítulo anterior.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#bicicletas-bambinas",
    "href": "05_GLMS.html#bicicletas-bambinas",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.15 Bicicletas bambinas",
    "text": "5.15 Bicicletas bambinas\n\nbicis = pd.read_csv(\"datos/bicis.csv\")\n\n\nmodelo_t = bmb.Model(\"alquiladas ~ temperatura\", bicis, family=\"negativebinomial\")\nidata_t = modelo_t.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alquiladas_alpha, Intercept, temperatura]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\nmodelo_t.graph()\n\n\n\n\n\n\n\n\nAhora vamos a graficar el ajuste medio a posteriori y las predicciones. Para ello usaremos la función plot_predictions del módulo interpret.\n\n_, axes = plt.subplots(1, 2, sharey=True, figsize=(12, 4)) \nbmb.interpret.plot_predictions(modelo_t, idata_t, \"temperatura\", ax=axes[0])\nbmb.interpret.plot_predictions(modelo_t, idata_t, \"temperatura\", pps=True, ax=axes[1])\n\naxes[0].plot(bicis.temperatura, bicis.alquiladas, \".\", color=\"0.5\",  zorder=-3)\naxes[1].plot(bicis.temperatura, bicis.alquiladas, \".\", color=\"0.5\", zorder=-3)\naxes[0].set_title(\"media\")\naxes[1].set_title(\"predicciones\");\n\n\n\n\n\n\n\n\nProbemos ahora ajustar un modelo de regresión con dos variables predictoras, temperatura y humedad.\n\nmodelo_th = bmb.Model(\"alquiladas ~ temperatura + humedad\", bicis, \n                     family=\"negativebinomial\")\n                     \nidata_th = modelo_th.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alquiladas_alpha, Intercept, temperatura, humedad]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\nbmb.interpret.plot_predictions(modelo_th, idata_th, [\"temperatura\", \"humedad\"],\n                               subplot_kwargs={\"group\":None, \"panel\":\"humedad\"},\n                               legend=False,\n                               fig_kwargs={\"sharey\":True, \"sharex\":True});\n\n\n\n\n\n\n\n\nEn la figura anterior podemos ver que la temperatura tiene un efecto positivo en el número de bicicletas alquiladas, mientras que la humedad tiene un efecto negativo. También podemos ver que el efecto de la temperatura es más fuerte que el de la humedad.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#regresión-polinomial",
    "href": "05_GLMS.html#regresión-polinomial",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.16 Regresión polinomial",
    "text": "5.16 Regresión polinomial\nUna forma de ajustar curvas usando un modelo de regresión lineal es construyendo un polinomio, como este:\n\\[\n   \\mu = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\beta_4 x^4 \\dots \\beta_m x^m\n\\]\ndonde \\(m\\) es el grado del polinomio.\nHay dos cosas importantes a tener en cuenta. Primero, la regresión polinómica sigue siendo una regresión lineal; la linealidad se refiere a los coeficientes (los \\(\\beta\\)s), no a las variables (los \\(x\\)s). La segunda es que simplemente estamos creando nuevas variables de la nada. La única variable observada es , el resto son sólo potencias de . Crear nuevas variables a partir de las observadas es un “truco” perfectamente válido al hacer regresión, a veces la transformación puede estar motivada o justificada por la teoría (como sacar la raíz cuadrada de la longitud de los bebés), pero a veces es solo una forma de ajustar una curva. La intuición con los polinomios es que para un valor dado de , cuanto mayor sea el grado del polinomio, más flexible será el ajuste. Un polinomio de grado 1 es una línea, un polinomio de grado 2 es una curva que puede subir o bajar, un polinomio de grado 3 es una curva que puede subir y luego bajar (o al revés), y así sucesivamente. Note que dije “puede” porque si tenemos un polinomio de grado 3 como \\(\\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3\\) pero los coeficientes \\(\\beta_2\\) y \\(\\beta_3\\) son 0 (o prácticamente 0), entonces la curva será una línea.\nHay dos formas de definir una regresión polinómica con Bambi. Podemos escribir los polinomios brutos:\n\"y ~ x + I(x ** 2) + I(x ** 3) + I(x ** 4)\"\ndonde usamos la función de identidad I para dejar claro que queremos elevar \\(x\\) a alguna potencia. Necesitamos esto porque el operador ** tiene un significado especial para Bambi. Si usamos esta sintaxis, le estamos diciendo a Bambi que modele la media de \\(y\\) como \\(\\alpha + \\beta_0 x + \\beta_0 x^2 + \\beta_0 x^3 + \\beta_0 x^4\\)\nAlternativamente podemos escribir\n\"y ~ poly(x, 4)\"\nEsto también generará un polinomio de grado 4, pero los términos del polinomio serán ortogonales entre sí, lo que significa que la correlación entre los términos se reduce. Sin entrar en detalles matemáticos, esto tiene al menos dos consecuencias importantes con respecto a los polinomios brutos. En primer lugar, la estimación puede ser numéricamente más estable y, en segundo lugar, la interpretación de los coeficientes es diferente. En la regresión polinómica estándar, los coeficientes pueden ser difíciles de interpretar, ya que cambiar el valor de un coeficiente afecta a todo el polinomio. En cambio, los polinomios ortogonales permiten interpretar más claramente el efecto de cada término, ya que son independientes entre sí. Si bien la interpretación de los coeficientes es diferente, otros resultados siguen siendo los mismos. Por ejemplo, deberías obtener las mismas predicciones con ambos enfoques.\nConstruyamos un polinomio ortogonal de grado 4 para modelar los datos de la bicis. Para este ejemplo, usaremos la variable hora:\n\nmodelo_poly4 = bmb.Model(\"alquiladas ~ poly(hora, degree=4)\", bicis,\n                       family=\"negativebinomial\")\nidata_poly4 = modelo_poly4.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alquiladas_alpha, Intercept, poly(hora, degree=4)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\n_, axes = plt.subplots(1, 2, sharey=True, sharex=\"col\", figsize=(12, 3)) \nbmb.interpret.plot_predictions(modelo_poly4, idata_poly4, \"hora\", ax=axes[0])\nbmb.interpret.plot_predictions(modelo_poly4, idata_poly4, \"hora\", pps=True, ax=axes[1])\n\nfor ax in axes.ravel():\n    ax.plot(bicis.hora, bicis.alquiladas, \"C2.\", zorder=-3)\naxes[0].set_title(\"media\")\naxes[1].set_title(\"predicciones\")\naxes[0].set_xlabel(\"\")\naxes[1].set_ylabel(\"\")\n\nText(0, 0.5, '')\n\n\n\n\n\n\n\n\n\nUn problema con los polinomios es que actúan globalmente. Cuando aplicamos un polinomio de grado \\(m\\) estamos diciendo que la relación entre las variables independientes y dependientes es de grado \\(m\\) para todo el conjunto de datos. Esto puede resultar problemático cuando diferentes regiones de nuestros datos necesitan diferentes niveles de flexibilidad. Esto podría conducir, por ejemplo, a curvas demasiado flexibles. A medida que aumenta el grado, el ajuste se vuelve más sensible a la eliminación de puntos o, de manera equivalente, a la adición de datos futuros. En otras palabras, a medida que aumenta el grado, el modelo se vuelve más propenso a sobreajustarse. La regresión polinomial Bayesiana generalmente sufre menos de este “exceso” gracias al uso de priors y al cálculo de toda una distribución a posteriori y no una estimación puntual.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#splines",
    "href": "05_GLMS.html#splines",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.17 Splines",
    "text": "5.17 Splines\nUna forma general de escribir modelos muy flexibles es aplicar funciones \\(B_{m}\\) a \\(X_{m}\\) y luego multiplicarlas por coeficientes \\(\\beta_m\\):\n\\[\n\\mu = \\beta_0 + \\beta_1 B_{1}(X_{1}) + \\beta_2 B_{2}(X_{2}) + \\cdots + \\beta_m B_{m}(X_{m})\n\\]\nSomos libres de elegir las funciones \\(B_{m}\\), por ejemplo, podemos elegir polinomios. Una opción popular es usar B-splines, no vamos a discutir su definición, pero podemos pensar en ellos como una forma de crear curvas suaves de tal manera que obtengamos flexibilidad, como con los polinomios, pero menos propensos al sobreajuste. Los B-splines son polinomios por partes, es decir, polinomios que están restringidos a afectar solo una parte de los datos. La siguiente figura muestra 3 ejemplos de polinomios por partes de grado creciente. Las líneas verticales punteadas muestran los “nudos”, que son los puntos utilizados para restringir las regiones, la línea gris discontinua representa la función que queremos aproximar y las líneas negras son los polinomios por partes.\n\nLa siguiente figura muestra ejemplos de splines de grado 1 y 3, los puntos en la parte inferior representan los nudos y las líneas discontinuas son los B-splines. En la parte superior tenemos todos los B-splines con igual peso, usamos una escala de grises para resaltar que tenemos muchos B-splines. En el panel inferior, cada B-splines tiene un peso diferente (los multiplicamos por coeficientes \\(\\beta_m\\)), si sumamos los B-splines ponderados obtenemos como resultado la línea negra. Esta línea negra es lo que solemos llamar “la spline”. Podemos utilizar la estadística Bayesiana para encontrar los pesos adecuados para los B-splines.\n\nPodemos usar B-splines con Bambi usando la función bs. Por ejemplo, ajustemos un spline de grado 3 a los datos de las bicis:\n\nnum_knots = 6\nknots = np.linspace(0, 23, num_knots+2)[1:-1]\nmodelo_spline = bmb.Model(\"alquiladas ~ bs(hora, degree=3, knots=knots)\", bicis,           \n                         family=\"negativebinomial\")\nidata_spline = modelo_spline.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alquiladas_alpha, Intercept, bs(hora, degree=3, knots=knots)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEn la siguiente figura podemos ver que el número de bicicletas de alquiler es el más bajo a altas horas de la noche. Luego se produce un aumento, probablemente cuando la gente se despierta y va al trabajo, a la escuela u otras actividades. Tenemos un primer pico alrededor de la hora 8, luego un ligero descenso, seguido por el segundo pico alrededor de la hora 18, probablemente porque la gente regresa a casa, después del cual hay un descenso constante. Observe que la curva no es muy suave, esto se debe a que los datos están discretizados (por hora).\n\n_, ax = plt.subplots(sharey=True, sharex=\"col\", figsize=(12, 6)) \nbmb.interpret.plot_predictions(modelo_spline, idata_spline, \"hora\", ax=ax)\nax.plot(bicis.hora, bicis.alquiladas, \"C2.\", zorder=-3);\n\n\n\n\n\n\n\n\nCuando trabajamos con splines, una decisión importante es determinar el número y la ubicación de los nudos. Esto puede ser una tarea algo desalentadora ya que el número óptimo de nudos y su espaciado no son evidentes de inmediato. Una sugerencia útil para determinar las ubicaciones de los nudos es considerar colocarlos según cuantiles en lugar de hacerlo de manera uniforme. Por ejemplo nudos = np.quantile(bicis.hora, np.linspace(0, 1, num_knots)). Al hacerlo, colocaríamos más nudos en áreas donde tenemos una mayor cantidad de datos, y menos nudos en áreas con menos datos. Esto da como resultado una aproximación más adaptable que captura efectivamente la variabilidad en regiones con una mayor densidad de puntos de datos. Además, es posible que deseemos ajustar splines con distintos números de nudos y posiciones y luego evaluar los resultados, utilizando herramientas como LOO, como veremos en el próximo capítulo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#modelos-distribucionales",
    "href": "05_GLMS.html#modelos-distribucionales",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.18 Modelos distribucionales",
    "text": "5.18 Modelos distribucionales\nAnteriormente vimos que podemos usar modelos lineales para parámetros distintos de la media. Por ejemplo, podemos utilizar un modelo lineal para la media y un modelo lineal para la desviación estándar de una distribución Gaussiana. Estos modelos suelen denominarse modelos distribucionales. La sintaxis de Bambi para los modelos distribucionales es muy similar, sólo necesitamos agregar una línea para los parámetros auxiliares que queremos modelar. Por ejemplo, sigma para una Gaussiano o alfa para un NegativaBinomial\nReproduzcamos ahora un ejemplo del capítulo anterior, el ejemplo de los bebés.\n\nbebes = pd.read_csv('datos/babies.csv')\n\n\nmodelo_cons = bmb.Model(\"Longitud ~ np.sqrt(Meses)\", bebes)\nidata_cons = modelo_cons.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Longitud_sigma, Intercept, np.sqrt(Meses)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEn el modelo anterior sigma es constante, ahora veamos un modelo distribucional. En este modelo sigma es una función lineal de Meses.\n\nformula = bmb.Formula(\n    \"Longitud ~ np.sqrt(Meses)\",\n    \"sigma ~ Meses\"\n)\nmodelo_dis = bmb.Model(formula, bebes)\nidata_dis = modelo_dis.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, np.sqrt(Meses), sigma_Intercept, sigma_Meses]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEn la siguiente figura podemos ver los valores a posteriori de sigma para los modelos con sigma constante y variable. Podemos ver que cuando se permite que sigma varíe obtenemos valores por debajo y por encima de la estimación para un sigma constante, lo que significa que estamos subestimando y sobreestimando este parámetro cuando no permitimos que cambie.\n\n\nMostrar Código\nfig, ax = plt.subplots(figsize=(12, 4))\nfrom matplotlib.lines import Line2D\n\nfor idx in idata_dis.posterior.coords.get(\"Longitud_obs\"):\n    values = idata_dis.posterior[\"sigma\"].sel(Longitud_obs=idx).to_numpy().flatten()\n    grid, pdf = az.kde(values)\n    ax.plot(grid, pdf, lw=1, color=\"C1\")\n\nvalues = idata_cons.posterior[\"Longitud_sigma\"].to_numpy().flatten()\ngrid, pdf = az.kde(values)\nax.plot(grid, pdf, lw=3, color=\"C0\")\n\nhandles = [\n    Line2D([0], [0], label=\"sigma variable\", lw=1.5, color=\"k\", alpha=0.6),\n    Line2D([0], [0], label=\"sigma constante\", lw=1.5, color=\"C0\")\n]\n\nlegend = ax.legend(handles=handles, loc=\"upper right\")\n\nax.set(xlabel=\"Alfa a posteriori\", yticks=[]);\n\n\n\n\n\n\n\n\n\nLa siguiente figura muestra el ajuste a posteriori para model_dis. Observe que el modelo puede capturar el aumento de la variabilidad a medida que los bebés crecen.\n\n_, ax = plt.subplots(sharey=True, sharex=\"col\", figsize=(12, 6)) \nbmb.interpret.plot_predictions(modelo_dis, idata_dis, \"Meses\", ax=ax, fig_kwargs={\"color\":\"k\"})\nbmb.interpret.plot_predictions(modelo_dis, idata_dis, \"Meses\", pps=True, ax=ax)\nax_ = bmb.interpret.plot_predictions(modelo_dis, idata_dis, \"Meses\", pps=True, ax=ax, prob=0.65)\nax_[1][0].get_children()[5].set_facecolor('C1')  \n\nax.plot(bebes.Meses, bebes.Longitud, \"C2.\", zorder=-3);\n\n\n\n\n\n\n\n\nAl trabajar con PyMC vimos que el muestreo de la distribución predictiva a posteriori, evaluado en valores no observados, requiere que definamos el modelo con las “X” como Mutable_data y luego actualicemos el valor de la variable mutable antes de calcular la distribución predictiva posterior. Con Bambi esto no es necesario, podemos usar el método predict para predecir nuevos valores pasando los nuevos valores al argumento data. Por ejemplo, predigamos la longitud de un bebé a los 0,5 meses (15 días):\n\nmodelo_dis.predict(idata_dis, kind=\"pps\", data=pd.DataFrame({\"Meses\":[0.5]}))\n\nEsto agrega un grupo posterior_predictive a idata_dis\n\nidata_dis\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 200kB\nDimensions:          (chain: 4, draw: 1000, Longitud_obs: 1)\nCoordinates:\n  * chain            (chain) int64 32B 0 1 2 3\n  * draw             (draw) int64 8kB 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\n  * Longitud_obs     (Longitud_obs) int64 8B 0\nData variables:\n    Intercept        (chain, draw) float64 32kB 47.92 47.92 47.94 ... 48.25 47.9\n    np.sqrt(Meses)   (chain, draw) float64 32kB 7.892 7.845 ... 7.879 7.934\n    sigma_Intercept  (chain, draw) float64 32kB 0.8885 0.9048 ... 0.8158 0.8987\n    sigma_Meses      (chain, draw) float64 32kB 0.03082 0.02981 ... 0.03055\n    Longitud_mean    (chain, draw, Longitud_obs) float64 32kB 53.5 ... 53.51\n    Longitud_sigma   (chain, draw, Longitud_obs) float64 32kB 2.469 ... 2.494\nAttributes:\n    created_at:                  2024-07-22T17:18:32.797577+00:00\n    arviz_version:               0.19.0\n    inference_library:           pymc\n    inference_library_version:   5.15.1\n    sampling_time:               3.6786086559295654\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:chain: 4draw: 1000Longitud_obs: 1Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Longitud_obs(Longitud_obs)int640array([0])Data variables: (6)Intercept(chain, draw)float6447.92 47.92 47.94 ... 48.25 47.9array([[47.91771846, 47.91992249, 47.93586981, ..., 48.09443877,\n        47.96839361, 47.91206188],\n       [48.06217855, 48.26491003, 47.98094919, ..., 48.38467063,\n        48.25822131, 47.80878658],\n       [47.76763464, 48.25976916, 48.08167666, ..., 47.83055773,\n        47.86021886, 47.75681441],\n       [48.45258761, 47.42670193, 48.34785534, ..., 48.27050085,\n        48.25281343, 47.89893323]])np.sqrt(Meses)(chain, draw)float647.892 7.845 7.998 ... 7.879 7.934array([[7.89245948, 7.84458374, 7.99800602, ..., 7.8018446 , 7.87920642,\n        8.0022317 ],\n       [7.8951179 , 7.82140799, 7.88992669, ..., 7.78171594, 7.80611068,\n        7.90036559],\n       [7.96897533, 7.76135908, 7.80241084, ..., 7.91609043, 7.93040629,\n        8.05043247],\n       [7.74691012, 8.04629332, 7.78245506, ..., 7.70768771, 7.87867895,\n        7.93412924]])sigma_Intercept(chain, draw)float640.8885 0.9048 ... 0.8158 0.8987array([[0.88853921, 0.9047667 , 0.84292493, ..., 0.83464737, 0.82742547,\n        0.89979627],\n       [0.91398902, 0.79656607, 0.7124011 , ..., 0.80292547, 0.87359909,\n        0.89603953],\n       [0.88232972, 0.7980029 , 0.76379873, ..., 0.86087956, 0.90236582,\n        0.91686502],\n       [0.76812365, 0.94810923, 0.85706704, ..., 0.87501978, 0.81577323,\n        0.89872523]])sigma_Meses(chain, draw)float640.03082 0.02981 ... 0.0321 0.03055array([[0.03082223, 0.0298126 , 0.03431812, ..., 0.0373662 , 0.03700639,\n        0.02988437],\n       [0.03285147, 0.03696041, 0.04775562, ..., 0.03412524, 0.03359771,\n        0.03035567],\n       [0.03068677, 0.04135866, 0.03862905, ..., 0.03402629, 0.02965904,\n        0.02921001],\n       [0.04017426, 0.02594319, 0.03210694, ..., 0.0368629 , 0.0321027 ,\n        0.03054941]])Longitud_mean(chain, draw, Longitud_obs)float6453.5 53.47 53.59 ... 53.82 53.51array([[[53.49853007],\n        [53.46688085],\n        [53.5913141 ],\n        ...,\n        [53.61117599],\n        [53.5398339 ],\n        [53.57049418]],\n\n       [[53.64486995],\n        [53.79548066],\n        [53.55996986],\n        ...,\n        [53.88717474],\n        [53.7779751 ],\n        [53.39518867]],\n\n       [[53.40255114],\n        [53.7478788 ],\n        [53.59881427],\n        ...,\n        [53.42807896],\n        [53.46786293],\n        [53.4493298 ]],\n\n       [[53.93048029],\n        [53.1162905 ],\n        [53.85088209],\n        ...,\n        [53.72065909],\n        [53.82388074],\n        [53.50920982]]])Longitud_sigma(chain, draw, Longitud_obs)float642.469 2.508 2.363 ... 2.298 2.494array([[[2.46933855],\n        [2.50846998],\n        [2.36335919],\n        ...,\n        [2.34745197],\n        [2.33014073],\n        [2.49612231]],\n\n       [[2.5355606 ],\n        [2.25928022],\n        [2.08815085],\n        ...,\n        [2.27047279],\n        [2.43609888],\n        [2.48734869]],\n\n       [[2.45388653],\n        [2.26750982],\n        [2.18827433],\n        ...,\n        [2.40582457],\n        [2.50226253],\n        [2.5382377 ]],\n\n       [[2.19945758],\n        [2.61452078],\n        [2.39437085],\n        ...,\n        [2.44354836],\n        [2.29750692],\n        [2.49427955]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Longitud_obsPandasIndexPandasIndex(Index([0], dtype='int64', name='Longitud_obs'))Attributes: (8)created_at :2024-07-22T17:18:32.797577+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :3.6786086559295654tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.0\n                      \n                  \n            \n            \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 40kB\nDimensions:       (chain: 4, draw: 1000, Longitud_obs: 1)\nCoordinates:\n  * chain         (chain) int64 32B 0 1 2 3\n  * draw          (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * Longitud_obs  (Longitud_obs) int64 8B 0\nData variables:\n    Longitud      (chain, draw, Longitud_obs) float64 32kB 48.83 49.05 ... 55.52\nAttributes:\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:chain: 4draw: 1000Longitud_obs: 1Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Longitud_obs(Longitud_obs)int640array([0])Data variables: (1)Longitud(chain, draw, Longitud_obs)float6448.83 49.05 50.98 ... 54.06 55.52array([[[48.82697274],\n        [49.05169218],\n        [50.97820524],\n        ...,\n        [53.87268366],\n        [52.34049638],\n        [55.03638748]],\n\n       [[55.16611995],\n        [56.3217108 ],\n        [51.63934665],\n        ...,\n        [57.44745826],\n        [54.08188411],\n        [52.27217071]],\n\n       [[54.59075763],\n        [53.85940292],\n        [54.41209247],\n        ...,\n        [54.76602992],\n        [55.07923841],\n        [50.48000406]],\n\n       [[53.93287158],\n        [54.18120697],\n        [55.46084545],\n        ...,\n        [50.81749724],\n        [54.0589155 ],\n        [55.51943343]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Longitud_obsPandasIndexPandasIndex(Index([0], dtype='int64', name='Longitud_obs'))Attributes: (2)modeling_interface :bambimodeling_interface_version :0.13.0\n                      \n                  \n            \n            \n            \n                  \n                  sample_stats\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 496kB\nDimensions:                (chain: 4, draw: 1000)\nCoordinates:\n  * chain                  (chain) int64 32B 0 1 2 3\n  * draw                   (draw) int64 8kB 0 1 2 3 4 5 ... 995 996 997 998 999\nData variables: (12/17)\n    acceptance_rate        (chain, draw) float64 32kB 0.9634 0.8389 ... 1.0\n    diverging              (chain, draw) bool 4kB False False ... False False\n    energy                 (chain, draw) float64 32kB 2.128e+03 ... 2.131e+03\n    energy_error           (chain, draw) float64 32kB -0.1448 0.4038 ... -1.335\n    index_in_trajectory    (chain, draw) int64 32kB -2 -1 3 -3 1 ... 2 -2 2 4 1\n    largest_eigval         (chain, draw) float64 32kB nan nan nan ... nan nan\n    ...                     ...\n    process_time_diff      (chain, draw) float64 32kB 0.0005846 ... 0.0009832\n    reached_max_treedepth  (chain, draw) bool 4kB False False ... False False\n    smallest_eigval        (chain, draw) float64 32kB nan nan nan ... nan nan\n    step_size              (chain, draw) float64 32kB 0.9659 0.9659 ... 1.119\n    step_size_bar          (chain, draw) float64 32kB 0.9013 0.9013 ... 0.9766\n    tree_depth             (chain, draw) int64 32kB 2 2 3 2 2 2 ... 2 2 2 2 3 2\nAttributes:\n    created_at:                  2024-07-22T17:18:32.816106+00:00\n    arviz_version:               0.19.0\n    inference_library:           pymc\n    inference_library_version:   5.15.1\n    sampling_time:               3.6786086559295654\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (17)acceptance_rate(chain, draw)float640.9634 0.8389 0.9794 ... 0.7334 1.0array([[0.96339565, 0.83888164, 0.97941019, ..., 0.47986966, 0.99139062,\n        0.66572272],\n       [0.59462122, 0.95206033, 0.2496578 , ..., 0.81399083, 0.86710035,\n        0.93278275],\n       [0.76091453, 0.73277358, 0.78687965, ..., 0.85612834, 0.92412518,\n        0.78422142],\n       [0.90594456, 0.96324394, 1.        , ..., 0.64882654, 0.73336392,\n        1.        ]])diverging(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])energy(chain, draw)float642.128e+03 2.128e+03 ... 2.131e+03array([[2127.56689358, 2128.34534615, 2130.2993243 , ..., 2129.75500971,\n        2127.41118168, 2130.21459891],\n       [2131.09391846, 2129.56351668, 2137.74447079, ..., 2130.66740891,\n        2132.68592627, 2128.09062783],\n       [2128.34785545, 2129.80480375, 2131.14698558, ..., 2126.95167641,\n        2127.3426137 , 2130.57494795],\n       [2129.36270087, 2132.02562962, 2131.31177933, ..., 2130.42550348,\n        2133.53445328, 2131.38446494]])energy_error(chain, draw)float64-0.1448 0.4038 ... 0.5079 -1.335array([[-0.14484357,  0.40378327,  0.15563521, ..., -0.01055528,\n        -0.06816132,  0.42902946],\n       [-0.04630251, -0.0456077 ,  1.69029629, ...,  0.35630574,\n        -0.59419156,  0.04598971],\n       [-0.16073785,  0.44430503, -0.26956433, ...,  0.07603307,\n         0.07306079,  0.30716679],\n       [ 0.33151738,  0.28517792, -0.52463128, ...,  0.74613665,\n         0.50788339, -1.33534244]])index_in_trajectory(chain, draw)int64-2 -1 3 -3 1 3 -1 ... 1 2 -2 2 4 1array([[-2, -1,  3, ..., -2,  1,  2],\n       [-2, -5, -1, ..., -1, -3, -2],\n       [-3,  2,  2, ..., -3, -1,  2],\n       [ 2, -2, -2, ...,  2,  4,  1]])largest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])lp(chain, draw)float64-2.126e+03 ... -2.127e+03array([[-2126.4228394 , -2128.01224118, -2129.2311997 , ...,\n        -2126.85826266, -2126.26661791, -2129.11321747],\n       [-2128.34146848, -2127.35391357, -2134.67560758, ...,\n        -2129.17118802, -2126.7342631 , -2127.20458182],\n       [-2126.77399044, -2128.6998843 , -2127.80020544, ...,\n        -2126.21013778, -2126.80053591, -2129.6402235 ],\n       [-2129.02569227, -2130.62787188, -2127.46720365, ...,\n        -2130.34620101, -2131.38065797, -2126.6241714 ]])max_energy_error(chain, draw)float64-0.1448 0.4038 ... 0.938 -1.335array([[-0.14484357,  0.40378327, -0.34214778, ...,  1.58079586,\n        -0.07379508,  0.47034948],\n       [ 1.09497979, -0.35333339,  1.69029629, ...,  0.35630574,\n        -0.59419156,  0.17043671],\n       [ 0.57537264,  0.44430503,  0.710298  , ...,  0.25401912,\n         0.14253123,  0.46471475],\n       [-0.36061503, -0.64347459, -0.52463128, ...,  0.74613665,\n         0.93795119, -1.33534244]])n_steps(chain, draw)float643.0 3.0 7.0 3.0 ... 3.0 3.0 7.0 3.0array([[3., 3., 7., ..., 3., 7., 3.],\n       [3., 7., 3., ..., 3., 3., 3.],\n       [7., 3., 3., ..., 3., 3., 3.],\n       [3., 7., 3., ..., 3., 7., 3.]])perf_counter_diff(chain, draw)float640.0005845 0.0006046 ... 0.0009829array([[0.0005845 , 0.00060456, 0.0011192 , ..., 0.000572  , 0.00114565,\n        0.0005753 ],\n       [0.00098293, 0.001981  , 0.00097717, ..., 0.00056389, 0.00057926,\n        0.0005686 ],\n       [0.00132289, 0.00070568, 0.00128283, ..., 0.00100113, 0.00086162,\n        0.00087348],\n       [0.00067223, 0.00122514, 0.00066551, ..., 0.00078213, 0.0016246 ,\n        0.00098288]])perf_counter_start(chain, draw)float642.697e+03 2.697e+03 ... 2.698e+03array([[2696.7230352 , 2696.72374002, 2696.72445462, ..., 2697.72253817,\n        2697.72321501, 2697.72447373],\n       [2697.28089751, 2697.28211876, 2697.2842804 , ..., 2698.35513089,\n        2698.35579822, 2698.35648238],\n       [2696.56302024, 2696.56447781, 2696.56547516, ..., 2697.58761051,\n        2697.58874769, 2697.58976629],\n       [2696.96978927, 2696.97061183, 2696.97195906, ..., 2698.06628338,\n        2698.06724527, 2698.06903785]])process_time_diff(chain, draw)float640.0005846 0.0006049 ... 0.0009832array([[0.00058465, 0.00060492, 0.00111945, ..., 0.0005723 , 0.00114612,\n        0.00057541],\n       [0.00098335, 0.00198122, 0.00097756, ..., 0.0005641 , 0.00057958,\n        0.00056886],\n       [0.00132319, 0.00070613, 0.00110778, ..., 0.00100161, 0.00086222,\n        0.00087388],\n       [0.00067268, 0.00122559, 0.00066594, ..., 0.00078297, 0.00162533,\n        0.00098321]])reached_max_treedepth(chain, draw)boolFalse False False ... False Falsearray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])smallest_eigval(chain, draw)float64nan nan nan nan ... nan nan nan nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]])step_size(chain, draw)float640.9659 0.9659 ... 1.119 1.119array([[0.96586085, 0.96586085, 0.96586085, ..., 0.96586085, 0.96586085,\n        0.96586085],\n       [0.78534127, 0.78534127, 0.78534127, ..., 0.78534127, 0.78534127,\n        0.78534127],\n       [1.12921692, 1.12921692, 1.12921692, ..., 1.12921692, 1.12921692,\n        1.12921692],\n       [1.11897716, 1.11897716, 1.11897716, ..., 1.11897716, 1.11897716,\n        1.11897716]])step_size_bar(chain, draw)float640.9013 0.9013 ... 0.9766 0.9766array([[0.90132524, 0.90132524, 0.90132524, ..., 0.90132524, 0.90132524,\n        0.90132524],\n       [0.85056648, 0.85056648, 0.85056648, ..., 0.85056648, 0.85056648,\n        0.85056648],\n       [0.8742606 , 0.8742606 , 0.8742606 , ..., 0.8742606 , 0.8742606 ,\n        0.8742606 ],\n       [0.97663897, 0.97663897, 0.97663897, ..., 0.97663897, 0.97663897,\n        0.97663897]])tree_depth(chain, draw)int642 2 3 2 2 2 2 2 ... 1 2 2 2 2 2 3 2array([[2, 2, 3, ..., 2, 3, 2],\n       [2, 3, 2, ..., 2, 2, 2],\n       [3, 2, 2, ..., 2, 2, 2],\n       [2, 3, 2, ..., 2, 3, 2]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-07-22T17:18:32.816106+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1sampling_time :3.6786086559295654tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.13.0\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 13kB\nDimensions:       (Longitud_obs: 796)\nCoordinates:\n  * Longitud_obs  (Longitud_obs) int64 6kB 0 1 2 3 4 5 ... 791 792 793 794 795\nData variables:\n    Longitud      (Longitud_obs) float64 6kB 49.19 51.22 51.22 ... 97.35 94.19\nAttributes:\n    created_at:                  2024-07-22T17:18:32.822410+00:00\n    arviz_version:               0.19.0\n    inference_library:           pymc\n    inference_library_version:   5.15.1\n    modeling_interface:          bambi\n    modeling_interface_version:  0.13.0xarray.DatasetDimensions:Longitud_obs: 796Coordinates: (1)Longitud_obs(Longitud_obs)int640 1 2 3 4 5 ... 791 792 793 794 795array([  0,   1,   2, ..., 793, 794, 795])Data variables: (1)Longitud(Longitud_obs)float6449.19 51.22 51.22 ... 97.35 94.19array([49.19285714, 51.22142857, 51.22142857, 52.74285714, 48.17857143,\n       49.7       , 46.15      , 49.19285714, 50.71428571, 48.17857143,\n       50.20714286, 49.7       , 50.20714286, 49.19285714, 49.19285714,\n       49.7       , 50.71428571, 48.68571429, 50.20714286, 50.20714286,\n       52.23571429, 49.7       , 49.19285714, 53.75714286, 46.15      ,\n       52.23571429, 51.72857143, 48.17857143, 52.23571429, 50.71428571,\n       49.19285714, 47.67142857, 51.22142857, 48.68571429, 47.67142857,\n       49.19285714, 49.19285714, 50.20714286, 49.7       , 52.23571429,\n       51.22142857, 49.7       , 48.17857143, 52.23571429, 51.72857143,\n       55.27857143, 50.71428571, 53.25      , 52.09239497, 52.9773925 ,\n       52.15931415, 54.79551317, 55.88960402, 56.15775148, 56.71321613,\n       56.14531822, 54.27152775, 53.18845079, 51.58980471, 56.52740991,\n       54.27041965, 53.90327795, 56.31186537, 52.85389383, 56.2498965 ,\n       55.3230851 , 52.96168533, 54.83012442, 56.90657333, 56.1674208 ,\n       57.87042139, 55.03640928, 61.33037799, 52.78255116, 53.94307754,\n       54.84143382, 51.75248234, 56.48636007, 56.19388644, 54.60045215,\n       53.89607373, 56.1067215 , 61.39098782, 60.03948235, 59.12081467,\n       59.47145582, 56.87930169, 57.01821414, 55.0298334 , 57.57946143,\n       59.89906647, 57.77073394, 56.61548298, 57.92039996, 59.38318439,\n       57.60909694, 59.98242783, 55.18881162, 56.40744072, 56.98018785,\n...\n       82.65200072, 84.37440979, 91.3085265 , 79.96338712, 81.61261347,\n       84.29581338, 88.81517149, 80.29882513, 77.40305079, 87.23796829,\n       84.06027194, 91.38395098, 89.59787794, 91.62079733, 92.81936454,\n       92.24137361, 76.43942909, 77.71863214, 88.55951887, 88.96395213,\n       77.95509383, 82.74625965, 91.23181564, 92.76141866, 85.54573872,\n       89.36846664, 89.10512726, 90.92382869, 90.97831844, 85.31646661,\n       83.2178514 , 82.74694287, 84.24183082, 88.53873707, 84.24292413,\n       77.67609253, 91.9678806 , 91.14871479, 84.65728687, 97.43958338,\n       86.3573666 , 90.30806077, 86.76620237, 78.94318283, 89.86260498,\n       86.70593948, 92.2386928 , 86.73034187, 81.02343959, 90.37105389,\n       80.49576392, 85.51492889, 91.65871132, 88.5279465 , 94.06219176,\n       87.13126778, 82.14414651, 83.48512537, 84.1944379 , 90.25150091,\n       85.40245169, 84.7221104 , 74.23082134, 92.32109173, 85.30380521,\n       86.94866672, 88.17681991, 79.07148226, 87.27725659, 93.07974128,\n       87.50474804, 78.82336361, 88.3197443 , 89.21055719, 85.10846706,\n       87.99056523, 84.5124126 , 87.9681095 , 83.8704532 , 89.92279315,\n       89.15198916, 87.85582658, 83.9765828 , 94.82978854, 89.38589518,\n       94.6727304 , 75.4419031 , 95.4900717 , 96.4306434 , 84.42186434,\n       86.15102724, 83.64517681, 81.13556856, 90.92918567, 97.35113965,\n       94.193379  ])Indexes: (1)Longitud_obsPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       786, 787, 788, 789, 790, 791, 792, 793, 794, 795],\n      dtype='int64', name='Longitud_obs', length=796))Attributes: (6)created_at :2024-07-22T17:18:32.822410+00:00arviz_version :0.19.0inference_library :pymcinference_library_version :5.15.1modeling_interface :bambimodeling_interface_version :0.13.0\n                      \n                  \n            \n            \n              \n            \n            \n\n\n\n\nMostrar Código\nref = 52.5\ny_ppc = idata_dis.posterior_predictive[\"Longitud\"].stack(sample=(\"chain\", \"draw\"))\ngrid, pdf = az.stats.density_utils._kde_linear(y_ppc.values)\nplt.plot(grid, pdf)\npercentile = int((y_ppc &lt;= ref).mean() * 100)\nplt.fill_between(\n    grid[grid &lt; ref],\n    pdf[grid &lt; ref],\n    label=\"percentil = {:2d}\".format(percentile),\n    color=\"C1\",\n)\nplt.xlabel(\"Longitud\")\nplt.yticks([])\nplt.legend();",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#predictores-categóricos",
    "href": "05_GLMS.html#predictores-categóricos",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.19 Predictores Categóricos",
    "text": "5.19 Predictores Categóricos\nUna variable categórica representa distintos grupos o categorías. La variable solo puede tomar un conjunto limitado de valores de esas categorías. Estos valores suelen ser etiquetas o nombres que no poseen significado numérico por sí solos. Algunos ejemplos son:\n\nAfiliación política: conservadora, liberal o progresista.\nSexo: femenino o masculino.\nNivel de satisfacción del cliente: muy insatisfecho, insatisfecho, neutral, satisfecho o muy satisfecho.\n\nLos modelos de regresión lineal pueden acomodar fácilmente variables categóricas, solo necesitamos codificar las categorías como números. Hay algunas opciones para hacerlo. Bambi puede manejar fácilmente los detalles por nosotros. El diablo está en los detalles de como interpretamos los resultados.\n\n5.19.1 Pingüinos Categóricos\nPara el ejemplo actual, vamos a utilizar el conjunto de datos de Palmer Penguins, que contiene 344 observaciones de 8 variables. Por el momento nos interesa modelar la masa de los pingüinos en función de la longitud de su pico. Se espera que la masa de los pingüinos aumente a medida que aumenta la longitud del pico. La novedad de este ejemplo es que vamos a considerar la variable categórica, species. Esta variable tiene 3 categorías o niveles, a saber, Adelie, Chinstrap y Gentoo. La Figura 5.1 muestra un diagrama de dispersión para las variables que queremos modelar.\n\n\nMostrar Código\npenguins = pd.read_csv(\"datos/penguins.csv\").dropna()\npenguins.head()\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length\nbill_depth\nflipper_length\nbody_mass\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n3.91\n1.87\n18.1\n3.75\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n3.95\n1.74\n18.6\n3.80\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n4.03\n1.80\n19.5\n3.25\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n3.67\n1.93\n19.3\n3.45\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n3.93\n2.06\n19.0\n3.65\nmale\n2007\n\n\n\n\n\n\n\n\n\n\nMostrar Código\n# Get unique categories\nunique_categories = np.unique(penguins.species)\n\n# Create color map for categories\ncategory_color_map = {cat: f\"C{i}\" for i, cat in enumerate(unique_categories)}\n\n# Generate colors for each category\ncolors = [category_color_map[cat] for cat in penguins.species]\n\n# Create scatter plot for each category\nfor cat in unique_categories:\n    category_data = penguins[penguins.species == cat]\n    plt.scatter(category_data.body_mass, category_data.bill_length, c=category_color_map[cat], label=cat)\n\n# Add labels and legend\nplt.ylabel(\"Body mass (g)\")\nplt.xlabel(\"Bill length (mm)\")\nplt.legend(labels=unique_categories, loc=\"lower right\");\n\n\n\n\n\n\n\n\nFigura 5.1: Largo del pico (bill_length) vs masa (body_mass) para 3 especies de pingüinos.\n\n\n\n\n\nPara ajustar un modelo con variables categoricas no necesitamos de ninguna sintáxis especial\n\nmodelo_p = bmb.Model(\"body_mass ~ bill_length + species\", data=penguins)\nidata_p = modelo_p.fit()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [body_mass_sigma, Intercept, bill_length, species]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\nLa Figura 5.2 muestra un forest plot para model_p. ¿Notás algo inesperado? No hay valores posteriores para Adelie. Esto no es un error. De forma predeterminada, Bambi codifica variables categóricas con N niveles (3 especies) como N-1 variables (2 especies). Así, los coeficientes species-Chinstrap y species-Gentoo representan deflecciones del modelo base:\n\\[\n\\text{body\\_mass} = \\beta_0 + \\beta_1 \\text{bill\\_length}\n\\]\n\n\nMostrar Código\nax = az.plot_forest(idata_p, combined=True, figsize=(12, 3))\nmean_chinstrap = idata_p.posterior[\"species\"].sel(species_dim=\"Chinstrap\").mean()\nmean_gentoo = idata_p.posterior[\"species\"].sel(species_dim=\"Gentoo\").mean()\nax[0].annotate(f\"{mean_chinstrap.item():.2f}\", (mean_chinstrap , 2.5), weight='bold')\nax[0].annotate(f\"{mean_gentoo.item():.2f}\", (mean_gentoo , 1.7), weight='bold');\n\n\n\n\n\n\n\n\nFigura 5.2: Fores plot para la distribución a posteriori de modelo_p.\n\n\n\n\n\nPara que esto quede más claro, revisemos un par de gráficos. Podemos leer la Figura 5.2 como que la masa corporal de Chinstrap es en promedio -0.89 respecto de la masa corporal media de Adelie. Lo mismo ocurre con Gentoo, pero esta vez tenemos que agregar 0,66 a la media del modelo base. Podés comprobar que estas dos afirmaciones son verdaderas mirando la Figura 5.3. Observá cómo las 3 líneas son esencialmente paralelas entre sí con Adelie en el medio, Chinstrap debajo (-0,89) y Gentoo arriba (0,58).\n\n\nMostrar Código\nbmb.interpret.plot_predictions(modelo_p, idata_p, [\"bill_length\",  \"species\"]);\n\n\n\n\n\n\n\n\nFigura 5.3: Predicciones del ajuste medio para modelo_p.\n\n\n\n\n\n\n\n5.19.2 Relación con modelos jerárquicos\nEn el Capítulo 3 analizamos y contrastamos los modelos agrupados y jerárquicos (o parcialmente agrupados). Allí mostramos que a menudo podemos aprovechar la estructura o las jerarquías de los datos. Siguiendo la lógica de ese capítulo, se podría argumentar que Adelie, Gentoo y Chinstrap, aunque son especies diferentes, son todos pingüinos. Por lo tanto, modelar jerárquicamente sus masas corporales puede ser una buena idea. Entonces, ¿Cuál es la diferencia entre dicho modelo y el que utilizamos en esta sección?\nEl factor distintivo reside en las sutilezas de los componentes de pendiente e intersección. En el caso de model_p (variables categóricos), la pendiente sigue siendo la misma en las tres especies de pingüinos, mientras que los interceptos pueden variar. Intercept + 0 para Adelie, Intercept + species[Chinstrap] para Chinstrap, y Intercept + species[Gentoo] para Gentoo. Por lo tanto, este modelo resalta los distintos incerceptos manteniendo la pendiente uniforme.\nSi, en cambio, hubiéramos construido el modelo jerárquico body_mass ~ bill_length|species), habríamos estado pidiendo una pendiente y un intercepto parcialmente agrupados. Y si en lugar de eso hubiéramos modelado body_mass ~ (0 + bill_length | specie) habríamos estado pidiendo una pendiente parcialmente agrupada y un intercepto común.\nEntonces, ¿Cuál es mejor modelo? Como siempre, depende, incluso en algunos casos podría ser mejor una combinación de ambos enfoques, ya que no son ideas mutuamente excluyentes. Como ya comentamos, el mejor modelo es el que se alinea con los objetivos de tu análisis y proporciona información útil. A menudo es una buena idea explorar múltiples modelos, comparar su desempeño usando criterios apropiados (como los discutidos en el ?sec-model_comparison y considerar las implicaciones prácticas de cada modelo en el contexto de la investigación o proceso de toma de decisiones.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#interacciones",
    "href": "05_GLMS.html#interacciones",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.20 Interacciones",
    "text": "5.20 Interacciones\nUn efecto de interacción o interacción estadística, ocurre cuando el efecto de una variable independiente sobre la respuesta cambia dependiendo del valor de otra variable independiente en el mismo modelo. Una interacción puede ocurrir entre dos o más variables. Algunos ejemplos son:\n\nEficacia de los medicamentos y edad: un medicamento que funciona mejor en personas mayores que en personas más jóvenes\nNivel de educación e impacto en los ingresos: Es posible que la educación superior tenga un efecto positivo más fuerte en los ingresos de un género en comparación con el otro, lo que resulta en una interacción entre la educación y el género.\nEfectos del ejercicio y la dieta sobre la pérdida de peso: Podría ser que el efecto de la dieta sobre la pérdida de peso sea pequeño para las personas que hacen nada o poco ejercicio y muy importante para las personas que hacen ejercicio moderado.\n*Temperatura y humedad para el crecimiento de los cultivos: El efecto de la temperatura y la humedad en el crecimiento de los cultivos puede depender del tipo de cultivo que se esté cultivando. Algunos cultivos podrían prosperar en condiciones cálidas y húmedas, mientras que otros podrían funcionar mejor en ambientes más fríos y menos húmedos, creando una interacción entre temperatura, humedad y tipo de cultivo.\n\nTenemos una interacción cuando el efecto combinado de dos o más variables actuando conjuntamente no es igual a la suma de sus efectos individuales. Si tenemos un modelo como\n\\[\n\\mu = \\alpha + \\beta_0 X_0 + \\beta_1 X_1\n\\]\nno podemos modelar un interacción, ya que los efectos son aditivos. La forma más común de modelar una interacción es multiplicando 2 o más variables. Por ejemplo en un modelo como:\n\\[\n\\mu = \\alpha + \\overbrace{\\beta_0 X_0 + \\beta_1 X_1 }^{\\text{término principal}} \\; + \\underbrace{\\beta_3 X_0X_1}_{\\text{término de interacción}}\n\\]\nEs común que al modelar una interacción se incluya también el término principal.\n\nMultiplicar dos variables puede verse como un truco similar al que usamos para la regresión polinómica (o cualquier transformación de una variable determinada). En lugar de multiplicar un predictor consigo mismo, multiplicamos dos predictores diferentes y obtenemos uno nuevo.\n\nDefinir una interacción es fácil; para un modelo PyMC, solo necesitamos multiplicar los dos predictores y agreagar un coeficiente más al modelo. Para que un modelo de Bambi es aún más fácil, usamos el operador :. Veamos un ejemplo de un modelo con y sin interacciones.\n\n# Sin interacción\nmodel_noint = bmb.Model(\"body_mass ~ bill_depth + bill_length\", data=penguins)\nidata_noint = model_noint.fit()\n\n# COn interacción\nmodel_int = bmb.Model(\"body_mass ~ bill_depth + bill_length + bill_depth:bill_length\", data=penguins)\nidata_int = model_int.fit()\n                    \n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [body_mass_sigma, Intercept, bill_depth, bill_length]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [body_mass_sigma, Intercept, bill_depth, bill_length, bill_depth:bill_length]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 14 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn la Figura 5.4 tenemos el ajuste de regresión media para bill_depth evaluado en 5 valores fijos de bill_length. A la izquierda tenemos el resultado dpara model_noint (sin interacciones) y a la derecha para model_int (con interacciones). Podemos ver que cuando no tenemos interacciones las rectas ajustadas para bill_ depth son paralelas en diferentes niveles de bill_length. En cambio, cuando tenemos interacciones las rectas ya no son paralelas, precisamente porque el efecto de cambiar bill_depth sobre cuánto cambia body_mass ya no es constante sino que está modulado por los valores de bill_length. Si generás una figura como Figura 5.4, pero fijando bill_depth en vez de bill_length observarás un fenómeno parecido.\n\n\nMostrar Código\n_, axes = plt.subplots(1, 2, figsize=(12, 4.5), gridspec_kw={'hspace': 0.1})\n\nbmb.interpret.plot_predictions(model_noint, idata_noint,\n                                [\"bill_depth\",  \"bill_length\"],\n                                ax=axes[0],\n                                legend=False,\n                                )\naxes[0].set_title(\"Sin interacción\")\n\n\nbmb.interpret.plot_predictions(model_int, idata_int,\n                               [\"bill_depth\",  \"bill_length\"],\n                                ax=axes[1],\n                                )\naxes[1].set_title(\"Con interacción\");\n\n\n\n\n\n\n\n\nFigura 5.4: Comparación de un modelo sin interacción (las lineas se mantienen paralelas) y con interacción (las lineas se cruzan).\n\n\n\n\n\nAcabamos de ver visualmente que interpretar modelos lineales con interacciones no es tan fácil como interpretar modelos lineales sin ellas. Veamos esto matemáticamente:\nSupongamos que tenemos un modelo con 2 variables \\(X_0\\) y \\(X_1\\) y una interacción entre ellas:\n\\[\n     \\mu = \\alpha + \\beta_0 X_0 + \\beta_1 X_1 + \\beta_3 X_0X_1\n\\]\npodemos reescribir este modelo como:\n\\[\n\\mu = \\alpha + \\underbrace{{(\\beta_0 + \\beta_2} X_1)}_{\\text{pendiente de } X_0} X_0 + \\beta_1 X_1\n\\]\no así:\n\\[\n\\mu = \\alpha + \\beta_0 X_0 + \\underbrace{(\\beta_1 + \\beta_2 x_0)}_{\\text{pendiente de } X_1} X_1\n\\]\nEsto nos muestra el siguiente gráfico de Fores para la distribución a posteriori de:\n\n¡El término de interacción puede entenderse como un modelo lineal dentro de un modelo lineal!\nLa interacción es simétrica; podemos pensar en ello como la pendiente de \\(x_0\\) en función de \\(x_1\\) y al mismo tiempo como la pendiente de \\(x_1\\) en función de \\(x_0\\). Esto también se puede ver en la figura interactiva.\nSabemos desde antes que el coeficiente \\(\\beta_0\\) se puede interpretar como la cantidad de cambio de \\(\\mu\\) por unidad de cambio de \\(x_0\\) (por eso lo llamamos pendiente). Si agregamos un término de interacción, entonces esto solo es cierto en \\(x_1 = 0\\). Intente utilizar la figura interactiva para verlo usted mismo. Matemáticamente, esto es cierto porque cuando \\(x_1 = 0\\) entonces \\(\\beta_2x_1 = 0\\), y por lo tanto la pendiente de \\(x_0\\) se reduce a \\(\\beta_0 x_0\\). Por simetría, el mismo razonamiento se puede aplicar a \\(\\beta_1\\).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#interpretando-modelos-con-bambi",
    "href": "05_GLMS.html#interpretando-modelos-con-bambi",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.21 Interpretando modelos con Bambi",
    "text": "5.21 Interpretando modelos con Bambi\nYa hemos usado bmb.interpret_plot_predictions en este capítulo. Pero esa no es la única herramienta que nos ofrece Bambi para ayudarnos a comprender los modelos. Otra opción es bmb.interpret_plot_comparisons. Esta herramienta nos ayuda a responder la pregunta: ¿Cuál es la diferencia predictiva esperada cuando comparamos dos valores de una variable determinada mientras mantenemos el resto en valores constantes?\nComo ejemplo usemos model_int, que ya ajustamos en la sección anterior.\n\nbmb.interpret.plot_comparisons(model_int, idata_int,\n                               contrast={\"bill_depth\":[1.4, 1.8]},\n                               conditional={\"bill_length\":[3.5, 4.5, 5.5]});\n\n\n\n\n\n\n\nFigura 5.5: Contraste de para bill_length de 1,8 a 1,4 cm para 3 valores fijos de bill_length, 3.5, 4.5 y 5.5.\n\n\n\n\n\nLa figura anterior muestra que al comparar un pingüino hipotético con profundidad de pico (bill_depth) de 1,8 con uno con profundida de pico de 1,4, la diferencia esperada es:\n\naproximadamente 0,8 kg para un pico de 3,5 de longitud\n-0,7 kg para un pico de 4,5 de largo\naproximadamente -2 kg para un pico de 5,5 de largo\n\nPara obtener esta misma información, pero en forma de tabla podemos usar la función bmb.interpret.comparisons y obtendremos un DataFrame de Pandas.\n\n\nMostrar Código\nbmb.interpret.comparisons(model_int, idata_int,\n                          contrast={\"bill_depth\":[1.4, 1.8]},\n                          conditional={\"bill_length\":[3.5, 4.5, 5.5]})\n\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\nbill_length\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nbill_depth\ndiff\n(1.4, 1.8)\n3.5\n0.768417\n0.498433\n1.035196\n\n\n1\nbill_depth\ndiff\n(1.4, 1.8)\n4.5\n-0.566772\n-0.674116\n-0.455068\n\n\n2\nbill_depth\ndiff\n(1.4, 1.8)\n5.5\n-1.901961\n-2.178738\n-1.664387\n\n\n\n\n\n\n\n\nOtra función muy útil es Otra función útil es bmb.interpret_plot_slopes. Esta función es similar a bmb.interpret_plot_comparison, la “tasa de cambio instantánea” o pendiente en un valor dado.\n\nbmb.interpret.plot_slopes(model_int, idata_int,\n                          wrt={\"bill_depth\":1.8},\n                          conditional={\"bill_length\":[3.5, 4.5, 5.5]});\n\n\n\n\n\n\n\nFigura 5.6: Comparación de las pendientes de bill_depth evaluada en 1.8 para tres valores de bill_length, 3.5, 4.5 y 5.5.\n\n\n\n\n\nLa Figura 5.6 muestra que las pendientes para bill_depth en 1.8 son:\n\n\\(\\approx\\) 2 kg/cm para un largo de pico de 3.5\n-1.4 kg/cm para un largo de pico de4.5\n\\(\\approx\\) -5 kg/cm para un largo de pico de 5.5\n\nSi deseas esta información en forma tabular, podés usar: la función bmb.interpret.slopes y obtendrás un DataFrame en lugar de un gráfico.\n\n\nMostrar Código\nbmb.interpret.slopes(model_int, idata_int,\n                     wrt={\"bill_depth\":1.8},\n                     conditional={\"bill_length\":[3.5, 4.5, 5.5]})\n\n\n\n\n\n\n\n\n\n\nterm\nestimate_type\nvalue\nbill_length\nestimate\nlower_3.0%\nupper_97.0%\n\n\n\n\n0\nbill_depth\ndydx\n(1.8, 1.8001)\n3.5\n1.921043\n1.246082\n2.587990\n\n\n1\nbill_depth\ndydx\n(1.8, 1.8001)\n4.5\n-1.416930\n-1.685290\n-1.137671\n\n\n2\nbill_depth\ndydx\n(1.8, 1.8001)\n5.5\n-4.754903\n-5.446846\n-4.160967\n\n\n\n\n\n\n\n\nEn esta sección, apenas hemos arañado la superficie de lo que podemos hacer con las herramientas del módulo bmb.interpret. Este módulo es una característica muy útil de Bambi, especialmente para modelos con interacciones y/o modelos con funciones de enlace distintas a la función de identidad. Les recomiendo que lea la documentación de Bambi para obtener más ejemplos y detalles que no se tratan aquí.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#selección-de-variables",
    "href": "05_GLMS.html#selección-de-variables",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.22 Selección de Variables",
    "text": "5.22 Selección de Variables\nLa selección de variables se refiere al proceso de identificar las variables más relevantes en un modelo a partir de un conjunto más amplio de predictores. Realizamos la selección de variables bajo el supuesto de que sólo un subconjunto de variables tiene un impacto considerable en el resultado de interés, mientras que otras aportan poco o ningún valor adicional.\nPodría decirse que “lo más bayesiano que se puede hacer” al construir un modelo es incluir todas las variables que podamos pensar en un solo modelo y luego usar la distribución a posteriori de ese modelo para hacer predicciones o comprender las relaciones de las variables. Este es el enfoque “más bayesiano” porque utilizamos la mayor cantidad de datos posible e incorporamos en la distribución a posteriori la incertidumbre sobre la importancia de las variables. Sin embargo, ser más bayesiano que Bayes no siempre es la mejor idea.\nRealizar selección de variables es una buena idea cuando:\n\nNecesitamos reducir el costo de medición. Por ejemplo, en medicina, es posible que tengamos el dinero y los recursos para realizar un estudio piloto y medir 30 variables para 200 pacientes. Pero no podemos hacer lo mismo con miles de personas. O tal vez podamos colocar muchos sensores en un campo para modelar el rinde de un cultivo, pero no podemos extender eso mismo al tamaño de toda una región productiva. Reducir costos no siempre es cuestión de dinero o tiempo. Cuando se trabaja con humanos u otros animales, también es importante reducir el dolor y la incomodidad.\nQueremos reducir el costo computacional. Esto no es un problema para modelos pequeños y simples, pero cuando tenemos muchas variables, muchos datos o ambos, el costo computacional puede ser prohibitivo.\nBuscamos una mejor comprensión de las estructuras de correlación significativas. Es decir, nos interesa entender qué variables proporcionan mejores predicciones. Es importante aclarar que no estamos hablando de causalidad. Si bien los modelos estadísticos, en particular los GLMS, pueden usarse para inferir causalidad, hacerlo requiere pasos y suposiciones adicionales. En este curso no discutimos cómo realizar inferencia causal. Para obtener una introducción muy sencilla a la inferencia causal, consulte este vídeo. O si su inteŕes es más serio, puede consultar el libro en Causal Inference: The Mixtape de Scott Cunningham. También el paquete CausalPy\nCuando deseamos un modelo que sea más robusto a los cambios en la distribución generadora de datos, podemos ver la selección de variables como un método para hacer que el modelo sea más robusto frente a datos no representativos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#inferencia-predictiva-por-proyección",
    "href": "05_GLMS.html#inferencia-predictiva-por-proyección",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.23 Inferencia predictiva por proyección",
    "text": "5.23 Inferencia predictiva por proyección\nExisten muchos métodos para realizar selección de variables. En esta sección, nos centraremos en uno de ellos llamado inferencia predictiva por proyección . La razón principal por la que nos centramos en este método es que ha mostrado un rendimiento muy bueno en una amplia gama de problemas.\nLos principales pasos de la iinferencia predictiva por proyección son:\n\nGenerar un modelo de referencia, es decir, un modelo con todas las variables que creas que pueden ser relevantes y/o pudiste medir.\nGenerar un conjunto de submodelos, es decir, modelos que solo incluyen algún subconjunto de las variables presentens en el modelo de referencia.\nEligir el modelo más pequeño que haga predicciones lo suficientemente cercanas al modelo de referencia.\n\nAl realizar inferencia predictiva por proyección, solo necesitamos realizar la inferencia Bayesiana “tradicional” una sola vez, solo para el modelo de referencia. Para los submodelos, las distribuciones a psoteriori se obtienen por proyección. Sin entrar en detalles técnicos, la proyección consiste en encontrar los parámetros para los submodelos de tal forma que las predicciones de los submodelos sean lo más cercanas posible a las predicciones del modelo de referencia. La proyección se puede realizar de una manera computacionalmente eficiente, por lo que el costo de estimar un posterior es mucho más económico que con los métodos MCMC. Esto es relevante porque el número total de submodelos posibles explota a medida que aumentamos el número de variables en el modelo de referencia. Considere que necesitamos evaluar todas las combinaciones posibles, sin repetir variables. Por ejemplo, digamos que tenemos cuatro variables (\\(A\\), \\(B\\), \\(C\\) y \\(D\\)) y necesitamos evaluar 7 modelos, a saber, \\(A\\), \\(B\\), \\(C\\), \\(AB\\), \\(BC\\), \\(AC\\) y el modelo de referencia \\(ABC\\). Siete no parece mucho, pero cuando tengamos 8 variables, necesitaremos evaluar 92 modelos diferentes. Duplicamos la cantidad de variables y la cantidad de modelos aumentó más de 10 veces!\nPor supuesto, hay formas de reducir el número total de submodelos a explorar. Por ejemplo, podríamos utilizar algún método económico para filtrar las variables más prometedoras y solo hacer inferencias predictivas de proyección sobre ellas. Otra alternativa se conoce como búsqueda directa; es decir, primero ajustamos tantos modelos como variables tenemos. Luego seleccionamos un modelo/variable, el que genera las predicciones más cercanas al modelo de referencia. Luego generamos todos los submodelos con 2 variables que incluyan la variable seleccionada en el paso anterior y así sucesivamente. Si hacemos este procedimiento directo para un modelo de referencia con 8 variables en lugar de 92 modelos diferentes, necesitaremos evaluar solo 36.\nOtro aspecto que es relevante considerar al realizar inferencia predictiva por proyección es que solo proporcionamos a prioris para el modelo de referencia. Los submodelos no tienen priors explícitos; simplemente heredan los priors del modelo de referencia a través del procedimiento de proyección.\nUna de las razones por las que la predicción proyectiva funciona en la práctica es gracias al uso de un modelo de referencia. Al ajustar los submodelos a las predicciones dentro de la muestra realizadas por el modelo de referencia, en lugar de los datos observados, estamos filtrando el ruido en los datos. Esto ayuda a separar las variables más relevantes de las menos relevantes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#selección-de-variables-con-kulprit",
    "href": "05_GLMS.html#selección-de-variables-con-kulprit",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.24 Selección de variables con Kulprit",
    "text": "5.24 Selección de variables con Kulprit\nKulprit es un paquete de Python para inferencia predictiva por proyecciones. Funciona con Bambi, ya que podemos pasar un modelo de referencia creado con él y Kulprit hará todo el trabajo pesado por nosotros.\nPara ilustrar cómo usar Kulprit, usaremos el conjunto de datos de grasa corporal. Este conjunto de datos tiene medidas de 251 individuos, incluida su edad, peso, altura, circunferencia del abdomen, etc. Nuestro propósito es predecir el porcentaje de grasa corporal (según lo estimado por la variable siri). Dado que obtener mediciones precisas de la grasa corporal es costoso y potencialmente molesto para los pacientes, queremos reducir las mediciones manteniendo una buena precisión predictiva para siri. El conjunto de datos original incluye 13 variables. Para que este ejemplo sea realmente simple, he preseleccionado 6.\nLo primero que debemos hacer es definir y ajustar un modelo de Bambi, como es habitual. Tenemos que asegurarnos de incluir el argumento idata_kwargs={'log_likelihood':True}}. Internamente, Kulprit calcula el ELPD, usando LOO.\n\nbody = pd.read_csv(\"datos/body_fat.csv\")\n\n\nmodel = bmb.Model(\"siri ~ age + weight + height + abdomen + thigh + wrist\",\n                  data=body)\nidata = model.fit(idata_kwargs={'log_likelihood': True})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [siri_sigma, Intercept, age, weight, height, abdomen, thigh, wrist]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 10 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEl principal punto de entrada de Kulprir es mediante la clase ProjectionPredictive. Una vez provista del modelo de Bambi y los datos resultantes del ajuste de ese modelo. Podemos pedirle a Kulprit que realice una búsqueda. Este paso puede demorar un rato, es la parte pesada de todo el proceso.\n\nppi = kpt.ProjectionPredictive(model, idata)\nppi.search()\n\nUna vez finalizada la búsqueda, podemos pedirle a Kulprit que compare los submodelos en términos del ELPD. Los submodelos se mostrarán ordenados desde el ELPD más bajo hasta el más alto, como en la siguiente figura\n\nppi.plot_compare(plot=True, figsize=(10, 4));\n\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/arviz/stats/stats.py:792: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.62 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nEn el eje x, tenemos el tamaño del submodelo, es decir, el número de variables; Comenzamos en cero porque incluimos un modelo con solo un intercepto y sin ninguna covariables. La línea gris discontinua corresponde al ELPD del modelo de referencia.\nPodemos ver que un submodelo de tamaño 3 es prácticamente equivalente al modelo de referencia. Pero ¿qué variables se incluyen exactamente en este y otros submodelos? Si imprimimos el objeto ppi, luego de realizar una búsqueda, obtendremos una lista ordenada de las fórmulas de los submodelos que coinciden con el orden en el gráfico obtenido con el comando ppi.plot_compare()\n\nppi\n\n  0 siri ~ 1\n  1 siri ~ abdomen\n  2 siri ~ abdomen + wrist\n  3 siri ~ abdomen + wrist + weight\n  4 siri ~ abdomen + wrist + weight + height\n  5 siri ~ abdomen + wrist + weight + height + age\n  6 siri ~ abdomen + wrist + weight + height + age + thigh\n\n\nEl modelo de tamaño 3 es el que incluye las variables abdomen, wrist y height. Este resultado nos dice que si queremos elegir un modelo con menos variables que el modelo de referencia pero con una precisión predictiva similar, entonces esta es una buena opción. Dependiendo del contexto, otros submodelos también pueden ser una buena idea. Por ejemplo, podemos argumentar que la diferencia entre el submodelo de tamaños 2 y 3 es bastante pequeña. Por lo tanto, es posible que estemos dispuestos a sacrificar algo de precisión en favor de un modelo aún más pequeño. Para este ejemplo, medir la altura de los pacientes puede no ser tan problemático, pero para otros escenarios, agregar una tercera variable podría resultar costoso, molesto, peligroso, etc.\nOtra forma de interpretar este resultado es notar qué los ELPD para modelos con tamaño 3 o mayor son esencialmente idénticos. Puede darse el caso de que si repetimos el análisis con un conjunto de datos ligeramente diferente, o incluso el mismo conjunto de datos pero con más muestras a posteriori, podamos obtener un orden ligeramente diferente. Por lo tanto, es posible que tengamos otros modelos de tamaño 3 con potencialmente la misma capacidad predictiva, entonces podríamos justificar la selección de la tercera variable por factores externos como qué tan fácil o barato es medirla, o cuál sería menos dolorosa de medir para los pacientes, etc.\nEn resumen, como ocurre con otras herramientas estadísticas, los resultados no deben tomarse a ciegas sino en contexto; usted deben tener la última palabra y no sus herramientas. Las herramientas solo deben ayudar a fundamentar sus decisiones.\nBien, digamos que efectivamente estamos interesados en el submodelo de tamaño 3 calculado por Kulprit; podemos conseguirlo con:\n\nsubmodelo = ppi.project(3)\n\nDesde el objeto submodel, podemos recuperar información útil como el modelo de Bambi submodelo.model o el objeto InferenceData submodelo.idata.\nUna advertencia al interpretar estos dos objetos: submodelo.model es un modelo de Bambi generado a partir de una fórmula. Así, sus priors serán los computados automáticamente por Bambi. Pero el posterior que calcula Kulprit, que está almacenado en submodelo.idata.posterior, no proviene directamente de este modelo. Ya que los priors son “heredados” implícitamente durante el paso de proyección.\n\naz.plot_posterior(submodelo.idata, figsize=(12, 6));\n\n\n\n\n\n\n\n\n¿Podemos confiar en las distribuciones a posteriori proyectados?\nEn condiciones muy generales, deberían ser distribuciones válidas, lo son al menos para obtener una idea aproximada de los valores de los parámetros y, por supuesto, es suficiente para la selección de variables. La falta de priors explícitos podría dificultar la interpretación del modelo, pero si solo nos importan las predicciones, eso no debería ser un problema. Por supuesto, siempre es posible usar Kulprit para determianr el submodelo y luego Bambi (o PyMC) para calcular explícitamente el posterior de ese modelo adaptado los priors de ser necesario.\nLa siguiente figura muestra un forestplot para el posteriors del submodelo 3 y para el modelo de referencia. Observe que aquí hay dos posibles fuentes de diferencias: las diferencias entre MCMC y los métodos predictivos por proyección y las diferencias intrínsecas entre los posteriors para ambos modelos.\n\nppi.plot_densities(var_names=[\"~Intercept\", \"~age\", \"~height\", \"~thigh\"],\n                   submodels=[3],\n                   kind=\"forest\",\n                   figsize=(11, 4),\n                   plot_kwargs={\"colors\":[\"C0\", \"C2\"]});",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "05_GLMS.html#ejercicios",
    "href": "05_GLMS.html#ejercicios",
    "title": "5  Modelos lineales y generalizaciones",
    "section": "5.25 Ejercicios",
    "text": "5.25 Ejercicios\n\nEn la siguiente definición de modelo probabilístico cual es el likelihood, cual es el a priori y cual el a posteriori.\n\n\\[\n\\begin{aligned}\ny_i &\\sim Normal(\\mu, \\sigma) \\\\\n\\mu &\\sim Normal(0, 10) \\\\\n\\sigma &\\sim HalfNormal(25)\n\\end{aligned}\n\\]\n\nEn el modelo del punto 1 ¿cuántos parámetros hay en el posterior? o expresado de otra forma ¿cuántas dimensiones tiene el a posteriori?\nEn el siguiente modelo ¿cuál es el modelo lineal? ¿cuál el likelihood y cuantos parámetros hay en la distribución a posteriori?\n\n\\[\n\\begin{aligned}\ny &\\sim Normal(\\mu, \\epsilon) \\\\\n\\mu &= \\alpha + \\beta x \\\\\n\\alpha &\\sim Normal(0, 10) \\\\\n\\beta &\\sim Normal(0, 1) \\\\\n\\epsilon &\\sim HalfNormal(25) \\\\\n\\end{aligned}\n\\]\n\nUsando el conjunto de datos howell (disponible junto con esta notebook) realice un modelo lineal del peso (\\(x\\)) versus la altura (\\(y\\)). Excluya a los menores de 18 años. Exponga los resultados.\nPara 4 individuos se registraron los pesos (45.73, 65.8, 54.2, 32.59), pero no las alturas. Usando el modelo del punto anterior prediga la altura esperada para cada individuo junto con un intervalo de credibilidad del 50% y del 89%.\nRepita el punto 4 pero para los menores de 18 años. Exponga los resultados.\nUse el modelo modelo_bl pero aplicada al conjunto de datos iris. Intente clasificar setosa o versicolor en función de sepal_length. ¿Cuán útil es este modelo comparado con una regresión logística?\nVuelva a correr el modelo_rl pero esta vez usando la variable petal_width ¿En que difieren los resultados? ¿Cuán ancho o angosto es el intervalo HDI 94%?\nLea este post y replique los resultados usted mismo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos lineales y generalizaciones</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html",
    "href": "06_modelos_de_mezcla.html",
    "title": "6  Modelos de mezcla",
    "section": "",
    "text": "6.1 Modelos de mezclas finitas\nUna forma de construir modelos mixtos es considerar una mezcla finita ponderada de dos o más distribuciones. Entonces, la densidad de probabilidad de los datos observados es una suma ponderada de la densidad de probabilidad de \\(K\\) subgrupos:\n\\[\np(x) = \\sum_{i=1}^{K} w_i p(x \\mid \\theta_i)\n\\]\nPodemos interpretar \\(w_i\\) como la probabilidad del componente \\(i\\), y por lo tanto sus valores están restringidos al intervalo [0, 1] y deben sumar 1. Los componentes $p(x _i) $ suelen ser distribuciones simples, como Gaussiana o Poisson. Si \\(K\\) es finito, tenemos un modelo de mezcla finita, si además \\(p\\) es Gaussiana, tenemos una mezcla Gaussianas. Para resolver dicho modelo, debemos proporcionar un valor de \\(K\\), ya sea porque conocemos el valor correcto de antemano o porque podemos hacer una suposición fundamentada.\nConceptualmente, para resolver un modelo mixto, todo lo que necesitamos hacer es asignar adecuadamente cada punto de datos a uno de los componentes. En un modelo probabilístico, podemos hacer esto introduciendo una variable aleatoria \\(z\\), cuya función es especificar a qué componente se asigna una observación particular. Esta variable generalmente se denomina variable latente porque no podemos observarla directamente. Si nuestros componentes son Gaussianos entonces tendremos que:\nEs decir, generamos \\(K\\) Gaussianas y usamos \\(z\\) para indexarlas. \\(z\\) tendrá la misma dimensión que \\(x\\), es decir una variable lantente por observación. \\(z\\) podrá tomar tanto valores como \\(K\\) clases tengamos. Si nuestro modelo es Bayesiano necesitamos completarlo especificando priors, una forma natural es establer que \\(z\\) sea una distribución categórica cuyo soporte será \\(\\{0, \\dots ,K-1\\}\\) (empezamos en 0 para que luego sea más directa la implementación en Python) y asumimos que el parámetro \\(p\\) de la categórica sigue una distribución de Dirichlet. Para la desviación standard de la gaussiana usamos una media-normal o similar, entonces nos queda:\nGraficamente tenemos:\nEl rectángulo de esquinas redondeadas indica que tenemos \\(K\\) componentes y las variables categóricas deciden cuál de ellas usamos para describir un punto de datos determinado. Observe que en este modelo los valores de \\(\\mu\\) depende de los diferentes componentes, mientras que el valor de \\(\\sigma\\) se comparten para todos ellos. Esto es una decisión de modelado, si fueses necesario podriamos cambiarlo y permitir que se condicionen otros parámetros a cada componente.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#modelos-de-mezclas-finitas",
    "href": "06_modelos_de_mezcla.html#modelos-de-mezclas-finitas",
    "title": "6  Modelos de mezcla",
    "section": "",
    "text": "\\[\\begin{split}\n\\begin{align*}\n\\mu_1, \\ldots, \\mu_K & \\sim N(0, \\sigma^2) \\\\\nx & \\sim N(\\mu_z, \\sigma^2)\n\\end{align*}\n\\end{split}\\]\n\n\\[\\begin{split}\n\\begin{align*}\n\\mu_1, \\ldots, \\mu_K & \\sim N(0, \\sigma^2) \\\\\n\\sigma & \\sim \\mathcal{HN}(\\dots) \\\\\n\\boldsymbol{w} & \\sim \\textrm{Dir}(\\boldsymbol{\\alpha}) \\\\\nz & \\sim \\textrm{Cat}(\\boldsymbol{w}) \\\\\ny & \\sim N(\\mu_z, \\sigma^2)\n\\end{align*}\n\\end{split}\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#mezclas-químicas",
    "href": "06_modelos_de_mezcla.html#mezclas-químicas",
    "title": "6  Modelos de mezcla",
    "section": "6.2 Mezclas químicas",
    "text": "6.2 Mezclas químicas\nVamos a utilizar los datos de desplazamientos químicos que ya vimos anteriormente. En la siguiente figura podemos ver un histograma de estos datos.\n\n\n\nHistograma de desplazamientos químicos\n\n\n\n\nMostrar Código\ncs_exp = pd.read_csv(\"datos/chemical_shifts_theo_exp.csv\")[\"exp\"]\n\n\nPodemos ver que estos datos no se pueden describir adecuadamente usando una sola distribución como una Gaussiana, pero quizá podriamos lograr una mejor descripción si usáramos tres o cuatro. Hay buenas razones teóricas, que ignoraremos y no discutiremos aquí, que indican que estos datos de provienen realmente de una mezcla de 40 subpoblaciones. Pero con sólo mirar los datos, parece imposible recuperar los grupos verdaderos ya que hay mucha superposición entre ellos.\nEn el siguiente bloque de código podemos ver un modelo de mezcla de gaussiana con 2 componentes:\nwith pm.Model() as modelo_kg:\n    w = pm.Dirichlet('w', a=np.ones(2))\n    z = pm.Categorical('z', p=w, shape=len(cs_exp))\n    μ = pm.Normal('μ', mu=cs_exp.mean(), sigma=10, shape=K)\n    σ = pm.HalfNormal('σ', sigma=5)\n\n    x = pm.Normal('x', mu=μ[z], sigma=σ, observed=cs_exp)\n    idata_kg = pm.sample()\nSi ejecutas este código, verás que corre muy lento y si realizas diagnósticos verás que el muestreo tiene muchos problemas ¿Podemos hacer que este modelo funcione más rápido? Sí, veamos cómo.\nEn el modelo_kg hemos incluido explícitamente la variable latente \\(z\\). El muestreo de esta variable discreta generalmente es problemático. Una forma de resolver esto es marginalizando la variable \\(z\\):\n\\[\\begin{split}\n\\begin{align*}\n\\mu_1, \\ldots, \\mu_K\n    & \\sim N(0, \\sigma^2) \\\\\n\\sigma & \\sim \\mathcal{HN}(\\dots) \\\\\n\\boldsymbol{w}\n    & \\sim \\textrm{Dir}(\\boldsymbol{\\alpha}) \\\\\np(x)\n    & = \\sum_{i = 1}^K w_i\\ N(x\\ |\\ \\mu_i, \\sigma^2),\n\\end{align*}\n\\end{split}\\]\nPyMC ofrece una sintáxis más directa para escribir este tipo de mmodelos, usando la distribución NormalMixture:\n\nK = 2\nwith pm.Model() as modelo_mg:\n    w = pm.Dirichlet('w', a=np.ones(K))\n    μ = pm.Normal('μ', mu=cs_exp.mean(), sigma=10, shape=K)\n    σ = pm.HalfNormal('σ', sigma=5)\n    x = pm.NormalMixture('x', w=w, mu=μ, sigma=σ, observed=cs_exp)\n    idata_mg = pm.sample(random_seed=123)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n\n\n\n\nOK, lo primero que notamos es que el modelo corre en un tiempo razonable. Pero tenemos reportes de \\(\\hat R\\) altos y ESS bajos! Veamos un foresplot, para lograr entender que está sucediendo\n\naz.plot_forest(idata_mg, var_names=\"μ\", figsize=(12, 3));\n\n\n\n\n\n\n\n\nNotan algo raro en estos resultados? Tomensé un momento para pensarlo.\n\nEn la figura anterior podemos ver que para μ[0] una de las estimaciones está alrededor de 47 y las otras tres alrededor de 57.5. Y lo contrario para μ[1], normalmente esperamos que las distintas cadenas nos den valores cercanos. Cuando los valores son muy diferentes sospechamos que el muestreo ha tenido problemas. Además si calcularamos la media de μ[0], obtendremos un valor cercano a 55 (\\(57,5 \\times 3 + 47 \\times 1\\)), que no es el valor correcto. Lo que estamos viendo es un ejemplo de un fenómeno conocido como no-identificabilidad de parámetros. Esto sucede porque, desde la perspectiva del modelo, no hay diferencia si el componente 1 tiene una media de 47 y el componente 2 tiene una media de 57,5 o viceversa; ambos escenarios son equivalentes. En el contexto de los modelos mixtos, esto también se conoce como problema de cambio de etiqueta (label-switching).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#no-identificabilidad",
    "href": "06_modelos_de_mezcla.html#no-identificabilidad",
    "title": "6  Modelos de mezcla",
    "section": "6.3 No-identificabilidad",
    "text": "6.3 No-identificabilidad\nUn modelo estadístico es no-identificable si uno o más de sus parámetros no pueden determinarse de forma única. Los parámetros de un modelo no se identifican si se obtiene la misma función de verosimilitud para más de un conjunto de parámetros. Esto puede suceder por que los datos no contengan suficiente información para estimar los parámetros o por que el modelo es estructuralmente no-identificable, lo que significa que los parámetros no pueden determinarse de manera única incluso si todos los datos necesarios están disponibles.\nCon los modelos mixtos, existen al menos dos formas de parametrizar un modelo para eliminar el problema de la no identificabilidad. Podemos forzar un orden arbitrario en los componentes; por ejemplo, establecer que el vector \\(\\mu\\) debe ser estrictamente creciente o podemos usar priors informativos. La primer estrategia suele ser más general y simple de implementar y la segunda no garantiza la eliminación de problemas.\nUsando PyMC, podemos implementar la primera opción con una transformación:\n\nwith pm.Model() as modelo_mgo:\n    w = pm.Dirichlet('w', a=np.ones(K))\n    μ = pm.Normal('μ', mu=cs_exp.mean(), sigma=10, shape=K,\n                 transform=pm.distributions.transforms.ordered,\n                 initval=np.array([cs_exp.mean()-1, cs_exp.mean()+1]),\n                 )\n    σ = pm.HalfNormal('σ', sigma=5)\n    x = pm.NormalMixture('x', w=w, mu=μ, sigma=σ, observed=cs_exp)\n    idata_mg = pm.sample(random_seed=123)    \n    \n    idata_mgo = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#como-elegir-k",
    "href": "06_modelos_de_mezcla.html#como-elegir-k",
    "title": "6  Modelos de mezcla",
    "section": "6.4 Como elegir K",
    "text": "6.4 Como elegir K\nUna de las principales preocupaciones con los modelos de mezclas finitas es cómo decidir el número de componentes. Una regla general es comenzar con una cantidad relativamente pequeña de componentes y luego aumentarla para el ajuste del modelo. Como ya vimos anteriormente el ajuste de un modelo se puede evaluar con una combinación de herramientas como las pruebas predictivas a posteriori, el ELPD y la experiencia de los modeladores.\nComparemos el modelo para \\(K = \\{2, 3, 4, 5\\}\\)\n\nKs = [2, 3, 4, 5]\n\nmodels = []\nidatas = []\nfor k in Ks:\n    with pm.Model() as model:\n        w = pm.Dirichlet('w', a=np.ones(k))\n        μ = pm.Normal('μ',\n                      mu=np.linspace(cs_exp.min(), cs_exp.max(), k),\n                      sigma=cs_exp.var() / k, shape=k,\n                      transform=pm.distributions.transforms.ordered,\n                     )\n        σ = pm.HalfNormal('σ', sigma=5)\n        x = pm.NormalMixture('x', w=w, mu=μ, sigma=σ, observed=cs_exp)\n        idata = pm.sample(random_seed=123,\n                          idata_kwargs={\"log_likelihood\":True}\n                         )\n                         \n        idatas.append(idata)\n        models.append(model)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 44 seconds.\nThere were 40 divergences after tuning. Increase `target_accept` or reparameterize.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 55 seconds.\nThere were 9 divergences after tuning. Increase `target_accept` or reparameterize.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [w, μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 31 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa siguiente figura muestra los modelos de mezcla para \\(K\\) Gaussianas. La linea negra y solida representa la media a posteriori y las lineas turquesa muestras de la distribución a posterori. La distribución media de cada componente está representado usando lineas punteadas\n\n\nMostrar Código\n_, ax = plt.subplots(2, 2, figsize=(11, 8))\n \nax = np.ravel(ax)\nx = np.linspace(cs_exp.min(), cs_exp.max(), 200)\nfor idx, idata_x in enumerate(idatas):\n    posterior_x = idata_x.posterior.stack(samples=(\"chain\", \"draw\"))\n    x_ = np.array([x] * Ks[idx]).T\n\n    for i_ in np.random.randint(0, posterior_x.samples.size, size=50):\n        dist = pz.Normal(posterior_x['μ'][:,i_], posterior_x['σ'][i_])\n        ax[idx].plot(x, np.sum(dist.pdf(x_) *  posterior_x['w'][:,i_].values, 1), 'C1')\n \n    p_y = posterior_x['w'].mean(\"samples\")\n    dist = pz.Normal(posterior_x['μ'].mean(\"samples\"), posterior_x['σ'].mean())\n    ax[idx].plot(x, np.sum(dist.pdf(x_) * p_y.values, 1), 'k', lw=3)\n    ax[idx].plot(x, dist.pdf(x_) * p_y.values, 'k--', alpha=0.7)\n         \n    ax[idx].set_title('K = {}'.format(Ks[idx]))\n    ax[idx].set_yticks([])\n    ax[idx].set_xlabel('x')\n\n\n\n\n\n\n\n\n\nVisualmente, parece que \\(K=2\\) es demasiado bajo, pero ¿cómo elegimos un valor mejor?\nComo ya hemos discutido, podemos usar pruebas predictivas a posteriori y calcular valores p bayesianos. La siguiente figura muestra un ejemplo de dicho cálculo y visualización. \\(K=5\\) es la mejor solución y \\(K=4\\) se acerca.\n\n\nMostrar Código\nppc_mm = [pm.sample_posterior_predictive(idatas[i],\n                                         models[i],\n                                         random_seed=4591,\n                                         progressbar=False) for i in range(4)]\n\nfig, ax = plt.subplots(2, 2, figsize=(10, 6), sharex=True)\nax = np.ravel(ax)\ndef iqr(x, a=0):\n    return np.subtract(*np.percentile(x, [75, 25], axis=a))\n    \nT_obs = iqr(cs_exp)\nfor idx, d_sim in enumerate(ppc_mm):\n    d_sim = d_sim.posterior_predictive[\"x\"]\n    T_sim = iqr(d_sim, 1)\n    p_value = np.mean(T_sim &gt;= T_obs)\n    az.plot_kde(T_sim, ax=ax[idx])\n    ax[idx].axvline(T_obs, 0, 1, color='k', ls='--')\n    ax[idx].set_title(f'K = {Ks[idx]} \\n p-value {p_value:.2f}')\n    ax[idx].set_yticks([])\n\n\nSampling: [x]\nSampling: [x]\nSampling: [x]\nSampling: [x]\n\n\n\n\n\n\n\n\n\nPara complementar las estas pruebas, podemos calcular el ELPD usando LOO. Podemos ver que los resultados coinciden con las pruebas predictivas\n\ncomp = az.compare(dict(zip([str(K) for K in Ks], idatas)))\ncomp\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\n5\n0\n-5129.403532\n10.050910\n0.000000\n1.000000e+00\n30.765814\n0.000000\nFalse\nlog\n\n\n4\n1\n-5155.672477\n19.914150\n26.268945\n0.000000e+00\n31.333449\n4.312002\nFalse\nlog\n\n\n3\n2\n-5192.861947\n15.129354\n63.458415\n0.000000e+00\n32.182557\n9.178287\nFalse\nlog\n\n\n2\n3\n-5215.851380\n3.201959\n86.447848\n4.024514e-11\n33.499721\n11.948419\nFalse\nlog\n\n\n\n\n\n\n\n\n\naz.plot_compare(comp, figsize=(10, 3), plot_ic_diff=False);\n\n\n\n\n\n\n\n\nEl ejemplo de los desplazamientos químicos, aunque simple, muestra las ideas principales sobre los modelos de mezclas finitas. Para este ejemplo, utilizamos gaussianos porque proporcionan una buena aproximación para modelar los datos. Sin embargo, somos libres de utilizar componentes no gaussianos si es necesario. Por ejemplo, podríamos usar un:\n\nModelo de mezcla de Poisson: suponga que está monitoreando la cantidad de clientes que ingresan a una tienda cada hora. Un modelo mixto de Poisson puede ayudar a identificar diferentes patrones de tráfico de clientes, como horas o días pico, suponiendo que los datos siguen una combinación de distribuciones de Poisson.\nModelo de mezcla exponencial: Imagina que estás estudiando la vida útil de cierto tipo de bombilla. Un modelo de mezcla exponencial puede ayudar a identificar diferentes grupos de bombillas con diferentes vidas útiles, sugiriendo posibles diferencias en la calidad de fabricación o factores ambientales.\n\nEn la siguiente sección, exploraremos dos tipos muy particulares de modelos mixto.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#modelos-zero-inflados-y-modelos-hurdle",
    "href": "06_modelos_de_mezcla.html#modelos-zero-inflados-y-modelos-hurdle",
    "title": "6  Modelos de mezcla",
    "section": "6.5 Modelos zero-inflados y modelos hurdle",
    "text": "6.5 Modelos zero-inflados y modelos hurdle\nAl contar cosas, como autos en una ruta, estrellas en el cielo, lunares en la piel o prácticamente cualquier otra cosa, una posiblidad es no contar nada, es decir, obtener cero. Podemos obtener cero por muchas razones; si estamos en una esquina contando autos rojos por hora podemos contar 0 autos rojos, por que ninguno pasó o por que pasó uno detras de un camión y no lo pudimos ver. Si utilizamos una distribución Poisson o NegativaBinomial para modelar dichos datos, es posible que notemos que el modelo genera menos ceros en comparación con los datos.\n¿Cómo arreglamos eso? Una posible solución es suponer que nuestras observaciones siguen un proceso que es en realidad una mezcla de dos procesos:\n\nUno modelado por una distribución discreta con probabilidad \\(\\psi\\)\nUno dando ceros adicionales con probabilidad \\(1 - \\psi\\)\n\nUn detalle, simple, pero que nos puede generar sorpresas si no prestamos atención es que en algunos textos (y software) el significado de \\(\\psi\\) está invertido, representando la probabilidad de ceros adiciones.\nLa familia de distribuciones que permiten ceros “adicionales” se conoce como distribución inflada en cero. Los miembros más comunes de esa familia son:\n\nPoisson inflada en cero\nNegativaBinomial inflada en cero\nBinomial inflada en cero\n\nDada una distribución base con función de masa de probabilidad (PMF). Podemos describir una distribución Hurdle como:\n\\[\\begin{split}\nf(x \\mid \\psi, n, p) = \\left\\{ \\begin{array}{l}\n    (1-\\psi) + \\psi \\; \\text{PMF}(0), \\text{si } x = 0 \\\\\n    \\psi \\; \\text{PMF}(x), \\text{si } x=1,2,3,\\ldots,n\n    \\end{array} \\right.\n\\end{split}\\]\nEn la siguiente sección, usaremos Poisson inflado de ceros para resolver un problema de regresión.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#regresión-de-poisson-inflada-en-cero",
    "href": "06_modelos_de_mezcla.html#regresión-de-poisson-inflada-en-cero",
    "title": "6  Modelos de mezcla",
    "section": "6.6 Regresión de Poisson inflada en cero",
    "text": "6.6 Regresión de Poisson inflada en cero\nPara ejemplificar un modelo de regresión de Poisson inflado en cero, vamos a trabajar con un conjunto de datos tomado del Instituto de Investigación y Educación Digital. Tenemos 250 grupos de visitantes a un parque, para cada grupo tenemos el registro de la cantidad de peces que capturaron count, cuántos niños había en el grupo child y si trajeron una casa-rodante/caravana al parque camper. Usando estos datos, vamos a construir un modelo de la cantidad de peces capturados en función de las variables del niño y del campista.\n\npesca = pd.read_csv('datos/pesca.csv')\n\nUsando PyMC podemos escribir un modelo para estos datos como:\n\nwith pm.Model() as ZIP_reg:\n    ψ = pm.Beta('ψ', 1, 1)\n    α = pm.Normal('α', 0, 1)\n    β = pm.Normal('β', 0, 1, shape=2)\n    θ = pm.math.exp(α + β[0] * pesca['child'] + β[1] * pesca['camper'])\n    yl = pm.ZeroInflatedPoisson('yl', ψ, θ, observed=pesca['count'])\n    idata_ZIP_reg = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [ψ, α, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n\n\n\n\n\n\n\n\n\n\n\ncamper es una variable binaria con 0 si el grupo no entró al parque en casa-rodante y 1 si lo hizo. A una variable que indica la ausencia/presencia de un atributo se le suele llamar variable binaria, dicotómica, “dummy” o variable indicadora. Es importante notar que cuando camper toma el valor de 0, el término que involucra a \\(\\beta_1\\) también será 0 y el modelo se reduce a una regresión con una sola variable independiente. Ya discutimos esto cuando discutimos el uso de covariables categóricas.\nLos resultados se muestran en la siguiente figura. Podemos ver que cuanto mayor es el número de niños, menor es el número de peces capturados. Además, las personas que viajan con una casa-rodante generalmente pescan más. Si revisamos los coeficientes asociados a child y camper, veremos que podemos decir:\n\nPor cada niño adicional, el recuento esperado de peces capturados disminuye en \\(\\approx 0,4\\)\nAcampar con una casa-rodante aumenta la cantidad esperada de peces capturados en \\(\\approx 2\\)\n\nLos modelos inflados en cero están estrechamente asociados con los modelos hurdle (obstáculos) y puede ser fácil confundirlos. Por lo que es buena idea discutir ambos modelos en simultaneo.\n\n\nMostrar Código\nchildren = [0, 1, 2, 3, 4]\nfish_count_pred_0 = []\nfish_count_pred_1 = []\n\nposterior = az.extract(idata_ZIP_reg)\n\nwithout_camper = posterior['α'] + posterior['β'][0] * xr.DataArray(children)\nwith_camper = without_camper + posterior['β'][1]\nfish_count_pred_0 = np.exp(without_camper)\nfish_count_pred_1 = np.exp(with_camper)\n\n_, ax = plt.subplots(figsize=(8, 4))\nax.plot(children, fish_count_pred_0.T, 'C0.', alpha=0.01)\nax.plot(children, fish_count_pred_1.T, 'C1.', alpha=0.01)\nax.plot(children, fish_count_pred_0.mean(\"sample\"), 'C0', ls=\"--\")\nax.plot(children, fish_count_pred_1.mean(\"sample\"), 'C1', ls=\"--\")\nax.set_xticks(children)\nax.set_xlabel('Número de niños')\nax.set_ylabel('Peces')\nax.plot([], 'C0o', label='sin casa-rodante')\nax.plot([], 'C1o', label='con casa-rodante')\nplt.legend();\n\n\n\n\n\n\n\n\n\n\n6.6.1 Modelos hurdle\nLos modelos de hurdle (obstáculo), también se describien como una mezcla de dos procesos de forma similar a los modelos inflados en cero. La diferencia es que en los modelos hurdles los ceros vienen dados exclusivamente con probabilidad \\(1 - \\psi\\) y los valores positivos vienen dados por una distribución base truncada en cero. Como consecuencia, un modelo inflado en cero solo puede aumentar la probabilidad de \\(P(x= 0)\\), pero para los modelos hurdle, la probabilidad puede ser mayor o menor que en la distribución base. La razón del nombre hurdle (obstáculo) es que podemos pensar a estas distribuciones como que estamos modelado la presencia de un obstáculo, que hae que nuestra respuesta sea cero, una vez superado el obstáculo la respuesta puede ser distinta de cero.\nAlgunas “distribuciones hurdle” comunente usadas son:\n\nPoisson Hurdle\nNegativaBinomial Hurdle\nGamma Hurdle\nNormal Hurdle\n\nFijensé que contrario a los modelos inflados en cero, cuya distribución base son discretas acá tenemos un par de casos de distribuciones continuas y por lo tanto obtenemos distribuciones que no son continuas ni discretas, si no una mezcla.\nDada una distribución base con función de distribución acumulada (CDF) y función de masa/densidad de probabilidad (PDF). Podemos describir una distribución Hurdle como:\n\\[\\begin{split}f(x \\mid \\psi, \\mu) =\n    \\left\\{\n        \\begin{array}{l}\n        (1 - \\psi)  \\ \\text{si } x = 0 \\\\\n        \\psi\n        \\frac{\\text{PDF}(x \\mid \\mu))}\n        {1 - \\text{CDF}(0 \\mid \\mu)} \\ \\text{si } x \\not= 0\\ldots\n        \\end{array}\n    \\right.\n\\end{split}\\]\nPara ilustrar los modelos hurdle, vamos a utilizar el conjunto de datos del cangrejo herradura Brockmann_1996.\nLos cangrejos herradura llegan a la playa en parejas para su ritual de desove. Los machos solitarios se agrupan alrededor de las parejas que anidan y compiten por la oportunidad de fertilizar los huevos. Estos individuos, conocidos como machos satélites, a menudo se congregan cerca de ciertas parejas, e ignoran a otras. Queremos modelar el número de satelites. Sospechamos que este número está relacionado con las propiedades de las hembras de cangrejo. Como predictores vamos a utilizar propiedades del caparazón width y color. El color se codifica utilizando los números enteros del 1 al 4, desde tonos más claros a más oscuros.\nUsaremos Bambi para escribir y ajustar cuatro modelos. La principal diferencia entre los cuatro modelos es que vamos a utilizar cuatro likelihoods diferentes, a saber, Poisson, Hurdle Poisson, NegativeBinomial y Hurdle NegativeBinomial.\n\ncrab = pd.read_csv(\"datos/horseshoe_crab.csv\")\n\n\nfamilias = [\"poisson\", \"hurdle_poisson\", \"negativebinomial\", \"hurdle_negativebinomial\"]\n\nmodelos = []\nidatas = []\n\nfor familia in familias:\n    modelo = bmb.Model(\"satellite ~ width + C(color)\", family=familia, data=crab)\n    idata = modelo.fit(idata_kwargs={\"log_likelihood\":True}, random_seed=123)\n    modelo.predict(idata, kind=\"pps\")\n    idatas.append(idata)\n    modelos.append(modelo)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [Intercept, width, C(color)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [satellite_psi, Intercept, width, C(color)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [satellite_alpha, Intercept, width, C(color)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [satellite_alpha, satellite_psi, Intercept, width, C(color)]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.\n  warn(\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimero hagamos una comparación en términos del ELPD\n\ncmp = az.compare(dict(zip(familias, idatas)))\ncmp\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nhurdle_negativebinomial\n0\n-372.810467\n6.341265\n0.000000\n0.00000\n13.689807\n0.000000\nFalse\nlog\n\n\nnegativebinomial\n1\n-380.355948\n5.654806\n7.545481\n0.41551\n14.122017\n5.727093\nFalse\nlog\n\n\nhurdle_poisson\n2\n-382.358981\n8.595326\n9.548513\n0.58449\n17.719552\n6.573658\nFalse\nlog\n\n\npoisson\n3\n-468.366717\n16.124879\n95.556249\n0.00000\n24.794667\n19.441265\nFalse\nlog\n\n\n\n\n\n\n\n\n\naz.plot_compare(cmp, figsize=(10, 2.5), plot_ic_diff=False);\n\n\n\n\n\n\n\n\nUna forma útil de evaluar visualmente el ajuste en modelos de conteo son los “hanging rootograms” (raizogramas colgantes), como se ve en la siguiente figura.\nEn los raizogramas colgantes, dibujamos las raíces cuadradas de los valores observados y predichos. Esta es una forma rápida de ajustar aproximadamente las diferencias de escala facilitando la comparación de frecuencias observadas y esperadas incluso para frecuencias bajas. En segundo lugar, las barras representando los datos observados cuelgan de los valores esperados, en lugar de crecer desde el cero. Debido a que las barras están valor, y si la barra cae por debajo de cero, entonces el modelo está subestimando ese valor.\n\n\nMostrar Código\ndef rotogram(idata, ax):\n    max_ = 17\n    bins = np.array(range(0, max_))\n    dims = idata.posterior_predictive.dims\n    n_samples = dims[\"chain\"] * dims[\"draw\"]\n    pred =  (np.histogram(idata.posterior_predictive[\"satellite\"].values.ravel(),  bins=bins)[0] / n_samples)**0.5\n    observed = np.histogram(crab[\"satellite\"].values, bins=bins)[0]**0.5\n\n    ax.bar(bins[:-1], observed, 0.5, bottom=pred-observed, color=\"C0\")\n    ax.plot(bins[:-1], pred,  \"k.--\")\n    ax.hlines(0, -0.5, max_-1.5, linestyle=\"--\", color=\"0.5\")\n\n\nfig, axes = plt.subplots(2, 2, sharey=True, figsize=(12, 6))\nfor ax, idata, model in zip(axes.ravel(), idatas, modelos):\n    rotogram(idata, ax)\n    ax.set_title(model.family.name)\n\naxes[1,1].set_xlabel(\"Satellites\")\naxes[1,0].set_xlabel(\"Satellites\")\nfig.text(-0.03, 0.5, \"$\\sqrt{frecuencia}$\", va=\"center\", rotation=\"vertical\", fontsize=14);\n\n\n/tmp/ipykernel_19366/424556328.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  n_samples = dims[\"chain\"] * dims[\"draw\"]\n\n\n\n\n\n\n\n\n\nResumamos cada uno de los 4 paneles en la figura anterior\n\nPoisson: Los ceros están subestimados y los conteos del 1 al 4 están sobreestimados. La mayoría de los valores a partir de 6 también están subestimados. Este patrón indica sobredispersión en los datos, y la enorme diferencia para 0 indica un exceso de ceros.\nNegativoBinomial: Vemos que la sobredispersión se maneja mucho mejor en comparación con el modelo de Poisson. Todavía vemos que los ceros están subestimados y los valores 1 y 2 están sobreestimados, lo que probablemente indica un exceso de ceros.\nHurdle Poisson: Como se esperaba de un modelo hurdle, obtenemos un ajuste perfecto para los ceros. Para los valores positivos todavía tenemos algunas desviaciones.\nHurdle NegativoBinomial: Vemos que el modelo puede ajustarse muy bien a los datos, siendo las desviaciones muy pequeñas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#modelos-mixtos-no-finitos",
    "href": "06_modelos_de_mezcla.html#modelos-mixtos-no-finitos",
    "title": "6  Modelos de mezcla",
    "section": "6.7 Modelos mixtos no-finitos",
    "text": "6.7 Modelos mixtos no-finitos\nPara algunos problemas, como intentar agrupar dígitos escritos a mano, es fácil justificar el número de grupos que esperamos encontrar en los datos. Para otros problemas, podemos tener buenas conjeturas; por ejemplo, podemos saber que nuestra muestra de flores de Iris se tomó de una región donde sólo crecen tres especies de Iris, por lo que utilizar tres componentes es un punto de partida razonable. Cuando no estamos tan seguros de la cantidad de componentes, podemos usar la selección de modelos para ayudarnos a elegir la cantidad de grupos. Sin embargo, para otros problemas, elegir a priori el número de grupos puede ser un inconveniente, o puede que nos interese estimar este número directamente a partir de los datos. Una solución Bayesiana para este tipo de problemas viene dada por el proceso de Dirichlet.\n\n6.7.1 Procesos de Dirichlet\nTodos los modelos que hemos visto hasta ahora han sido modelos paramétricos, es decir, modelos con un número fijo de parámetros. En estos modelos asumimos una distribución para los datos (likelihood) y luego una distribución para los parámetros desconocidos. Pero también es posible crear modelos no-paramétricos. Este tipo de modelos no es que no tenga parámetros es que el número de parámetros es variable y depende en alguna medida de lo datos. Podemos pensar en los modelos no paramétricos como modelos con un número teóricamente infinito de parámetros junto a algún mecanismo que en la práctica nos permita trabajar con objetos finitos.\nEn este curso veremos tres ejemplos de dichos modelos: el proceso gaussiano, los árboles de regresión aditiva bayesiana y el proceso de Dirichlet.\nLa definición formal de un Proceso de Dirichlet (PD) es algo opaca y requiere de familiaridad con procesos estocásticos y teoría de la medida. En la literatura es común encontrarla definida de forma implicita mediante varios mecanismos alternativos. Uno de ellos es el proceso de rotura de palos. Veamos.\nPrimero generamos una serie de pesos:\n\\[\\begin{align}\n\\beta_i & \\sim \\text{Beta}(1, \\alpha) \\\\\nw_i & = \\beta_i \\prod_{j=1}^{i-1} (1 - \\beta_j)\n\\end{align}\\]\nEste proceso es análogo a imaginar que tenemos un palo de longitud 1, lo partimos en dos partes. Guardamos una de las partes y partimos la restante nuevamente, repetimos indefinidamente. Podemos ver que \\(\\alpha\\) controla el proceso de rotura. Cuando \\(\\alpha\\) se aproxima a 0, la distribución Beta se concentra hacia el valor 1, cuando \\(\\alpha=1\\) la distribución Beta es uniforme y a medida que \\(\\alpha\\) crece la distribución Beta se concentra hacia 0. Por lo que un valor alto de \\(alpha\\) favorece pesos pequeños.\nEl proceso continua asignado una ubicación \\(\\theta_i\\) al peso \\(w_i\\):\n\\[\n\\theta_i \\sim H\n\\]\n\\(H\\) es la distribución base del PD\nDados estos elementos podemos definir a un proceso de Dirichlet \\(G \\sim DP(\\alpha, H)\\) como una suma pesada de masas puntuales localizadas según la distribución base.\n\\[\nG = \\sum_{i=1}^{\\infty} w_i \\delta_{\\theta_i}\n\\]\ndonde \\(\\delta_{\\theta_i}\\) es la función delta de Dirac centrada en \\(\\theta_i\\)\nLa siguiente figura muestra un ejemplo de una relización (muestra) de un proceso de Dirichlet para 4 valores distintos de \\(\\alpha\\)\nAsi como la distribución de Dirichlet es la generalización n-dimensional de la distribución Beta, el proceso de Dirichlet es la generalización de dimensión infinita de la distribución de Dirichlet.\n\ndef stick_breaking_process(alpha, base_dist):\n    \"\"\"\n    Generate a realization from a Dirichlet Process using the stick-breaking process.\n\n    Parameters:\n    ----------\n    \n    alpha : float\n        Concentration parameter of the Dirichlet Process\n    base_dist : PreliZ distribution\n        Base distribution\n    \"\"\"\n    K_max = max(10, int(alpha/10)) \n    beta = pz.Beta(1, alpha).rvs(K_max)\n    w = np.empty(K_max)\n    w[0] = beta[0]\n    w[1:] = beta[1:] * (1 - beta[:-1]).cumprod()\n    w /= w.sum()  \n\n    loc = base_dist.rvs(K_max)\n\n    samples = np.random.choice(loc, p=w, size=K_max)\n\n    return samples\n\nN = 20\nbase_distribution = pz.Normal(0, 1)\n\n_, axes = plt.subplots(1,3, figsize=(10, 3), sharey=True)\n\nfor alpha, ax in zip([1, 100, 1000], axes.ravel()):\n    for _ in range(N):\n        sample = stick_breaking_process(alpha, base_distribution)\n        ax.ecdf(sample, color=\"0.5\", alpha=0.5)\n        \n    pz.Normal(0, 1).plot_cdf(legend=False, ax=ax)\n    ax.set_title(fr\"$\\alpha$={alpha}\")\n    \nplt.suptitle(f'{N} Realizaciones de un proceso de Dirichlet');\n\n\n\n\n\n\n\n\n\nK = 10\n\nwith pm.Model() as model_DP:\n    α = pm.Gamma('α', 2, 1)\n\n    w = pm.StickBreakingWeights(\"w\", α, K-1)\n    means = pm.Normal('means',\n                      mu=np.linspace(cs_exp.min(), cs_exp.max(), K),\n                      sigma=5, shape=K,\n                      transform=pm.distributions.transforms.ordered,\n                     )\n    \n    sd = pm.HalfNormal('sd', sigma=5, shape=K)\n    obs = pm.NormalMixture('obs', w, means, sigma=sd, observed=cs_exp.values)\n    idata = pm.sample(random_seed=123, target_accept=0.9, nuts_sampler=\"nutpie\")\n\n\n\n\n\n\n\n    Sampler Progress\n    Total Chains: 4\n    Active Chains: 0\n    \n        Finished Chains:\n        4\n    \n    Sampling for 5 minutes\n    \n        Estimated Time to Completion:\n        now\n    \n\n    \n    \n    \n        \n            \n                Progress\n                Draws\n                Divergences\n                Step Size\n                Gradients/Draw\n            \n        \n        \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    19\n                    0.07\n                    127\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    12\n                    0.08\n                    511\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    1\n                    0.07\n                    255\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.05\n                    383\n                \n            \n            \n        \n    \n\n\n\nDebido a que estamos aproximando el DP (infinito) con un valor finito, es importante verificar que el valor de truncamiento (\\(K=15\\) en este ejemplo) no introduzca ningún sesgo. Una forma sencilla de hacerlo es calcular el peso promedio de cada componente, ordenarlos y luego visualizar la suma acumulada. Para estar seguros, deberíamos tener al menos algunos componentes con un peso insignificante; de lo contrario, debemos aumentar el valor de truncamiento. El siguiente gráfico es un ejemplo de esto.\n\n_, ax = plt.subplots(figsize=(10, 3))\nplot_w = np.arange(K)\nax.plot(np.cumsum(np.sort(idata.posterior['w'].mean((\"chain\", \"draw\")))[::-1]), 'o-')\nax.hlines(0.99, 0, K, ls=\"--\", color=\"0.5\")\nax.set_xticks(plot_w, plot_w+1)\nax.set_xlabel('Número de componentes')\nax.set_ylabel('Peso promedio');\n\n\n\n\n\n\n\n\nPodemos ver que los primeros 9 componentes representan más del 99% del peso total (línea discontinua gris en la figura anterior) y por lo tanto podemos estar seguros de que el valor elegido (\\(K=15\\)) es adecuado para estos datos.\n\nx_plot = np.linspace(cs_exp.min()-1, cs_exp.max()+1, 500)\n\nposterior = idata.posterior.stack(samples=(\"chain\", \"draw\"))\n\npost_pdf_contribs = pz.Normal(posterior['means'].values[:, None, :],\n                              posterior['sd'].values[:, None, :]).pdf(np.atleast_3d(x_plot))\n\npost_pdfs = (posterior['w'].values[:, np.newaxis, :] * post_pdf_contribs).sum(axis=0)\n\n\n_, ax = plt.subplots(figsize=(10, 3))\n\nax.plot(x_plot, post_pdfs[:,::100], c='C1', alpha=0.25)\nax.plot(x_plot, post_pdfs.mean(axis=1), c='k', label=\"media a posteriori\")\n\nax.set_xlabel('x')\nax.set_yticks([])\nax.legend();",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#mezclas-continuas",
    "href": "06_modelos_de_mezcla.html#mezclas-continuas",
    "title": "6  Modelos de mezcla",
    "section": "6.8 Mezclas continuas",
    "text": "6.8 Mezclas continuas\nEl enfoque de este capítulo estuvo en los modelos de mezcla discreta, pero también podemos tener modelos de mezcla continua. Y de hecho ya conocemos algunos de ellos. Por ejemplo, los modelos jerárquicos también pueden interpretarse como modelos de mezcla continua donde los parámetros de cada grupo provienen de una distribución continua en el nivel superior. Para hacerlo más concreto, piense en realizar una regresión lineal para varios grupos. Podemos suponer que cada grupo tiene su propia pendiente o que todos los grupos comparten la misma pendiente. Alternativamente, en lugar de enmarcar nuestro problema como dos opciones discretas extremas, un modelo jerárquico nos permite modelar efectivamente una mezcla continua de estas dos opciones.\n\n6.8.1 Algunas distribuciones comunes son mezclas\nBetaBinomial es una distribución discreta que generalmente se utiliza para describir el número de éxitos \\(y\\) para \\(n\\) ensayos de Bernoulli cuando se desconoce la probabilidad de éxito \\(p\\) en cada ensayo y se supone que sigue una distribución beta con parámetros \\(\\alpha\\) y \\(\\beta\\):\n\\[\n\\text{BetaBinomial}(y \\mid n, \\alpha,\\beta) = \\int_0^1 \\text{Bin}(y \\mid p, n) \\; \\text{Beta}(p \\mid \\alpha, \\beta) dp\n\\]\nEs decir, para encontrar la probabilidad de observar el resultado \\(y\\), promediamos todos los valores posibles (y continuos) de \\(p\\). Por tanto, el BetaBinomial puede considerarse como un modelo de mezcla continua. Si el modelo BetaBinomial te suena familiar es porque estuviste prestando atención en los dos primeros capítulos del libro. Este es el modelo que usamos para el problema de lanzar una moneda, aunque usamos explícitamente una distribución Beta y Binomial, en lugar de usar la distribución Beta-Binomio ya .\nDe manera similar tenemos la distribución Binomial Negativa, que puede entenderse como una mezcla Gamma-Poisson. Es decir, una mezcla de distribuciones de Poisson donde el parámetro de velocidad tiene una distribución Gamma. La distribución binomial negativa se utiliza a menudo para evitar un problema común que se encuentra al tratar con datos de conteo. Este problema se conoce como sobredispersión. Suponga que está utilizando una distribución de Poisson para modelar los datos de recuento y luego se da cuenta de que la varianza en sus datos excede la del modelo; El problema con el uso de una distribución de Poisson es que la media y la varianza se describen mediante el mismo parámetro. Una forma de explicar la sobredispersión es modelar los datos como una mezcla (continua) de distribuciones de Poisson. Al considerar una combinación de distribuciones, nuestro modelo tiene más flexibilidad y puede adaptarse mejor a la media y la varianza de los datos.\nOtro ejemplo de mezcla de distribuciones es la distribución t de Student. Introdujimos esta distribución como una alternativa sólida a la distribución gaussiana. En este caso, la distribución t resulta de una mezcla de distribuciones gaussianas con media \\(\\mu\\) y varianza desconocida distribuida como una distribución Gamma inversa.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "06_modelos_de_mezcla.html#resumen",
    "href": "06_modelos_de_mezcla.html#resumen",
    "title": "6  Modelos de mezcla",
    "section": "6.9 Resumen",
    "text": "6.9 Resumen\nMuchos problemas pueden describirse como una población general compuesta de distintas subpoblaciones. Cuando sabemos a qué subpoblación pertenece cada observación, podemos modelar específicamente cada subpoblación como un grupo separado. Sin embargo, muchas veces no tenemos acceso directo a esta información, por lo que puede ser apropiado modelar esos datos utilizando modelos mixtos. Podemos utilizar modelos mixtos para intentar capturar subpoblaciones reales en los datos o como un truco estadístico general para modelar distribuciones complejas combinando distribuciones más simples.\nEn este capítulo, dividimos los modelos de mezclas en tres clases: modelos de mezclas finitas, modelos de mezclas no finitas y modelos de mezclas continuas. Un modelo de mezcla finita es una mezcla finita ponderada de dos o más distribuciones, donde cada distribución o componente representa un subgrupo de datos. En principio, los componentes pueden ser prácticamente cualquier cosa que consideremos útil, desde distribuciones simples, como una gaussiana o una Poisson, hasta objetos más complejos, como modelos jerárquicos o redes neuronales. Conceptualmente, para resolver un modelo mixto, todo lo que necesitamos hacer es asignar adecuadamente cada punto de datos a uno de los componentes. Podemos hacer esto introduciendo una variable latente \\(z\\). Usamos una distribución categórica para \\(z\\), que es la distribución discreta más general, con un previo de Dirichlet, que es la generalización n-dimensional de la distribución Beta. El muestreo de la variable discreta \\(z\\) puede ser problemático, por lo que puede resultar conveniente marginarla. PyMC incluye una distribución de mezcla normal y una distribución de mezcla que realiza esta marginación por nosotros, lo que facilita la construcción de modelos de mezcla con PyMC.\nUn problema común que analizamos en este capítulo cuando trabajamos con modelos mixtos es que este modelo puede conducir al problema de cambio de etiqueta, una forma de no identificabilidad. Una forma de eliminar la no identificabilidad es forzar el pedido de los componentes. Un desafío con los modelos de mezclas finitas es cómo decidir el número de componentes. Una solución es realizar una comparación de modelos para un conjunto de modelos en torno a un número estimado de componentes. Esa estimación debe guiarse, cuando sea posible, por nuestro conocimiento del problema en cuestión. Otra opción es intentar estimar automáticamente la cantidad de componentes a partir de los datos. Por esta razón, introdujimos el concepto del proceso de Dirichlet como una versión de dimensión infinita de la distribución de Dirichlet que podemos usar para construir un modelo de mezcla no paramétrico.\nFinalmente, para cerrar el capítulo, discutimos brevemente cuántos modelos, como el BetaBinomial (el que se usa para el problema de lanzar una moneda), el Binomial Negativo, la distribución t de Student e incluso los modelos jerárquicos, pueden interpretarse como modelos de mezcla continua.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelos de mezcla</span>"
    ]
  },
  {
    "objectID": "08_BART.html",
    "href": "08_BART.html",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "",
    "text": "7.1 Árboles de decisión\nSupongamos que tenemos dos variables \\(X_1\\) y \\(X_2\\) y queremos usar esas variables para clasificar objetos en dos clases: ⬤ o ▲. Para lograr este objetivo podemos utilizar una estructura de árbol como se muestra en el panel izquierdo de la siguiente figura.\nUn árbol es un grafo en el que cualquier par de vértices (o nodos) están conectados por exactamente un camino (o lado). El árbol de la figura anterior es un árbol binario porque cada nodo puede tener como máximo dos nodos hijos. Los nodos sin hijos se conocen como nodos hoja o nodos terminales. En este ejemplo tenemos dos nodos internos o interiores (representados como rectángulos) y 3 nodos terminales (representados como rectángulos redondeados). Cada nodo interno tiene una regla de decisión asociada. Si seguimos esas reglas de decisión, eventualmente llegaremos a un nodo hoja que nos proporcionará la respuesta a nuestro problema de decisión. Por ejemplo, si una instancia de la variable \\(X_1\\) es mayor que \\(c_1\\) el árbol de decisión nos dice que le asignemos a esa instancia la clase ⬤. Si en cambio observamos un valor de \\(x_{1i}\\) menor que \\(c_1\\) y el valor de \\(x_{2i}\\) menor que \\(c_2\\) entonces debemos asignar la clase ▲.\nAlgorítmicamente podemos conceptualizar un árbol como un conjunto de declaraciones if-else que seguimos para realizar una determinada tarea, como una clasificación. Otra perspectiva útil es la geométrica. Podemos entender un árbol binario como una forma de dividir el espacio muestral en bloques, como se muestra en el panel derecho de la figura anterior. Cada bloque está definido por líneas de división (asociadas a las reglas de clasificación de los nodos internos). Cada división del espacio muestral se alineará con uno de los ejes de las covariables. En la figura anterior usamos dos variables por que es más sencillo visualmente, pero la misma idea se puede extender fácilmente a mayores dimensiones.\nPara facilitar la discusión de BART resulta conveniente definir un árbol \\(g\\) como una 2-tupla con elementos:\nEntonces \\(G(X; \\mathcal{T}, \\mathcal{M})\\) es la función que asigna \\(\\mu_i \\in M\\) a \\(X\\). Por ejemplo, en la figura anterior los valores de \\(\\mu_{i}\\) son (⬤, ⬤ y ▲). Y la función \\(G\\) asigna ⬤, a casos con \\(X_1\\) mayor que \\(c_1\\), ⬤, a \\(X_1\\) menor que \\(c_1\\) y \\(X_2\\) mayor que \\(c_2\\) y ▲, a \\(X_1\\) menor que \\(c_1\\) y \\(X_2\\) menor que \\(c_2\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#árboles-de-decisión",
    "href": "08_BART.html#árboles-de-decisión",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "",
    "text": "\\(\\mathcal{T}\\) el conjunto de lados y nodos (los cuadrados, los cuadrados redondeados y las líneas que los unen en la figura anterior) junto con las reglas de decisión asociadas con los nodos internos.\n\\(\\mathcal{M} = \\{\\mu_1, \\mu_2, \\dots, \\mu_b\\}\\) denota un conjunto de valores de parámetros asociados con cada uno de los nodos terminales de \\(\\mathcal{T}\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#árboles-de-regresión",
    "href": "08_BART.html#árboles-de-regresión",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.2 Árboles de regresión",
    "text": "7.2 Árboles de regresión\nEn un árbol de decisión, $ contiene clases o etiquetas. Pero en principio podemos asociar otros elementos, típicamente números reales.\nEn la siguiente figura se muestra un caso de regresión con una sola covariable. A la izquierda vemos un árbol binario similar al de la figura anterior, con la principal diferencia de que en lugar de devolver un valor de clase en cada nodo hoja, el árbol devuelve un número.\n\nEn este caso hemos aproximado una serie de puntos, que parecen seguir una curva sinusoidal, con tres valores constantes, que geométricamente podemos interpretar como tres segmentos no-continuos, o de forma más general como una función definida por partes. En ese caso el valor de cada nodo hoja se corresponde con la media de los puntos correspondientes a su partición. La elección de la media es arbitraria, y se relaciona principalmente con su simpleza y facilidad de cálculo. Algunas alternativas serían la mediana, lo que podría ofrecer robustez a valores extremos. O incluso funciones más complejas como una regresión lineal, un spline, un proceso Gaussiano o una red neuronal. Sin embargo, la media es probablemente la opción más común para los árboles de regresión.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#interpretabilidad-y-flexibilidad",
    "href": "08_BART.html#interpretabilidad-y-flexibilidad",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.3 Interpretabilidad y flexibilidad",
    "text": "7.3 Interpretabilidad y flexibilidad\nEs importante señalar que, en general, un árbol de regresión no es una aproximación “suave” o “continua” sino una función escalonada por partes, aunque existen excepciones en la literatura. Esto no significa que los árboles de regresión sean necesariamente una mala elección para ajustar funciones continuas. En principio podemos aproximar cualquier función continua con una función escalonada y en la práctica esta aproximación podría ser bastante buena.\nUna característica atractiva de los árboles de decisión/regresión es su interpretabilidad: literalmente se puede leer el árbol y seguir los pasos necesarios para resolver un determinado problema. Y, por lo tanto, se puede comprender de forma transparente qué está haciendo el método, porque funciona y porque algunas clases pueden no estar clasificadas adecuadamente o porque algunos datos no están bien aproximados. Además, también es fácil explicar el resultado a una audiencia no técnica con términos simples.\nAdemás los árboles ofrecen un método muy flexible, ya que siempre se puede encontrar un árbol lo suficientemente complejo como para que cada nodo hoja tenga asociado una observación. La contracara de esta flexibilidad es el sobreajuste. La siguiente figura muestra un ejemplo de un árbol que ha sobreajustado los datos.\n\nOtro punto a notar es que es posible encontrar más de un árbol que ajuste igualmente bien un conjunto de datos. Esto quiere decir que áun cuando interpretables, podríamos encontrar interpretaciones alternativas. Un caso sencillo se da en la primer figura, el punto \\(C_1\\) no es único, hay una cantidad infinita de puntos a su alrededor que darían árboles que proveen exactamente el mismo ajuste y por lo tanto indistinguibles (al menos in-sample).\nUna propiedad interesante de los árboles surge cuando pensamos en ellos en términos de efectos e interacciones principales como lo hicimos con los modelos lineales. Observe que el término \\(\\mathbb{E}(Y \\mid \\boldsymbol{X})\\) es igual a la suma de todos los parámetros del nodo hoja \\(\\mu_{ij}\\), por lo tanto:\n\nCuando un árbol depende de una sola variable cada uno de esos \\(\\mu_{ij}\\) representa un efecto principal\nCuando un árbol depende de más de una variable, cada \\(\\mu_{ij}\\) representa un efecto de interacción.\n\nPor ejemplo en la primer figura del árbol de decisión, obtener un triángulo requiere la interacción de \\(X_1\\) y \\(X_2\\) ya que la condición del nodo secundario (\\(X_2 &gt; c_2\\)) depende de la condición del nodo principal (\\(X_1 &gt; c_1\\)).\nComo en principio el tamaño de los árboles es variable, podemos utilizar árboles para modelar de forma automática interacciones de distintos órdenes. Es decir, a medida que un árbol se vuelve más profundo, aumenta la posibilidad de utilizar más variables y por lo tanto de representar interacciones de orden superior. Sin embargo no todo lo que brilla es oro, la capacidad teórica de un método de representar interacciones de orden arbitrario no implica que en la práctica seamos capaces de detectar o aprender esas interacciones con cierto grado de certeza. En general, y no solo para árboles, estimar una interacción requiere de más datos que estimar una efecto principal y estimar una interacción de bajo orden requiere menos datos que una de mayor orden.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#conjuntos-de-árboles",
    "href": "08_BART.html#conjuntos-de-árboles",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.4 Conjuntos de árboles",
    "text": "7.4 Conjuntos de árboles\nTeniendo en cuenta que los árboles demasiado complejos probablemente no serán muy buenos para predecir datos nuevos, es común introducir dispositivos para regularizar la complejidad de los árboles y disminuir el riesgo de sobreajuste. Varias de las soluciones encontradas a lo largo de los años consisten en utilizar no un solo árbol, si no un conjunto de árboles donde la capacidad de aprendizaje/ajuste de cada árbol se limita. Es importante notar que una suma de árboles es otro árbol. Por lo que en principio será posible trabajar con un solo árbol y encontrar una solución que no sobreajuste. Pero en la práctica se ha observado repetidas veces, que es mejor usar un conjunto. Esto es válido tanto para métodos no-bayesianos como random forest o bayesianos como BART.\nUna desventaja de utilizar conjuntos de árboles es que perdemos la interpretabilidad de un único árbol. Para obtener una respuesta no podemos seguir un solo árbol, debemos considerar a todos, lo que generalmente dificulta cualquier interpretación directa. Hemos cambiado la interpretabilidad por la flexibilidad y la generalización.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#bart",
    "href": "08_BART.html#bart",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.5 BART",
    "text": "7.5 BART\nDe forma general podemos escribir un modelo BART como:\n\\[\nY = \\phi \\left(\\sum_{j=0}^m G(\\boldsymbol{X}; \\mathcal{T}_i, \\mathcal{M}_i), \\theta \\right)\n\\]\nDonde \\(G\\) representa una función árbol parametrizada por \\(\\mathcal{T}_i\\) y \\(\\mathcal{M}_i\\), que como ya vimos\\(\\mathcal{T}_i\\) representa la estructura de un árbol binario, es decir, el conjunto de nodos internos y sus reglas de decisión asociadas y un conjunto de nodos terminales. Mientras que \\(\\mathcal{M}_i\\) representa los valores en los nodos terminales. \\(\\phi\\) representa una distribución de probabilidad arbitraria que se usará como likelihood en nuestro modelo y \\(\\theta\\) otros parámetros de \\(\\phi\\) no modelados como una suma de árboles.\nPor ejemplo si \\(\\phi\\) es una distribución Normal, podríamos usar la suma de árboles para representar la media \\(\\mu\\) y tendríamos a \\(\\sigma\\) como variable auxiliar.\n\\[\nY = \\mathcal{N}\\left(\\mu = \\sum_{j=0}^m G(\\boldsymbol{X}; \\mathcal{T}_j, \\mathcal{M}_j), \\sigma^2  \\right)\n\\]\nComo es habitual, para especificar completamente un modelo BART, debemos elegir los priors sobre \\(\\mathcal{T}\\) y \\(\\mathcal{M}\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#priors-para-bart",
    "href": "08_BART.html#priors-para-bart",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.6 Priors para BART",
    "text": "7.6 Priors para BART\nEn el artículo original de BART y en la mayoría de las modificaciones e implementaciones posteriores, los priors para BART son conjugados. La implementación de BART en PyMC-BART no utiliza priors conjugados y también se desvía de otras maneras de gran parte del resto de la literatura. En lugar de discutir las diferencias nos centraremos en la implementación de PyMC-BART, que es la que vamos a utilizar para los ejemplos.\n\n7.6.1 Priors independientes\nPara simplificar la especificación de los priors asumimos que la estructura del árbol \\(\\mathcal{T}\\) y los valores de las hojas \\(\\mathcal{M}\\) son independientes. Además estos priors son independientes de los priors para \\(\\theta\\).\nEl prior para la estructura de árbol \\(\\mathcal{T}\\) se especifica mediante tres aspectos:\n\nLa probabilidad de que un nodo de profundidad \\(d=(0, 1, 2, \\dots)\\) sea no terminal está dado por \\(\\alpha(1 + d)^{-\\beta}\\) con \\(\\alpha \\in (0, 1)\\) y \\(\\beta \\in [0, \\infty)\\).\nLa distribución sobre la variable de partición. Lo más habitual es que sea Uniforme entre las covariables disponibles. Es posible utilizar otras distribuciones. PyMC-BART permite pasar un vector split_prior que tiene la misma interpretación que el parámetro de concentración \\(\\alpha\\) en una distribución de Dirichlet.\nLa distribución sobre los valores de partición. Es decir, una vez que elegimos una variable de partición, qué valor usamos para tomar una decisión. Es uniforme sobre los valores disponibles.\n\nEl prior para los valores de las hojas $_{ij}\nUsamos \\(\\mathcal{N}(\\mu_\\text{pred}, {\\varepsilon^2})\\), donde \\(\\mu_\\text{pred}\\) se calcula como la media de la suma actual de árboles dividida por número de árboles . \\(\\varepsilon\\) se calcula inicialmente a partir de \\(Y\\), siendo \\(\\varepsilon = \\frac{3}{\\sqrt{m}}\\) para datos binomiales y \\(\\varepsilon = \\frac{Y_\\text{std}}{\\sqrt{m}}\\) para datos distintos del binomial.\nEl número de árboles \\(m\\) debe ser especificado por el usuario, valores comunmente usados suelen ser 50, 100 o 200. En general mientras más árboles se utilicen mejor serán los resultados. Cuando se evalúa usando LOO, en general lo que se observa al aumentar \\(m\\) es una saturación sin llegar a sobrejustar. Es decir LOO aumenta a medida que \\(m\\) aumenta, pero el incremento va disminuyendo. Esto se puede explicar, al menos en parte, por el hecho que el aumento de \\(m\\) implica un valor cada vez más pequeño de \\(\\mu\\).\nLa especificación de los priors para BART, se desvía un poco de la especificación típica de priors en modelos Bayesianos, y la razón es que están diseñados para ser automáticos, algo similar a lo que hace Bambi. Por ejemplo usamos \\(Y\\) para especificar \\(\\mu\\), además este valor de \\(\\mu\\) es solo utilizado inicialmente. Durante la fase de ajuste el valor de \\(\\mu\\) es actualizado utilizando la varianza de las predicciones de cada árbol ajustado. Algo similar sucede con las variables de partición, por defecto todas tienen la misma probabilidad, pero durante la fase de ajuste se va actualizando esta probabiliad de acuerdo a la frecuencia con la que las variables entran en los árboles. Esto disminuye la probabilidad de que variables espurias participen de la suma de árboles, mejorado el uso de los recursos computacionales y mejorando la estimación de la importancia de las variables. Es claro que estos “trucos” hacen que el método no sea 100% bayesiano, si no una aproximación.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#inferencia-sobre-árboles-de-regresión-aditiva-bayesiana",
    "href": "08_BART.html#inferencia-sobre-árboles-de-regresión-aditiva-bayesiana",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.7 Inferencia sobre árboles de regresión aditiva bayesiana",
    "text": "7.7 Inferencia sobre árboles de regresión aditiva bayesiana\nHasta ahora hemos discutido ideas generales sobre los árboles y algo sobre como especificar distribuciones a priori para árboles, pero no hemos discutido detalles de calcular una distribución a posteriori de árboles. Hay muchas estrategias para hacer esto y los detalles son demasiado específicos para este curso. Por ese motivo vamos a describir sólo los elementos principales. Para más detalles pueden leer este artículo.\nPara ajustar los modelos BART no podemos usar métodos basados en gradientes como el Monte Carlo Hamiltoniano porque el espacio de los árboles es discreto, y por lo tanto no hay forma directa de obtener gradientes. Por esa razón, se han desarrollado métodos de muestreo específicos para árboles, muchos de ellos son variantes de MCMC.\nA grandes rasgos, cada paso del método implementado en PyMC-BART consiste en elegir uno de los \\(m_i\\) árboles disponibles y proponer un nuevo árbol que lo reemplace. Para ello se procede de la siguiente forma\n\nSe hacen crecer \\(N\\) árboles, comenzando desde la raíz y siguiendo los priors.\nSe calcula un peso para cada uno de los \\(N\\) árboles y para el árbol \\(m_i\\)\nSe reemplaza el árbol \\(m_i\\) por un árbol muestreado de forma proporcional a los pesos del punto anterior\n\nEn este algoritmo los priors son utilizado como distribución de propuesta, esto no es lo más común. En métodos como MH, HMC, NUTS, etc la distribución de propuesta y los priors son objetos completamente distintos. El peso calculado en el punto 2 es el log-likelihood, teniendo en cuenta la suma del árbol de propuesta y todos los demás árboles \\(m_{-i}\\). La razón de incluir a \\(m_i\\), es garantizar que la probabilidad de no-innovar sea no nula. Además, como sucede con métodos MCMC, la probabilidad de elegir un árbol que “empeore” el ajuste es no nula.\nEste procedimiento se repite hasta ajustar los \\(m\\) árboles. Es importante notar que la suma de los \\(m\\) árboles representa un punto en el espacio de la distribución a posteriori. Es decir, para obtener 1000 muestras de la distribución a posteriori necesitamos calcular \\(1000 \\times m\\) árboles. En la práctica PyMC-BART solo ajusta un subconjunto de los \\(m\\) árboles por iteración, lo que permite reducir el costo computacional.\nLos parámetros \\(\\theta\\), es decir los parámetros que no están vinculados a la suma de árboles, se calculan con los métodos estándar de PyMC. Es decir que la distribución a posteriori se consigue con una combinación de métodos de muestreo.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#minería-de-carbón-con-bart",
    "href": "08_BART.html#minería-de-carbón-con-bart",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.8 Minería de carbón con BART",
    "text": "7.8 Minería de carbón con BART\nPara comprender mejor BART en la práctica, utilizaremos dataset de la minería del carbón que ya usamos en dos ejemplos anteriores. En lugar de pensar este problema como un modelo de punto de cambio con dos distribuciones de Poisson, como en el ejemplo original de PyMC. Vamos a pensar en este problema como una regresión no paramétrica con una respuesta de Poisson, esto generalmente se discute en términos de procesos de Poisson o procesos de Cox.\nDebido a que nuestros datos son solo una columna con fechas, necesitamos realizar un procesamiento previo. Vamos a discretizar los datos, como si estuviéramos construyendo un histograma. Vamos a utilizar los centros de los bins como la variable \\(X\\) y la frecuencia por bin como la variable \\(Y\\).\n\ncoal = np.loadtxt(\"datos/coal.csv\")\n\n\n# discretize data\nyears = int(coal.max() - coal.min())\nbins = years // 4\nhist, x_edges = np.histogram(coal, bins=bins)\n# compute the location of the centers of the discretized data\nx_centers = x_edges[:-1] + (x_edges[1] - x_edges[0]) / 2\n# xdata needs to be 2D for BART\nx_data = x_centers[:, None]\n# express data as the rate number of disaster per year\ny_data = hist\n\nUna variable BART se puede definir de manera muy similar a otras variables aleatorias. Una diferencia importante es que tenemos que pasar los valores de X e Y a la variable BART, esta información se usa al muestrear árboles.\nAquí también dejamos explícito que vamos a utilizar una suma de 20 árboles (m=20). Un número bajo de árboles como 20 podría ser suficiente para modelos simples como este y también podría funcionar muy bien como una aproximación rápida para modelos más complejos, en particular durante la etapa inicial del modelado, cuando es posible que queramos probar algunas cosas tan rápido como sea posible.\n\nwith pm.Model() as modelo_coal:\n    μ_ = pmb.BART(\"μ_\", X=x_data, Y=np.log(y_data), m=20)\n    μ = pm.Deterministic(\"μ\", pm.math.exp(μ_))\n    y_pred = pm.Poisson(\"y_pred\", mu=μ, observed=y_data)\n    idata_coal = pm.sample(random_seed=RANDOM_SEED)\n\nMultiprocess sampling (4 chains in 4 jobs)\nPGBART: [μ_]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 24 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n\n\n\n\n\n\n\n\n\n\n\nAntes de comprobar el resultado, necesitamos discutir un detalle más, la variable BART siempre devuelve muestras en los reales, lo que significa que en principio podemos obtener valores que van desde \\(-\\infty\\) hasta \\(\\infty\\). Por lo tanto, es posible que necesitemos transformar estos valores como lo haríamos para modelos lineales generalizados, por ejemplo en modelo_coal calculamos pm.math.exp(μ_) porque la distribución de Poisson espera valores que van de 0 a \\(\\infty\\). Hasta acá no hay demasiada novedad. Lo nuevo es que es posible que necesitemos aplicar la transformación inversa a los valores de \\(Y\\), como hicimos en el modelo anterior donde tomamos \\(\\log(Y)\\). Como ya mencionamos los valores del argumento Y se utilizan para obtener un valor inicial razonable. Por tanto, aplicar la transformación inversa es una forma sencilla de mejorar la eficiencia y precisión del resultado. ¿Deberíamos hacer esto siempre? Bueno no. Si usamos BART para el parámetro \\(\\mu\\) de distribuciones como Normal, T de Student o LaplaceAsimétrica, no necesitamos hacer nada ya que el soporte de estos parámetros son los reales. Ahora, una excepción no trivial es cuando usemos como likelihood Bernoulli (o Binomial con n=1), en ese caso, necesitamos aplicar la función logística a la variable BART, pero no es necesario aplicar su inversa para transformar Y, PyMC-BART es capaz de lidiar con este caso particular internamente.\nBien, ahora veamos el resultado de modelo_coal.\n\n\nMostrar Código\n_, ax = plt.subplots(figsize=(10, 6))\n\nrates = idata_coal.posterior[\"μ\"] / 4\nrate_mean = rates.mean(dim=[\"draw\", \"chain\"])\nax.plot(x_centers, rate_mean, \"w\", lw=3)\nax.plot(x_centers, y_data / 4, \"k.\")\naz.plot_hdi(x_centers, rates, smooth=False)\naz.plot_hdi(x_centers, rates, hdi_prob=0.5, smooth=False, plot_kwargs={\"alpha\": 0})\nax.plot(coal, np.zeros_like(coal) - 0.5, \"k|\")\nax.set_xlabel(\"years\")\nax.set_ylabel(\"rate\");\n\n\n\n\n\n\n\n\n\nLa línea blanca en el gráfico anterior muestra la tasa media de accidentes. La franja cyan más oscura representa el HDI 50% y la más clara el HDI 94%. Podemos ver una rápida disminución en los accidentes relacionados con el carbón entre 1880 y 1900.\nEn el gráfico anterior, la línea blanca es la media de 4000 muestras de la distribución a posteriori, y cada uno de esos muestras es una suma de 20 árboles.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#bicicleteando-con-bart",
    "href": "08_BART.html#bicicleteando-con-bart",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.9 Bicicleteando con BART",
    "text": "7.9 Bicicleteando con BART\nVeamos otro ejemplo, esta vez usando el dataset de bikes.\n\nbikes = pd.read_csv(\"datos/bikes.csv\")\n\nfeatures = [\"hour\", \"temperature\", \"humidity\", \"weekday\"]\n\nX = bikes[features]\nY = bikes[\"rented\"]\n\n\nwith pm.Model() as model_bikes:\n    α = pm.Exponential(\"α\", 1)\n    μ = pmb.BART(\"μ\", X, np.log(Y), m=50)\n    y = pm.NegativeBinomial(\"y\", mu=pm.math.exp(μ), alpha=α, observed=Y)\n    idata_bikes = pm.sample(compute_convergence_checks=False, random_seed=RANDOM_SEED)\n\nMultiprocess sampling (4 chains in 4 jobs)\nCompoundStep\n&gt;NUTS: [α]\n&gt;PGBART: [μ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 79 seconds.\n\n\n\n\n\n\n\n\n\n\n\n\n7.9.1 Diagnóstico de convergencia\nPara verificar la convergencia de muestreo de los modelos BART, recomendamos un enfoque de 2 pasos.\n\nPara las variables que no son BART (como \\(\\alpha\\) en model_bikes) seguimos las recomendaciones estándar, como verificar los diagnósticos numéricos R-hat (&lt;= 1.01) y ESS (&lt; 100x número de cadenas), así como usar trazar gráficos o incluso mejores gráficos de clasificación\nPara las variables BART recomendamos utilizar la función pmb.plot_convergence.\n\n\naz.plot_trace(idata_bikes, var_names=[\"α\"], kind=\"rank_bars\");\n\n\n\n\n\n\n\n\n\npmb.plot_convergence(idata_bikes, var_name=\"μ\");\n\n/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/arviz/plots/ecdfplot.py:295: BehaviourChangeWarning: In future versions, if `eval_points` is not provided, then the ECDF will be evaluated at the unique values of the sample. To keep the current behavior, provide `eval_points` explicitly.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nEn la literatura de BART, el diagnóstico de las variables de BART a veces se considera menos importante que el diagnóstico de las variables que no son de BART; el argumento principal es que las estimaciones individuales de las variables latentes no tienen ningún interés directo y, en cambio, solo deberíamos preocuparnos. sobre qué tan bien estamos estimando toda la función/regresión.\nEn cambio, consideramos que verificar la convergencia de las variables BART es una parte importante del flujo de trabajo Bayesiano. La razón principal para usar pmb.plot_convergence es que normalmente la variable BART será un vector grande (estimamos una distribución por observación) y, por lo tanto, necesitaremos verificar una gran cantidad de diagnósticos. Además, el umbral de R-hat de 1,01 no es un umbral estricto; este valor se eligió suponiendo que se examinan uno o varios R-hat (y que las cadenas son lo suficientemente largas para estimar con precisión su autocorrelación), y si observamos una gran cantidad de R-que se espera que algunos de ellos sean mayores que el umbral de 1,01 (o cualquier umbral que elijamos) incluso si no hay nada malo en nuestra inferencia. Por esa razón, un análisis justo debe incluir un ajuste de comparación múltiple, y eso es lo que pmb.plot_convergence hace automáticamente por usted. Entonces, ¿cómo leer su salida? Tenemos dos paneles uno para ESS y otro para R-hat. La línea azul es la distribución acumulativa empírica de esos valores, para ESS queremos que toda la curva esté por encima de la línea discontinua y para R-hat queremos que la curva esté completamente por debajo de la línea discontinua. En la figura anterior, podemos ver que apenas lo logramos para ESS y para R-hat tenemos muy pocos valores por encima del umbral. ¿Son nuestros resultados inútiles? Probablemente no. Pero, sin duda, es posible que queramos realizar algunos sorteos más.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#partial-dependence-plots",
    "href": "08_BART.html#partial-dependence-plots",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.10 Partial dependence plots",
    "text": "7.10 Partial dependence plots\nPara ayudarnos a interpretar los resultados de nuestro modelo, utilizaremos gráficos de dependencia parcial. Este es un tipo de gráfico que muestra el efecto marginal que tiene una covariable sobre la variable predicha. Es decir, ¿cuál es el efecto que tiene una covariable \\(X_i\\) sobre \\(Y\\) mientras promediamos todas las demás covariables (\\(X_j, \\forall j \\not = i\\)). Esta herramienta no es exclusiva de BART. Pero se utilizan a menudo en la literatura de BART.\n\npmb.plot_pdp(μ, X=X, Y=Y, grid=(2, 2), func=np.exp, var_discrete=[3]);\n\n\n\n\n\n\n\n\nEn este gráfico, podemos ver el efecto principal de cada covariable sobre el valor predicho. Esto es muy útil ya que podemos recuperar relaciones complejas más allá de efectos monótonos crecientes o decrecientes. Por ejemplo para la covariable “hora” podemos ver dos picos alrededor de las 8 y 17 hs y un mínimo a medianoche.\nAl interpretar gráficos de dependencia parcial debemos tener cuidado con los supuestos de este gráfico. Primero, asumimos que las variables son independientes. Por ejemplo, al calcular el efecto de la “hora” tenemos que marginar el efecto de la “temperatura” y esto significa que para calcular el valor de dependencia parcial en “hora=0” estamos incluyendo todos los valores de temperatura observados, y esto puede incluir temperaturas. que no se observan a medianoche, dado que es más probable que haya temperaturas más bajas que más altas. Solo estamos viendo promedios, por lo que si para una covariable la mitad de los valores están asociados positivamente con la variable predicha y la otra mitad está asociada negativamente. La gráfica de dependencia parcial será plana ya que sus contribuciones se cancelarán entre sí. Este es un problema que se puede resolver utilizando gráficos de expectativas condicionales individuales pmb.plot_ice(...). Observe que todos estos supuestos son supuestos del gráfico de dependencia parcial, ¡no de nuestro modelo! De hecho, BART puede acomodar fácilmente interacciones de variables de orden arbitrario, las interacciones de alto orden están regularizadas.\nFinalmente, al igual que con otros métodos de regresión, debemos tener cuidado de que los efectos que observamos en las variables individuales estén condicionados a la inclusión de otras variables. Así, por ejemplo, aunque la “humedad” parece ser mayoritariamente plana, lo que significa que esta covariable tiene un pequeño efecto en el número de bicicletas usadas. Este podría ser el caso porque la “humedad” y la “temperatura” están correlacionadas hasta cierto punto y una vez que incluimos la “temperatura” en nuestro modelo, la “humedad” no proporciona demasiada información adicional. Intente, por ejemplo, ajustar el modelo nuevamente, pero esta vez con “humedad” como covariable única y luego ajustar el modelo nuevamente con “hora” como covariable única. Debería ver que el resultado de este modelo de variable única será muy similar a la figura anterior para la covariable “hora”, pero menos similar para la covariable “humedad”.\n\n7.10.1 Selección de variables\nComo vimos en la sección anterior, un gráfico de dependencia parcial nos permite interpretar el efecto (marginal) de cada covariable sobre la respuesta. Además nos da una idea de cuánto contribuye cada covariable a la variable predicha. Pero hay una forma más directa de hacer esto. Veamos primero un gráfico y luego como interpretarlo y calcularlo.\n\npmb.plot_variable_importance(idata_bikes, μ, X);\n\n\n\n\n\n\n\n\nEn el eje x tenemos los nombres de las covariables y en el eje y el R² (el cuadrado del coeficiente de correlación de Pearson) entre las predicciones realizadas para el modelo completo (todas las variables incluidas) y los submodelos, aquellos con sólo un subconjunto de las variables.\nEn este ejemplo, la variable más importante es “hora”, luego “temperatura”, “humedad” y finalmente “día de la semana”. Observe que el primer valor de R² es el valor de un modelo que solo incluye la variable “hora”, el segundo R² es para un modelo con dos variables, “hora” y “temperatura”, y así sucesivamente. Podemos ver como un modelo con las variables “hora” y “temperatura”, es capaz de hacer predicciones equivalentes a un modelo con todas las variables. Las barras de error representan el 94% HDI de la distribución predictiva a posteriori.\nplot_variable_importance es rápido porque hace dos suposiciones:\n\nEl ordenamiento de las variables se calcula con una heurística simple. Contamos cuántas veces se incluye una variable en todos los árboles de regresión. La intuición es que si una variable es importante debería aparecer con más frecuencia en los árboles ajustados que las variables menos importantes.\nLas predicciones utilizadas para el cálculo de R² provienen de los árboles ya ajustados. Por ejemplo, para estimar el efecto de un modelo BART con la variable hora podamos la rama que no incluye esta variable. Esto hace que los cálculos sean mucho más rápidos, ya que no necesitamos encontrar un nuevo conjunto de árboles. Esto es similar a lo que hacemos al calcular un PDP.\n\nEn lugar de utilizar la “heurística de conteo”. También puede realizar una búsqueda hacia atrás, pmb.plot_variable_importance(..., method=\"backward\"). Internamente, esto calculará el R² para el modelo completo, luego para todos los modelos con una variable menos que el modelo completo, y luego para todos los modelos con menos de dos, y así sucesivamente. En cada etapa, descartamos la variable que da el R² más bajo. El método inverso será más lento, ya que necesitamos calcular predicciones para más modelos.\n\npmb.plot_variable_importance(idata_bikes, μ, X, method=\"backward\");",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#modelos-distribucionales-con-bart",
    "href": "08_BART.html#modelos-distribucionales-con-bart",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.11 Modelos distribucionales con BART",
    "text": "7.11 Modelos distribucionales con BART\nComo ya vimos para modelos lineales generalizados, no estamos restringidos a crear modelos lineales para la media o el parámetro de ubicación; También podemos modelar otros parámetros, como el parámetro de dispersión. Lo mismo se aplica a los modelos BART.\nPara ejemplificar esto probemos extender el modelo anterior, esta vez usando la suma de árboles tanto para modelar \\(\\mu\\) como \\(\\alpha\\).\n\nwith pm.Model() as modelo_bb:\n    μ = pmb.BART(\"μ\", X, np.log(Y), shape=(2, 348), separate_trees=True)\n    pm.NegativeBinomial('yl', mu=np.exp(μ[0]), alpha=np.exp(μ[1]), observed=Y)\n    idata_bb = pm.sample(compute_convergence_checks=False, random_seed=RANDOM_SEED)\n\nMultiprocess sampling (4 chains in 4 jobs)\nPGBART: [μ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 166 seconds.\n\n\n\n\n\n\n\n\n\n\n\nTomémonos un momento para asegurarnos de que entendemos este modelo.\nPrimero, observe que pasamos un argumento shape a pmb.BART(). Esto nos permitirá definir una sola variable BART, pero usarla para modelar dos parámetros de forma independiente. Al usar separate_trees = True le indicamos a PyMC-BART que ajuste dos conjuntos independiente de árboles, si en cambio fuera False, tendríamos el mismo conjunto de árboles, pero cada nodo hoja devolvería dos valores muestreados independientemente.\nLuego necesitamos indexar μ para usar la primera dimensión para el parámetro \\(\\mu\\) y la segunda para el parámetro \\(\\alpha\\).\nOtro aspecto importante del modelo_bb es que tomamos la función exponencial de μ. Hacemos esto para garantizar que la distribución binomial negativa obtenga solo valores positivos, tanto para \\(\\mu\\) como para \\(\\alpha\\). Este es el mismo tipo de transformación que discutimos en el contexto de los modelos lineales generalizados.\nLa siguiente figura muestra un partial dependence plots con dos columnas una por cada parámetro de la distribución NegativaBinomial\n\npmb.plot_pdp(μ, X, Y, \n             xs_interval=\"insample\", func=np.exp , var_discrete=[3],\n             grid=(4, 2), sharey=\"col\", figsize=(10, 6));",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  },
  {
    "objectID": "08_BART.html#ejercicios",
    "href": "08_BART.html#ejercicios",
    "title": "7  Árboles de regresión aditivos Bayesianos",
    "section": "7.12 Ejercicios",
    "text": "7.12 Ejercicios\n\nPodriamos tener un ejercicio donde ajustamos un dataset muy simple con una sola covariable y hacemos predicciones fuera del rango de los datos y pedimos a los estudiantes que expliquen por que see observa lo que se observa y luego repetir pero cambiando la respuesta lineal.\nEsto podría ser otro mostrando que las predicciones insample son similares pero los PDPs no https://www.pymc.io/projects/bart/en/latest/examples/bart_categorical_hawks.html\ngeneramos este dataset\n\nX = np.random.uniform(-1, 1, (250, 3))\nlala = np.where(X[:,2] &gt;= 0,  np.zeros_like(X[:,2]), np.ones_like(X[:,2]))\ne = np.random.normal(0, 0.1, 250)\nY = 0.2*X[:,0] - 5*X[:,1] + 10*X[:,1] * lala+ e\n\n\nplt.plot(X[:,1], Y, '.');\nusan BART y calculan un PDP y un ICE, expliquen diferencia\n\nSpace influenza con distintos valores de m [5, 20, 50, 100] tienen que usar LOO y un gráfico para comparar los resultados y explicar las diferencias.\n\nspace_in = pd.read_csv(\"datos/space_influenza.csv\")\nX = np.atleast_2d(space_in[\"age\"]).T\nY = space_in[\"sick\"]\n\n\nY_jittered = np.random.normal(Y, 0.02)\nplt.plot(X[:,0], Y_jittered, \".\", alpha=0.5)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Árboles de regresión aditivos Bayesianos</span>"
    ]
  }
]