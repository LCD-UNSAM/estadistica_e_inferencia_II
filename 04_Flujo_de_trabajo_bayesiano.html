<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.557">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Estadística a Inferencia II - 4&nbsp; Flujo de trabajo Bayesiano</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./05_GLMS.html" rel="next">
<link href="./03_Modelos_jerárquicos.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_Flujo_de_trabajo_bayesiano.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Flujo de trabajo Bayesiano</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Estadística a Inferencia II</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="github" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="github"><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/LCD-UNSAM/estadistica_e_inferencia_II">
            Fuente
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/LCD-UNSAM/estadistica_e_inferencia_II/issues/new">
            Reportar errores
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Modo claro/oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Modo sin distracciones">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‎</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Inferencia Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programación_probabilística.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Programación probabilista</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jerárquicos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelado Jerárquico</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Flujo_de_trabajo_bayesiano.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Flujo de trabajo Bayesiano</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_GLMS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos lineales y generalizaciones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_modelos_de_mezcla.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de mezcla</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_BART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Árboles de regresión aditivos Bayesianos</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#de-datos-y-suposiciones-a-insights" id="toc-de-datos-y-suposiciones-a-insights" class="nav-link active" data-scroll-target="#de-datos-y-suposiciones-a-insights"><span class="header-section-number">4.1</span> De datos y suposiciones a insights</a></li>
  <li><a href="#el-flujo-de-trabajo-bayesiano" id="toc-el-flujo-de-trabajo-bayesiano" class="nav-link" data-scroll-target="#el-flujo-de-trabajo-bayesiano"><span class="header-section-number">4.2</span> El flujo de trabajo bayesiano</a></li>
  <li><a href="#pruebas-predictivas-a-priori" id="toc-pruebas-predictivas-a-priori" class="nav-link" data-scroll-target="#pruebas-predictivas-a-priori"><span class="header-section-number">4.3</span> Pruebas predictivas a priori</a>
  <ul class="collapse">
  <li><a href="#predadores-y-presas" id="toc-predadores-y-presas" class="nav-link" data-scroll-target="#predadores-y-presas"><span class="header-section-number">4.3.1</span> Predadores y presas</a></li>
  </ul></li>
  <li><a href="#pruebas-predictivas-a-posteriori" id="toc-pruebas-predictivas-a-posteriori" class="nav-link" data-scroll-target="#pruebas-predictivas-a-posteriori"><span class="header-section-number">4.4</span> Pruebas predictivas a posteriori</a></li>
  <li><a href="#valores-p-bayesianos" id="toc-valores-p-bayesianos" class="nav-link" data-scroll-target="#valores-p-bayesianos"><span class="header-section-number">4.5</span> Valores p Bayesianos</a></li>
  <li><a href="#comparación-de-modelos" id="toc-comparación-de-modelos" class="nav-link" data-scroll-target="#comparación-de-modelos"><span class="header-section-number">4.6</span> Comparación de modelos</a>
  <ul class="collapse">
  <li><a href="#el-equilibro-entre-simplicidad-y-exactitud" id="toc-el-equilibro-entre-simplicidad-y-exactitud" class="nav-link" data-scroll-target="#el-equilibro-entre-simplicidad-y-exactitud"><span class="header-section-number">4.6.1</span> El equilibro entre simplicidad y exactitud</a></li>
  <li><a href="#muchos-parámetros-pueden-conducir-a-sobreajuste" id="toc-muchos-parámetros-pueden-conducir-a-sobreajuste" class="nav-link" data-scroll-target="#muchos-parámetros-pueden-conducir-a-sobreajuste"><span class="header-section-number">4.6.2</span> Muchos parámetros (pueden) conducir a sobreajuste</a></li>
  <li><a href="#muy-pocos-parámetros-conducen-a-un-subajuste" id="toc-muy-pocos-parámetros-conducen-a-un-subajuste" class="nav-link" data-scroll-target="#muy-pocos-parámetros-conducen-a-un-subajuste"><span class="header-section-number">4.6.3</span> Muy pocos parámetros conducen a un subajuste</a></li>
  <li><a href="#medidas-de-exactitud-predictiva" id="toc-medidas-de-exactitud-predictiva" class="nav-link" data-scroll-target="#medidas-de-exactitud-predictiva"><span class="header-section-number">4.6.4</span> Medidas de exactitud predictiva</a></li>
  <li><a href="#validación-cruzada" id="toc-validación-cruzada" class="nav-link" data-scroll-target="#validación-cruzada"><span class="header-section-number">4.6.5</span> Validación cruzada</a></li>
  <li><a href="#criterios-de-información" id="toc-criterios-de-información" class="nav-link" data-scroll-target="#criterios-de-información"><span class="header-section-number">4.6.6</span> Criterios de información</a></li>
  <li><a href="#entropia" id="toc-entropia" class="nav-link" data-scroll-target="#entropia"><span class="header-section-number">4.6.7</span> Entropia</a></li>
  <li><a href="#waic" id="toc-waic" class="nav-link" data-scroll-target="#waic"><span class="header-section-number">4.6.8</span> WAIC</a></li>
  <li><a href="#loo-y-la-validación-cruzada-aproximada" id="toc-loo-y-la-validación-cruzada-aproximada" class="nav-link" data-scroll-target="#loo-y-la-validación-cruzada-aproximada"><span class="header-section-number">4.6.9</span> LOO y la validación cruzada (aproximada)</a></li>
  <li><a href="#retomando" id="toc-retomando" class="nav-link" data-scroll-target="#retomando"><span class="header-section-number">4.6.10</span> Retomando</a></li>
  <li><a href="#loo-y-waic" id="toc-loo-y-waic" class="nav-link" data-scroll-target="#loo-y-waic"><span class="header-section-number">4.6.11</span> LOO y WAIC</a></li>
  <li><a href="#calculando-loo" id="toc-calculando-loo" class="nav-link" data-scroll-target="#calculando-loo"><span class="header-section-number">4.6.12</span> Calculando LOO</a></li>
  </ul></li>
  <li><a href="#métodos-numéricos-de-inferencia-bayesiana" id="toc-métodos-numéricos-de-inferencia-bayesiana" class="nav-link" data-scroll-target="#métodos-numéricos-de-inferencia-bayesiana"><span class="header-section-number">4.7</span> Métodos numéricos de Inferencia Bayesiana</a></li>
  <li><a href="#calculando-la-distribución-a-posteriori" id="toc-calculando-la-distribución-a-posteriori" class="nav-link" data-scroll-target="#calculando-la-distribución-a-posteriori"><span class="header-section-number">4.8</span> Calculando la distribución a posteriori</a>
  <ul class="collapse">
  <li><a href="#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc"><span class="header-section-number">4.8.1</span> Markov Chain Monte Carlo (MCMC)</a></li>
  <li><a href="#metropolis-hastings" id="toc-metropolis-hastings" class="nav-link" data-scroll-target="#metropolis-hastings"><span class="header-section-number">4.8.2</span> Metropolis-Hastings</a></li>
  <li><a href="#mh-adaptativo" id="toc-mh-adaptativo" class="nav-link" data-scroll-target="#mh-adaptativo"><span class="header-section-number">4.8.3</span> MH adaptativo</a></li>
  </ul></li>
  <li><a href="#diagnóstico-del-muestreo" id="toc-diagnóstico-del-muestreo" class="nav-link" data-scroll-target="#diagnóstico-del-muestreo"><span class="header-section-number">4.9</span> Diagnóstico del muestreo</a>
  <ul class="collapse">
  <li><a href="#trace-plots" id="toc-trace-plots" class="nav-link" data-scroll-target="#trace-plots"><span class="header-section-number">4.9.1</span> Trace plots</a></li>
  <li><a href="#rank-plots" id="toc-rank-plots" class="nav-link" data-scroll-target="#rank-plots"><span class="header-section-number">4.9.2</span> Rank plots</a></li>
  <li><a href="#hat-r-r-sombrero" id="toc-hat-r-r-sombrero" class="nav-link" data-scroll-target="#hat-r-r-sombrero"><span class="header-section-number">4.9.3</span> <span class="math inline">\(\hat R\)</span> (R sombrero)</a></li>
  <li><a href="#gráfico-de-autocorrelación" id="toc-gráfico-de-autocorrelación" class="nav-link" data-scroll-target="#gráfico-de-autocorrelación"><span class="header-section-number">4.9.4</span> Gráfico de autocorrelación</a></li>
  <li><a href="#tamaño-de-muestra-efectivo-ess" id="toc-tamaño-de-muestra-efectivo-ess" class="nav-link" data-scroll-target="#tamaño-de-muestra-efectivo-ess"><span class="header-section-number">4.9.5</span> Tamaño de muestra efectivo (ESS)</a></li>
  <li><a href="#error-estándar-del-monte-carlo-mcse" id="toc-error-estándar-del-monte-carlo-mcse" class="nav-link" data-scroll-target="#error-estándar-del-monte-carlo-mcse"><span class="header-section-number">4.9.6</span> Error estándar del Monte Carlo (MCSE)</a></li>
  <li><a href="#montecarlo-hamiltoniano-hmc" id="toc-montecarlo-hamiltoniano-hmc" class="nav-link" data-scroll-target="#montecarlo-hamiltoniano-hmc"><span class="header-section-number">4.9.7</span> Montecarlo Hamiltoniano (HMC)</a></li>
  <li><a href="#propuestas-aleatorias-vs-hamiltonianos" id="toc-propuestas-aleatorias-vs-hamiltonianos" class="nav-link" data-scroll-target="#propuestas-aleatorias-vs-hamiltonianos"><span class="header-section-number">4.9.8</span> Propuestas aleatorias vs hamiltonianos</a></li>
  <li><a href="#hmc-dinámico-y-adaptativo" id="toc-hmc-dinámico-y-adaptativo" class="nav-link" data-scroll-target="#hmc-dinámico-y-adaptativo"><span class="header-section-number">4.9.9</span> HMC dinámico y adaptativo</a></li>
  <li><a href="#diagnóstico-de-algoritmos-basados-en-gradiente" id="toc-diagnóstico-de-algoritmos-basados-en-gradiente" class="nav-link" data-scroll-target="#diagnóstico-de-algoritmos-basados-en-gradiente"><span class="header-section-number">4.9.10</span> Diagnóstico de algoritmos basados en gradiente</a></li>
  <li><a href="#divergencias" id="toc-divergencias" class="nav-link" data-scroll-target="#divergencias"><span class="header-section-number">4.9.11</span> Divergencias</a></li>
  </ul></li>
  <li><a href="#qué-hacer-cuando-los-diagnósticos-no-dan-bien" id="toc-qué-hacer-cuando-los-diagnósticos-no-dan-bien" class="nav-link" data-scroll-target="#qué-hacer-cuando-los-diagnósticos-no-dan-bien"><span class="header-section-number">4.10</span> Qué hacer cuando los diagnósticos no dan bien?</a></li>
  <li><a href="#una-hoja-de-ruta-para-el-bayesian-workflow" id="toc-una-hoja-de-ruta-para-el-bayesian-workflow" class="nav-link" data-scroll-target="#una-hoja-de-ruta-para-el-bayesian-workflow"><span class="header-section-number">4.11</span> Una hoja de ruta para el Bayesian workflow</a>
  <ul class="collapse">
  <li><a href="#resume-el-problema" id="toc-resume-el-problema" class="nav-link" data-scroll-target="#resume-el-problema"><span class="header-section-number">4.11.1</span> Resume el problema</a></li>
  <li><a href="#familiarízate-con-los-datos" id="toc-familiarízate-con-los-datos" class="nav-link" data-scroll-target="#familiarízate-con-los-datos"><span class="header-section-number">4.11.2</span> Familiarízate con los datos</a></li>
  <li><a href="#cuente-una-historia-para-los-datos" id="toc-cuente-una-historia-para-los-datos" class="nav-link" data-scroll-target="#cuente-una-historia-para-los-datos"><span class="header-section-number">4.11.3</span> Cuente una historia para los datos</a></li>
  <li><a href="#escribe-un-modelo" id="toc-escribe-un-modelo" class="nav-link" data-scroll-target="#escribe-un-modelo"><span class="header-section-number">4.11.4</span> Escribe un modelo</a></li>
  <li><a href="#implementar-el-modelo" id="toc-implementar-el-modelo" class="nav-link" data-scroll-target="#implementar-el-modelo"><span class="header-section-number">4.11.5</span> Implementar el modelo</a></li>
  <li><a href="#evaluar-la-distribución-predictiva-a-priori" id="toc-evaluar-la-distribución-predictiva-a-priori" class="nav-link" data-scroll-target="#evaluar-la-distribución-predictiva-a-priori"><span class="header-section-number">4.11.6</span> Evaluar la distribución predictiva a priori</a></li>
  <li><a href="#calcular-la-distribución-a-posteriori" id="toc-calcular-la-distribución-a-posteriori" class="nav-link" data-scroll-target="#calcular-la-distribución-a-posteriori"><span class="header-section-number">4.11.7</span> Calcular la distribución a posteriori</a></li>
  <li><a href="#evaluar-muestras" id="toc-evaluar-muestras" class="nav-link" data-scroll-target="#evaluar-muestras"><span class="header-section-number">4.11.8</span> Evaluar muestras</a></li>
  <li><a href="#validar-el-modelo" id="toc-validar-el-modelo" class="nav-link" data-scroll-target="#validar-el-modelo"><span class="header-section-number">4.11.9</span> Validar el modelo</a></li>
  <li><a href="#comparar-modelos" id="toc-comparar-modelos" class="nav-link" data-scroll-target="#comparar-modelos"><span class="header-section-number">4.11.10</span> Comparar modelos</a></li>
  <li><a href="#resumir-resultados" id="toc-resumir-resultados" class="nav-link" data-scroll-target="#resumir-resultados"><span class="header-section-number">4.11.11</span> Resumir resultados</a></li>
  </ul></li>
  <li><a href="#comentarios-finales" id="toc-comentarios-finales" class="nav-link" data-scroll-target="#comentarios-finales"><span class="header-section-number">4.12</span> Comentarios finales</a></li>
  <li><a href="#ejercicios" id="toc-ejercicios" class="nav-link" data-scroll-target="#ejercicios"><span class="header-section-number">4.13</span> Ejercicios</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-Bayesian-Worflow" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Flujo de trabajo Bayesiano</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="1699600a" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="de-datos-y-suposiciones-a-insights" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="de-datos-y-suposiciones-a-insights"><span class="header-section-number">4.1</span> De datos y suposiciones a insights</h2>
<p>Usamos datos para comprender el mundo que nos rodea, lo que podría consistir en revelar el origen del universo, predecir cuándo debemos plantar y cuándo cosechar, o cómo hacer sugerencias de productos útiles para mantener a los clientes interesados y comprando nuestros productos. Sin embargo, el mundo suele ser un lugar complejo y, por lo tanto, los datos deben procesarse e interpretarse para que sean útiles. Una forma de interpretar los datos es construir modelos. Los modelos son útiles porque nos permiten incorporar suposiciones y evaluarlas.</p>
<p>Los modelos funcionan como ficciones científicas; mapas que nos ayudan a navegar relaciones complejas. Por lo general (aunque no siempre), los modelos no son el objeto de interés principal, sino que son andamios que proporcionan un marco estructurado para comprender e interpretar datos.</p>
<p>Al discutir estadística Bayesiana se suele hacer en torno a modelos de probabilidad. Tomamos algunos priors, algunos likelihoods, que luego mezclamos con datos siguiendo como receta el Teorema de Bayes, y Voila!, somos Bayesianos!</p>
<p>Esta descripción no es incorrecta, simplemente no refleja muchos de los aspectos prácticos de la estadística Bayesiano (o del modelado en general). Lo que sucede es que muchos de esos aspectos prácticos no han sido completamente formalizados (como sí lo ha sido el proceso de inferencia). Incluso para varios de esos aspectos, no tenemos aún buenas herramientas o incluso no tenemos aún buenos marcos conceptuales.</p>
</section>
<section id="el-flujo-de-trabajo-bayesiano" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="el-flujo-de-trabajo-bayesiano"><span class="header-section-number">4.2</span> El flujo de trabajo bayesiano</h2>
<p>La siguiente figura muestra un esquema de un flujo de trabajo Bayesiano. Podemos ver que hay muchos pasos. Necesitamos todos estos pasos porque los modelos son sólo elucubraciones de nuestra mente sin garantía de ayudarnos a comprender los datos. Primero debemos ser capaces de construir un modelo y luego comprobar su utilidad y, si no es lo suficientemente útil, seguir trabajando o, a veces, dejar de intentarlo. Es posible que también hayas notado el paso “evaluar muestras”. Necesitamos esto porque, normalmente, utilizamos métodos computacionales para resolver modelos Bayesianos, los cuales solos proveen garantías asintóticas.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Bayesian_workflow.png" class="img-fluid figure-img"></p>
<figcaption>Principales elementos de un flujo de trabajo Bayesiano.</figcaption>
</figure>
</div>
<p>Diseñar un modelo adecuado para una tarea de análisis de datos determinada generalmente requiere una combinación de experiencia estadística, conocimiento del dominio, comprensión de las herramientas computacionales y usualmente mucha perseverancia. Rara vez obtenemos el modelo queremos en un solo paso. Es similar a escribir un programa de computadora. Difícilmente no cometamos errores. Incluso los programas muy cortos requieren algo de prueba y error. Por lo general, es necesario probar, depurar y perfeccionar y, a veces, cambiar de enfoque . Lo mismo ocurre con los modelos estadísticos; después de todo, podemos ver los modelos estadísticos como software generador de datos.</p>
<p>En las siguientes secciones vamos a discutir algunos de los pasos del flujo de trabajo Bayesiano. Y al final vamos a describir un resumen de un trabajo Bayesiano. La mejor forma de lograr familiaridad con el flujo de trabajo Bayesiano y los sub-flujos es resolviendo problemas.</p>
</section>
<section id="pruebas-predictivas-a-priori" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="pruebas-predictivas-a-priori"><span class="header-section-number">4.3</span> Pruebas predictivas a priori</h2>
<p>La distribución predictiva a priori se define como:</p>
<p><span class="math display">\[
p(y^\ast) =  \int_{\Theta} p(y^\ast \mid \theta) \; p(\theta) \; d\theta
\]</span></p>
<p>donde <span class="math inline">\(y^\ast\)</span> representa datos no observados pero potencialmente observables, al menos de acuerdo a nuestro modelo. Los datos generados son predictivos ya que son los datos que el modelo esperara ver, es decir son datos no observados pero potencialmente observables.</p>
<p>Lo que estamos haciendo es marginalizando el likelihood al integrar sobre todos los valores posibles del prior. Por lo tanto, desde la perspectiva de nuestro modelo, estamos describiendo la distribución marginal de los datos, es decir independientemente de los parámetros. En otros palabras estamos generando predicciones del modelo “antes” de ver los datos. Esta distribución representa lo que el modelo “cree” sobre la cantidad modelada.</p>
<p>Obtener esta distribución de forma analítica no siempre es sencillo, pero si lo es computacionalmente, siempre y cuando podamos escribir un modelo en un PPL. Podemos generar muestras de esta distribución según el siguiente procedimiento:</p>
<ol type="1">
<li>Elegimos un valor de <span class="math inline">\(\theta\)</span> de acuerdo a la distribución a priori <span class="math inline">\(p(\theta \mid y)\)</span></li>
<li>Fijamos <span class="math inline">\(\theta\)</span> en la distribución que usamos como likelihood <span class="math inline">\(p(y^\ast \mid \theta)\)</span> y generamos una muestra aleatoria</li>
<li>Repetimos desde 1, tantas veces como muestras necesitemos</li>
</ol>
<p>Uno de los usos prácticos de esta distribución es evaluar el modelo. A grandes rasgos esto se puede realizar generando datos a partir de la distribución predictiva a priori y comparándolos con nuestro conocimiento de domino. Es común que las comparaciones sean visuales y semi-cuantitativas, es decir buscamos acuerdos razonables. Por ejemplo podemos hacernos preguntas como ¿La mayor parte de la distribución simulada está en un rango razonable? ¿Existen valores extremos? Es recomendable NO comparar con los datos observados, en cambio usar valores de referencia. Los valores de referencia son datos empíricos u observaciones históricas, normalmente serán valores mínimos, máximos o esperados.</p>
<section id="predadores-y-presas" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="predadores-y-presas"><span class="header-section-number">4.3.1</span> Predadores y presas</h3>
<p>Estamos interesados en modelar la relación entre las masas de organismos que son presas y organismos que son predadores, como las masas varían en órdenes de magnitud desde una célula de 1e-14 gramos a una ballena azul de 1.5e8 gramos, es conveniente trabajar en una escala logarítmica. Entonces un modelo podría ser</p>
<p><span class="math display">\[\begin{align}
    \mu =&amp; Normal(\cdots, \cdots) \\
    \sigma =&amp; HalfNormal(\cdots) \\
    log(masas) =&amp; Normal(\mu, \sigma)
\end{align}\]</span></p>
<p>Para definir los valores del prior, podríamos definir el modelo con algunos priors y ver que implican estos priors en la escala de los datos. Para muestrear de la predictiva a priori usamos <code>pm.sample_prior_predictive()</code> en vez de <code>sample</code> y necesitamos definir observaciones “dummy”. Esto es necesario para indicar cual es el likelihood y para controlar el tamaño de cada distribución predicha.</p>
<div id="66da3ef8" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>pp_mass <span class="op">=</span> pd.read_csv(<span class="st">"datos/pp_mass.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a>pp_mass[<span class="st">"predator_log"</span>] <span class="op">=</span> np.log(pp_mass[<span class="st">"predator"</span>])</span>
<span id="cb2-3"><a href="#cb2-3"></a>pp_mass[<span class="st">"prey_log"</span>] <span class="op">=</span> np.log(pp_mass[<span class="st">"prey"</span>])</span>
<span id="cb2-4"><a href="#cb2-4"></a></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co"># valores de referencia en escala log</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>refs <span class="op">=</span> {<span class="st">"Planeta Tierra"</span>:np.log(<span class="fl">5.97e+27</span>),</span>
<span id="cb2-7"><a href="#cb2-7"></a>        <span class="st">"Ballena Azul"</span>:np.log(<span class="fl">1.5e8</span>), </span>
<span id="cb2-8"><a href="#cb2-8"></a>        <span class="st">"Célula más pequeña"</span>:np.log(<span class="fl">1e-14</span>)}</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8de4b3c0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb3-2"><a href="#cb3-2"></a>    α <span class="op">=</span> pm.Normal(<span class="st">"α"</span>, <span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>    β <span class="op">=</span> pm.Normal(<span class="st">"β"</span>, <span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">5</span>)</span>
<span id="cb3-5"><a href="#cb3-5"></a>    presa <span class="op">=</span> pm.Normal(<span class="st">"presa"</span>, α <span class="op">+</span> β <span class="op">*</span> pp_mass[<span class="st">"prey_log"</span>], σ, observed<span class="op">=</span>pp_mass[<span class="st">"predator_log"</span>])</span>
<span id="cb3-6"><a href="#cb3-6"></a>    idata <span class="op">=</span> pm.sample_prior_predictive(samples<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [presa, α, β, σ]</code></pre>
</div>
</div>
<p>Podemos ver que el idata no tiene grupo <code>posterior</code>, pero si tiene <code>prior</code> y <code>prior_predictive</code></p>
<div id="c3f00527" class="cell" data-scrolled="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>idata</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">

            <div>
              <div class="xr-header">
                <div class="xr-obj-type">arviz.InferenceData</div>
              </div>
              <ul class="xr-sections group-sections">
              
            <li class="xr-section-item">
                  <input id="idata_prior250d196f-bbd6-48fb-a203-a3a508cced3b" class="xr-section-summary-in" type="checkbox">
                  <label for="idata_prior250d196f-bbd6-48fb-a203-a3a508cced3b" class="xr-section-summary">prior</label>
                  <div class="xr-section-inline-details"></div>
                  <div class="xr-section-details">
                      <ul id="xr-dataset-coord-list" class="xr-var-list">
                          <div style="padding-left:2rem;"><div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewbox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewbox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body[data-theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-index-preview {
  grid-column: 2 / 5;
  color: var(--xr-font-color2);
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data,
.xr-index-data-in:checked ~ .xr-index-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-index-name div,
.xr-index-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2,
.xr-no-icon {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class="xr-text-repr-fallback">&lt;xarray.Dataset&gt;
Dimensions:  (chain: 1, draw: 100)
Coordinates:
  * chain    (chain) int64 0
  * draw     (draw) int64 0 1 2 3 4 5 6 7 8 9 ... 90 91 92 93 94 95 96 97 98 99
Data variables:
    α        (chain, draw) float64 -123.2 21.44 -225.4 ... -53.03 -168.3 30.35
    β        (chain, draw) float64 46.55 103.0 19.07 ... -156.6 73.03 -255.0
    σ        (chain, draw) float64 7.648 12.21 0.7211 ... 0.1937 3.182 6.897
Attributes:
    created_at:                 2024-05-29T16:33:48.453734+00:00
    arviz_version:              0.19.0.dev0
    inference_library:          pymc
    inference_library_version:  5.13.1+16.g0ad689c6a</pre><div class="xr-wrap" style="display:none"><div class="xr-header"><div class="xr-obj-type">xarray.Dataset</div></div><ul class="xr-sections"><li class="xr-section-item"><input id="section-8119cec5-da92-49eb-9a37-d020a6739b5d" class="xr-section-summary-in" type="checkbox" disabled=""><label for="section-8119cec5-da92-49eb-9a37-d020a6739b5d" class="xr-section-summary" title="Expand/collapse section">Dimensions:</label><div class="xr-section-inline-details"><ul class="xr-dim-list"><li><span class="xr-has-index">chain</span>: 1</li><li><span class="xr-has-index">draw</span>: 100</li></ul></div><div class="xr-section-details"></div></li><li class="xr-section-item"><input id="section-1662f092-2cda-4a01-89a4-b1823b2ef041" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-1662f092-2cda-4a01-89a4-b1823b2ef041" class="xr-section-summary">Coordinates: <span>(2)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">chain</span></div><div class="xr-var-dims">(chain)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0</div><input id="attrs-c5018f04-4a7c-4b33-a96c-080a40d7ba12" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-c5018f04-4a7c-4b33-a96c-080a40d7ba12" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-b1d825fc-2e3e-49d1-bd6a-832fb0816e72" class="xr-var-data-in" type="checkbox"><label for="data-b1d825fc-2e3e-49d1-bd6a-832fb0816e72" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([0])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">draw</span></div><div class="xr-var-dims">(draw)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0 1 2 3 4 5 6 ... 94 95 96 97 98 99</div><input id="attrs-1465bbb2-8ddc-4e88-be69-a00c3ce498e1" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-1465bbb2-8ddc-4e88-be69-a00c3ce498e1" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-a2bdd32b-f089-47f2-8620-59022ce3d88e" class="xr-var-data-in" type="checkbox"><label for="data-a2bdd32b-f089-47f2-8620-59022ce3d88e" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-e3a2250a-906b-4ac0-bb62-c5ec32008377" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-e3a2250a-906b-4ac0-bb62-c5ec32008377" class="xr-section-summary">Data variables: <span>(3)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span>α</span></div><div class="xr-var-dims">(chain, draw)</div><div class="xr-var-dtype">float64</div><div class="xr-var-preview xr-preview">-123.2 21.44 ... -168.3 30.35</div><input id="attrs-f9f9a6c9-7d8a-409e-9146-8b7f87f7b496" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-f9f9a6c9-7d8a-409e-9146-8b7f87f7b496" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-fef26397-3874-468a-9b4d-c31d39951f13" class="xr-var-data-in" type="checkbox"><label for="data-fef26397-3874-468a-9b4d-c31d39951f13" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([[-123.15654512,   21.44089854, -225.39225936,  -55.18379781,
         -54.91282611, -146.97261748,  -70.36829401,   18.72229119,
          -5.07746909,  108.92761235,    1.51476244,   12.02327497,
        -133.44702941,  113.0618795 ,  -61.07264711, -100.52234018,
         -80.4726031 , -249.92378553,   43.42324316,  265.70252081,
         144.32785031,  -66.93841575,  -53.83466882,   25.23298511,
         -66.20760098,  192.93078873,  -77.28336704, -150.37464651,
          -1.26643435, -201.96092972,   17.35253409,   14.58719489,
         -67.44383708,  149.64992328,   60.67564193,   80.51036313,
          97.38665986,  -60.53454806,   82.97465288,   79.73798601,
         -10.50700563,  -21.00698949,  178.93955055,   54.59926352,
          81.96886937,  190.45066278, -183.78745531,   82.42607318,
        -112.04094134,  174.05726305,   43.10966837,   99.54443371,
          39.45311743,   75.81610786,    7.52944959,   91.7387799 ,
         -39.44332897,   94.0153816 ,   33.69478959,  128.70283735,
          25.80941454,  107.04114027,  -58.32779702, -101.80697951,
         -57.57390012,  -18.56288296,  -19.37981065, -173.48614567,
        -144.64015412,  118.26740827,  -35.46026637,  -41.77276805,
          -8.52504933,  -72.31228954,  -68.32508255,  100.06681632,
        -109.72630481,  325.76276474,  -29.6967429 ,   76.55093835,
         -54.80867334, -144.5876842 ,  -36.4334084 ,   98.601535  ,
         100.88711611,   30.27950558,   80.28777033,   29.8959835 ,
          16.0457536 ,   28.04525057,  -38.76725937,   -0.81232118,
        -161.17817518,  102.04700159, -148.82587243,   52.70887482,
          13.53586924,  -53.02596827, -168.32670368,   30.34812519]])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span>β</span></div><div class="xr-var-dims">(chain, draw)</div><div class="xr-var-dtype">float64</div><div class="xr-var-preview xr-preview">46.55 103.0 19.07 ... 73.03 -255.0</div><input id="attrs-9c10a0cc-761b-44cf-9cd1-b82c5330fcd5" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-9c10a0cc-761b-44cf-9cd1-b82c5330fcd5" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-d7c2bdae-2df2-4c75-82c9-154a1974d85d" class="xr-var-data-in" type="checkbox"><label for="data-d7c2bdae-2df2-4c75-82c9-154a1974d85d" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([[  46.54577716,  103.00952237,   19.06538346,   58.6669498 ,
         -70.32841262,   43.19036973,   -2.96548749,   64.95787827,
          41.72853288,   64.3310516 ,  -31.39580186,   57.33650301,
          88.43987657,   -6.00563173,   19.93496761,   52.91659619,
        -157.34246745,   31.45906773,  147.00800232, -122.43521241,
         145.70157185,   25.81050981,  103.7643737 ,   16.91108382,
          65.17110025,   44.19414489,  138.11537569,  225.11276628,
        -167.49246185,  -47.36823873,  285.27211423,  -54.84147757,
        -121.72803213,   63.61900554,   77.37109032,    2.16963199,
         -21.31171355,  170.20497085,   16.95631279,   75.7637642 ,
        -110.58944543,  -68.75314299,  -59.50878542,   85.80580009,
          -4.33060171,   42.65848457,   29.51427526,   36.26240843,
          10.95564874,  -23.18949293,  102.90032554,  -64.55775387,
          24.9309488 ,  -65.91802562, -160.96934413,  -36.57395047,
         -57.98334997,   39.02562912,  120.51455229, -122.53789059,
          96.21875873,  163.07636658,   92.6278664 ,  -28.78108552,
          62.52731207,   69.75434302,  -65.66080059,   45.88407943,
         -54.12723433,  -11.48614187,  -79.07725876,  -26.66465991,
          87.69662251, -178.56973711,   -7.61753971,   56.61112941,
          -7.41552862, -120.56891824,  218.12951459, -104.78330417,
         194.06584695, -119.95704536,  179.57871506,   -2.39112613,
        -221.01000781,   61.52644325,  -86.46341505,  -27.66120922,
         166.98333876,    6.94043997,  -97.14134075,  -30.94343977,
         -44.3703914 ,   15.07962071,   -4.33520056, -118.07660514,
         -13.46177777, -156.62879128,   73.02748533, -255.02948303]])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span>σ</span></div><div class="xr-var-dims">(chain, draw)</div><div class="xr-var-dtype">float64</div><div class="xr-var-preview xr-preview">7.648 12.21 0.7211 ... 3.182 6.897</div><input id="attrs-a137d8c6-03e8-4ebd-a188-cf1b538aa96a" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-a137d8c6-03e8-4ebd-a188-cf1b538aa96a" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-2cf5bd2b-afb0-47c9-86f1-9942a03a6a6c" class="xr-var-data-in" type="checkbox"><label for="data-2cf5bd2b-afb0-47c9-86f1-9942a03a6a6c" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([[ 7.6482893 , 12.21255144,  0.72111847,  7.83634032,  9.73980526,
         5.81728725,  7.168321  , 10.98142961,  2.65554341,  1.90516887,
         8.12291864,  0.52161356,  4.73880116,  6.4856232 ,  1.47361891,
         0.25360066,  2.75615288,  4.42266368,  0.85511351,  2.35284602,
         5.03795635,  7.2930565 ,  8.56813918,  4.05667194,  2.03816454,
         8.70738791,  2.57010589,  4.45611256,  8.66372128,  2.88649958,
         5.1645769 ,  8.70913914,  2.39337102,  0.48210902,  1.92870335,
         1.37705476,  1.96421991,  4.56115163,  2.51608891,  1.63421971,
         2.37054139,  8.79677888,  4.4234058 ,  3.62126027,  2.94736306,
         4.18750886,  1.76676318,  1.28122265,  7.63483926,  3.82400824,
         1.80196265,  9.3136449 ,  5.30271365,  8.0367355 ,  2.20809841,
        11.20496308,  4.84784534,  1.57979769,  5.79565937,  1.34429007,
         2.06264483,  4.34549597,  7.67840749,  1.54501748,  5.90292849,
         1.96609794,  7.84376649,  2.24373778,  5.62569029,  5.7931091 ,
         9.35388206,  3.05381312,  6.73585966,  2.36409005,  0.8613097 ,
         3.09645147,  1.54571594,  6.69770508,  4.05787763,  6.87814737,
         4.56068007,  0.85990879,  6.63762207,  6.31734068,  4.99601865,
         4.54481182,  3.03410246,  6.25893615,  0.45956313,  1.80887868,
         0.77297443,  1.04552915,  2.2652946 ,  0.77884824,  4.89360674,
         4.58807034,  0.66924474,  0.19365903,  3.1823294 ,  6.89671286]])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-bdd9e265-a298-4c7f-83f8-8b6b3314c2db" class="xr-section-summary-in" type="checkbox"><label for="section-bdd9e265-a298-4c7f-83f8-8b6b3314c2db" class="xr-section-summary">Indexes: <span>(2)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-index-name"><div>chain</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-0567c089-49ad-4927-94b4-3981bb68bc61" class="xr-index-data-in" type="checkbox"><label for="index-0567c089-49ad-4927-94b4-3981bb68bc61" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([0], dtype='int64', name='chain'))</pre></div></li><li class="xr-var-item"><div class="xr-index-name"><div>draw</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-c0be1a49-b801-492e-95ed-db0f9bafec5b" class="xr-index-data-in" type="checkbox"><label for="index-c0be1a49-b801-492e-95ed-db0f9bafec5b" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],
      dtype='int64', name='draw'))</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-dc4da75d-3923-443b-94e9-6bc1b224285f" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-dc4da75d-3923-443b-94e9-6bc1b224285f" class="xr-section-summary">Attributes: <span>(4)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><dl class="xr-attrs"><dt><span>created_at :</span></dt><dd>2024-05-29T16:33:48.453734+00:00</dd><dt><span>arviz_version :</span></dt><dd>0.19.0.dev0</dd><dt><span>inference_library :</span></dt><dd>pymc</dd><dt><span>inference_library_version :</span></dt><dd>5.13.1+16.g0ad689c6a</dd></dl></div></li></ul></div></div><br></div>
                      </ul>
                  </div>
            </li>
            
            <li class="xr-section-item">
                  <input id="idata_prior_predictive48f8f79f-5655-4fea-aaa7-a6f63725d5ec" class="xr-section-summary-in" type="checkbox">
                  <label for="idata_prior_predictive48f8f79f-5655-4fea-aaa7-a6f63725d5ec" class="xr-section-summary">prior_predictive</label>
                  <div class="xr-section-inline-details"></div>
                  <div class="xr-section-details">
                      <ul id="xr-dataset-coord-list" class="xr-var-list">
                          <div style="padding-left:2rem;"><div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewbox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewbox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body[data-theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-index-preview {
  grid-column: 2 / 5;
  color: var(--xr-font-color2);
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data,
.xr-index-data-in:checked ~ .xr-index-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-index-name div,
.xr-index-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2,
.xr-no-icon {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class="xr-text-repr-fallback">&lt;xarray.Dataset&gt;
Dimensions:      (chain: 1, draw: 100, presa_dim_0: 13085)
Coordinates:
  * chain        (chain) int64 0
  * draw         (draw) int64 0 1 2 3 4 5 6 7 8 9 ... 91 92 93 94 95 96 97 98 99
  * presa_dim_0  (presa_dim_0) int64 0 1 2 3 4 ... 13080 13081 13082 13083 13084
Data variables:
    presa        (chain, draw, presa_dim_0) float64 -554.6 -13.9 ... -757.0
Attributes:
    created_at:                 2024-05-29T16:33:48.455627+00:00
    arviz_version:              0.19.0.dev0
    inference_library:          pymc
    inference_library_version:  5.13.1+16.g0ad689c6a</pre><div class="xr-wrap" style="display:none"><div class="xr-header"><div class="xr-obj-type">xarray.Dataset</div></div><ul class="xr-sections"><li class="xr-section-item"><input id="section-e80e8517-8a62-49b0-8e7d-e60df0adfd25" class="xr-section-summary-in" type="checkbox" disabled=""><label for="section-e80e8517-8a62-49b0-8e7d-e60df0adfd25" class="xr-section-summary" title="Expand/collapse section">Dimensions:</label><div class="xr-section-inline-details"><ul class="xr-dim-list"><li><span class="xr-has-index">chain</span>: 1</li><li><span class="xr-has-index">draw</span>: 100</li><li><span class="xr-has-index">presa_dim_0</span>: 13085</li></ul></div><div class="xr-section-details"></div></li><li class="xr-section-item"><input id="section-e75f43ec-3fb4-40e0-ac95-acfdc795ba28" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-e75f43ec-3fb4-40e0-ac95-acfdc795ba28" class="xr-section-summary">Coordinates: <span>(3)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">chain</span></div><div class="xr-var-dims">(chain)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0</div><input id="attrs-386dd7d3-10f0-4c20-bfa5-c6f8b2efce11" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-386dd7d3-10f0-4c20-bfa5-c6f8b2efce11" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-ff8f0efb-88b6-4eb5-ab84-aba361c53e3e" class="xr-var-data-in" type="checkbox"><label for="data-ff8f0efb-88b6-4eb5-ab84-aba361c53e3e" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([0])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">draw</span></div><div class="xr-var-dims">(draw)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0 1 2 3 4 5 6 ... 94 95 96 97 98 99</div><input id="attrs-fa694eeb-9b64-430c-89d3-aa4594ec0c93" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-fa694eeb-9b64-430c-89d3-aa4594ec0c93" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-103ce27c-696f-4ad0-8f8b-8f79fc39e970" class="xr-var-data-in" type="checkbox"><label for="data-103ce27c-696f-4ad0-8f8b-8f79fc39e970" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
       90, 91, 92, 93, 94, 95, 96, 97, 98, 99])</pre></div></li><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">presa_dim_0</span></div><div class="xr-var-dims">(presa_dim_0)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0 1 2 3 ... 13081 13082 13083 13084</div><input id="attrs-f70b4274-98fa-47ca-8f53-d63e998f58e3" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-f70b4274-98fa-47ca-8f53-d63e998f58e3" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-4f217f86-4bd4-4f62-adf9-5668ec20559d" class="xr-var-data-in" type="checkbox"><label for="data-4f217f86-4bd4-4f62-adf9-5668ec20559d" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([    0,     1,     2, ..., 13082, 13083, 13084])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-ecf3bf92-81bb-4252-80a4-1b7263bf8014" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-ecf3bf92-81bb-4252-80a4-1b7263bf8014" class="xr-section-summary">Data variables: <span>(1)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span>presa</span></div><div class="xr-var-dims">(chain, draw, presa_dim_0)</div><div class="xr-var-dtype">float64</div><div class="xr-var-preview xr-preview">-554.6 -13.9 ... -899.8 -757.0</div><input id="attrs-ce499647-cf15-47bd-b322-8d138c8d0308" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-ce499647-cf15-47bd-b322-8d138c8d0308" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-15e50c64-4f7c-477e-93b3-4c60a7ee0078" class="xr-var-data-in" type="checkbox"><label for="data-15e50c64-4f7c-477e-93b3-4c60a7ee0078" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([[[-5.54630702e+02, -1.38978784e+01, -5.52719702e+02, ...,
         -2.51143249e+01,  4.92035931e+01,  1.06103678e+01],
        [-8.97074397e+02,  2.43654358e+02, -9.11364387e+02, ...,
          2.22040396e+02,  4.04188048e+02,  3.45346612e+02],
        [-4.02040729e+02, -1.80677233e+02, -4.01619739e+02, ...,
         -1.89308831e+02, -1.54891978e+02, -1.68020701e+02],
        ...,
        [ 1.38983308e+03, -4.13374027e+02,  1.38955219e+03, ...,
         -3.57948298e+02, -6.24060705e+02, -5.34265566e+02],
        [-8.43626026e+02, -2.34210786e+00, -8.35684170e+02, ...,
         -2.75020553e+01,  9.11354616e+01,  5.63484290e+01],
        [ 2.38366480e+03, -5.71478058e+02,  2.37672188e+03, ...,
         -4.72643569e+02, -8.99840308e+02, -7.57007844e+02]]])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-21dcc5ff-c121-4882-9487-6a9917362631" class="xr-section-summary-in" type="checkbox"><label for="section-21dcc5ff-c121-4882-9487-6a9917362631" class="xr-section-summary">Indexes: <span>(3)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-index-name"><div>chain</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-cbc38a1e-9f17-4840-819e-94fc6fa4e7b2" class="xr-index-data-in" type="checkbox"><label for="index-cbc38a1e-9f17-4840-819e-94fc6fa4e7b2" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([0], dtype='int64', name='chain'))</pre></div></li><li class="xr-var-item"><div class="xr-index-name"><div>draw</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-c09217ff-6425-4665-83cd-b2408a039332" class="xr-index-data-in" type="checkbox"><label for="index-c09217ff-6425-4665-83cd-b2408a039332" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
       72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
       90, 91, 92, 93, 94, 95, 96, 97, 98, 99],
      dtype='int64', name='draw'))</pre></div></li><li class="xr-var-item"><div class="xr-index-name"><div>presa_dim_0</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-16b51f32-4843-4a8e-b7f0-ae41772111c5" class="xr-index-data-in" type="checkbox"><label for="index-16b51f32-4843-4a8e-b7f0-ae41772111c5" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,
       ...
       13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084],
      dtype='int64', name='presa_dim_0', length=13085))</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-943580ff-d7f2-4286-a761-dcafcaf19369" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-943580ff-d7f2-4286-a761-dcafcaf19369" class="xr-section-summary">Attributes: <span>(4)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><dl class="xr-attrs"><dt><span>created_at :</span></dt><dd>2024-05-29T16:33:48.455627+00:00</dd><dt><span>arviz_version :</span></dt><dd>0.19.0.dev0</dd><dt><span>inference_library :</span></dt><dd>pymc</dd><dt><span>inference_library_version :</span></dt><dd>5.13.1+16.g0ad689c6a</dd></dl></div></li></ul></div></div><br></div>
                      </ul>
                  </div>
            </li>
            
            <li class="xr-section-item">
                  <input id="idata_observed_datae75063c8-4652-4e8c-bccf-694a9472a19f" class="xr-section-summary-in" type="checkbox">
                  <label for="idata_observed_datae75063c8-4652-4e8c-bccf-694a9472a19f" class="xr-section-summary">observed_data</label>
                  <div class="xr-section-inline-details"></div>
                  <div class="xr-section-details">
                      <ul id="xr-dataset-coord-list" class="xr-var-list">
                          <div style="padding-left:2rem;"><div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
<defs>
<symbol id="icon-database" viewbox="0 0 32 32">
<path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
<path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
<path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
</symbol>
<symbol id="icon-file-text2" viewbox="0 0 32 32">
<path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
<path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
<path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
</symbol>
</defs>
</svg>
<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body[data-theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block !important;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-index-preview {
  grid-column: 2 / 5;
  color: var(--xr-font-color2);
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data,
.xr-index-data-in:checked ~ .xr-index-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-index-name div,
.xr-index-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data,
.xr-index-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2,
.xr-no-icon {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
</style><pre class="xr-text-repr-fallback">&lt;xarray.Dataset&gt;
Dimensions:      (presa_dim_0: 13085)
Coordinates:
  * presa_dim_0  (presa_dim_0) int64 0 1 2 3 4 ... 13080 13081 13082 13083 13084
Data variables:
    presa        (presa_dim_0) float64 -18.42 2.303 -9.21 ... 5.369 6.544 6.044
Attributes:
    created_at:                 2024-05-29T16:33:48.456463+00:00
    arviz_version:              0.19.0.dev0
    inference_library:          pymc
    inference_library_version:  5.13.1+16.g0ad689c6a</pre><div class="xr-wrap" style="display:none"><div class="xr-header"><div class="xr-obj-type">xarray.Dataset</div></div><ul class="xr-sections"><li class="xr-section-item"><input id="section-cb1ed7ca-f0be-46d6-aa67-bbc504962cb0" class="xr-section-summary-in" type="checkbox" disabled=""><label for="section-cb1ed7ca-f0be-46d6-aa67-bbc504962cb0" class="xr-section-summary" title="Expand/collapse section">Dimensions:</label><div class="xr-section-inline-details"><ul class="xr-dim-list"><li><span class="xr-has-index">presa_dim_0</span>: 13085</li></ul></div><div class="xr-section-details"></div></li><li class="xr-section-item"><input id="section-01ef9c6b-1ec0-45c2-8638-d1d86ad713d4" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-01ef9c6b-1ec0-45c2-8638-d1d86ad713d4" class="xr-section-summary">Coordinates: <span>(1)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span class="xr-has-index">presa_dim_0</span></div><div class="xr-var-dims">(presa_dim_0)</div><div class="xr-var-dtype">int64</div><div class="xr-var-preview xr-preview">0 1 2 3 ... 13081 13082 13083 13084</div><input id="attrs-940e6606-6f7d-4277-b4b2-b6d6f4673611" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-940e6606-6f7d-4277-b4b2-b6d6f4673611" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-a9b4d2e6-91a2-48d6-b25f-4194901c6b3e" class="xr-var-data-in" type="checkbox"><label for="data-a9b4d2e6-91a2-48d6-b25f-4194901c6b3e" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([    0,     1,     2, ..., 13082, 13083, 13084])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-bbfaca53-af73-4d53-b0e9-02dc9580ad46" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-bbfaca53-af73-4d53-b0e9-02dc9580ad46" class="xr-section-summary">Data variables: <span>(1)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-var-name"><span>presa</span></div><div class="xr-var-dims">(presa_dim_0)</div><div class="xr-var-dtype">float64</div><div class="xr-var-preview xr-preview">-18.42 2.303 -9.21 ... 6.544 6.044</div><input id="attrs-179d4a69-b335-4871-95b5-df5ebd7cd4fc" class="xr-var-attrs-in" type="checkbox" disabled=""><label for="attrs-179d4a69-b335-4871-95b5-df5ebd7cd4fc" title="Show/Hide attributes"><svg class="icon xr-icon-file-text2"><use href="#icon-file-text2"></use></svg></label><input id="data-81259fbc-0e43-4df7-8816-96ed796aab3f" class="xr-var-data-in" type="checkbox"><label for="data-81259fbc-0e43-4df7-8816-96ed796aab3f" title="Show/Hide data repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-var-attrs"><dl class="xr-attrs"></dl></div><div class="xr-var-data"><pre>array([-18.42068074,   2.30258509,  -9.21034037, ...,   5.36933899,
         6.54377083,   6.04402043])</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-6973cb4d-b8ee-4685-b024-337b06cd7f1f" class="xr-section-summary-in" type="checkbox"><label for="section-6973cb4d-b8ee-4685-b024-337b06cd7f1f" class="xr-section-summary">Indexes: <span>(1)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><ul class="xr-var-list"><li class="xr-var-item"><div class="xr-index-name"><div>presa_dim_0</div></div><div class="xr-index-preview">PandasIndex</div><div></div><input id="index-6a7b30db-86e4-4de3-a485-a86d971df4f3" class="xr-index-data-in" type="checkbox"><label for="index-6a7b30db-86e4-4de3-a485-a86d971df4f3" title="Show/Hide index repr"><svg class="icon xr-icon-database"><use href="#icon-database"></use></svg></label><div class="xr-index-data"><pre>PandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,
       ...
       13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084],
      dtype='int64', name='presa_dim_0', length=13085))</pre></div></li></ul></div></li><li class="xr-section-item"><input id="section-a25f9338-67ab-4ba4-a29c-9dc692e913ab" class="xr-section-summary-in" type="checkbox" checked=""><label for="section-a25f9338-67ab-4ba4-a29c-9dc692e913ab" class="xr-section-summary">Attributes: <span>(4)</span></label><div class="xr-section-inline-details"></div><div class="xr-section-details"><dl class="xr-attrs"><dt><span>created_at :</span></dt><dd>2024-05-29T16:33:48.456463+00:00</dd><dt><span>arviz_version :</span></dt><dd>0.19.0.dev0</dd><dt><span>inference_library :</span></dt><dd>pymc</dd><dt><span>inference_library_version :</span></dt><dd>5.13.1+16.g0ad689c6a</dd></dl></div></li></ul></div></div><br></div>
                      </ul>
                  </div>
            </li>
            
              </ul>
            </div>
            <style> /* CSS stylesheet for displaying InferenceData objects in jupyterlab.
 *
 */

:root {
  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
  --xr-border-color: var(--jp-border-color2, #e0e0e0);
  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
  --xr-background-color: var(--jp-layout-color0, white);
  --xr-background-color-row-even: var(--jp-layout-color1, white);
  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
}

html[theme=dark],
body.vscode-dark {
  --xr-font-color0: rgba(255, 255, 255, 1);
  --xr-font-color2: rgba(255, 255, 255, 0.54);
  --xr-font-color3: rgba(255, 255, 255, 0.38);
  --xr-border-color: #1F1F1F;
  --xr-disabled-color: #515151;
  --xr-background-color: #111111;
  --xr-background-color-row-even: #111111;
  --xr-background-color-row-odd: #313131;
}

.xr-wrap {
  display: block;
  min-width: 300px;
  max-width: 700px;
}

.xr-text-repr-fallback {
  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
  display: none;
}

.xr-header {
  padding-top: 6px;
  padding-bottom: 6px;
  margin-bottom: 4px;
  border-bottom: solid 1px var(--xr-border-color);
}

.xr-header > div,
.xr-header > ul {
  display: inline;
  margin-top: 0;
  margin-bottom: 0;
}

.xr-obj-type,
.xr-array-name {
  margin-left: 2px;
  margin-right: 10px;
}

.xr-obj-type {
  color: var(--xr-font-color2);
}

.xr-sections {
  padding-left: 0 !important;
  display: grid;
  grid-template-columns: 150px auto auto 1fr 20px 20px;
}

.xr-sections.group-sections {
  grid-template-columns: auto;
}

.xr-section-item {
  display: contents;
}

.xr-section-item input {
  display: none;
}

.xr-section-item input + label {
  color: var(--xr-disabled-color);
}

.xr-section-item input:enabled + label {
  cursor: pointer;
  color: var(--xr-font-color2);
}

.xr-section-item input:enabled + label:hover {
  color: var(--xr-font-color0);
}

.xr-section-summary {
  grid-column: 1;
  color: var(--xr-font-color2);
  font-weight: 500;
}

.xr-section-summary > span {
  display: inline-block;
  padding-left: 0.5em;
}

.xr-section-summary-in:disabled + label {
  color: var(--xr-font-color2);
}

.xr-section-summary-in + label:before {
  display: inline-block;
  content: '►';
  font-size: 11px;
  width: 15px;
  text-align: center;
}

.xr-section-summary-in:disabled + label:before {
  color: var(--xr-disabled-color);
}

.xr-section-summary-in:checked + label:before {
  content: '▼';
}

.xr-section-summary-in:checked + label > span {
  display: none;
}

.xr-section-summary,
.xr-section-inline-details {
  padding-top: 4px;
  padding-bottom: 4px;
}

.xr-section-inline-details {
  grid-column: 2 / -1;
}

.xr-section-details {
  display: none;
  grid-column: 1 / -1;
  margin-bottom: 5px;
}

.xr-section-summary-in:checked ~ .xr-section-details {
  display: contents;
}

.xr-array-wrap {
  grid-column: 1 / -1;
  display: grid;
  grid-template-columns: 20px auto;
}

.xr-array-wrap > label {
  grid-column: 1;
  vertical-align: top;
}

.xr-preview {
  color: var(--xr-font-color3);
}

.xr-array-preview,
.xr-array-data {
  padding: 0 5px !important;
  grid-column: 2;
}

.xr-array-data,
.xr-array-in:checked ~ .xr-array-preview {
  display: none;
}

.xr-array-in:checked ~ .xr-array-data,
.xr-array-preview {
  display: inline-block;
}

.xr-dim-list {
  display: inline-block !important;
  list-style: none;
  padding: 0 !important;
  margin: 0;
}

.xr-dim-list li {
  display: inline-block;
  padding: 0;
  margin: 0;
}

.xr-dim-list:before {
  content: '(';
}

.xr-dim-list:after {
  content: ')';
}

.xr-dim-list li:not(:last-child):after {
  content: ',';
  padding-right: 5px;
}

.xr-has-index {
  font-weight: bold;
}

.xr-var-list,
.xr-var-item {
  display: contents;
}

.xr-var-item > div,
.xr-var-item label,
.xr-var-item > .xr-var-name span {
  background-color: var(--xr-background-color-row-even);
  margin-bottom: 0;
}

.xr-var-item > .xr-var-name:hover span {
  padding-right: 5px;
}

.xr-var-list > li:nth-child(odd) > div,
.xr-var-list > li:nth-child(odd) > label,
.xr-var-list > li:nth-child(odd) > .xr-var-name span {
  background-color: var(--xr-background-color-row-odd);
}

.xr-var-name {
  grid-column: 1;
}

.xr-var-dims {
  grid-column: 2;
}

.xr-var-dtype {
  grid-column: 3;
  text-align: right;
  color: var(--xr-font-color2);
}

.xr-var-preview {
  grid-column: 4;
}

.xr-var-name,
.xr-var-dims,
.xr-var-dtype,
.xr-preview,
.xr-attrs dt {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  padding-right: 10px;
}

.xr-var-name:hover,
.xr-var-dims:hover,
.xr-var-dtype:hover,
.xr-attrs dt:hover {
  overflow: visible;
  width: auto;
  z-index: 1;
}

.xr-var-attrs,
.xr-var-data {
  display: none;
  background-color: var(--xr-background-color) !important;
  padding-bottom: 5px !important;
}

.xr-var-attrs-in:checked ~ .xr-var-attrs,
.xr-var-data-in:checked ~ .xr-var-data {
  display: block;
}

.xr-var-data > table {
  float: right;
}

.xr-var-name span,
.xr-var-data,
.xr-attrs {
  padding-left: 25px !important;
}

.xr-attrs,
.xr-var-attrs,
.xr-var-data {
  grid-column: 1 / -1;
}

dl.xr-attrs {
  padding: 0;
  margin: 0;
  display: grid;
  grid-template-columns: 125px auto;
}

.xr-attrs dt,
.xr-attrs dd {
  padding: 0;
  margin: 0;
  float: left;
  padding-right: 10px;
  width: auto;
}

.xr-attrs dt {
  font-weight: normal;
  grid-column: 1;
}

.xr-attrs dt:hover span {
  display: inline-block;
  background: var(--xr-background-color);
  padding-right: 10px;
}

.xr-attrs dd {
  grid-column: 2;
  white-space: pre-wrap;
  word-break: break-all;
}

.xr-icon-database,
.xr-icon-file-text2 {
  display: inline-block;
  vertical-align: middle;
  width: 1em;
  height: 1.5em !important;
  stroke-width: 0;
  stroke: currentColor;
  fill: currentColor;
}
.xr-wrap{width:700px!important;} </style>
</div>
</div>
<p>Nuestro modelo tiene priors tan vagos que todos los valores que ni siquiera podemos distinguir nuestro valores de referencia.</p>
<div id="48745c60" class="cell" data-hide_input="true" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>ax <span class="op">=</span> az.plot_ppc(idata, group<span class="op">=</span><span class="st">"prior"</span>, kind<span class="op">=</span><span class="st">"cumulative"</span>, mean<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="cf">for</span> key, val <span class="kw">in</span> refs.items():</span>
<span id="cb6-4"><a href="#cb6-4"></a>    ax.axvline(val, ls<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"0.5"</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a>    ax.text(val<span class="op">-</span><span class="dv">7</span>, <span class="fl">0.5</span><span class="op">-</span>(<span class="bu">len</span>(key)<span class="op">/</span><span class="dv">100</span>), key, rotation<span class="op">=</span><span class="dv">90</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6acb4ede" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb7-2"><a href="#cb7-2"></a>    α <span class="op">=</span> pm.Normal(<span class="st">"α"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a>    β <span class="op">=</span> pm.Normal(<span class="st">"β"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">5</span>)</span>
<span id="cb7-5"><a href="#cb7-5"></a>    presa <span class="op">=</span> pm.Normal(<span class="st">"presa"</span>, α <span class="op">+</span> β <span class="op">*</span> pp_mass[<span class="st">"prey_log"</span>], σ, observed<span class="op">=</span>pp_mass[<span class="st">"predator_log"</span>])</span>
<span id="cb7-6"><a href="#cb7-6"></a>    idata <span class="op">=</span> pm.sample_prior_predictive(samples<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [presa, α, β, σ]</code></pre>
</div>
</div>
<p>Con estos nuevos priors todavía tenemos algunos valores sin sentido, pero al menos la mayor parte de la masa de nuestras predicciones está dentro de rangos razonables.</p>
<div id="a3c1dc70" class="cell" data-hide_input="true" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>ax <span class="op">=</span> az.plot_ppc(idata, group<span class="op">=</span><span class="st">"prior"</span>, kind<span class="op">=</span><span class="st">"cumulative"</span>, mean<span class="op">=</span><span class="va">False</span>, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="cf">for</span> key, val <span class="kw">in</span> refs.items():</span>
<span id="cb9-4"><a href="#cb9-4"></a>    ax.axvline(val, ls<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"0.5"</span>)</span>
<span id="cb9-5"><a href="#cb9-5"></a>    ax.text(val<span class="op">-</span><span class="dv">7</span>, <span class="fl">0.5</span><span class="op">-</span>(<span class="bu">len</span>(key)<span class="op">/</span><span class="dv">100</span>), key, rotation<span class="op">=</span><span class="dv">90</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>PreliZ nos permite hacer algo similar pero de forma interactiva</p>
<div id="ddb9a35a" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> pp_model(α_μ<span class="op">=</span><span class="dv">0</span>, α_σ<span class="op">=</span><span class="dv">100</span>, β_μ<span class="op">=</span><span class="dv">0</span>, β_σ<span class="op">=</span><span class="dv">100</span>, σ_σ<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb10-2"><a href="#cb10-2"></a>    α <span class="op">=</span> pz.Normal(α_μ, α_σ).rvs()</span>
<span id="cb10-3"><a href="#cb10-3"></a>    β <span class="op">=</span> pz.Normal(β_μ, β_σ).rvs()</span>
<span id="cb10-4"><a href="#cb10-4"></a>    σ <span class="op">=</span> pz.HalfNormal(σ_σ).rvs()</span>
<span id="cb10-5"><a href="#cb10-5"></a>    prey <span class="op">=</span> pz.Normal(α <span class="op">+</span> β <span class="op">*</span> pp_mass.predator_log, σ).rvs()</span>
<span id="cb10-6"><a href="#cb10-6"></a>    <span class="cf">return</span> prey</span>
<span id="cb10-7"><a href="#cb10-7"></a></span>
<span id="cb10-8"><a href="#cb10-8"></a>refs <span class="op">=</span> {<span class="st">"Earth"</span>:np.log(<span class="fl">5.97e+27</span>), <span class="st">"Blue whale"</span>:np.log(<span class="fl">1.5e8</span>), <span class="st">"Smallest cell"</span>:np.log(<span class="fl">1e-14</span>)}</span>
<span id="cb10-9"><a href="#cb10-9"></a>pz.predictive_explorer(pp_model, references<span class="op">=</span>refs)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c61ede27f17f415fb2f93ec284bf1d25","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
</section>
<section id="pruebas-predictivas-a-posteriori" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="pruebas-predictivas-a-posteriori"><span class="header-section-number">4.4</span> Pruebas predictivas a posteriori</h2>
<p>Se define como</p>
<p><span class="math display">\[
p(\tilde{y}  \mid  y) = \int p(\tilde{y} \mid \theta) p(\theta \mid y) d\theta
\]</span></p>
<p>donde <span class="math inline">\(\tilde{y}\)</span> representa los datos generados por un modelo una vez obtenido el <em>a posteriori</em>. Es decir, las predicciones del modelo. Es similar a la distribución predictiva a priori, pero esta vez integramos sobre los valores <em>a posteriori</em> de <span class="math inline">\(\theta\)</span></p>
<p>Computacionalmente podemos generar muestras de esta distribución según el siguiente procedimiento:</p>
<ol type="1">
<li>Elegimos un valor de <span class="math inline">\(\theta\)</span> de acuerdo a la distribución a posteriori <span class="math inline">\(p(\theta \mid y)\)</span></li>
<li>Fijamos <span class="math inline">\(\theta\)</span> en la distribución que usamos como likelihood <span class="math inline">\(p(\tilde{y} \mid \theta)\)</span> y generamos una muestra aleatoria</li>
<li>Repetimos desde 1, tantas veces como muestras necesitemos</li>
</ol>
<p>Las pruebas predictivas a posteriori son usadas de forma muy extendida para evaluar un modelo. En este caso SI es común compara contra los datos observados. Al comparar con los datos que se usaran para ajustar el modelo este tipo de pruebas son una forma de evaluación de la consistencia interna de un modelo. Es decir, de mínima esperamos que un modelo sea capaz de reproducir los datos usados para ajustarlo.</p>
<div id="36804b60" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>accidentes <span class="op">=</span> pd.Series([<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">6</span>,</span>
<span id="cb11-2"><a href="#cb11-2"></a>                       <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">5</span>,</span>
<span id="cb11-3"><a href="#cb11-3"></a>                       <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>,</span>
<span id="cb11-4"><a href="#cb11-4"></a>                       <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>,</span>
<span id="cb11-5"><a href="#cb11-5"></a>                       <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>,</span>
<span id="cb11-6"><a href="#cb11-6"></a>                       <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">4</span>,</span>
<span id="cb11-7"><a href="#cb11-7"></a>                       <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb11-8"><a href="#cb11-8"></a>años <span class="op">=</span> np.arange(<span class="dv">1851</span>, <span class="dv">1962</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9e07a627" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_cat:</span>
<span id="cb12-2"><a href="#cb12-2"></a>    pc <span class="op">=</span> pm.DiscreteUniform(<span class="st">"pc"</span>, lower<span class="op">=</span>años.<span class="bu">min</span>(), upper<span class="op">=</span>años.<span class="bu">max</span>())</span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a>    t_0 <span class="op">=</span> pm.Exponential(<span class="st">"t_0"</span>, <span class="dv">1</span>)</span>
<span id="cb12-5"><a href="#cb12-5"></a>    t_1 <span class="op">=</span> pm.Exponential(<span class="st">"t_1"</span>, <span class="dv">1</span>)</span>
<span id="cb12-6"><a href="#cb12-6"></a></span>
<span id="cb12-7"><a href="#cb12-7"></a>    tasa <span class="op">=</span> pm.Deterministic(<span class="st">"tasa"</span>, pm.math.switch(pc <span class="op">&gt;=</span> años, t_0, t_1))</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a>    acc <span class="op">=</span> pm.Poisson(<span class="st">"acc"</span>, tasa, observed<span class="op">=</span>accidentes)</span>
<span id="cb12-10"><a href="#cb12-10"></a>    idata_cat <span class="op">=</span> pm.sample(<span class="dv">1000</span>, random_seed<span class="op">=</span><span class="dv">1791</span>, progressbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb12-11"><a href="#cb12-11"></a>    idata_cat.extend(pm.sample_posterior_predictive(idata_cat, progressbar<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Metropolis: [pc]
&gt;NUTS: [t_0, t_1]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.
The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details
Sampling: [acc]</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="5c2ce3ab" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>ax <span class="op">=</span> az.plot_ppc(idata_cat, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>), num_pp_samples<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb14-2"><a href="#cb14-2"></a>ax.set_xlabel(<span class="st">"acc"</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="valores-p-bayesianos" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="valores-p-bayesianos"><span class="header-section-number">4.5</span> Valores p Bayesianos</h2>
<p>Un valor-p Bayesiano se define como:</p>
<p><span class="math display">\[
\text{valor-p Bayesiano} \triangleq p(T_{\text{sim}} \le T_{\text{obs}} \mid \tilde y)
\]</span></p>
<p>Donde <span class="math inline">\(T\)</span> es un estadístico sumario como la media, mediana, desviación estándar o lo que se desee comparar, que se calcula para los datos observados <span class="math inline">\(T_{\text{obs}}\)</span> y para los datos simulados <span class="math inline">\(T_{\text{sim}}\)</span>.</p>
<p>Si los valores observados coinciden con los predichos, el valor esperado será 0,5. Es decir, la mitad de las predicciones estarán por debajo de las observaciones y la otra mitad por encima.</p>
<blockquote class="blockquote">
<p>Para aquellos que están familiarizados con los valores p y su uso en estadística frecuentista, hay un par de aclaraciones. Lo que hay de Bayesiano en estos valores p es que NO estamos utilizando una distribución muestral sino la distribución predictiva posterior. Además, no estamos haciendo una prueba de hipótesis nula ni tratando de declarar que una diferencia es “significativa”.</p>
</blockquote>
<div id="18d54841" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>))</span>
<span id="cb15-2"><a href="#cb15-2"></a></span>
<span id="cb15-3"><a href="#cb15-3"></a><span class="kw">def</span> iqr(x, a<span class="op">=-</span><span class="dv">1</span>):</span>
<span id="cb15-4"><a href="#cb15-4"></a>    <span class="co">"""interquartile range"""</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>    <span class="cf">return</span> np.subtract(<span class="op">*</span>np.percentile(x, [<span class="dv">75</span>, <span class="dv">25</span>], axis<span class="op">=</span>a))</span>
<span id="cb15-6"><a href="#cb15-6"></a></span>
<span id="cb15-7"><a href="#cb15-7"></a>az.plot_bpv(idata_cat, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span><span class="st">"mean"</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb15-8"><a href="#cb15-8"></a>az.plot_bpv(idata_cat, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span><span class="st">"median"</span>, ax<span class="op">=</span>ax[<span class="dv">1</span>])</span>
<span id="cb15-9"><a href="#cb15-9"></a>az.plot_bpv(idata_cat, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span>iqr, ax<span class="op">=</span>ax[<span class="dv">2</span>])</span>
<span id="cb15-10"><a href="#cb15-10"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"media"</span>)</span>
<span id="cb15-11"><a href="#cb15-11"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"mediana"</span>)</span>
<span id="cb15-12"><a href="#cb15-12"></a>ax[<span class="dv">2</span>].set_title(<span class="st">"Rango inter-cuartil"</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Un caso especial se da al comparar si los valores simulados son menores que los observados, es decir</p>
<p><span class="math display">\[
p(\tilde y \le y_{\text{obs}} \mid y)
\]</span></p>
<div id="06c0855c" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>az.plot_bpv(idata_cat, kind<span class="op">=</span><span class="st">"p_value"</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Otra posibilidad es realizar la comparación por observación.</p>
<p><span class="math display">\[
p(\tilde y_i \le y_i \mid y)
\]</span></p>
<p>Esto se suele llamar valor-p marginal y la distribución ideal es uniforme estándar.</p>
<p>La linea blanca en la siguiente figura representa el valor ideal y la banda gris la desviación esperada dado el tamaño de los datos. Los valores de x se pueden interpretar como cuantiles, es decir los valores centrales representan el “seno” de la distribución y los valores extremos las “colas”.</p>
<div id="bfde72d7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>az.plot_bpv(idata_cat)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Por qué esperamos una distribución uniforme? Debido a una propiedad llamada transformada integral de probabilidad (PIT por su sigla en inglés). También llamada a veces universalidad de la uniforme.</p>
<p>Dada una variable aleatoria continua <span class="math inline">\(X\)</span> y CDF <span class="math inline">\(F_X\)</span> podemos computar una variable aleatoria <span class="math inline">\(Y\)</span> con distribución uniforme estándar haciendo.</p>
<p><span class="math display">\[
Y = F_X (X)
\]</span></p>
<p>Es decir si tomamos una variable aleatoria <span class="math inline">\(X\)</span> y le aplicamos su propia CDF, la transformamos en <span class="math inline">\(Y \sim \mathcal{U}[0, 1]\)</span>. Empíricamente podemos ver esto haciendo:</p>
<div id="3ba88989" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>dist <span class="op">=</span> pz.Normal(<span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Probar con otras distribuciones</span></span>
<span id="cb18-2"><a href="#cb18-2"></a>plt.hist(dist.cdf(dist.rvs(<span class="dv">1000</span>)), bins<span class="op">=</span><span class="st">"auto"</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Si desconocemos <span class="math inline">\(F_X\)</span>, pero contamos con muestras de <span class="math inline">\(X\)</span>, podemos usar la CDF empírica que es lo que estamos haciendo al calcular el valor-p marginal.</p>
<div id="4e8865d4" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>dist <span class="op">=</span> pz.Normal(<span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Probar con otras distribuciones</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>pred_f <span class="op">=</span> np.exp(dist.rvs(<span class="dv">1000</span>))<span class="op">**</span><span class="fl">0.3</span></span>
<span id="cb19-3"><a href="#cb19-3"></a>obs_f <span class="op">=</span> np.exp(dist.rvs(<span class="dv">1000</span>))<span class="op">**</span><span class="fl">0.3</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="41fb5ecc" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>pit <span class="op">=</span> []</span>
<span id="cb20-2"><a href="#cb20-2"></a><span class="cf">for</span> m <span class="kw">in</span> obs_f:</span>
<span id="cb20-3"><a href="#cb20-3"></a>    pit.append(np.mean(pred_f <span class="op">&lt;=</span> m))</span>
<span id="cb20-4"><a href="#cb20-4"></a>    </span>
<span id="cb20-5"><a href="#cb20-5"></a>plt.hist(pit)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comparación-de-modelos" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="comparación-de-modelos"><span class="header-section-number">4.6</span> Comparación de modelos</h2>
<section id="el-equilibro-entre-simplicidad-y-exactitud" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="el-equilibro-entre-simplicidad-y-exactitud"><span class="header-section-number">4.6.1</span> El equilibro entre simplicidad y exactitud</h3>
<p>Al elegir entre explicaciones alternativas, existe un principio conocido como la navaja de Occam. En lineas muy generales este principio establece que dadas dos o más explicaciones equivalentes para el mismo fenómeno, la más simple es la explicación preferida. Un criterio común de simplicidad es la cantidad de parámetros de un modelo.</p>
<p>Otro factor que generalmente debemos tener en cuenta al comparar modelos es su exactitud, es decir, qué tan bueno es un modelo ajustando los datos. Según este criterio si tenemos dos (o más) modelos y uno de ellos explica los datos mejor que el otro, entonces ese es el modelo preferido.</p>
<p>Intuitivamente, parece que al comparar modelos, tendemos a preferir aquellos que mejor ajusten los datos y aquellos que sean más simples. ¿Pero que hacer si estos dos principios se contraponen? O de forma más general, ¿Existe una forma cuantitativa de contemplar ambas contribuciones? La respuesta corta es que si. De hecho hay más de una forma de hacerlo. Pero antes veamos un ejemplo a fin de generar mayor intuición.</p>
</section>
<section id="muchos-parámetros-pueden-conducir-a-sobreajuste" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="muchos-parámetros-pueden-conducir-a-sobreajuste"><span class="header-section-number">4.6.2</span> Muchos parámetros (pueden) conducir a sobreajuste</h3>
<p>Vamos a comenzar por combinar polinomios cada vez más complejos en un conjunto de datos muy simple. En lugar de utilizar la maquinaria Bayesiana, usaremos la aproximación de mínimos cuadrados para ajustar modelos lineales.</p>
<div id="91e53424" class="cell" data-hide_input="false" data-execution_count="18">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb21-2"><a href="#cb21-2"></a></span>
<span id="cb21-3"><a href="#cb21-3"></a></span>
<span id="cb21-4"><a href="#cb21-4"></a>x0 <span class="op">=</span> np.array([<span class="fl">4.</span>, <span class="fl">5.</span>, <span class="fl">6.</span>, <span class="fl">9.</span>, <span class="dv">12</span>, <span class="fl">14.</span>])</span>
<span id="cb21-5"><a href="#cb21-5"></a>y0 <span class="op">=</span> np.array([<span class="fl">4.2</span>, <span class="fl">6.1</span>, <span class="fl">5.</span>, <span class="fl">10.</span>, <span class="dv">10</span>, <span class="fl">14.</span>])</span>
<span id="cb21-6"><a href="#cb21-6"></a></span>
<span id="cb21-7"><a href="#cb21-7"></a>order <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb21-8"><a href="#cb21-8"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb21-9"><a href="#cb21-9"></a></span>
<span id="cb21-10"><a href="#cb21-10"></a></span>
<span id="cb21-11"><a href="#cb21-11"></a>ax.set_yticks([])</span>
<span id="cb21-12"><a href="#cb21-12"></a>ax.set_xticks([])</span>
<span id="cb21-13"><a href="#cb21-13"></a></span>
<span id="cb21-14"><a href="#cb21-14"></a>x_n <span class="op">=</span> np.linspace(x0.<span class="bu">min</span>(), x0.<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb21-15"><a href="#cb21-15"></a>ps <span class="op">=</span> []</span>
<span id="cb21-16"><a href="#cb21-16"></a><span class="cf">for</span> i <span class="kw">in</span> order:</span>
<span id="cb21-17"><a href="#cb21-17"></a>    p <span class="op">=</span> np.polynomial.Polynomial.fit(x0, y0, deg<span class="op">=</span>i)</span>
<span id="cb21-18"><a href="#cb21-18"></a>    ps.append(p)</span>
<span id="cb21-19"><a href="#cb21-19"></a>    yhat <span class="op">=</span> p(x0)</span>
<span id="cb21-20"><a href="#cb21-20"></a>    ybar <span class="op">=</span> np.mean(y0)</span>
<span id="cb21-21"><a href="#cb21-21"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb21-22"><a href="#cb21-22"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb21-23"><a href="#cb21-23"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb21-24"><a href="#cb21-24"></a>    ax.plot(x_n, p(x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb21-25"><a href="#cb21-25"></a></span>
<span id="cb21-26"><a href="#cb21-26"></a>    </span>
<span id="cb21-27"><a href="#cb21-27"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>De la figura anterior podemos ver que el aumento de la complejidad del modelo se acompaña de una mayor exactitud reflejada en el coeficiente de determinación R². De hecho, podemos ver que el polinomio de orden 5 se ajusta perfectamente a los datos, obteniendo un R²=1.</p>
<p>¿Por qué el polinomio de grado 5 puede capturar los datos sin perder uno solo de ellos? La razón es que tenemos el mismo número de parámetros que de datos es decir 6. Por lo tanto, el modelo está actuando como una forma alternativa de expresar los datos. El modelo no está <em>aprendiendo</em> algo sobre los datos, ¡Está memorizando los datos! A partir de este simple ejemplo, podemos ver que un modelo con mayor ajuste no siempre es lo ideal.</p>
<p>Ahora agregaremos dos datos nuevos y sin volver a ajustar los modelos veremos como cambia el R². Se puede ver que al modelo lineal le va mejor en este caso que al polinomial.</p>
<div id="aa57fe12" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>_, ax <span class="op">=</span> plt.subplots( figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb22-2"><a href="#cb22-2"></a>x_ <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">10</span>])</span>
<span id="cb22-3"><a href="#cb22-3"></a>y_ <span class="op">=</span> np.array([<span class="dv">7</span>, <span class="dv">10</span>])</span>
<span id="cb22-4"><a href="#cb22-4"></a></span>
<span id="cb22-5"><a href="#cb22-5"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb22-6"><a href="#cb22-6"></a>ax.plot(x_, y_, <span class="st">'ks'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb22-7"><a href="#cb22-7"></a></span>
<span id="cb22-8"><a href="#cb22-8"></a>ax.set_yticks([])</span>
<span id="cb22-9"><a href="#cb22-9"></a>ax.set_xticks([])</span>
<span id="cb22-10"><a href="#cb22-10"></a></span>
<span id="cb22-11"><a href="#cb22-11"></a>x1 <span class="op">=</span> np.concatenate((x0, x_))</span>
<span id="cb22-12"><a href="#cb22-12"></a>y1 <span class="op">=</span> np.concatenate((y0, y_))</span>
<span id="cb22-13"><a href="#cb22-13"></a></span>
<span id="cb22-14"><a href="#cb22-14"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(order):</span>
<span id="cb22-15"><a href="#cb22-15"></a>    yhat <span class="op">=</span> ps[idx](x1)</span>
<span id="cb22-16"><a href="#cb22-16"></a>    ybar <span class="op">=</span> np.mean(y1)</span>
<span id="cb22-17"><a href="#cb22-17"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb22-18"><a href="#cb22-18"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb22-19"><a href="#cb22-19"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb22-20"><a href="#cb22-20"></a>    ax.plot(x_n, ps[idx](x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb22-21"><a href="#cb22-21"></a></span>
<span id="cb22-22"><a href="#cb22-22"></a>    </span>
<span id="cb22-23"><a href="#cb22-23"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Cuando un modelo ajusta muy bien, el conjunto de datos utilizado para aprender los parámetros de ese modelo, pero muy mal otros conjuntos de datos, decimos que tenemos sobreajuste (overfitting). Este es un problema muy común al analizar datos.</p>
<p>Una forma muy útil de pensar el sobreajuste es considerar que un conjunto de datos tiene dos componentes; la señal y el ruido. La señal es lo que queremos capturar (o aprender) de los datos. Si usamos un conjunto de datos es porque creemos que hay una señal allí, de lo contrario será un ejercicio fútil. El ruido, en cambio, no es útil y es el producto de los errores de medición, las limitaciones en la forma en que se generaron o capturaron los datos, la presencia de datos corruptos, etc. Un modelo sobreajusta cuando es tan flexible (para un conjunto de datos) que es capaz de <em>aprender</em> el ruido. Esto tiene como consecuencia que la señal queda oculta.</p>
<p>Esta es una justificación práctica para la navaja de Occam. Y nos advierte que al menos en principio, siempre es posible crear un modelo tan complejo que explique todos los detalles, incluso los más irrelevantes. Tal como en el Imperio descrito por Borges, donde los cartógrafos alcanzaron tal nivel de sofisticación que crearon un mapa del Imperio cuyo tamaño era el del propio Imperio, y que coincidía punto por punto con él.</p>
</section>
<section id="muy-pocos-parámetros-conducen-a-un-subajuste" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="muy-pocos-parámetros-conducen-a-un-subajuste"><span class="header-section-number">4.6.3</span> Muy pocos parámetros conducen a un subajuste</h3>
<p>Continuando con el mismo ejemplo pero en el otro extremo de complejidad, tenemos el modelo de orden 0. Este modelo es simplemente una Gaussiana disfrazada de modelo lineal. Este modelo solo es capaz de capturar el valor de la media de <span class="math inline">\(y\)</span>, y es por lo tanto totalente indiferente a los valores de <span class="math inline">\(x\)</span>. Decimos que este modelo ha subajustado los datos.</p>
</section>
<section id="medidas-de-exactitud-predictiva" class="level3" data-number="4.6.4">
<h3 data-number="4.6.4" class="anchored" data-anchor-id="medidas-de-exactitud-predictiva"><span class="header-section-number">4.6.4</span> Medidas de exactitud predictiva</h3>
<p><em>Todo debe hacerse tan simple como sea posible, pero no más simple</em> es una cita que a menudo se atribuye a Einstein. Al igual que en una dieta saludable, al modelar tenemos que mantener un balance. Idealmente, nos gustaría tener un modelo que ni sub-ajuste ni sobre-ajuste los datos. De alguna forma hay que balancear simplicidad y bondad de ajuste.</p>
<p>En el ejemplo previo, es relativamente fácil de ver que el modelo de orden 0 es <em>demasiado</em> simple mientras que el modelo de orden 5 es <em>demasiado</em> complejo. Pero que podemos decir de los otros dos modelos? Cómo podríamos establecer un ranking numérico de estos modelos? Para poder hacer esto necesitamos formalizar nuestra intuición sobre este balance entre simplicidad y exactitud</p>
<p>Veamos un par de términos que nos serán de utilidad.</p>
<ul>
<li><strong>Exactitud dentro de la muestra</strong> (within-sample accuracy). La exactitud medida con los mismos datos usado para ajustar el modelo.</li>
<li><strong>Exactitud fuera de la muestra</strong> (out-of-sample accuracy). La exactitud medida con datos no usados para ajustar el modelo.</li>
</ul>
<p>La exactitud dentro de la muestra será, en promedio, mayor a la exactitud fuera de la muestra. Es por ello que usar la exactitud dentro de la muestra para evaluar un modelo en general conducirá a pensar que tenemos un mejor modelo de lo que realmente es. Utilizar la exactitud fuera de la muestra es por lo tanto una mejor idea para evitar engañarnos a nosotros mismos. Sin embargo, esta aproximación requiere dejar datos fuera del ajuste, lo cual es un lujo que en general no nos podemos dar. Ya que este es un problema central en el análisis de datos existen varias propuestas para abordarlo. Dos aproximaciones muy populares son:</p>
<ul>
<li><p>Validación cruzada: esta es una estrategia empírica basada en dividir los datos disponibles en subconjuntos separados que se utilizan para ajustar y evaluar de forma alternativa</p></li>
<li><p>Criterios de información: este es un término general usado para referirse a varias expresiones que aproximan la exactitud fuera de la muestra como la exactitud dentro de la muestra más un término que penaliza la complejidad del modelo.</p></li>
</ul>
</section>
<section id="validación-cruzada" class="level3" data-number="4.6.5">
<h3 data-number="4.6.5" class="anchored" data-anchor-id="validación-cruzada"><span class="header-section-number">4.6.5</span> Validación cruzada</h3>
<p>La validación cruzada es una solución simple y, en la mayoría de los casos, efectiva para comparar modelos. Tomamos nuestros datos y los dividimos en K porciones. Intentamos mantener las porciones más o menos iguales (en tamaño y, a veces, también en otras características, como, por ejemplo, un número igual de clases). Luego usamos K-1 porciones para entrenar el modelo y el resto para evaluarlo. Este proceso se repite sistemáticamente dejando, por cada iteración, una porción diferente fuera del conjunto de entrenamiento y usando esa porción como el conjunto de evaluación. Esto se repite hasta que hayamos completado K rondas de ajuste-evaluación. La exactitud del modelo será la del promedio a lo largo de las K rondas. Esto se conoce como validación cruzada K-fold. Por último, una vez que hemos realizado la validación cruzada, usamos todos los datos para ajustar por última vez nuestro modelo y este es el modelo que se utiliza para hacer predicciones o para cualquier otro fin.</p>
<p><img src="img/cv.png" width="500"></p>
<p>Cuando K es igual a la cantidad de puntos de datos, obtenemos lo que se conoce como <em>validación cruzada dejando uno afuera</em> (LOOCV del inglés leave-one-out cross-validation).</p>
<p>La validación cruzada es una práctica de rutina en <em>machine learning</em>. Y apenas hemos descripto los aspectos más esenciales de esta práctica. Para mayor información pueden leer <a href="http://themlbook.com/">The Hundred-Page Machine Learning Book</a> o <a href="https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow-ebook/dp/B0742K7HYF/ref=dp_ob_title_def">Python Machine Learning</a>, by Sebastian Raschka, o <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a> by Jake Vanderplas.</p>
<p>La validación cruzada es una idea muy simple y útil, pero para algunos modelos o para grandes cantidades de datos, el costo computacional de la validación cruzada puede estar más allá de nuestras posibilidades. Muchas personas han tratado de encontrar cantidades más simples de calcular que se aproximen a los resultados obtenidos con la validación cruzada o que funcionen en escenarios donde la validación cruzada no puede ser tan fácil de realizar. Y ese es el tema de la siguiente sección.</p>
</section>
<section id="criterios-de-información" class="level3" data-number="4.6.6">
<h3 data-number="4.6.6" class="anchored" data-anchor-id="criterios-de-información"><span class="header-section-number">4.6.6</span> Criterios de información</h3>
<p>Los criterios de información son una colección de herramientas estrechamente relacionadas que se utilizan para comparar modelos en términos de la bondad del ajuste y de la complejidad del modelo. En otras palabras, los criterios de información formalizan la intuición que desarrollamos al comienzo del capítulo. La forma exacta en que se derivan estas cantidades tiene que ver con un campo conocido como <a href="http://www.inference.org.uk/mackay/itila/book.html">Teoría de la Información</a>.</p>
<p>Una forma intuitiva de medir qué tan bien un modelo se ajusta a los datos es calcular el error cuadrático medio entre los datos y las predicciones realizadas por el modelo:</p>
<p><span class="math display">\[
\frac{1}{N} \sum_i^N  (y_i - \operatorname{E} (y_i \mid \theta))^2
\]</span></p>
<p><span class="math inline">\(\operatorname{E} (y_i \mid \theta)\)</span> es el valor predicho dados los parámetros estimados. Es importante notar que esto es esencialmente el promedio de la diferencia entre los datos observados y los predichos. Tomar el cuadrado de los errores asegura que las diferencias no se cancelen y enfatiza grandes errores comparado con otros alternativas como por ejemplo calcular el valor absoluto.</p>
<p>El error cuadrático medio, puede resultarnos familiar ya que es muy popular. Pero si nos detenemos a reflexionar sobre esta cantidad veremos que en principio no tiene nada de especial y bien podríamos idear otras expresiones similares. Intentemos encontrar una métrica más general y compatible con la aproximación probabilista de este curso.</p>
</section>
<section id="entropia" class="level3" data-number="4.6.7">
<h3 data-number="4.6.7" class="anchored" data-anchor-id="entropia"><span class="header-section-number">4.6.7</span> Entropia</h3>
<p>For a probability distribution with <span class="math inline">\(N\)</span> possible different events which each possible event having probability <span class="math inline">\(p_i\)</span>, the entropy is defined as:</p>
<p><span class="math display">\[
H(p) = - \mathbb{E}[\log{p}] = -\sum_i^N p_i \log{p_i}
\]</span></p>
<p>La entropía es una medida de la incertidumbre de una distribución. En este sentido podemos decir que la incertidumbre contenida en una distribución es el logaritmo de la probabilidad promedio de un evento. Si solo un evento es posible la entropía será 0, si todos los eventos tienen la misma probabilidad la entropía será máxima. El concepto de entropía se puede extender a distribuciones continuas, pero no vamos a entrar en esos detalles.</p>
<div id="a37eff52" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-2"><a href="#cb23-2"></a></span>
<span id="cb23-3"><a href="#cb23-3"></a><span class="cf">for</span> p, ax <span class="kw">in</span> <span class="bu">zip</span>([<span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.0001</span>], axes.ravel()):</span>
<span id="cb23-4"><a href="#cb23-4"></a>    dist <span class="op">=</span> pz.Bernoulli(p<span class="op">=</span>p)</span>
<span id="cb23-5"><a href="#cb23-5"></a>    dist.plot_pdf(ax<span class="op">=</span>ax, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-6"><a href="#cb23-6"></a>    ax.set_title(<span class="ss">f"Entropy=</span><span class="sc">{</span>dist<span class="sc">.</span>entropy()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb23-7"><a href="#cb23-7"></a>    ax.set_ylim(<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El concepto de entropía aparece muchas veces en estadística. Puede ser útil, por ejemplo al definir priors. En general queremos utilizar un prior que sea de máxima entropía dado nuestro conocimiento (ver por ej funcion <code>maxent</code> de PreliZ). Y también a la hora de comparar modelos. Veamos.</p>
<p>Supongamos que tenemos una distribución objetivo <span class="math inline">\(p\)</span>, con la cual no podemos trabajar de forma directa y solo tenemos acceso a <span class="math inline">\(q\)</span>. Queremos evaluar que tan bien <span class="math inline">\(q\)</span> approxima a <span class="math inline">\(p\)</span>, o si <span class="math inline">\(q\)</span> es una familia paramétrica encontrar que parámetros hacen que <span class="math inline">\(q\)</span> sea lo más cercana a <span class="math inline">\(p\)</span> que sea posible. Una forma de hacer esto es medir la divergencia de Kulback-Leibler:</p>
<p><span class="math display">\[
\mathbb{KL}(p \parallel q) =  \overbrace{-\sum_i^N p_i \log{q_i}}^{H(p, q)} -  \overbrace{\left(-\sum_{i}^n p_i \log{p_i}\right)}^{H(p)}
\]</span></p>
<p>Fijense que tiene dos componentes la entropia de <span class="math inline">\(p\)</span>, <span class="math inline">\(H(p)\)</span> y la entropía cruzada <span class="math inline">\(H(p, q)\)</span>, es decir la entropía de <span class="math inline">\(q\)</span> pero evaluada según <span class="math inline">\(p\)</span>. Esto puede parecer algo abstracto, pero si pensamos que tenemos <span class="math inline">\(N\)</span> muestras que asumimos provienen de una distribución <span class="math inline">\(p\)</span> desconocida y tenemos un modelo descripto por <span class="math inline">\(q(y \mid \theta)\)</span>, entonces veremos que estamos describiendo una situación típica en análisis de datos.</p>
<p>Según esta expresión la divergencia de KL representa la entropía “extra” que introducimos al aproximar <span class="math inline">\(p\)</span> por <span class="math inline">\(q\)</span>. Es común encontrarla escrita de otras formas, como:</p>
<p><span class="math display">\[
\mathbb{KL}(p \parallel q) \quad=\quad- \sum_i^N p_i (\log{q_i} - \log{p_i}) \quad=\quad \mathbb{E}_p[\log{p}] - \mathbb{E}_p[\log{q}] \quad=\quad \sum_i^N p_i \log{\frac{p_i}{q_i}}
\]</span></p>
<p>Todas formas equivalentes y útiles depediendo en contexto. Algo común en todas estas expresiones es que no podemos aplicar de forma directa si <span class="math inline">\(p\)</span> es desconocida. Por ejemplo si <span class="math inline">\(p\)</span> representa el <strong>proceso generador de datos</strong> o la <strong>población</strong> o la distribución <strong>verdadera</strong>, estamos perdidos… Pero, si lo que nos interesa es comparar modelos veremos que NO es necesario el cálculo directo, la razón es que aún cuando desconozcamos <span class="math inline">\(p\)</span> su entropía es un término constante.</p>
<p><span class="math display">\[
\begin{split}
        \mathbb{KL}(p \parallel q_0) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_0)}] \\
        \mathbb{KL}(p \parallel q_1) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_1)}] \\
        &amp;\cdots \\
        \mathbb{KL}(p \parallel q_2) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_2)}]
\end{split}
\]</span></p>
<p>Si comparamos modelos entonces el mejor modelo, dado el conjunto de modelos comparados, será aquel que tenga un valor más grande de verosimilitud. En otras palabras mimimizar la divergencia de KL es proporcional a maximizar la verosimilitud (likelihood).</p>
<p>En la práctica tampoco tenemos acceso a <span class="math inline">\(\mathbb{E}[\log{q}]\)</span>, lo que podemos hacer es estimar esta cantidad a partir de una muestra, pero como ya sabemos usar una muestra para estimar los parámetros de un modelo y usar la misma muestra para evaluarlo introduce un sesgo, que de alguna manera debemos corregir. Una forma de corregir este sesgo viene dada por los criterior de información.</p>
<section id="criterio-de-información-de-akaike" class="level4" data-number="4.6.7.1">
<h4 data-number="4.6.7.1" class="anchored" data-anchor-id="criterio-de-información-de-akaike"><span class="header-section-number">4.6.7.1</span> Criterio de información de Akaike</h4>
<p>Este es un criterio de información muy conocido y ampliamente utilizado fuera del universo Bayesiano y se define como:</p>
<p><span class="math display">\[
AIC = -2 \sum_i^N \log p(y_i \mid \hat{\theta}_{mle}) + 2 k
\]</span></p>
<p>Donde, <span class="math inline">\(k\)</span> es el número de parámetros del modelo y <span class="math inline">\(\hat{\theta}_{mle}\)</span> es la estimación por máxima verosimilitud para <span class="math inline">\(\theta\)</span>. Para el resto de nuestra discusión vamos a omitir la constante -2 y escribir</p>
<p><span class="math display">\[
AIC = \sum_i^N \log p(y_i \mid \hat{\theta}_{mle}) - k
\]</span></p>
<p>De esta forma es más fácil ver que el criterio de Akaike es una maxima-verosimilitud penalizada (se hace más chica, se minimiza) mientras más parámetros tenga un modelo.Además, esta versión sin el -2 tiene una correspondencia más clara con otras expresiones que veremos a continuación.</p>
<p>Qué el número de parámetros sea un criterio válido de penalización es intuitivo, ya que como vimos en el ejemplo anterior con los polinomios, un modelo con mayor número de parámetros es, en general, más flexible. Pero es importante destacar que el criterio de Akaike tiene una justificación teórica, no es que Akaike simplemente pensó que usar <span class="math inline">\(k\)</span> era buena idea.</p>
<p>El criterio de AIC es muy útil, pero presenta problemas para modelos Bayesianos. Una de las razones es que no utiliza la distribución a posteriori de <span class="math inline">\(\theta\)</span> y, por lo tanto, descarta información. Además AIC, desde una perspectiva Bayesiana, asume que los priors son <em>planos</em> y, por lo tanto, AIC es incompatible con priors informativos y/o ligeramente informativos. Además, la cantidad de parámetros de un modelo no es una buena medida de la complejidad del mismo cuando se usan priors informativos o estructuras como la jerárquica. Agregar información a un modelo en su estructura, equivale a reducir la <em>cantidad efectiva de parámetros</em>, algo también conocido como <em>regularización</em>.</p>
<p>Podemos encontrar una expresión equivalente, pero mejor ajustada a modelos Bayesianos?</p>
</section>
</section>
<section id="waic" class="level3" data-number="4.6.8">
<h3 data-number="4.6.8" class="anchored" data-anchor-id="waic"><span class="header-section-number">4.6.8</span> WAIC</h3>
<p>Como ya vimos en el criterio de Akaike, la bondad del ajuste viene dada por:</p>
<p><span class="math display">\[
\sum_i^N \log p(y_i \mid \hat{\theta}_{mle})
\]</span></p>
<p>Pero en estadística Bayesiana, NO tenemos una estimación puntual de <span class="math inline">\(\theta\)</span>. Tenemos una distribución, por lo que deberíamos hacer:</p>
<p><span class="math display">\[
\sum_i^N \log
    \int \ p(y_i \mid \theta) \; p(\theta \mid y) d\theta
\]</span></p>
<p>Como en general no tenemos una expresión analítica para el posterior, <span class="math inline">\(p(\theta \mid y)\)</span>, pero tenemos unas serie de muestras (como las obtenidas por MCMC), entonces podemos aproximar la integral por:</p>
<p><span class="math display">\[
\sum_i^N \log \left(\frac{1}{S} \sum_{j}^S p(y_i \mid \theta^j) \right)
\]</span></p>
<p>LLamaremos a esta cantidad ELPD, que es la sigla en inglés para valor esperado de la densidad log-predictiva.</p>
<p>OK, ya tenemos como medir la bondad de ajuste. Ahora necesitamos un término que penalice la complejidad del modelo. Encontrar la expresión correcta para esto, requiere de trabajo, asi que la vamos a presentar sin justificar. Este nuevo criterio (la versión Bayesiana de Akaike) se llama Widely applicable information criterion:</p>
<p><span class="math display">\[
WAIC = \sum_i^N \log \left(\frac{1}{S} \sum_{j}^S p(y_i \mid \theta^j) \right) - \sum_i^N  \left( V_{j}^S \log p(y_i \mid \theta^j) \right)
\]</span></p>
<p>Donde el término de penalización viene dado por la varianza de los log-likelihoods sobre las <span class="math inline">\(S\)</span> muestras del posterior. Intuitivamente el término penaliza modelos que tengan mucha variabilidad en sus predicciones. Veamos como ejemplo un modelo lineal:</p>
<p><span class="math display">\[
Y = \alpha + \beta X
\]</span></p>
<p>Un modelo donde <span class="math inline">\(\beta=0\)</span> será menos flexible, ya que equivale a un modelo que solo tiene un parámetro, <span class="math inline">\(\alpha\)</span>. De forma un poco más sutil un modelo donde <span class="math inline">\(\beta\)</span> varía en un rango estrecho será menos flexible (más regularizado), que un modelo donde <span class="math inline">\(\beta\)</span> puede tomar cualquier valor.</p>
</section>
<section id="loo-y-la-validación-cruzada-aproximada" class="level3" data-number="4.6.9">
<h3 data-number="4.6.9" class="anchored" data-anchor-id="loo-y-la-validación-cruzada-aproximada"><span class="header-section-number">4.6.9</span> LOO y la validación cruzada (aproximada)</h3>
<p>Existe otra alternativa para penalizar el término</p>
<p><span class="math display">\[
\sum_i^N \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i \mid \theta^s) \right)
\]</span></p>
<p>Y es calcular</p>
<p><span class="math display">\[
\sum_i^N \log
    \left( \frac{1}{S}\sum_j^S \mathbin{\color{#E9692C}{p(y_i \mid \theta_{-i}^j)}} \right)
\]</span></p>
<p>donde <span class="math inline">\(_{-i}\)</span> quiere decir que dejamos la observación <span class="math inline">\(i\)</span> afuera. Una implementación Naive de esta estimación requiere que estimemos tantas distribuciones a posteriori como datos tengamos, ya que para cada una de ellas eliminaremos una observación. Sin embargo, esto no es necesario ya que es posible estiamar <span class="math inline">\(\color{#E9692C}{p(y_i \mid \theta_{-i}^j})\)</span> usando <strong>Muestreo de Importancia</strong> (importance sampling).</p>
<p>Antes de seguir con nuestra agenda, necesitamos hacer un pequeño detour.</p>
<section id="muestreo-de-importancia" class="level4" data-number="4.6.9.1">
<h4 data-number="4.6.9.1" class="anchored" data-anchor-id="muestreo-de-importancia"><span class="header-section-number">4.6.9.1</span> Muestreo de importancia</h4>
<p>Esta es una técnica para estimar propiedades de una distribución de interés <span class="math inline">\(f\)</span>, dado que solo tenemos muestras de una distribución <span class="math inline">\(g\)</span>. Usar el muestreo de importancia tiene sentido, por ejemplo, cuando es más simple muestrear <span class="math inline">\(g\)</span> y no <span class="math inline">\(f\)</span>.</p>
<p>Si tenemos un conjunto de muestras de la variable aleatoria <span class="math inline">\(X\)</span> y podemos evaluar <span class="math inline">\(g\)</span> y <span class="math inline">\(f\)</span> puntualmente, podemos calcular los pesos de importancia como:</p>
<p><span class="math display">\[\begin{equation}
     w_i = \frac{f(x_i)}{g(x_i)}
\end{equation}\]</span></p>
<p>Computacionalmente queda de la siguiente manera:</p>
<ul>
<li>Extraer <span class="math inline">\(N\)</span> muestras <span class="math inline">\(x_i\)</span> de <span class="math inline">\(g\)</span></li>
<li>Calcular la probabilidad de cada muestra <span class="math inline">\(g(x_i)\)</span></li>
<li>Evaluar <span class="math inline">\(f\)</span> sobre las <span class="math inline">\(N\)</span> muestras <span class="math inline">\(f(x_i)\)</span></li>
<li>Calcular los pesos de importancia <span class="math inline">\(w_i = \frac{f(x_i)}{g(x_i)}\)</span></li>
</ul>
<p>Una vez obtenidos los pesos <span class="math inline">\(w_i\)</span>, podemos usarlos para estimar propiedades de <span class="math inline">\(f\)</span>, su densidad, momentos, cuantiles, etc.</p>
<p>A continuación se muestre un bloque de código donde <span class="math inline">\(g\)</span> es una Normal y <span class="math inline">\(f\)</span> una Gamma y usamos muestreo de importancia para estimar la PDF de <span class="math inline">\(f\)</span>. Este es solo un ejemplo didáctico, ya que en realidad sabemos como calcular la PDF de una Gamma. Pero en la práctica <span class="math inline">\(f\)</span> puede ser un objeto mucho más complejo.</p>
<div id="fa98a363" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>g <span class="op">=</span> pz.Normal(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb24-2"><a href="#cb24-2"></a>samples <span class="op">=</span> g.rvs(<span class="dv">1000</span>)</span>
<span id="cb24-3"><a href="#cb24-3"></a>f <span class="op">=</span> pz.Gamma(mu<span class="op">=</span><span class="dv">4</span>, sigma<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb24-4"><a href="#cb24-4"></a></span>
<span id="cb24-5"><a href="#cb24-5"></a>w <span class="op">=</span> f.pdf(samples) <span class="op">/</span> g.pdf(samples)</span>
<span id="cb24-6"><a href="#cb24-6"></a></span>
<span id="cb24-7"><a href="#cb24-7"></a>plt.hist(samples, bins<span class="op">=</span><span class="dv">100</span>, density<span class="op">=</span><span class="va">True</span>, weights<span class="op">=</span>w, alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'C1'</span>, label<span class="op">=</span><span class="st">'Weighted samples'</span>)</span>
<span id="cb24-8"><a href="#cb24-8"></a>plt.xlim(<span class="dv">0</span>, <span class="dv">15</span>)</span>
<span id="cb24-9"><a href="#cb24-9"></a></span>
<span id="cb24-10"><a href="#cb24-10"></a></span>
<span id="cb24-11"><a href="#cb24-11"></a>f.plot_pdf()<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Al hacer muestreo de importancia mientras más similares sean <span class="math inline">\(g\)</span> y <span class="math inline">\(f\)</span> mejor serán los resultados. En la práctica las inferencias son más confiables cuando <span class="math inline">\(g\)</span> tiene un soporte mayor que <span class="math inline">\(f\)</span>, es decir cuando es más “ancha”, intuitivamente necesitamos que las muestras de <span class="math inline">\(g\)</span> cubran todo el soporte de <span class="math inline">\(f\)</span> (o al menos las regiones de densidad alta).</p>
</section>
</section>
<section id="retomando" class="level3" data-number="4.6.10">
<h3 data-number="4.6.10" class="anchored" data-anchor-id="retomando"><span class="header-section-number">4.6.10</span> Retomando</h3>
<p>Ahora que tenemos una mejor idea de muestreo por importancia veamos como podemos usarlo. La distribución que conocemos es la distribución a posteriori, y la que queremos aproximar por muestreo de importancia es la distribución a posteriori dejando uno afuera <span class="math inline">\(p(y_i \mid \theta_{-i}^j)\)</span>. Por lo que los pesos de importancia que nos interesa calcular son:</p>
<p><span class="math display">\[
w_i^j = \frac{p(\theta^j \mid y_{-i} )}{p(\theta^j \mid y)} \propto \frac{p(\theta) \prod_{i\not=-i}^n p(y_i \mid \theta)}{p(\theta) \prod_i^n p(y_i \mid \theta)} \propto \frac{1}{p(y_i \mid \theta^j)}
\]</span></p>
<p>Es decir los términos comunes (y que por lo tanto se cancelan) entre numerador y denominador son todos menos el likelihood para la observación que queremos remover. Nótese que los pesos son proporcionales y no están normalizados, pero esto no es un problema ya que se pueden normalizar simplemente dividiendo cada peso por la suma total de los pesos.</p>
<p>Este resultado es una gran noticia, porque nos dice que es posible calcular el ELPD por validación cruzada dejando uno afuera, a partir de un solo ajuste de los datos! y que solo necesitamos los valores de los log-likelihoods, cuyo costo computacional es, en general, muy bajo.</p>
<p>La trampa, por que siempre hay una trampa, es que es esperable que <span class="math inline">\(p(\theta^j \mid y_{-i} )\)</span> sea más “ancha” que <span class="math inline">\(p(\theta^j \mid y)\)</span>, ya que es una distribución a posteriori estimada con una observación menos. Esto es lo contrario al caso ideal en muestreo por importancia. Para muchos casos puede que la diferencia no sea relevante, ya que eliminar una observación puede conducir a una distribución a posteriori prácticamente equivalente. Pero en algunos casos la diferencia puede ser relativamente grande. Cuándo? Pues, mientras más “influyente” sea la observación. En términos de importance sampling esto se traduce en pesos con mayor importancia relativa y que por lo tanto tienen a dominar la estimación.</p>
<p>Una forma de corregir esto problema es simplemente truncando los pesos “demasiado altos”, pero esto trae otros problemas que no vamos a discutir. Otra forma consiste en respaldarse en la teoría. La teoría indica que bajo ciertas condiciones los pesos altos se distribuyen según una Pareto. Por lo que en vez de truncarlos podemos ajustarlos a una distribución de Pareto y luego remplazarlos por valores obtenidos de esa distribución. Esto es una forma de suavizado que, dentro de cierto rango, permite estabilizar la estimación por muestreo de importancia, ya que hará que alguno valores “muy grandes” no lo sean tanto.</p>
<p>Cuando combinamos todas estas ideas obtenemos un método llamado Pareto-Smooth Importance Sampling Leave-One-Out Cross Validation, que se abrevia como PSIS-LOO-CV. Dado que el nombre y la sigla son horriblemente largo y difíciles de pronunciar nosotros lo llamaremos LOO (pronunciado como “lu”).</p>
</section>
<section id="loo-y-waic" class="level3" data-number="4.6.11">
<h3 data-number="4.6.11" class="anchored" data-anchor-id="loo-y-waic"><span class="header-section-number">4.6.11</span> LOO y WAIC</h3>
<p>Asintóticamente LOO y WAIC convergen, y además funcionan bajo el mismo conjunto de supuestos. Por lo que teóricamente son equivalentes. Sin embargo en la práctica LOO es más robusto, y además nos ofrece un diagnóstico que indica cuándo podría estar fallando (esto gracias al ajuste de Pareto). Por lo que en la práctica preferimos LOO.</p>
</section>
<section id="calculando-loo" class="level3" data-number="4.6.12">
<h3 data-number="4.6.12" class="anchored" data-anchor-id="calculando-loo"><span class="header-section-number">4.6.12</span> Calculando LOO</h3>
<p>Luego de toda esta introducción calcular LOO, puede parecer algo decepcionante. Solo tenemos que llamar a la función <code>loo</code> de ArviZ y pasarle un objeto InfereceData que contenga el grupo log-likelihood. Por defecto PyMC NO agrega este grupo al llamar a <code>pm.sample</code>. Podemos calcularlo junto con el posterior si hacemos <code>pm.sample(., )</code></p>
<div id="b5f8dc11" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="cf">with</span> modelo_cat:</span>
<span id="cb25-2"><a href="#cb25-2"></a>    pm.compute_log_likelihood(idata_cat,</span>
<span id="cb25-3"><a href="#cb25-3"></a>                              extend_inferencedata<span class="op">=</span><span class="va">True</span>,  <span class="co"># actualizamos "in-place"</span></span>
<span id="cb25-4"><a href="#cb25-4"></a>                              progressbar<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb25-5"><a href="#cb25-5"></a>                             )  </span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<div id="a6d92db9" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>loo_p <span class="op">=</span> az.loo(idata_cat)</span>
<span id="cb26-2"><a href="#cb26-2"></a>loo_p</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/proyectos/00_BM/arviz-devs/arviz/arviz/stats/stats.py:792: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>Computed from 4000 posterior samples and 111 observations log-likelihood matrix.

         Estimate       SE
elpd_loo  -171.18     7.90
p_loo        2.92        -

There has been a warning during the calculation. Please check the results.
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.7]   (good)      108   97.3%
   (0.7, 1]   (bad)         1    0.9%
   (1, Inf)   (very bad)    2    1.8%</code></pre>
</div>
</div>
<p>Podemos ver que obtenemos el valor del ELPD estimado usando LOO y su error estándar. <code>p_loo</code> se puede interpretar aproximadamente como el número efectivo de parámetros. De hecho, si cuentan el número de parámetros de <code>modelo_cat</code> verán que es efectivamente 3.</p>
<p>Luego podemos ver una tabla con los “Valor del diagnóstico de Pareto k”. Ya algo adelantamos sobre esto. Dijimos que usábamos una Pareto para regularizar la estimación de los pesos de importancia. Uno de los parámetros de ese ajuste se llama k. Como tenemos un ajuste de Pareto por observación tenemos un valor k por observación. Este parámetro es útil por que nos indica dos caras de una misma moneda, nos dice cuando una observación es “muy influyente” y nos indica que la aproximación empleada por LOO podría estar fallando para esa observación (lean el mensaje de advertencia con fondo rosa).</p>
<p>Como regla general si k es menor a 0.7 no hay problemas, si estamos entre 0.7 y 1 es muy probable que estemos en problemas y si el mayor a 1, estamos perdidos. El valor corte 0.7 no es fijo, estrictamente puede ser menor y depende del número total de muestras de la distribución a posteriori, 4000, en este ejemplo. Pero cuando el número es un poco mayor a 2000 ya estamos casi en 0.7. En la práctica es común usar valores de muestras de 2000 o mayores. Incrementar el número de muestras (<code>draws</code> en la función <code>pm.sample</code>) puede reducir el valor de k y por lo podríamos remover algunas de estas advertencias, pero en general el número necesario podría ser demasiado grande como para que tenga sentido práctico.</p>
<p>Es posible visualizar los valores de k, usando <code>plot_khat</code></p>
<div id="dc71aeb6" class="cell" data-scrolled="true" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>az.plot_khat(loo_p, threshold<span class="op">=</span><span class="fl">0.7</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Si bien la función principal de LOO es comparar modelos, los valores de k puede ser útiles incluso si solo tenemos uno. Por ejemplo podríamos tener conocimiento extra que nos indique por qué estas observaciones son influyentes, quizá hubo un problema en la toma de datos y los valores son incorrectos. O quizá los valores son correctos pero desde la perspectiva de nuestro modelo son influyentes, “extraños”, “sorprendentes”.</p>
<p>Si k &gt; 0.7, el valor de p_loo puede darnos algo más de información. Siendo <span class="math inline">\(p\)</span> es el número total de parámetros en un modelo.</p>
<ul>
<li><p>Si p_loo &lt;&lt; p entonces el modelo debe estar mal-especificado. Esto debería verse también en las pruebas predictivas a posteriori. Una solución es usar un modelo sobredispersado (como cambiar una Poisson por una NegativaBinomial o por una ZeroInflatedPoisson o HurdlePoisson, o cambiar una Normal por una T de Student, etc). O es probable que el modelo necesite más estructura o complejidad, quizá necesitamos un término no-lineal, etc</p></li>
<li><p>Si p_loo &lt; p y las observaciones son relativamente pocas comparadas con <span class="math inline">\(p\)</span>, (digamos p&gt;N/5). Es probable que tengamos un modelo demasiado flexible y/o priors demasiado vagos. Esto puede pasar para modelos jerárquicos con muy pocas observaciones por grupo o por ejemplo para splines con muchos nudos o Procesos Gaussianos con valores de escala muy cortos</p></li>
<li><p>If p_loo &gt; p, entonces el modelo tiene problemas muy serios. Si p&lt;&lt;N, entonces las pruebas predictivas a posterior también deberían reportar problemas. Si en cambio p es relativamente grande (digamos p&gt;N/5). Entonces es posible que las pruebas predictivas a posteriori no reflejen problemas.</p></li>
</ul>
<p>Por último, otra forma de usar LOO incluso en ausencia de otro modelo es mediante <code>plot_loo_pit</code>. Si el gráfico luce similar al que vimos para los valores p-Bayesianos marginales, es por que estamos haciendo lo mismo. Pero esta vez al usar LOO, estamos considerando:</p>
<p><span class="math display">\[
p(\tilde y_i \le y_i \mid y_{-i})
\]</span></p>
<p>Es decir estamos evaluando, de forma aproximada, la capacidad del modelo de predecir una observación cuando removemos esa observación de los datos observados.</p>
<div id="03e25d35" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>az.plot_loo_pit(idata_cat, y<span class="op">=</span><span class="st">"acc"</span>, use_hdi<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="otros-criterios-de-información" class="level4" data-number="4.6.12.1">
<h4 data-number="4.6.12.1" class="anchored" data-anchor-id="otros-criterios-de-información"><span class="header-section-number">4.6.12.1</span> Otros criterios de información</h4>
<p>Otro criterio de información muy usado es DIC, si usamos el <em>bayesómetro™</em>, DIC es más bayesiano que AIC pero menos que WAIC. Aunque aún es popular, WAIC y principalmentete LOO han demostrado ser más útiles tanto teóricamente como empíricamente que DIC. Por lo cual NO recomendamos su uso.</p>
<p>Otro criterio muy usado es BIC (del inglés Bayesian Information Criteria), al igual que la regresión logística y la <em>sopa seca</em> de mi madre, este nombre puede ser engañoso. BIC se propuso como una forma de corregir algunos de los problemas con AIC y el autor propuso una justificación Bayesiana para ello. Pero BIC no es realmente Bayesiano en el sentido que al igual que AIC asume priors <em>planos</em> y utiliza una estimación por máxima verosimilitud.</p>
<p>Pero lo que es más importante, es que BIC difiere de AIC y WAIC en su objetivo. AIC y WAIC intentan reflejar cuál modelo generaliza mejor a otros datos (exactitud predictiva) mientras que BIC intenta identificar cuál es el modelo <em>correcto</em> y por lo tanto está más relacionado a los factores de Bayes que con WAIC. Más adelante discutiremos Factores de Bayes y veremos cómo se diferencia de criterios como WAIC y LOO.</p>
<div id="af6aa2fa" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>target <span class="op">=</span> pz.StudentT(nu<span class="op">=</span><span class="dv">4</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>).rvs(<span class="dv">200</span>)</span>
<span id="cb31-2"><a href="#cb31-2"></a></span>
<span id="cb31-3"><a href="#cb31-3"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_n:</span>
<span id="cb31-4"><a href="#cb31-4"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">"μ"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb31-5"><a href="#cb31-5"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">1</span>)</span>
<span id="cb31-6"><a href="#cb31-6"></a>    pm.Normal(<span class="st">"y"</span>, μ, σ, observed<span class="op">=</span>target)</span>
<span id="cb31-7"><a href="#cb31-7"></a>    idata_n <span class="op">=</span> pm.sample(idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>})</span>
<span id="cb31-8"><a href="#cb31-8"></a>    </span>
<span id="cb31-9"><a href="#cb31-9"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_t:</span>
<span id="cb31-10"><a href="#cb31-10"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">"μ"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb31-11"><a href="#cb31-11"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">1</span>)</span>
<span id="cb31-12"><a href="#cb31-12"></a>    ν <span class="op">=</span> pm.Exponential(<span class="st">"ν"</span>, scale<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb31-13"><a href="#cb31-13"></a>    pm.StudentT(<span class="st">"y"</span>, nu<span class="op">=</span>ν, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>target)</span>
<span id="cb31-14"><a href="#cb31-14"></a>    idata_t <span class="op">=</span> pm.sample(idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>})</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [μ, σ]</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"56f3d0e0f882481d91d4f2de06d61c40","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="df8ce9c2" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1"></a>cmp_df <span class="op">=</span> az.compare({<span class="st">'modelo_n'</span>:idata_n, <span class="st">'modelo_t'</span>:idata_t})</span>
<span id="cb33-2"><a href="#cb33-2"></a>cmp_df</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/proyectos/00_BM/arviz-devs/arviz/arviz/stats/stats.py:792: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd_loo</th>
<th data-quarto-table-cell-role="th">p_loo</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
<th data-quarto-table-cell-role="th">scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">modelo_t</td>
<td>0</td>
<td>-385.178047</td>
<td>3.073423</td>
<td>0.000000</td>
<td>1.0</td>
<td>17.274565</td>
<td>0.00000</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">modelo_n</td>
<td>1</td>
<td>-448.317291</td>
<td>10.794644</td>
<td>63.139244</td>
<td>0.0</td>
<td>37.293694</td>
<td>27.61818</td>
<td>True</td>
<td>log</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>En las filas tenemos los modelos comparados y en la columnas tenemos</p>
<ul>
<li>rank : el orden de los modelos (de mejor a peor)</li>
<li>elpd : la estimación puntual del elpd usando</li>
<li>p : los parámetros efectivos</li>
<li>elpd_diff : la diferencia entre el ELPD del mejor modelo y los demás modelos</li>
<li>weight : el peso relativo de cada modelo. Si quisieramos hacer predicciones combinando los distintos modelos, en vez de elegir uno solo, este sería el peso que deberíamos asignar a cada modelo. En este caso vemos que <code>model_t</code> se lleva todo el peso.</li>
<li>se : el error estándard del ELPD</li>
<li>dse : el error estándard de las diferencias</li>
<li>warning : una advertencia sobre si hay almenos un valor k alto</li>
<li>scale : la escala en la que se calcula el ELPD</li>
</ul>
<p>También podemos obtener más o menos la misma información de forma gráfica usando la función `az.compareplot</p>
<div id="645e4af8" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1"></a>az.plot_compare(cmp_df, plot_ic_diff<span class="op">=</span><span class="va">False</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-29-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Los círculos vacíos representan los valores del ELPD y líneas negras el error estándar.</li>
<li>El valor más alto del ELPD se indica con una línea gris discontinua vertical para facilitar la comparación con otros valores.</li>
<li>Para todos los modelos, excepto <em>el mejor</em>, también obtenemos un triángulo que indica el valor de la diferencia del ELPD entre cada modelo y el <em>mejor</em> modelo. La barra de error gris que indica el error estándar de las diferencias entre las estimaciones puntuales.</li>
</ul>
<p>La forma más sencilla de utilizar los criterios de información es elegir un único modelo. Simplemente elija el modelo con el valor más alto de ELPD. Si seguimos esta regla tendremos que aceptar que el modelo cuadrático es el mejor. Incluso si tenemos en cuenta los errores estándar podemos ver que estos no se solapan. Lo que nos da cierta seguridad que efectivamente los modelos son <em>diferentes</em> entre si. Si, en cambio, los errores estándar se superpusieran, deberíamos proporcionar una respuesta más matizada.</p>
</section>
</section>
</section>
<section id="métodos-numéricos-de-inferencia-bayesiana" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="métodos-numéricos-de-inferencia-bayesiana"><span class="header-section-number">4.7</span> Métodos numéricos de Inferencia Bayesiana</h2>
<p>La estadística Bayesiana es una técnica flexible y poderosa que ofrece un marco conceptual unificado para el análisis de datos. Lamentablemente esta formulación conduce a expresiones que no siempre tienen solución analítica por lo que se requiere de métodos numéricos de inferencia. Los lenguajes de programación probabilista (lpp) han sido propuestos como una forma de superar estas limitaciones técnicas y facilitar la creación de modelos probabilistas. El objetivo de los lpp es unificar los lenguajes de programación general con el modelado probabilista, permitiendo que estudiantes, investigadores y practicantes se focalicen en crear e interpretar modelos en vez de tener que lidiar con <em>detalles</em> computacionales y/o matemáticos. La posibilidad de aplicar métodos Bayesianos a una amplia variedad de problemas sin requerir, por parte del analista, de avanzados conocimientos matemáticos y computacionales es relativamente reciente. Este hito descansa, principalmente, en el aumento de poder de cálculo y en el desarrollo de métodos de inferencia automática. Para entender donde radica la dificultad de la inferencia Bayesiana podemos revisitar el teorema de Bayes.</p>
<p><span class="math display">\[
\underbrace{p(\boldsymbol{\theta} \mid \boldsymbol{Y})}_{\text{posterior}} = \frac{\overbrace{p(\boldsymbol{Y} \mid \boldsymbol{\theta})}^{\text{likelihood}}\; \overbrace{p(\boldsymbol{\theta})}^{\text{prior}}}{\underbrace{{p(\boldsymbol{Y})}}_{\text{marginal likelihood}}}
\]</span></p>
<p>El teorema de Bayes, tiene una formulación que a primera vista parece muy inocente. Pero el diablo está en los detalles. El likelihood marginal toma la forma de una integral.</p>
<p><span class="math display">\[
{p(\boldsymbol{Y}) = \int_{\boldsymbol{\Theta}} p(\boldsymbol{Y} \mid \boldsymbol{\theta})p(\boldsymbol{\theta}) d\boldsymbol{\theta}}
\]</span></p>
<p>Esta integral suele ser difícil de resolver. Veamos, esta expresión nos dice que debemos evaluar el likelihood para cada uno de los posibles valores del prior <span class="math inline">\(\theta\)</span>. En la práctica esa tarea no siempre es sencilla o barata de realizar. Si <span class="math inline">\(\theta\)</span> representa un solo parámetro desconocido (como en el modelo beta-binomial) entonces solo hay que resolver una integral 1D, pero si <span class="math inline">\(\theta\)</span> representa dos parámetros (como en el modelo Gaussiano) entonces la integral será doble. En definitiva la integral tendrá tantas dimensiones como parámetros el modelo. En general las integrales en grandes dimensiones no son simples de resolver.</p>
<p>Para obtener una buena aproximación de la distribución a posteriori podemos concentrarnos en las regiones donde tanto la contribución del prior como del likelihood son <em>relativamente grandes</em> (área gris en la siguiente figura), en general esto es lo que hacen métodos numéricos como MCMC, encontrar de forma automática la regiones de mayor densidad de probabilidad. Esa misma aproximación puede conducir a errores gruesos en el cálculo del likelihood marginal</p>
<center>
<img src="img/grid.png" width="800">
</center>
<p>Para algunos problemas es posible calcular la distribución a posteriori de forma analítica. Esto ya lo vimos para el modelo beta-binomial donde la distribución a posteriori es:</p>
<p><span class="math display">\[
p(\theta \mid y) \propto \operatorname{Beta}(\alpha_{a priori} + y, \beta_{a priori} + N - y)
\]</span></p>
<p>Para esos casos suele ser posible también calcular el marginal likelihood de forma analítica.</p>
<p>Pero en general no tenemos expresiones analíticas y entonces debemos confiar en métodos numéricos.</p>
</section>
<section id="calculando-la-distribución-a-posteriori" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="calculando-la-distribución-a-posteriori"><span class="header-section-number">4.8</span> Calculando la distribución a posteriori</h2>
<p>Hay muchas formas de calcular la distribución a posteriori</p>
<ul>
<li><font color="gray"> Conjugación </font></li>
<li><font color="gray"> Método de Laplace </font></li>
<li><font color="gray"> Aproximación de Laplace Anidada Integrada (INLA) </font></li>
<li><font color="gray"> Inferencia Variacional (VI) </font></li>
<li>Markov Chain Monte Carlo (MCMC)</li>
<li><font color="gray"> Sequential Monte Carlo </font></li>
<li>…</li>
</ul>
<p>Por ahora solo hablaremos de los métodos MCMC ya que, por el momento, son los métodos más generales. Pero para entender de forma más simple que es lo que hacen estos métodos conviene empezar desde otro método, conocido como método de la grilla.</p>
<section id="markov-chain-monte-carlo-mcmc" class="level3" data-number="4.8.1">
<h3 data-number="4.8.1" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc"><span class="header-section-number">4.8.1</span> Markov Chain Monte Carlo (MCMC)</h3>
<p>Esta es una familia muy extensa de métodos utilizados para resolver muchos problemas, entre los que se encuentra el cálculo de la distribución a posteriori. Conceptualmente se puede pensar a estos métodos como generalizaciones del método de la grilla, ya que también se basan en la posibilidad de realizar evaluaciones punto a punto del prior y likelihood. La diferencia crucial es que en vez de utilizar una grilla predefinida el método realiza evaluaciones que progresivamente se concentran en regiones de alta probabilidad. No solo eso si no que eventualmente el método devolverá muestras de forma proporcional a la probabilidad a posteriori. Es decir si una región es 3 veces más probable que otra obtendremos 3 veces más muestras de esa región que de la otra.</p>
<p>A muy grandes rasgos, y dado un punto inicial arbitrario, los métodos MCMC, constan de dos pasos.</p>
<ol type="1">
<li>Generar un nuevo punto a partir de perturbar uno preexistente.</li>
<li>Aceptar o rechazar ese nuevo punto de forma probabilista y comparando la probabilidad del punto preexistente y del nuevo punto.</li>
</ol>
<p>Esta es esencialmente la receta, la forma exacta en que hacemos cada uno de estos pasos define los distintos métodos dentro de la familia MCMC. Veamos uno de los más sencillos de entender y de implementar.</p>
</section>
<section id="metropolis-hastings" class="level3" data-number="4.8.2">
<h3 data-number="4.8.2" class="anchored" data-anchor-id="metropolis-hastings"><span class="header-section-number">4.8.2</span> Metropolis-Hastings</h3>
<p>Metropolis-Hastings no es un algoritmo muy moderno o particularmente eficiente, pero Metropolis-Hastings es simple de entender y también proporciona una base para comprender métodos más sofisticados y poderosos.</p>
<p>El algoritmo Metropolis-Hasting se define de la siguiente manera:</p>
<ol type="1">
<li>Inicialice el valor del parámetro <span class="math inline">\(\boldsymbol{X}\)</span> en <span class="math inline">\(x_i\)</span></li>
<li>Utilice una distribución de propuesta <span class="math inline">\(q(x_{i + 1} \mid x_i)\)</span> para generar un nuevo valor <span class="math inline">\(x_{i + 1}\)</span></li>
<li>Calcule la probabilidad de aceptar el nuevo valor como:</li>
</ol>
<p><span class="math display">\[
p_a (x_{i + 1} \mid x_i) = \min \left(1, \frac{p(x_{i + 1}) \; q(x_i \mid x_{i + 1})} {p(x_i) \; q (x_{i + 1} \mid x_i)} \right)
\]</span></p>
<ol start="4" type="1">
<li>Si <span class="math inline">\(p_a &gt; R\)</span> donde <span class="math inline">\(R \sim \mathcal{U}(0, 1)\)</span>, guarde el nuevo valor; de lo contrario, guarde el anterior.</li>
<li>Iterar de 2 a 4 hasta que se haya generado una muestra <em>suficientemente grande</em></li>
</ol>
<p>El algoritmo Metropolis es muy general y se puede usar en aplicaciones no Bayesianas, pero para la presente discusión, <span class="math inline">\(p(x_i)\)</span> es la densidad del posterior evaluada en el valor del parámetro <span class="math inline">\(x_i\)</span>. Una forma de simplificar un poco el método es notar que si <span class="math inline">\(q\)</span> es una distribución simétrica, los términos <span class="math inline">\(q(x_i \mid x_{i + 1})\)</span> y <span class="math inline">\(q(x_{i + 1} \mid x_i)\)</span> se cancelarán (conceptualmente significa que es igualmente probable que vayamos de <span class="math inline">\(x_{i+1}\)</span> a <span class="math inline">\(x_i\)</span> o de <span class="math inline">\(x_{i}\)</span> a <span class="math inline">\(x_{i+1}\)</span>), dejando solo un cociente entre el posterior evaluado en dos puntos. Este algoritmo siempre aceptará moverse de una región de baja probabilidad a una más alta y aceptará probabilísticamente moverse de una región de alta a una baja probabilidad.</p>
<p>¡Otra observación importante es que el algoritmo Metropolis-Hastings no es un método de optimización! No nos importa encontrar el valor del parámetro con la máxima probabilidad, queremos <em>explorar</em> la distribución <span class="math inline">\(p\)</span>. Intuitivamente esto es posible ya que en general el sistema puede moverse de una región de alta probabilidad a una región de menor probabiliad. Estrictamente MH cumple con la condición de balance detallado, que se describe como:</p>
<p><span class="math display">\[
p_i t_{ij} = p_j t_{ji}
\]</span></p>
<p>En palabras, la probabilidad de estar en un estado <span class="math inline">\(i\)</span> por la probabilidad de moverse del estado <span class="math inline">\(i\)</span> al <span class="math inline">\(j\)</span> es igual que la probabilidad de estar en el estado <span class="math inline">\(j\)</span> y moverse del <span class="math inline">\(j\)</span> al <span class="math inline">\(i\)</span>.</p>
<p>La condición de balance detallado es suficiente para garantizar que un algoritmo de MCMC es capaz de muestrear de forma correcta de una distribución arbitraria dada una cantidad infinita de pasos. Entonces una forma de probar que un algortimo de muestre es teóricamente válido es demostrar que cumple con el balance detallado.</p>
<p>Para hacer las cosas más concretas, intentemos resolver el modelo Beta-Binomial.</p>
<span class="math display">\[\begin{aligned}
    \theta \sim &amp;\; \text{Beta}(\alpha, \beta) \\
    Y \sim &amp;\; \text{Bin}(n=1, p=\theta)
\end{aligned}\]</span>
<p>Este modelo tiene solución analítica. Pero supongamos que no sabemos cómo calcularla, y por lo tanto, implementaremos el algoritmo Metropolis-Hastings usando Python.</p>
<div id="2be96e1a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a><span class="kw">def</span> post(θ, Y, α<span class="op">=</span><span class="dv">1</span>, β<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb36-2"><a href="#cb36-2"></a>    <span class="cf">if</span> <span class="dv">0</span> <span class="op">&lt;=</span> θ <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb36-3"><a href="#cb36-3"></a>        prior <span class="op">=</span> pz.Beta(α, β).pdf(θ)</span>
<span id="cb36-4"><a href="#cb36-4"></a>        like  <span class="op">=</span> pz.Bernoulli(θ).pdf(Y).prod()</span>
<span id="cb36-5"><a href="#cb36-5"></a>        prob <span class="op">=</span> like <span class="op">*</span> prior</span>
<span id="cb36-6"><a href="#cb36-6"></a>    <span class="cf">else</span>:</span>
<span id="cb36-7"><a href="#cb36-7"></a>        prob <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb36-8"><a href="#cb36-8"></a>    <span class="cf">return</span> prob</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>También necesitamos datos, por lo que generaremos algunos datos falsos aleatorios para este propósito.</p>
<div id="d04bff59" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a>Y <span class="op">=</span> pz.Bernoulli(<span class="fl">0.7</span>).rvs(<span class="dv">20</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Y finalmente ejecutamos nuestra implementación del algoritmo Metropolis-Hastings:</p>
<div id="6a69434c" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>n_iters <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>can_sd <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb38-3"><a href="#cb38-3"></a>α <span class="op">=</span> β <span class="op">=</span>  <span class="dv">1</span></span>
<span id="cb38-4"><a href="#cb38-4"></a>θ <span class="op">=</span> <span class="fl">0.5</span> </span>
<span id="cb38-5"><a href="#cb38-5"></a>trace <span class="op">=</span> {<span class="st">"θ"</span>:np.zeros(n_iters)}</span>
<span id="cb38-6"><a href="#cb38-6"></a>p2 <span class="op">=</span> post(θ, Y, α, β)</span>
<span id="cb38-7"><a href="#cb38-7"></a></span>
<span id="cb38-8"><a href="#cb38-8"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(n_iters):</span>
<span id="cb38-9"><a href="#cb38-9"></a>    θ_can <span class="op">=</span> stats.norm(θ, can_sd).rvs(<span class="dv">1</span>)</span>
<span id="cb38-10"><a href="#cb38-10"></a>    p1 <span class="op">=</span> post(θ_can, Y, α, β)  </span>
<span id="cb38-11"><a href="#cb38-11"></a>    pa <span class="op">=</span> p1 <span class="op">/</span> p2</span>
<span id="cb38-12"><a href="#cb38-12"></a></span>
<span id="cb38-13"><a href="#cb38-13"></a>    <span class="cf">if</span> pa <span class="op">&gt;</span> stats.uniform(<span class="dv">0</span>, <span class="dv">1</span>).rvs(<span class="dv">1</span>):</span>
<span id="cb38-14"><a href="#cb38-14"></a>        θ <span class="op">=</span> θ_can</span>
<span id="cb38-15"><a href="#cb38-15"></a>        p2 <span class="op">=</span> p1</span>
<span id="cb38-16"><a href="#cb38-16"></a></span>
<span id="cb38-17"><a href="#cb38-17"></a>    trace[<span class="st">"θ"</span>][<span class="bu">iter</span>] <span class="op">=</span> θ</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_17064/2595604670.py:17: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)
  trace["θ"][iter] = θ</code></pre>
</div>
</div>
<p>En la línea 9 del bloque de código anterior generamos una propuesta muestreando una distribución Normal con desviación estándar <code>can_sd</code>. En la línea 10 evaluamos el posterior en el nuevo valor generado <code>θ_can</code> y en la línea 11 calculamos la probabilidad de aceptación. En la línea 17 guardamos un valor de <code>θ</code> en el array <code>trace</code>. Dependiendo del resultado de la comparación en la línea 13, el valor guardado será nuevo o repetiremos el anterior.</p>
<p>El primer panel de la siguiente figura muestra cada valor muestreado en cada paso, y el panel de la derecha el histograma de esos valores. El resultado parece razonable. Nada mal para unas pocas lineas de código!</p>
<div id="325fb0e9" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-2"><a href="#cb40-2"></a>axes[<span class="dv">0</span>].plot(trace[<span class="st">'θ'</span>])</span>
<span id="cb40-3"><a href="#cb40-3"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'θ'</span>, rotation<span class="op">=</span><span class="dv">0</span>, labelpad<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb40-4"><a href="#cb40-4"></a>axes[<span class="dv">1</span>].hist(trace[<span class="st">'θ'</span>], orientation<span class="op">=</span><span class="st">"horizontal"</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb40-5"><a href="#cb40-5"></a>axes[<span class="dv">1</span>].set_xticks([])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-33-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><a href="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&amp;target=banana">Acá</a> pueden ver una versión interactiva de un Metropolis-Hastings</p>
</section>
<section id="mh-adaptativo" class="level3" data-number="4.8.3">
<h3 data-number="4.8.3" class="anchored" data-anchor-id="mh-adaptativo"><span class="header-section-number">4.8.3</span> MH adaptativo</h3>
<p>Las garantías teóricas de MH y otros MCMC son válidas cuando la cantidad de pasos tiende a infinito. Si tomáramos infinitas muestras, cualquier distribución de propuesta nos conduciría al mismo resultado. Tampoco importaría el punto inicial.</p>
<p>Sin embargo, no podemos tomar infinitas muestras y por lo tanto la eficiencia puede cambiar drásticamente de acuerdo a la distribución de propuesta que utilicemos y en menor medida al punto inicial. Además, la eficiencia de una distribución de propuesta dada dependerá de la geometría de la distribución a posteriori. Por ejemplo, si la distribución a posteriori es muy alargada en una dirección y muy angosta en otra, una distribución de propuesta que isotrópica será ineficiente. Es decir no existe una única distribución de propuesta que sea eficiente para todos los problemas.</p>
<p>Varios estudios teóricos muestran que bajos ciertas condiciones la tasa de aceptación óptima para MH es de 0.4 para distribuciones a posterirori unidimensionales y <span class="math inline">\(\approx 0.234\)</span> en el límite de dimensión infinita. En la práctica “infinito suele ser <span class="math inline">\(\lessapprox 10\)</span>”. Estos resultados teóricos proporcionan una guía para diseñar métodos adatativos. Es decir podemos agregar al algortimo una primer fase the ajuste (tuning) donde se modifica algún aspecto de la distribución de propuesta de forma tal de lograr tasas de aceptación entre 0.23 y 0.4.</p>
<p>Existen muchos esquemas de ajuste uno común es usar como distribución de propuesta una gaussiana multivariada y ajustar la varianza de forma adaptativa. Muchas veces la matriz de covarianza usada es diagonal y se ajusta por separado cada componente. Estos esquemas adaptativos permiten que MH sea aplicado a una gran cantidad de problemas sin necesidad de realizar modificaciones al método.</p>
<p>Al usar métodos adaptativos hay que tomar alguno recaudos. Principalmente es importante destacar que las muestras generadas durante el ajuste no son muestras válidas. Esencialmente al cambiar lo hiper-parámetros del método, perdemos las garantías teóricas que aseguran que un MCMC sea valido. Es por ello que en la práctica se suele descartar las muestras generadas durante el ajuste. Vale aclarar que es posible diseñar esquemas de ajuste que no requieran descartar muestras, pero estos son más complejos y no son tan comunes.</p>
<p>Es posible tener que un algoritmo MCMC sea eficiente sin fase de ajuste, pero oso implica mucha suerte o que alguien se tomó el trabajo de ajusar el algoritmo a un caso particular.</p>
<p>En resumen, la fase de ajuste permite que el método MCMC se adapte a la geometría de la distribución a posteriori y por lo tanto permite generalizar estar métodos a una amplia variedad de problemas. Es por ello que los métodos MCMC a veces reciben el nombre de “motores de inferencia universal”. El nombre es bastante rimbomante pero refleja el hecho, de que al menos en teoría, es posible escribir un modelo Bayesiano arbitrario y resolverlo. Esta separación entre modelo e inferencia es un aspecto central de la programación probabilista, ya que saca el foco del proceso de inferencia en si y pone todo el peso en el modelado. En la realidad esto es una verdad a medias, o si se quiere una promesa. En la práctica los métodos de MCMC son muy útiles hasta que dejan de serlo. Por ello es que necesitamos de métodos de diagnóstico del muestreo.</p>
</section>
</section>
<section id="diagnóstico-del-muestreo" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="diagnóstico-del-muestreo"><span class="header-section-number">4.9</span> Diagnóstico del muestreo</h2>
<p>Un método de diagnóstico, evalua alguna propiedad esperada de una muestra y nos indica sobre posibles desviaciones entre lo observado y lo predicho por la teoría. Si el diagnóstico encuentra un problema, en general es que hay un problema. Pero si el diagnóstico no encuentra un problema, no quiere decir, estrictamente, que este no exista. Además, como veremos no existe un criterio claro de demarcación. Es el problema del pelado. Se estima que un humano tienen alrededor de 150000 cabellos en su cabeza. Alguien con 0 pelos es claramente un pelado. Pero es dificil establecer un número único y no arbitrario que divida pelados de no pelados.</p>
<section id="trace-plots" class="level3" data-number="4.9.1">
<h3 data-number="4.9.1" class="anchored" data-anchor-id="trace-plots"><span class="header-section-number">4.9.1</span> Trace plots</h3>
<p>Este es un gráfico muy común. Para cada parámetro graficamos su valor (eje-y) en cada iteración (eje-x). Lo esperable es no ver ningún patrón, solo ruido como en primer panel de la siguiente figura (marco turquesa).</p>
<center>
<img src="diapo/img/trace_single_good_bad.png" width="800">
</center>
<p>En cambio los otros tres paneles (marco magenta) muestran problemas. De izquierda a derecha y arriba a abajo:</p>
<ul>
<li><p>El segundo panel muestra que el muestreo es “pegajoso”, le toma muchos pasos a la cadena moverse de valores altos a valores bajos, es difícil predecir que sucedería si seguimos corriendo, la cadena se movería hacia arriba nuevamente, se estabilizaría en valos bajos, continuaría bajando aún más?</p></li>
<li><p>El tercer panel muestra una cadena menos “pegajosa”, pero también daría la impresión que aún no ha terminado de estabilizarse</p></li>
<li><p>El último panel, en cambio, muestra que hay una región donde el sampler se mueve bien, pero cada tanto “salta” a estados donde se queda atascado. Quizá esto se deba a una distribución a posteriori multimodal o dificultades en el sampler para explorar regiones con distinta curvatura.</p></li>
</ul>
<p>En general combine correr más de una cadena de MCMC empezando de puntos distintos. Lo esperable es que no podamos distinguir diferencias entre cadenas. Un traceplot con 4 cadenas superpuestas se ve así lo cual es un poco dificil de interpretar.</p>
<center>
<img src="diapo/img/trace_multiple_good.png" width="800/">
</center>
<p>ArviZ permite graficar trace-plots usando la función <code>az.plot_trace()</code>. Por defecto obtenemos el trace a la derecha y un KDE (para variables continuas) y un histograma (para discretas) a la izquierda</p>
<center>
<img src="diapo/img/trace_multiple_good_arviz.png" width="900">
</center>
<p>El KDE o histograma, también nos puedo ayudar a interpretar si hay problemas. Ya que esperamos que las distribuciones sean similares, más allá de un poco de ruido producto del número finito de muestras.</p>
</section>
<section id="rank-plots" class="level3" data-number="4.9.2">
<h3 data-number="4.9.2" class="anchored" data-anchor-id="rank-plots"><span class="header-section-number">4.9.2</span> Rank plots</h3>
<p>Los trace plots son muy comunes, pero existe una alternativa más moderna llamada rank plots. La idea básica es la siguiente. Para un parámetro tomamos todas las cadenas y ordenamos los valores de menor a mayor y les asignamos un rango es decir al valor más bajo le ponemos 0, al que sigue 1 y así hasta llegar a un número que será igual a la cantidad de muestras totales (cantidad de cadenas multiplicado por la cantidad de muestras por cadena). Luego reagrupamos los rankings según las cadenas que les dieron origen y para cada cadena hacemos un histograma. Si las cadenas fuesen indistinguibles esperaríamos que los histogramas sean uniformes. Ya que no hay razón para que una cadena tenga más rankings bajos (o medios o altos) que el resto.</p>
<p>La siguiente figura muestra 4 ejemplos, donde solo uno (marco cyan) no muestra problemas</p>
<center>
<img src="diapo/img/rankbar_single_good_bad.png" width="800">
</center>
<p>En ArviZ los rank plots se pueden obtener con la función <code>az.plot_rank</code> o pasando un argumento a plot_trace <code>az.plot_trace(⋅, kind="rank_bars")</code></p>
</section>
<section id="hat-r-r-sombrero" class="level3" data-number="4.9.3">
<h3 data-number="4.9.3" class="anchored" data-anchor-id="hat-r-r-sombrero"><span class="header-section-number">4.9.3</span> <span class="math inline">\(\hat R\)</span> (R sombrero)</h3>
<p>Los gráficos suelen ser útiles para descubrir patrones, pero a veces queremos números, por ejemplo al evaluar rápidamente una lista de cientos, o miles, de parámetros. <span class="math inline">\(\hat R\)</span> es la respuesta a la pregunta ¿Lograron las cadenas <em>mezclarse</em> adecuadamente?</p>
<p>En la literatura podrán encontrar que hay varias versiones de este diagnóstico, en texto viejos puede aparecer como Gelman-Rubin, por los nombres de los autores de la primer versión de este diagnóstico. Pero hoy en día contamos con versiones más modernas y más robustas y generales de las versiones anteriores. La versión implementada en ArviZ es la última versión de este diagnóstico y su cálculo tiene varios pasos. Pero la idea central es que compara la varianza <em>entre</em> cadenas con la varianza <em>dentro</em> de cada cadena. Si las cadenas provienen de la misma distribución entonces <span class="math inline">\(\hat R = 1\)</span>. En la práctica se suele considerar que <span class="math inline">\(\hat R \lessapprox 1.01\)</span> son seguros. Pero acá retomamos el problema del pelado. El valor de corte es arbitrario, tiene cierto sustento empírico pero es arbitrario. Por ejemplo en la primer fase de modelado valores más altos como <span class="math inline">\(\hat R \approx 1.1\)</span> pueden estár bien. Además el valor de <span class="math inline">\(\hat R \lessapprox 1.01\)</span> es razonable cuando tenemos unos pocos parámetros pero es esperable que si tenemos muchos paramétros varios de ellos tengan valores de <span class="math inline">\(\hat R\)</span> mayores a 1.01. Un caso particular que veremos más adelante es el de BART, un método no paramétrico de regresión. Es conocido que BART suele generar valores de <span class="math inline">\(\hat R\)</span> relativamente alto y aún ser útil.</p>
<p>La siguiente animación muestra, en el panel superior, 4 cadenas que progresivamente se van haciendo más similares. En el panel inferior tenemos 2 Gaussianas centradas en 0, una de ellas con las varianza intra cadena o y la otra entre cadenas.</p>
<center>
<img src="diapo/img/r_hat.gif" width="900">
</center>
<p>Usando ArviZ podemos obtener <span class="math inline">\(\hat R\)</span> usando <code>az.rhat(⋅)</code>, <code>az.summary(⋅)</code> y <code>az.plot_forest(⋅, r_hat=True)</code></p>
</section>
<section id="gráfico-de-autocorrelación" class="level3" data-number="4.9.4">
<h3 data-number="4.9.4" class="anchored" data-anchor-id="gráfico-de-autocorrelación"><span class="header-section-number">4.9.4</span> Gráfico de autocorrelación</h3>
<p>Idealmente, nos gustaría poder trabajar con muestras independientes e idénticamente distribuidas (iid). Por construcción, las muestras MCMC están correlacionadas, ya que la probabilidad de aceptar el paso <span class="math inline">\(i\)</span> depende del paso <span class="math inline">\(i-1\)</span>. En la práctica, queremos muestras con baja autocorrelación.</p>
<p>En ArviZ obtenemos este gráfico con la función <code>az.plot_autocorr()</code></p>
<div id="73bdb4a8" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>cadenas_defectuosas <span class="op">=</span> {<span class="st">"cadenas_defectuosas"</span>: np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>).reshape(<span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>)}</span>
<span id="cb41-2"><a href="#cb41-2"></a>az.plot_autocorr(cadenas_defectuosas)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'np' is not defined</code></pre>
</div>
</div>
<div id="dbffd34e" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a>cadenas_adecuadas <span class="op">=</span> {<span class="st">"cadena_adecuadas"</span>: pz.Uniform(<span class="dv">0</span>, <span class="dv">1</span>).rvs(size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">500</span>))}</span>
<span id="cb43-2"><a href="#cb43-2"></a>az.plot_autocorr(cadenas_adecuadas)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-35-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="tamaño-de-muestra-efectivo-ess" class="level3" data-number="4.9.5">
<h3 data-number="4.9.5" class="anchored" data-anchor-id="tamaño-de-muestra-efectivo-ess"><span class="header-section-number">4.9.5</span> Tamaño de muestra efectivo (ESS)</h3>
<p>Como las muestras de un MCMC están correlacionadas la cantidad de información “útil” es menor que una muestra del mismo tamaño pero iid.</p>
<p>La siguiente figura muestra la distribución correcta como una linea punteada y un histograma de muestras que sucesivamente van aumento. Podemos ver que en el panel de arriba, donde la muestra no están correlacionadas, obtenemos una mejor representación de la distribución real con un menor número de muestras que en el panel inferior donde las muestras si lo están.</p>
<br> <br>
<center>
<img src="diapo/img/ess.gif" width="600">
</center>
<p>Podemos estimar el <strong>tamaño de muestra efectivo</strong> (ESS), es decir, el tamaño de una muestra con la cantidad equivalente de información pero sin autocorrelación. Esto es útil para determinar si el tamaño de muestra que tenemos es lo suficientemente grande. Se recomienda que el ESS sea superior a 100 por cadena. Es decir para para 4 cadenas queremos un mínimo de 400.</p>
<p>Con ArviZ podemos obtenerlo <code>az.ess(⋅)</code>, <code>az.summary(⋅)</code> y <code>az.plot_forest(⋅, ess=True)</code></p>
<div id="8d6896b9" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a>pd.concat((az.ess(cadenas_defectuosas).to_pandas(),</span>
<span id="cb44-2"><a href="#cb44-2"></a>           az.ess(cadenas_adecuadas).to_pandas()))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>NameError: name 'pd' is not defined</code></pre>
</div>
</div>
<p>Vemos que <code>az.summary(⋅)</code> devuelve dos valores de ESS, <code>ess_bulk</code> y <code>ess_tail</code>. Esto se debe a que, distintas regiones del espacio de los parámetros pueden tener distinto valor de ESS, ya que no todas las regiones son muestreadas con la misma eficiencia. Intuitivamente uno puede pensar que al muestrear una distribución como una Gaussiana es más fácil obtener mejor calidad de muestra alrededor de la media que de las colas, simplemente por que tenemos más muestras de esa región.</p>
<div id="b86b18da" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a>pd.concat([az.summary(cadenas_adecuadas, kind<span class="op">=</span><span class="st">"diagnostics"</span>),</span>
<span id="cb46-2"><a href="#cb46-2"></a>           az.summary(cadenas_defectuosas, kind<span class="op">=</span><span class="st">"diagnostics"</span>)])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si las muestras de MCMC las vamos a usar para calcular valores centrales como medias o medianas entonces tenemos que asegurarnos que el <code>ess_bulk</code> sea lo suficientemente algo, en cambio, si queremos calcular intervalos como un HDI 95% hay que asegurarse que <code>ess_tail</code> sea adecuado.</p>
<p>ArviZ ofrece varias funciones vinculadas al ESS. Por ejemplo si queremos evaluar el desempeño del sampler para varias regiones al mismo tiempo podemos usar <code>az.plot_ess</code>.</p>
<div id="99f14b7b" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb47-2"><a href="#cb47-2"></a>az.plot_ess(cadenas_adecuadas, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb47-3"><a href="#cb47-3"></a>az.plot_ess(cadenas_defectuosas, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-38-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Una forma simple de aumentar el ESS es aumentar la cantidad de muestras, pero podría darse el caso que el ESS crezca muy lento con el número de muestras, por lo que aún si aumentáramos 10 veces la cantidad de muestras estaríamos por debajo de lo requerido. Una forma de estimar “cuanto nos falta” es usar <code>az.plot_ess(⋅, kind="evolution")</code>. Este gráfico nos muestra como fue cambiando el ESS con cada muestra, lo que nos permite hacer proyecciones. En el siguiente ejemplo vemos que para <code>cadenas_adecuadas</code> el ESS crece linealmente con el número de muestras mientras que para <code>cadenas_defectuosas</code> no crece para nada. Este último caso no hay esperanzas de mejorar el ESS simplemente aumentando la cantidad de muestras.</p>
<div id="e9d08319" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb48-2"><a href="#cb48-2"></a>az.plot_ess(cadenas_adecuadas, kind<span class="op">=</span><span class="st">"evolution"</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb48-3"><a href="#cb48-3"></a>az.plot_ess(cadenas_defectuosas,  kind<span class="op">=</span><span class="st">"evolution"</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-39-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="error-estándar-del-monte-carlo-mcse" class="level3" data-number="4.9.6">
<h3 data-number="4.9.6" class="anchored" data-anchor-id="error-estándar-del-monte-carlo-mcse"><span class="header-section-number">4.9.6</span> Error estándar del Monte Carlo (MCSE)</h3>
<p>Una ventaja del ESS es que no tiene escala, da igual si un parámetro varía entre 0.1 y 0.2 y otro entre -2000 y 5000, un ESS de 400 tiene el mismo significado en ambos casos. En modelos con muchos parámetros rápidamente podemos indentificar cuales parámetros son más problemáticos. Sin embargo, a la hora de reportar resultados no es muy informativo saber si el ESS fue de 1372 o 1501. En cambio nos gustaría saber el orden del error que estamos cometiendo al aproximar la distribución a posteriori. Esa información la da el <strong>error estándar del Monte Carlo</strong> (MCSE). Al igual que el ESS, el MCSE tiene en cuenta la autocorrelación de las muestras. Este error debe estar por debajo de la precisión deseada en nuestros resultados. Es decir si para un parámetro el MCSE es 0.1, no tiene sentido reportar que la media de ese parámetro es 3.15. Ya que tranquilamente el valor correcto podría estar entre 3.4 y 2.8.</p>
<p>Una de las cantidades devueltas por <code>az.summary(⋅)</code> es mc_error.</p>
</section>
<section id="montecarlo-hamiltoniano-hmc" class="level3" data-number="4.9.7">
<h3 data-number="4.9.7" class="anchored" data-anchor-id="montecarlo-hamiltoniano-hmc"><span class="header-section-number">4.9.7</span> Montecarlo Hamiltoniano (HMC)</h3>
<p>Supongamos que queremos simular el movimiento de una partícula sobre una superficie. Si queremos que nuestra simulación sea fidedigna necesitamos describirla usando las leyes de la física. Una forma de describir el movimiento de la partícula es utilizando lo que se conoce como mecánica Hamiltoniana. Sin entrar en detalles diremos que un Hamiltonianio es una descripción de la energía total de un sistema físico. Si asumimos que no hay fricción ni ninguna otra forma de “disipar” energía podemos describir el compartamiento de partícula sobre una superficie con solo 2 componentes. La energía cinética y la potencial.</p>
<p>La energía cinética es la energía asociada al movimiento de la partícula y la potencial es la energía asociada a la posición de la partícula. Supongamos que nuestra superficie tiene una forma de U. Y nuestra partícula está en la parte más baja. Esa partícula tendrá energía potencial 0 y si está quieta energía cinética 0. Nuestra simulación será terriblemente aburrida, ya que la partícula permanecerá en esa posición para siempre. Para ponerle algo de diversión podemos empujar la partícula, es decir le impartimos momentum, la partícula se moverá hacia arriba perdiendo cada vez más energía cinética (cada vez se moverá más lento) y ganando potencial, hasta que llegue a un punto en que se detenga, en ese punto toda la energía cinética se habrá convertido en potencial y la partícula comenzara a caer y la energía potencial se convertirá en cinética. Como no hay fricción la energía total del sistema se mantiene constante. Y todo los cambios en la energía cinética son compensados por cambios en la energía potencial.</p>
<p>Para un sistema como el que acabamos de describir la energía total será:</p>
<p><span class="math display">\[
\underbrace{H(\overbrace{\mathbf{q}}^{\text{posición}}, \overbrace{\mathbf{p}}^{\text{momemtum}})}_{\text{Hamiltoniano}}  = \underbrace{K(\mathbf{p}, \mathbf{q})}_{\text{Energía cinética}} + \underbrace{V(\mathbf{q})}_{\text{Energía potencial}}
\]</span></p>
<p>Desde un punto de vista matemático da igual si la superficie es una U, una montaña rusa, un satélite en órbita o incluso una distribución a posteriori. En todos estos casos podemos describir el movimiento de la partícula usando un Hamiltoniano.</p>
<p>La siguiente figura muestra un ejemplo de un distribución a posteriori 2D y multiples trayectorias de una partícula. En la figura se puede ver que iniciamos una simulación, la detenemos, marcamos un punto y empezamos desde ese punto empujando de vuelta la particula con una fuerza y direcciones arbitrarias.</p>
<center>
<img src="diapo/img/Hamiltonian_Monte_Carlo.gif" width="400">
</center>
<p>En el caso de la distribución a posteriori la posición de la particula son los valores de los parámetros. La energía potencial vendrá dada por la densidad de probabilidad a posteriori, estrictamente por el menos logaritmo de esa densidad. Y el momentum es una variable auxiliar. Es decir una variable completamente inventada, pero útil por que nos permite calcular el hamiltoniano.</p>
<p><span class="math display">\[
H(\mathbf{q}, \mathbf{p}) = \overbrace{-\log p(\mathbf{p} \mid \mathbf{q})}^{K(\mathbf{p}, \mathbf{q})} \overbrace{- \log p(\mathbf{q})}^{ + V(\mathbf{q})}
\]</span></p>
<p>Fijensé que en este punto no estamos haciendo ninguna analogía, estrictamente un Hamiltonian MonteCarlo es un método que simula el movimiento de una partícula en un espacio de parámetros.</p>
<p>A grandes rasgos un HMC tiene dos pasos que se repiten hasta obtener la cantidad de muestras necesarias:</p>
<ol type="1">
<li>Generar un nuevo punto a partir del hamiltoniano</li>
<li>Aceptar o rechazar ese nuevo punto según el criterio de metropolis.</li>
</ol>
<p>Para generar mejor intuición recomiendo jugar con ese <a href="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=NaiveNUTS&amp;target=banana">demo</a></p>
</section>
<section id="propuestas-aleatorias-vs-hamiltonianos" class="level3" data-number="4.9.8">
<h3 data-number="4.9.8" class="anchored" data-anchor-id="propuestas-aleatorias-vs-hamiltonianos"><span class="header-section-number">4.9.8</span> Propuestas aleatorias vs hamiltonianos</h3>
<p>Por qué es buena idea usar el Hamiltoniano? Porque estamos explorando la distribución a posteriori siguiendo una representación fidedigna de la misma. OK, esto es cierto pero no genera demasiada intuición. Veamos un par de enfoques alternativos.</p>
<p>En un MH la propuesta es aleatoria, es como querer encontrar algo en una habitación desconocida a oscuras, hay que ir a tientas. Si la habitación es pequeña y simple (cuadrada, con pocos muebles, escaleras etc) hacerlo a ciegas no será tarea demasiado compleja. Sin embargo con el Hamiltoniano es como tener una linterna, ahora podemos ver, al menos localmente, que hay en la habitación, por lo que recorrerla será más eficiente.</p>
<p>Vamos con otra explicación, para resolver un hamiltoniano necesitamos calcular derivadas, las derivadas nos dan información sobre la curvatura de una función, por ejemplo el cálculo de la primer derivada en un punto nos dice hacia donde (de)crece una función. Si siguiéramos la derivada hacia donde crece la función, eventualmente llegaríamos a un máximo (asumiendo que este existe). Esto se llama maximizar una función y de hecho muchos métodos de minimización de funciones como los encontrados en <a href="https://docs.scipy.org/doc/scipy/reference/optimize.html">SciPy.optimize</a> utilizan derivadas. Al agregar el <em>momemtum</em> podemos hacer algo más interesante, no solo podemos encontrar máximos, también podemos escapar de ellos. Esto nos permite obtener puntos de toda la distribución a posteriori de forma eficiente. Esto es importante en estadística Bayesiana, ya que no solo queremos el máximo, si no una descripción de toda la distribución a posteriori.</p>
<center>
<img src="diapo/img/hmc_landscape.gif" width="700">
</center>
</section>
<section id="hmc-dinámico-y-adaptativo" class="level3" data-number="4.9.9">
<h3 data-number="4.9.9" class="anchored" data-anchor-id="hmc-dinámico-y-adaptativo"><span class="header-section-number">4.9.9</span> HMC dinámico y adaptativo</h3>
<p>Un HMC tiene varios hipeparámetros, por ejemplo para simular una trayectoria tenemos que hacerlo de a pasos discretos, mientras más pequeños los pasos más fidedigna la simulación, pero también más costosa. Otro hiperparámetro es la longitud de cada simulación si esta es muy corta demoraremos mucho tiempo en explorar la distribución a posteriori, pero si está es muy larga corremos el riesgo de retornar al punto de partida, o sus inmediaciones, es decir habremos gastado un montón de recursos para terminar en el mismo lugar.</p>
<p>En la siguiente figura se muestran tres ejemplos. A la izquierda el paso es muy corto, por lo que la exploración no es eficiente, en el centro tenemos un mejor paso pero simulamos durante tanto tiempo que terminamos regresando al punto de partida. Finalmente y a la derecha tanto el paso como el tiempo de simulación son adecuados. Decimos que es adecuado, ya que logramos genear un nuevo punto que simultaneamente está alejado en el espacio de los parámetros, pero con alta probabilidad de aceptación. De hecho en este ejemplo la probabilidad de aceptación es 1, ya que el valor de la pdf es el mismo para el punto de partida y para el punto final.</p>
<center>
<img src="img/hmc_1D.gif" width="900">
</center>
<p>Este es otro ejemplo, en cada caso se muestra una densidad de probabilidad que va de más probable (amarillo) a menos probable (violeta), las flechas naranjas indican la trayectoria calculada de a pasos. En en el primer caso vemos una trayectoria elíptica tan larga que vuelve al punto de partida. En el segundo ejemplo vemos que el paso no es adecuado, esto produce una simulación inestable que se manifiesta en <strong>divergencias</strong> de la trayectoria correcta. En este último caso, y como en el ejemplo anterior, vemos que tanto el paso como el tiempo de simulación son adecuamos y la propuesta genera un punto alejado en el espacio de los parámetros, pero con alta probabilidad de aceptación (1 en este caso).</p>
<center>
<img src="diapo/img/HMC_trayectoria.png" width="900">
</center>
<p>Las divergencias ocurren cuando hay cambios de “curvatura” demasiado bruscos. Es decir cuando la partícula pasa de zonas de baja densidad de probabilidad a zonas de alta densidad o viceversa. En estos casos el método de integración numérica que se utiliza para resolver el hamiltoniano no es suficientemente preciso. PyMC registra cuando las divergencias ocurren y como veremos más adelante, es posible utilizar las divergencias para diagnosticar problemas con el método de muestreo.</p>
<p>Al igual que en un MH adaptativo, en un HMC también necesitamos ajustar la matriz de covarianza, usualmente llamada Matriz de Masa (mass matrix). En HMC esta matriz es la que determina el momemtum.</p>
<p>Cuando los hiper-parámetros de un HMC son adecuados, el muestreo es muy eficiente. De hecho es mucho más eficiente que un MH. Los valores de los hiper-parámetros dependen esencialmente de la geometría de la distribución a posteriori, por lo que no existe un solo conjunto de hiper-parámetros mejor que los demás. Es por ello que en la práctica estos se calculan de forma adaptativa corriendo una cantidad de pasos de HMC los cuales se utilizan para ajustar eso hiper-parámetros automáticamente y luego se descartan.</p>
<p>NUTS (No U-Turn sampler), el sampler por defecto en PyMC es un HMC dinámico y adaptativo. El nombre proviene de una rutina del método que evita que las trayectorias den vueltas en U. Este método detecta en cada paso de si estamos retornando el punto de partida, de ser así detiene el paso, evalúa si aceptar o no y comienza un nuevo paso. Al evitar trayectoria que vuelven al punto de partida, NUTS es capaz de explorar la distribución a posteriori de forma más eficiente.</p>
</section>
<section id="diagnóstico-de-algoritmos-basados-en-gradiente" class="level3" data-number="4.9.10">
<h3 data-number="4.9.10" class="anchored" data-anchor-id="diagnóstico-de-algoritmos-basados-en-gradiente"><span class="header-section-number">4.9.10</span> Diagnóstico de algoritmos basados en gradiente</h3>
<p>Debido a su funcionamiento interno, algoritmos como NUTS ofrecen algunas pruebas específicas que no están disponibles para otros métodos. Generalmente estas pruebas son muy sensibles</p>
<p>Para ejemplificar esto vamos a cargar dos InferenceData de modelos pre-calculados. Los detalles de como se generaron estos idatas no son relevantes por el momento. Solo diremos que son dos modelos que son matemáticamente equivalente pero parametrizados de formas distintas. En este caso la parametrización afecta la eficiencia del sampler. El modelo <code>centrado</code> es muestreado de forma más eficiente que el modelo <code>no centrado</code>.</p>
<div id="87a258ff" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1"></a>idata_cm <span class="op">=</span> az.load_arviz_data(<span class="st">"centered_eight"</span>)</span>
<span id="cb49-2"><a href="#cb49-2"></a>idata_ncm <span class="op">=</span> az.load_arviz_data(<span class="st">"non_centered_eight"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="divergencias" class="level3" data-number="4.9.11">
<h3 data-number="4.9.11" class="anchored" data-anchor-id="divergencias"><span class="header-section-number">4.9.11</span> Divergencias</h3>
<p>Una ventaja de NUTS es que <em>falla con el estilo</em>. Esto sucede por ejemplo al intentar pasar de regiones de baja curvatura a regiones de alta curvatura. En estos casos las trayectorias numéricas pueden divergir. En esencia esto sucede porque en esos casos no existe un único conjunto de hiper-parámetros que permita el muestreo eficiente de ambas regiones. Por lo que una de la regiones es muestreada adecuandamente y cuando el sampler se mueve hacia la otra región falla. Las trayectorias numéricas divergentes son identificadores extremadamente sensibles de <em>vecindarios patológicos</em>.</p>
<p>El siguiente ejemplo muestra dos cosas el modelo <code>no centrado</code> muestra varias divergencias (círculos turquesas) agrupados en una región. En el modelo <code>centrado</code>, que no tiene divergencias, se puede ver que alrededor de esa misma región hay muestras para valores más pequeños de <code>tau</code>. Es decir el modelo <code>no centrado</code> falla en muestrear una región, pero al menos avisa que está teniendo problemas en muestrear esa región!</p>
<div id="95ba3d06" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), constrained_layout<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb50-2"><a href="#cb50-2"></a></span>
<span id="cb50-3"><a href="#cb50-3"></a></span>
<span id="cb50-4"><a href="#cb50-4"></a><span class="cf">for</span> ax, idata, nombre <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), (idata_cm, idata_ncm), (<span class="st">"centrado"</span>, <span class="st">"no_centrado"</span>)):</span>
<span id="cb50-5"><a href="#cb50-5"></a>    az.plot_pair(idata, var_names<span class="op">=</span>[<span class="st">'theta'</span>, <span class="st">'tau'</span>], coords<span class="op">=</span>{<span class="st">'school'</span>:<span class="st">"Choate"</span>}, kind<span class="op">=</span><span class="st">'scatter'</span>,</span>
<span id="cb50-6"><a href="#cb50-6"></a>                 divergences<span class="op">=</span><span class="va">True</span>, divergences_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C1'</span>},</span>
<span id="cb50-7"><a href="#cb50-7"></a>                 ax<span class="op">=</span>ax)</span>
<span id="cb50-8"><a href="#cb50-8"></a>    ax.set_title(nombre)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-41-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="784c2014" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a>az.plot_parallel(idata_cm, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="04_Flujo_de_trabajo_bayesiano_files/figure-html/cell-42-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="qué-hacer-cuando-los-diagnósticos-no-dan-bien" class="level2" data-number="4.10">
<h2 data-number="4.10" class="anchored" data-anchor-id="qué-hacer-cuando-los-diagnósticos-no-dan-bien"><span class="header-section-number">4.10</span> Qué hacer cuando los diagnósticos no dan bien?</h2>
<p><br></p>
<ul>
<li><p><font color="gray"> Más muestras o más pasos de tuning. Esto solo suele ser útil cuando los problemas son menores</font></p></li>
<li><p><font color="gray"> Burn-in. Los métodos MCMC, pueden demorar un tiempo en converger. En estos casos una solución simple es eliminar la primer porción de muestras, lo que se llama burnin. Software moderno como PyMC utiliza una cantidad de muestras para ajustar los hiper-parámetros de los métodos de muestreo. Por defecto esas muestras son eliminadas, por lo que en general no es necesario hacer burn-in manualmente. Pero lo mencionamos, ya que es una práctica que suele mencionarse en la literatura.</font></p></li>
<li><p><font color="gray"> Cambiar el método de muestreo! </font></p></li>
<li><p>Reparametrizar el modelo</p></li>
<li><p><font color="orange"> Mejorar las distribuciones <em>a priori</em> </font></p>
<ul>
<li>El <em>teorema popular</em> de la estadística computacional: Cuando tienes problemas computacionales, a menudo hay un problema con tu modelo. La recomendación NO es cambiar la distribución <em>a priori</em> para mejorar la calidad del muestreo. La recomendación es que si el muestreo es malo, quizá el modelo también lo sea. En ese caso, podemos pensar en mejorar el modelo, una forma de mejorarlo es usar conocimiento previo para mejorar las distribuciones <em>a priori</em>.</li>
</ul></li>
<li><p>Algunos modelos pueden expresarse en más de una forma, todas matemáticamente equivalentes. En esos casos, algunas parametrizaciones pueden ser más eficientes que otras. Por ejemplo, como veremos más adelante con modelos lineales jerárquicos.</p></li>
<li><p>En el caso de las divergencias, estas suelen eliminarse aumentando la tasa de aceptación (<code>pm.sample(..., target_accept=x)</code> x&gt;0.8)</p></li>
<li><p>Leer los mensajes de advertencia y sugerencias de PyMC! ;-)</p></li>
</ul>
</section>
<section id="una-hoja-de-ruta-para-el-bayesian-workflow" class="level2" data-number="4.11">
<h2 data-number="4.11" class="anchored" data-anchor-id="una-hoja-de-ruta-para-el-bayesian-workflow"><span class="header-section-number">4.11</span> Una hoja de ruta para el Bayesian workflow</h2>
<p>A continuación se describen una serie de consejos y recomendaciones a modo de referencia rápida, sobre como encarar un análisis de datos y modelado. Las recomendaciones están orientadas a estadística Bayesiana en particular, pero pueden ser útiles al utilizar otro tipo de herramientas y modelos.</p>
<p>Las recomendaciones están escritas de forma lineal, pero en la práctica, es posible que debas retroceder uno o más pasos y, a veces, omitir pasos. Piensa en estas notas, no como una partitura de una pieza clásica que un violinista tiene que seguir exactamente, sino como la partitura que sigue un bajista de Jazz, eres libre de improvisar, reorganizar algunas partes y omitir otras, e incluso puedes agregar tus propias notas!</p>
<section id="resume-el-problema" class="level3" data-number="4.11.1">
<h3 data-number="4.11.1" class="anchored" data-anchor-id="resume-el-problema"><span class="header-section-number">4.11.1</span> Resume el problema</h3>
<p>Resuma los puntos clave de su problema y lo que le gustaría aprender de los datos. Piensa también en los demás, en lo que a tu jefe, cliente o colega le gustaría saber o aprender. No es necesario que esto sea muy completo; puedes revisar los objetivos más adelante, pero pueden ayudarte a organizar tus esfuerzos de modelado y evitar desviaciones excesivas.</p>
<p>Comuníquese con las partes interesadas cuando surjan dudas. Una respuesta de la persona adecuada, puede ahorrarnos horas de trabajo.</p>
<p>A veces no tendrás una idea clara de como enfocar un análisis; tu única expectativa podría ser obtener “algo útil” de un conjunto de datos, y eso está bien. Pero otras veces puede que incluso sepas qué tipo de modelo quieres, tal vez tu jefe te pidió explícitamente que ejecutaras tal o cual análisis. Si ya sabe qué tipo de modelo o herramienta es necesaria, pero no está muy familiarizado con el enfoque, busque qué métodos, métricas o visualizaciones son comunes para ese problema/datos y pida consejo a otros. Esto es más importante cuanto menos familiarizado esté con ese tipo de problema/datos. Si está familiarizado, es posible que ya sepa qué métodos, visualizaciones y resúmenes desea utilizar u obtener.</p>
<p>Escriba todos estos elementos preliminares como una lista de puntos a tener en cuenta o una hoja de ruta a seguir, en problemas complejos es fácil perder el foco. Esta lista puede ser revisada y actualizada de ser necesario, pero es importante establecer expectativas preliminares de lo que es deseable e ir actualizándolas según lo que sea posible. Quizá los datos no sirvan para contestar lo que nos interesa, o quizá necesitamos información extra o incluso puede que hayamos encontrado algo aún mas importante que lo que queríamos originalmente.</p>
</section>
<section id="familiarízate-con-los-datos" class="level3" data-number="4.11.2">
<h3 data-number="4.11.2" class="anchored" data-anchor-id="familiarízate-con-los-datos"><span class="header-section-number">4.11.2</span> Familiarízate con los datos</h3>
<p>Siempre es una buena idea realizar un análisis exploratorio de los datos. Modelar ciegamente tus datos te lleva a todo tipo de problemas. Tomarse el tiempo de mirar los datos es rara vez una pérdida de tiempo y al contrario suele ahorrarnos tiempo y proporcionar ideas útiles. A veces un buen resumen de los datos puede ser suficiente para nuestro propósito y hacer innecesarias otras aproximaciones más complejas como modelos estadísticos o de otros tipos.</p>
<p>La exploración de los datos debe conducir al entendimiento de los mismos. La forma exacta de lograr esto puede variar mucho de un conjunto de datos a otro y de un análisis a otro. Pero hay comprobaciones que suelen ser útiles, como comprobar si hay valores faltantes o errores en los datos. Es importantes considerar el contexto. Una valor de 200 es razonable si se refiere al peso en gramo de frutas, pero <em>problemático</em> si se refiere a registros de clima en el planeta Tierra. ¿Son correctos los tipos de datos? ¿Todos los valores que deberían ser números, son realmente números (generalmente enteros o flotantes) o son cadenas? ¿Qué variables son categóricas? ¿Cuáles son continuos? En esta etapa, es posible que deba realizar una limpieza de sus datos. Esto le ahorrará tiempo en el futuro. Y es posible que sea necesario comunicarse con quien generó o proveyó los datos, para asegurarse que estamos interpretando de forma correcta los datos y que cualquier procesamiento de los mismos es correcto.</p>
<p>Por lo general, también nos gustaría hacer algunos gráficos, histogramas, diagramas de caja, diagramas de dispersión, matrices de correlaciones, etc. Además de los gráficos, también calcule resúmenes numéricos, medias y medianas, para todos los datos, o agrupando los datos, etc.</p>
<p>Acá es importante llevar registro de lo que se va observando. Cualquier cosa que resulte llamativa, inesperada o que consideremos relevante para análisis posteriores. En esta etapa los gráficos y análisis no tienen que ser extremadamente prolijos. Después de todo es un análisis preliminar, pero mantener cierto orden es de utilidad. Un análisis más o menos ordenado puede ser suficiente para compartir en una discusión técnica con colegas o clientes. Incluso puede ser muy útil para nuestros yo futuro, nada tan frustrante como retomar un análisis luego de un par de meses y no entender que fue lo que nosotros mismos hicimos!</p>
</section>
<section id="cuente-una-historia-para-los-datos" class="level3" data-number="4.11.3">
<h3 data-number="4.11.3" class="anchored" data-anchor-id="cuente-una-historia-para-los-datos"><span class="header-section-number">4.11.3</span> Cuente una historia para los datos</h3>
<p>A menudo resulta útil pensar en cómo se podrían haber generado los datos. Esto suele denominarse <strong>proceso generador de datos</strong> o mecanismo de generación de datos. No necesitamos descubrir el mecanismo verdadero, muchas veces sólo necesitamos pensar en mecanismos plausibles.</p>
<p>Haz dibujos y trata de ser muy esquemático, garabatos y figuras geométricas deberían ser suficientes a menos que seas un buen dibujante. Este paso puede ser complicado, así que usemos un ejemplo. Digamos que estás estudiando los niveles de agua de un lago, piensa en qué hace que el agua aumente; lluvia, ríos, etc, y lo que la hace disminuir; evaporación, animales bebiendo agua, producción de energía, etc. Intenta pensar cuáles de estos elementos pueden ser relevantes y cuáles podrían ser insignificantes. Utilice todo el contexto que tenga para su problema.</p>
<p>Intente mantenerlo simple pero no más simple. Por ejemplo, un mecanismo podría ser “El peso de los cerdos aumenta cuando se les dá mayor cantidad de maíz”, ese es un buen mecanismo si todo lo que necesita predecir son sus ganancias por la venta de cerdos. Pero será un mecanismo demasiado simplista si se estudia la absorción intestinal a nivel celular.</p>
<p>Si se te ocurren historias alternativas y no sabes decidir cuál es mejor. ¡No te preocupes, enuméralas todos! ¡Quizás podamos usar los datos para decidir!</p>
</section>
<section id="escribe-un-modelo" class="level3" data-number="4.11.4">
<h3 data-number="4.11.4" class="anchored" data-anchor-id="escribe-un-modelo"><span class="header-section-number">4.11.4</span> Escribe un modelo</h3>
<p>Intente traducir el proceso generador de datos a un modelo. Si te sientes cómodo con las matemáticas, úsalas. Si prefiere una representación visual como un modelo gráfico, úsela. Si te gusta el código, hazlo. Los modelos incompletos están bien como primer paso. Por ejemplo, si usa código, siéntase libre de usar pseudocódigo o agregar comentarios para señalar los elementos que faltan mientras piensa en el modelo. Puedes refinarlo más tarde.</p>
<p>Intente comenzar de manera simple, no use jerarquías, preferible empezar con priors unidimensionales e independientes, omita interacciones para modelos lineales, etc. Si por alguna razón el punto de partida es un modelo complejo, está bien, puede pensar en formas de simplificarlo.</p>
<p>A veces, es posible que puedas utilizar un modelo de libro de texto estándar o algo que hayas visto en una publicación de blog o en una charla. Es común que para ciertos problemas la gente tienda a utilizar ciertos modelos “predeterminados”. Puede que sea un buen comienzo, o quizá todo lo que necesite. Mantenga las cosas simples, a menos que necesite algo más.</p>
<p>Este es un buen paso para pensar en tus antecedentes, no solo qué familia vas a utilizar, sino qué parámetros específicos. Si no tienes ni idea, utiliza un previo vago. Pero si tienes alguna información úsala. Intente codificar información muy general, como que este parámetro no puede ser negativo, o es probable que este parámetro sea más pequeño que esto o esté dentro de este rango. Busque la fruta madura, normalmente eso será suficiente. La excepción será cuando tengas suficiente información de buena calidad para definir un previo muy preciso, pero incluso entonces, eso es algo que puedes agregar más adelante.</p>
</section>
<section id="implementar-el-modelo" class="level3" data-number="4.11.5">
<h3 data-number="4.11.5" class="anchored" data-anchor-id="implementar-el-modelo"><span class="header-section-number">4.11.5</span> Implementar el modelo</h3>
<p>Escriba el modelo en un lenguaje de programación probabilístico. Si usó código en el ejemplo anterior, la línea entre este paso y el anterior puede ser difusa, está bien. Intente mantener el modelo simple al principio; agregaremos más capas más adelante a medida que sigamos iterando el flujo de trabajo. Empezar de forma sencilla normalmente le ahorra tiempo a largo plazo. Los modelos simples son más fáciles de depurar y depurar un problema a la vez es generalmente menos frustrante que tener que solucionar varios problemas antes de que nuestro modelo se ejecute.</p>
<p>Una vez que tenga un modelo, verifique que el modelo se compile y/o ejecute sin errores. Al depurar un modelo, especialmente en una etapa inicial del análisis, es posible que desee trabajar con un conjunto de datos reducido, por ej un 50% o 10% si el conjunto de datos es demasiado grande, o tal vez comenzar con solo unas pocas covariables, y luego agrega el resto. Esto puede ayudar a acelerar el modelo, para que pueda cambiarlo e iterar más rápido. Esto tiene la desventaja de que es posible que se pierdan los datos necesarios para descubrir algún patrón relevante, pero podría estar bien al principio, cuando suele ser el momento en el que cometerá la mayoría de los errores o tendrá mayores dudas sobre lo que está haciendo. En las primeras etapas, también puede reducir la cantidad de pasos de ajuste y muestreo.</p>
</section>
<section id="evaluar-la-distribución-predictiva-a-priori" class="level3" data-number="4.11.6">
<h3 data-number="4.11.6" class="anchored" data-anchor-id="evaluar-la-distribución-predictiva-a-priori"><span class="header-section-number">4.11.6</span> Evaluar la distribución predictiva a priori</h3>
<p>Generalmente es una buena idea generar datos a partir de la distribución predictiva a priori y compararlos con su conocimiento previo. ¿Está la mayor parte de la distribución simulada dentro de un rango razonable? ¿Existen valores extremos? Utilice valores de referencia como guía. Los valores de referencia son datos empíricos u observaciones históricas, normalmente serán valores mínimos, máximos o esperados. Evite comparar con los datos observados, ya que eso puede generar problemas si no es lo suficientemente cuidadoso.</p>
</section>
<section id="calcular-la-distribución-a-posteriori" class="level3" data-number="4.11.7">
<h3 data-number="4.11.7" class="anchored" data-anchor-id="calcular-la-distribución-a-posteriori"><span class="header-section-number">4.11.7</span> Calcular la distribución a posteriori</h3>
<p>Hay muchas formas de calcular el a posteriori; en esta serie de recomendaciones asumimos el uso de métodos MCMC, ya que son los métodos más generales y más usados.</p>
</section>
<section id="evaluar-muestras" class="level3" data-number="4.11.8">
<h3 data-number="4.11.8" class="anchored" data-anchor-id="evaluar-muestras"><span class="header-section-number">4.11.8</span> Evaluar muestras</h3>
<p>Cuando utilizamos métodos MCMC, debemos comprobar que las muestras sean lo suficientemente buenas. Para ello, necesitamos calcular diagnósticos como <span class="math inline">\(\hat R\)</span> (r-hat) y el tamaño de muestra efectivo (ESS). Y evalúe gráficos como traceplot y rank-plots. No es necesario que los diagnósticos sean tan buenos en las primeras etapas del flujo de trabajo. Al mismo tiempo, un diagnóstico muy malo podría ser una señal de un problema con nuestro(s) modelo(s).</p>
</section>
<section id="validar-el-modelo" class="level3" data-number="4.11.9">
<h3 data-number="4.11.9" class="anchored" data-anchor-id="validar-el-modelo"><span class="header-section-number">4.11.9</span> Validar el modelo</h3>
<p>Hay muchas formas de validar su modelo, como una prueba predictiva a posteriori, valores p Bayesianos, análisis de residuos, recuperación de parámetros a partir de datos sintéticos. O una combinación de todo esto. A veces es posible que puedas utilizar un conjunto de extra de datos para evaluar el rendimiento predictivo de tu modelo. El objetivo principal aquí es encontrar si el modelo es lo suficientemente bueno para su propósito y qué limitaciones puede tener. Todos los modelos tendrán limitaciones, pero algunas limitaciones pueden ser irrelevantes en el contexto de su análisis, algunas pueden valer la pena eliminarlas mejorando los modelos y otras simplemente vale la pena saber que existen.</p>
</section>
<section id="comparar-modelos" class="level3" data-number="4.11.10">
<h3 data-number="4.11.10" class="anchored" data-anchor-id="comparar-modelos"><span class="header-section-number">4.11.10</span> Comparar modelos</h3>
<p>Si logras conseguir más de un modelo (normalmente es una buena idea), es posible que tengas que definir cuál te gustaría conservar (suponiendo que sólo necesitas uno). Para comparar modelos se pueden utilizar validación cruzada (incluido LOO) y/o criterios de información. Pero también puedes utilizar los resultados del paso anterior (validación del modelo). A veces comparamos modelos para mantener un solo modelo, la comparación de modelos también puede ayudarnos a comprender mejor un modelo, sus fortalezas y limitaciones, y también puede ser una motivación para mejorar un modelo o probar uno nuevo. El promediado de modelos, es decir, la combinación de varios modelos en uno solo, suele ser una estrategia sencilla y eficaz para mejorar el rendimiento predictivo.</p>
</section>
<section id="resumir-resultados" class="level3" data-number="4.11.11">
<h3 data-number="4.11.11" class="anchored" data-anchor-id="resumir-resultados"><span class="header-section-number">4.11.11</span> Resumir resultados</h3>
<p>Resuma los resultados de una manera que le ayude a alcanzar sus objetivos. ¿Logró responder las preguntas clave? ¿Es esto algo que convencerá a tu jefe o al departamento de marketing? Piense en formas efectivas de mostrar los resultados. Si su audiencia es muy técnica, haga un resumen técnico, pero si su audiencia solo se preocupa por maximizar ganancias, concéntrese en eso. Intenta utilizar resúmenes que sean fáciles de entender sin ocultar detalles valiosos, no querrás engañar a tu audiencia.</p>
</section>
</section>
<section id="comentarios-finales" class="level2" data-number="4.12">
<h2 data-number="4.12" class="anchored" data-anchor-id="comentarios-finales"><span class="header-section-number">4.12</span> Comentarios finales</h2>
<p>En conclusión, el flujo de trabajo Bayesiano no es un conjunto rígido de instrucciones sino un enfoque de modelado dinámico y en evolución. Piense en ello como un marco conceptual que guía sus pensamientos y acciones en la búsqueda de mejores modelos y análisis.</p>
<p>Los métodos, herramientas y prácticas para el análisis Bayesiano mejorarán con el tiempo. A medida que avance la tecnología, es esperable una mayor automatización y mejorar en las herramientas de software y esta guía evolucionará en consecuencia.</p>
<p>Además, el flujo de trabajo Bayesiano subraya la importancia de valorar tanto el viaje como el destino. Fomenta una comprensión más profunda del problema y mejora las habilidades aplicables en diversos dominios. En última instancia, el flujo de trabajo Bayesiano representa un compromiso con el aprendizaje y el refinamiento continuos en el modelado y el análisis.</p>
</section>
<section id="ejercicios" class="level2" data-number="4.13">
<h2 data-number="4.13" class="anchored" data-anchor-id="ejercicios"><span class="header-section-number">4.13</span> Ejercicios</h2>
<ol type="1">
<li><p>(Borrador, Está bien esto como ejercicio o lo demostramos en el texto?) Demuestre que la transformada integral de probabilidad es cierta.</p></li>
<li><p>(Borrador) Usando la transformada integral de probabilidad describa una método general para generar muestreas aleatorias de cualquier distribución a partir de una distribución uniforme.</p></li>
<li><p>(Borrador) deberíamos tener una serie de ejercicios donde calculen los valores-p marginales para distribuciónes sintéticas, por tomar una Gaussiana de base y comparar con</p></li>
</ol>
<ul>
<li>una gaussian más ancha, otra más angosta y otra desplazada y ver en cada caso como la distribución se desvía de la uniforme.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_Modelos_jerárquicos.html" class="pagination-link" aria-label="Modelado Jerárquico">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelado Jerárquico</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./05_GLMS.html" class="pagination-link" aria-label="Modelos lineales y generalizaciones">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos lineales y generalizaciones</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Licencia Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png"></a><br>Este obra está bajo <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">licencia Creative Commons Reconocimiento 4.0 Internacional</a>.</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>