<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Estadística a Inferencia II - 6&nbsp; Modelos de mezcla</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08_BART.html" rel="next">
<link href="./05_GLMS.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_modelos_de_mezcla.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de mezcla</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Estadística a Inferencia II</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="github" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="github"><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/LCD-UNSAM/estadistica_e_inferencia_II">
            Fuente
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/LCD-UNSAM/estadistica_e_inferencia_II/issues/new">
            Reportar errores
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Modo claro/oscuro"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Modo sin distracciones">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‎</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Inferencia Bayesiana</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programación_probabilística.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Programación probabilista</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jerárquicos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelado Jerárquico</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Flujo_de_trabajo_bayesiano.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Flujo de trabajo Bayesiano</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_GLMS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos lineales y generalizaciones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_modelos_de_mezcla.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de mezcla</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_BART.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Árboles de regresión aditivos Bayesianos</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#modelos-de-mezclas-finitas" id="toc-modelos-de-mezclas-finitas" class="nav-link active" data-scroll-target="#modelos-de-mezclas-finitas"><span class="header-section-number">6.1</span> Modelos de mezclas finitas</a></li>
  <li><a href="#mezclas-químicas" id="toc-mezclas-químicas" class="nav-link" data-scroll-target="#mezclas-químicas"><span class="header-section-number">6.2</span> Mezclas químicas</a></li>
  <li><a href="#no-identificabilidad" id="toc-no-identificabilidad" class="nav-link" data-scroll-target="#no-identificabilidad"><span class="header-section-number">6.3</span> No-identificabilidad</a></li>
  <li><a href="#como-elegir-k" id="toc-como-elegir-k" class="nav-link" data-scroll-target="#como-elegir-k"><span class="header-section-number">6.4</span> Como elegir K</a></li>
  <li><a href="#modelos-zero-inflados-y-modelos-hurdle" id="toc-modelos-zero-inflados-y-modelos-hurdle" class="nav-link" data-scroll-target="#modelos-zero-inflados-y-modelos-hurdle"><span class="header-section-number">6.5</span> Modelos zero-inflados y modelos hurdle</a></li>
  <li><a href="#regresión-de-poisson-inflada-en-cero" id="toc-regresión-de-poisson-inflada-en-cero" class="nav-link" data-scroll-target="#regresión-de-poisson-inflada-en-cero"><span class="header-section-number">6.6</span> Regresión de Poisson inflada en cero</a>
  <ul class="collapse">
  <li><a href="#modelos-hurdle" id="toc-modelos-hurdle" class="nav-link" data-scroll-target="#modelos-hurdle"><span class="header-section-number">6.6.1</span> Modelos hurdle</a></li>
  </ul></li>
  <li><a href="#modelos-mixtos-no-finitos" id="toc-modelos-mixtos-no-finitos" class="nav-link" data-scroll-target="#modelos-mixtos-no-finitos"><span class="header-section-number">6.7</span> Modelos mixtos no-finitos</a>
  <ul class="collapse">
  <li><a href="#procesos-de-dirichlet" id="toc-procesos-de-dirichlet" class="nav-link" data-scroll-target="#procesos-de-dirichlet"><span class="header-section-number">6.7.1</span> Procesos de Dirichlet</a></li>
  </ul></li>
  <li><a href="#mezclas-continuas" id="toc-mezclas-continuas" class="nav-link" data-scroll-target="#mezclas-continuas"><span class="header-section-number">6.8</span> Mezclas continuas</a>
  <ul class="collapse">
  <li><a href="#algunas-distribuciones-comunes-son-mezclas" id="toc-algunas-distribuciones-comunes-son-mezclas" class="nav-link" data-scroll-target="#algunas-distribuciones-comunes-son-mezclas"><span class="header-section-number">6.8.1</span> Algunas distribuciones comunes son mezclas</a></li>
  </ul></li>
  <li><a href="#resumen" id="toc-resumen" class="nav-link" data-scroll-target="#resumen"><span class="header-section-number">6.9</span> Resumen</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-mixture" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de mezcla</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div id="91a876cd" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> bambi <span class="im">as</span> bmb</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="im">import</span> xarray <span class="im">as</span> xr</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="b90ee1f5" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>az.style.use(<span class="st">'arviz-doc'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>El Río de la Plata es el río más ancho de la Tierra y una frontera natural entre Argentina y Uruguay. A finales del siglo XIX, la zona portuaria a lo largo de este río era un lugar donde miembros de pueblos originarios se mezclaban con africanos (la mayoría de ellos esclavos) e inmigrantes europeos. Una consecuencia de este encuentro fue la mezcla de músicas europeas, como el vals y la mazurca, con el candombe africano y la milonga argentina (que, a su vez, es una mezcla de ritmos afroamericanos), dando origen a la danza y la música que conocemos como Tango.</p>
<p>Mezclar elementos previamente existentes es una excelente manera de crear cosas nuevas, no solo en el contexto de la música. En estadística, los modelos mixtos son un enfoque común para la construcción de modelos. Estos modelos se construyen mezclando distribuciones más simples para obtener otras más complejas. Por ejemplo, podemos combinar dos Gaussianas para describir una distribución bimodal o muchas Gaussianas para describir distribuciones arbitrarias. Si bien el uso de Gaussianas es muy común, en principio podemos mezclar cualquier familia de distribuciones que queramos. Los modelos mixtos se utilizan para diferentes propósitos, como modelar directamente subpoblaciones o como un <em>truco</em> para lidiar con distribuciones complejas dificiles de describir con las típicas distribuciones de probabilidad.</p>
<p>Los modelos de mezcla surgen naturalmente cuando la población general es una combinación de subpoblaciones distintas. Un ejemplo familiar es la distribución de alturas en una población humana adulta, que puede describirse como una mezcla de subpoblaciones femeninas y masculinas. Otro ejemplo clásico es la agrupación de dígitos escritos a mano. En este caso, es muy razonable esperar 10 subpoblaciones, ¡al menos en un sistema de base 10!</p>
<p>Si sabemos a qué subpoblación pertenece cada observación, generalmente es una buena idea utilizar esa información para modelar cada subpoblación como un grupo separado. Sin embargo, cuando no tenemos acceso directo a esta información, los modelos de mezcla vienen muy bien.</p>
<p>Al construir un modelo mixto, no es necesario creer que estamos describiendo subpoblaciones reales en los datos. Los modelos mixtos también se pueden utilizar como un truco estadístico para agregar flexibilidad a nuestra caja de herramientas. Tomemos, por ejemplo, la distribución Gaussiana. Podemos usar esta distribución como un aproximación razonable para muchas distribuciones unimodales y aproximadamente simétricas, incluso en algunos casos podemos aproximar datos discretos. Pero ¿qué pasa con las distribuciones multimodales, sesgadas o con colas pesadas? ¿Podemos utilizar distribuciones Gaussianas en estos casos? Si podemos, será cuestión de usar varias distribuciones.</p>
<p>En un modelo de mezcla de Gaussianaa, cada componente será una Gaussiano con una media diferente y potencialmente con una desviación estándar diferente. El número exacto de distribuciones necesarias dependerá de la precisión de la aproximación y de los detalles de los datos. De hecho, hemos estado usando esta estrategia en capítulos anteriores. La técnica de KDE (kernel density estimation) es una implementación no-bayesiana de esta idea. Por ej, cuando llamamos a <code>az.plot_kde</code>, la función centra una gaussiana, con una varianza fija, encima de cada dato y luego se combinan todas las Gaussianas individuales. De esta forma logramos aproximar la distribución empírica de los datos a una distribución continua.</p>
<p>La siguiente figura muestra un ejemplo de cómo podemos combinar 7 Gaussianas para representar una distribución bimodal.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/KDE_example.png" class="img-fluid figure-img"></p>
<figcaption>En azul la densidad no normalizada, resultante de sumar cada Gaussiana (lineas grises puntedas) centrada en una observación (puntos azules)</figcaption>
</figure>
</div>
<section id="modelos-de-mezclas-finitas" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="modelos-de-mezclas-finitas"><span class="header-section-number">6.1</span> Modelos de mezclas finitas</h2>
<p>Una forma de construir modelos mixtos es considerar una mezcla finita ponderada de dos o más distribuciones. Entonces, la densidad de probabilidad de los datos observados es una suma ponderada de la densidad de probabilidad de <span class="math inline">\(K\)</span> subgrupos:</p>
<p><span class="math display">\[
p(x) = \sum_{i=1}^{K} w_i p(x \mid \theta_i)
\]</span></p>
<p>Podemos interpretar <span class="math inline">\(w_i\)</span> como la probabilidad del componente <span class="math inline">\(i\)</span>, y por lo tanto sus valores están restringidos al intervalo [0, 1] y deben sumar 1. Los componentes $p(x _i) $ suelen ser distribuciones simples, como Gaussiana o Poisson. Si <span class="math inline">\(K\)</span> es finito, tenemos un modelo de mezcla finita, si además <span class="math inline">\(p\)</span> es Gaussiana, tenemos una mezcla Gaussianas. Para resolver dicho modelo, debemos proporcionar un valor de <span class="math inline">\(K\)</span>, ya sea porque conocemos el valor correcto de antemano o porque podemos hacer una suposición fundamentada.</p>
<p>Conceptualmente, para resolver un modelo mixto, todo lo que necesitamos hacer es asignar adecuadamente cada punto de datos a uno de los componentes. En un modelo probabilístico, podemos hacer esto introduciendo una variable aleatoria <span class="math inline">\(z\)</span>, cuya función es especificar a qué componente se asigna una observación particular. Esta variable generalmente se denomina <code>variable latente</code> porque no podemos observarla directamente. Si nuestros componentes son Gaussianos entonces tendremos que:</p>
<span class="math display">\[\begin{split}
\begin{align*}
\mu_1, \ldots, \mu_K &amp; \sim N(0, \sigma^2) \\
x &amp; \sim N(\mu_z, \sigma^2)
\end{align*}
\end{split}\]</span>
<p>Es decir, generamos <span class="math inline">\(K\)</span> Gaussianas y usamos <span class="math inline">\(z\)</span> para indexarlas. <span class="math inline">\(z\)</span> tendrá la misma dimensión que <span class="math inline">\(x\)</span>, es decir una variable lantente por observación. <span class="math inline">\(z\)</span> podrá tomar tanto valores como <span class="math inline">\(K\)</span> clases tengamos. Si nuestro modelo es Bayesiano necesitamos completarlo especificando priors, una forma <em>natural</em> es establer que <span class="math inline">\(z\)</span> sea una distribución categórica cuyo soporte será <span class="math inline">\(\{0, \dots ,K-1\}\)</span> (empezamos en 0 para que luego sea más directa la implementación en Python) y asumimos que el parámetro <span class="math inline">\(p\)</span> de la categórica sigue una distribución de Dirichlet. Para la desviación standard de la gaussiana usamos una media-normal o similar, entonces nos queda:</p>
<span class="math display">\[\begin{split}
\begin{align*}
\mu_1, \ldots, \mu_K &amp; \sim N(0, \sigma^2) \\
\sigma &amp; \sim \mathcal{HN}(\dots) \\
\boldsymbol{w} &amp; \sim \textrm{Dir}(\boldsymbol{\alpha}) \\
z &amp; \sim \textrm{Cat}(\boldsymbol{w}) \\
y &amp; \sim N(\mu_z, \sigma^2)
\end{align*}
\end{split}\]</span>
<p>Graficamente tenemos:</p>
<p><img src="img/mezcla_finita_dag.png" width="400"></p>
<p>El rectángulo de esquinas redondeadas indica que tenemos <span class="math inline">\(K\)</span> componentes y las variables categóricas deciden cuál de ellas usamos para describir un punto de datos determinado. Observe que en este modelo los valores de <span class="math inline">\(\mu\)</span> depende de los diferentes componentes, mientras que el valor de <span class="math inline">\(\sigma\)</span> se comparten para todos ellos. Esto es una decisión de modelado, si fueses necesario podriamos cambiarlo y permitir que se condicionen otros parámetros a cada componente.</p>
</section>
<section id="mezclas-químicas" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="mezclas-químicas"><span class="header-section-number">6.2</span> Mezclas químicas</h2>
<p>Vamos a utilizar los datos de desplazamientos químicos que ya vimos anteriormente. En la siguiente figura podemos ver un histograma de estos datos.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/cs_exp_hist.png" class="img-fluid figure-img"></p>
<figcaption>Histograma de desplazamientos químicos</figcaption>
</figure>
</div>
<div id="97478f32" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>cs_exp <span class="op">=</span> pd.read_csv(<span class="st">"datos/chemical_shifts_theo_exp.csv"</span>)[<span class="st">"exp"</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Podemos ver que estos datos no se pueden describir adecuadamente usando una sola distribución como una Gaussiana, pero quizá podriamos lograr una mejor descripción si usáramos tres o cuatro. Hay buenas razones teóricas, que ignoraremos y no discutiremos aquí, que indican que estos datos de provienen realmente de una mezcla de 40 subpoblaciones. Pero con sólo mirar los datos, parece imposible recuperar los grupos verdaderos ya que hay mucha superposición entre ellos.</p>
<p>En el siguiente bloque de código podemos ver un modelo de mezcla de gaussiana con 2 componentes:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_kg:</span>
<span id="cb4-2"><a href="#cb4-2"></a>    w <span class="op">=</span> pm.Dirichlet(<span class="st">'w'</span>, a<span class="op">=</span>np.ones(<span class="dv">2</span>))</span>
<span id="cb4-3"><a href="#cb4-3"></a>    z <span class="op">=</span> pm.Categorical(<span class="st">'z'</span>, p<span class="op">=</span>w, shape<span class="op">=</span><span class="bu">len</span>(cs_exp))</span>
<span id="cb4-4"><a href="#cb4-4"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">'μ'</span>, mu<span class="op">=</span>cs_exp.mean(), sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>K)</span>
<span id="cb4-5"><a href="#cb4-5"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, sigma<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb4-6"><a href="#cb4-6"></a></span>
<span id="cb4-7"><a href="#cb4-7"></a>    x <span class="op">=</span> pm.Normal(<span class="st">'x'</span>, mu<span class="op">=</span>μ[z], sigma<span class="op">=</span>σ, observed<span class="op">=</span>cs_exp)</span>
<span id="cb4-8"><a href="#cb4-8"></a>    idata_kg <span class="op">=</span> pm.sample()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Si ejecutas este código, verás que corre muy lento y si realizas diagnósticos verás que el muestreo tiene muchos problemas ¿Podemos hacer que este modelo funcione más rápido? Sí, veamos cómo.</p>
<p>En el <code>modelo_kg</code> hemos incluido explícitamente la variable latente <span class="math inline">\(z\)</span>. El muestreo de esta variable discreta generalmente es problemático. Una forma de resolver esto es marginalizando la variable <span class="math inline">\(z\)</span>:</p>
<span class="math display">\[\begin{split}
\begin{align*}
\mu_1, \ldots, \mu_K
    &amp; \sim N(0, \sigma^2) \\
\sigma &amp; \sim \mathcal{HN}(\dots) \\
\boldsymbol{w}
    &amp; \sim \textrm{Dir}(\boldsymbol{\alpha}) \\
p(x)
    &amp; = \sum_{i = 1}^K w_i\ N(x\ |\ \mu_i, \sigma^2),
\end{align*}
\end{split}\]</span>
<p>PyMC ofrece una sintáxis más directa para escribir este tipo de mmodelos, usando la distribución <code>NormalMixture</code>:</p>
<div id="68c65cc3" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>K <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_mg:</span>
<span id="cb5-3"><a href="#cb5-3"></a>    w <span class="op">=</span> pm.Dirichlet(<span class="st">'w'</span>, a<span class="op">=</span>np.ones(K))</span>
<span id="cb5-4"><a href="#cb5-4"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">'μ'</span>, mu<span class="op">=</span>cs_exp.mean(), sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>K)</span>
<span id="cb5-5"><a href="#cb5-5"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, sigma<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb5-6"><a href="#cb5-6"></a>    x <span class="op">=</span> pm.NormalMixture(<span class="st">'x'</span>, w<span class="op">=</span>w, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>cs_exp)</span>
<span id="cb5-7"><a href="#cb5-7"></a>    idata_mg <span class="op">=</span> pm.sample(random_seed<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5 seconds.
The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details
The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e1485fa435d24ad49a9be9effecf7082","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<p>OK, lo primero que notamos es que el modelo corre en un tiempo razonable. Pero tenemos reportes de <span class="math inline">\(\hat R\)</span> altos y ESS bajos! Veamos un foresplot, para lograr entender que está sucediendo</p>
<div id="1da6a5ab" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>az.plot_forest(idata_mg, var_names<span class="op">=</span><span class="st">"μ"</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>))<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Notan algo raro en estos resultados? Tomensé un momento para pensarlo.</p>
<hr>
<p>En la figura anterior podemos ver que para <code>μ[0]</code> una de las estimaciones está alrededor de 47 y las otras tres alrededor de 57.5. Y lo contrario para <code>μ[1]</code>, normalmente esperamos que las distintas cadenas nos den valores cercanos. Cuando los valores son muy diferentes sospechamos que el muestreo ha tenido problemas. Además si calcularamos la media de <code>μ[0]</code>, obtendremos un valor cercano a 55 (<span class="math inline">\(57,5 \times 3 + 47 \times 1\)</span>), que no es el valor correcto. Lo que estamos viendo es un ejemplo de un fenómeno conocido como <strong>no-identificabilidad</strong> de parámetros. Esto sucede porque, desde la perspectiva del modelo, no hay diferencia si el componente 1 tiene una media de 47 y el componente 2 tiene una media de 57,5 o viceversa; ambos escenarios son equivalentes. En el contexto de los modelos mixtos, esto también se conoce como problema de cambio de etiqueta (label-switching).</p>
</section>
<section id="no-identificabilidad" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="no-identificabilidad"><span class="header-section-number">6.3</span> No-identificabilidad</h2>
<p>Un modelo estadístico es no-identificable si uno o más de sus parámetros no pueden determinarse de forma única. Los parámetros de un modelo no se identifican si se obtiene la misma función de verosimilitud para más de un conjunto de parámetros. Esto puede suceder por que los datos no contengan suficiente información para estimar los parámetros o por que el modelo es estructuralmente no-identificable, lo que significa que los parámetros no pueden determinarse de manera única incluso si todos los datos necesarios están disponibles.</p>
<p>Con los modelos mixtos, existen al menos dos formas de parametrizar un modelo para eliminar el problema de la no identificabilidad. Podemos forzar un orden arbitrario en los componentes; por ejemplo, establecer que el vector <span class="math inline">\(\mu\)</span> debe ser estrictamente creciente o podemos usar priors informativos. La primer estrategia suele ser más general y simple de implementar y la segunda no garantiza la eliminación de problemas.</p>
<p>Usando PyMC, podemos implementar la primera opción con una transformación:</p>
<div id="e66c8ad3" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> modelo_mgo:</span>
<span id="cb8-2"><a href="#cb8-2"></a>    w <span class="op">=</span> pm.Dirichlet(<span class="st">'w'</span>, a<span class="op">=</span>np.ones(K))</span>
<span id="cb8-3"><a href="#cb8-3"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">'μ'</span>, mu<span class="op">=</span>cs_exp.mean(), sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>K,</span>
<span id="cb8-4"><a href="#cb8-4"></a>                 transform<span class="op">=</span>pm.distributions.transforms.ordered,</span>
<span id="cb8-5"><a href="#cb8-5"></a>                 initval<span class="op">=</span>np.array([cs_exp.mean()<span class="op">-</span><span class="dv">1</span>, cs_exp.mean()<span class="op">+</span><span class="dv">1</span>]),</span>
<span id="cb8-6"><a href="#cb8-6"></a>                 )</span>
<span id="cb8-7"><a href="#cb8-7"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, sigma<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb8-8"><a href="#cb8-8"></a>    x <span class="op">=</span> pm.NormalMixture(<span class="st">'x'</span>, w<span class="op">=</span>w, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>cs_exp)</span>
<span id="cb8-9"><a href="#cb8-9"></a>    idata_mg <span class="op">=</span> pm.sample(random_seed<span class="op">=</span><span class="dv">123</span>)    </span>
<span id="cb8-10"><a href="#cb8-10"></a>    </span>
<span id="cb8-11"><a href="#cb8-11"></a>    idata_mgo <span class="op">=</span> pm.sample()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0329cb90187846ed902ab9976755392b","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7cbacf783fd04acabafe0d21832a82d2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
</section>
<section id="como-elegir-k" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="como-elegir-k"><span class="header-section-number">6.4</span> Como elegir K</h2>
<p>Una de las principales preocupaciones con los modelos de mezclas finitas es cómo decidir el número de componentes. Una regla general es comenzar con una cantidad relativamente pequeña de componentes y luego aumentarla para el ajuste del modelo. Como ya vimos anteriormente el ajuste de un modelo se puede evaluar con una combinación de herramientas como las pruebas predictivas a posteriori, el ELPD y la experiencia de los modeladores.</p>
<p>Comparemos el modelo para <span class="math inline">\(K = \{2, 3, 4, 5\}\)</span></p>
<div id="dc6fefd0" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>Ks <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>]</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a>models <span class="op">=</span> []</span>
<span id="cb10-4"><a href="#cb10-4"></a>idatas <span class="op">=</span> []</span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="cf">for</span> k <span class="kw">in</span> Ks:</span>
<span id="cb10-6"><a href="#cb10-6"></a>    <span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb10-7"><a href="#cb10-7"></a>        w <span class="op">=</span> pm.Dirichlet(<span class="st">'w'</span>, a<span class="op">=</span>np.ones(k))</span>
<span id="cb10-8"><a href="#cb10-8"></a>        μ <span class="op">=</span> pm.Normal(<span class="st">'μ'</span>,</span>
<span id="cb10-9"><a href="#cb10-9"></a>                      mu<span class="op">=</span>np.linspace(cs_exp.<span class="bu">min</span>(), cs_exp.<span class="bu">max</span>(), k),</span>
<span id="cb10-10"><a href="#cb10-10"></a>                      sigma<span class="op">=</span>cs_exp.var() <span class="op">/</span> k, shape<span class="op">=</span>k,</span>
<span id="cb10-11"><a href="#cb10-11"></a>                      transform<span class="op">=</span>pm.distributions.transforms.ordered,</span>
<span id="cb10-12"><a href="#cb10-12"></a>                     )</span>
<span id="cb10-13"><a href="#cb10-13"></a>        σ <span class="op">=</span> pm.HalfNormal(<span class="st">'σ'</span>, sigma<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-14"><a href="#cb10-14"></a>        x <span class="op">=</span> pm.NormalMixture(<span class="st">'x'</span>, w<span class="op">=</span>w, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>cs_exp)</span>
<span id="cb10-15"><a href="#cb10-15"></a>        idata <span class="op">=</span> pm.sample(random_seed<span class="op">=</span><span class="dv">123</span>,</span>
<span id="cb10-16"><a href="#cb10-16"></a>                          idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>}</span>
<span id="cb10-17"><a href="#cb10-17"></a>                         )</span>
<span id="cb10-18"><a href="#cb10-18"></a>                         </span>
<span id="cb10-19"><a href="#cb10-19"></a>        idatas.append(idata)</span>
<span id="cb10-20"><a href="#cb10-20"></a>        models.append(model)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 15 seconds.
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 44 seconds.
There were 40 divergences after tuning. Increase `target_accept` or reparameterize.
The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details
The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 55 seconds.
There were 9 divergences after tuning. Increase `target_accept` or reparameterize.
The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details
The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [w, μ, σ]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 31 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d6709f69adb84a1e9221139e1a2e6d3a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2369864a1f1142f599a36d1bb4137b5a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a5107518b736491eb6aca9564b848587","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"90eea8c4cb254db59c189061f0608ff8","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<p>La siguiente figura muestra los modelos de mezcla para <span class="math inline">\(K\)</span> Gaussianas. La linea negra y solida representa la media a posteriori y las lineas turquesa muestras de la distribución a posterori. La distribución media de cada componente está representado usando lineas punteadas</p>
<div id="35b2b1ff" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">11</span>, <span class="dv">8</span>))</span>
<span id="cb12-2"><a href="#cb12-2"></a> </span>
<span id="cb12-3"><a href="#cb12-3"></a>ax <span class="op">=</span> np.ravel(ax)</span>
<span id="cb12-4"><a href="#cb12-4"></a>x <span class="op">=</span> np.linspace(cs_exp.<span class="bu">min</span>(), cs_exp.<span class="bu">max</span>(), <span class="dv">200</span>)</span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="cf">for</span> idx, idata_x <span class="kw">in</span> <span class="bu">enumerate</span>(idatas):</span>
<span id="cb12-6"><a href="#cb12-6"></a>    posterior_x <span class="op">=</span> idata_x.posterior.stack(samples<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb12-7"><a href="#cb12-7"></a>    x_ <span class="op">=</span> np.array([x] <span class="op">*</span> Ks[idx]).T</span>
<span id="cb12-8"><a href="#cb12-8"></a></span>
<span id="cb12-9"><a href="#cb12-9"></a>    <span class="cf">for</span> i_ <span class="kw">in</span> np.random.randint(<span class="dv">0</span>, posterior_x.samples.size, size<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb12-10"><a href="#cb12-10"></a>        dist <span class="op">=</span> pz.Normal(posterior_x[<span class="st">'μ'</span>][:,i_], posterior_x[<span class="st">'σ'</span>][i_])</span>
<span id="cb12-11"><a href="#cb12-11"></a>        ax[idx].plot(x, np.<span class="bu">sum</span>(dist.pdf(x_) <span class="op">*</span>  posterior_x[<span class="st">'w'</span>][:,i_].values, <span class="dv">1</span>), <span class="st">'C1'</span>)</span>
<span id="cb12-12"><a href="#cb12-12"></a> </span>
<span id="cb12-13"><a href="#cb12-13"></a>    p_y <span class="op">=</span> posterior_x[<span class="st">'w'</span>].mean(<span class="st">"samples"</span>)</span>
<span id="cb12-14"><a href="#cb12-14"></a>    dist <span class="op">=</span> pz.Normal(posterior_x[<span class="st">'μ'</span>].mean(<span class="st">"samples"</span>), posterior_x[<span class="st">'σ'</span>].mean())</span>
<span id="cb12-15"><a href="#cb12-15"></a>    ax[idx].plot(x, np.<span class="bu">sum</span>(dist.pdf(x_) <span class="op">*</span> p_y.values, <span class="dv">1</span>), <span class="st">'k'</span>, lw<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-16"><a href="#cb12-16"></a>    ax[idx].plot(x, dist.pdf(x_) <span class="op">*</span> p_y.values, <span class="st">'k--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb12-17"><a href="#cb12-17"></a>         </span>
<span id="cb12-18"><a href="#cb12-18"></a>    ax[idx].set_title(<span class="st">'K = </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(Ks[idx]))</span>
<span id="cb12-19"><a href="#cb12-19"></a>    ax[idx].set_yticks([])</span>
<span id="cb12-20"><a href="#cb12-20"></a>    ax[idx].set_xlabel(<span class="st">'x'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Visualmente, parece que <span class="math inline">\(K=2\)</span> es demasiado bajo, pero ¿cómo elegimos un valor mejor?</p>
<p>Como ya hemos discutido, podemos usar pruebas predictivas a posteriori y calcular valores p bayesianos. La siguiente figura muestra un ejemplo de dicho cálculo y visualización. <span class="math inline">\(K=5\)</span> es la mejor solución y <span class="math inline">\(K=4\)</span> se acerca.</p>
<div id="74634413" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>ppc_mm <span class="op">=</span> [pm.sample_posterior_predictive(idatas[i],</span>
<span id="cb13-2"><a href="#cb13-2"></a>                                         models[i],</span>
<span id="cb13-3"><a href="#cb13-3"></a>                                         random_seed<span class="op">=</span><span class="dv">4591</span>,</span>
<span id="cb13-4"><a href="#cb13-4"></a>                                         progressbar<span class="op">=</span><span class="va">False</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>)]</span>
<span id="cb13-5"><a href="#cb13-5"></a></span>
<span id="cb13-6"><a href="#cb13-6"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>), sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-7"><a href="#cb13-7"></a>ax <span class="op">=</span> np.ravel(ax)</span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="kw">def</span> iqr(x, a<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb13-9"><a href="#cb13-9"></a>    <span class="cf">return</span> np.subtract(<span class="op">*</span>np.percentile(x, [<span class="dv">75</span>, <span class="dv">25</span>], axis<span class="op">=</span>a))</span>
<span id="cb13-10"><a href="#cb13-10"></a>    </span>
<span id="cb13-11"><a href="#cb13-11"></a>T_obs <span class="op">=</span> iqr(cs_exp)</span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="cf">for</span> idx, d_sim <span class="kw">in</span> <span class="bu">enumerate</span>(ppc_mm):</span>
<span id="cb13-13"><a href="#cb13-13"></a>    d_sim <span class="op">=</span> d_sim.posterior_predictive[<span class="st">"x"</span>]</span>
<span id="cb13-14"><a href="#cb13-14"></a>    T_sim <span class="op">=</span> iqr(d_sim, <span class="dv">1</span>)</span>
<span id="cb13-15"><a href="#cb13-15"></a>    p_value <span class="op">=</span> np.mean(T_sim <span class="op">&gt;=</span> T_obs)</span>
<span id="cb13-16"><a href="#cb13-16"></a>    az.plot_kde(T_sim, ax<span class="op">=</span>ax[idx])</span>
<span id="cb13-17"><a href="#cb13-17"></a>    ax[idx].axvline(T_obs, <span class="dv">0</span>, <span class="dv">1</span>, color<span class="op">=</span><span class="st">'k'</span>, ls<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb13-18"><a href="#cb13-18"></a>    ax[idx].set_title(<span class="ss">f'K = </span><span class="sc">{</span>Ks[idx]<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss"> p-value </span><span class="sc">{</span>p_value<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb13-19"><a href="#cb13-19"></a>    ax[idx].set_yticks([])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [x]
Sampling: [x]
Sampling: [x]
Sampling: [x]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Para complementar las estas pruebas, podemos calcular el ELPD usando LOO. Podemos ver que los resultados coinciden con las pruebas predictivas</p>
<div id="9bacc0e5" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>comp <span class="op">=</span> az.compare(<span class="bu">dict</span>(<span class="bu">zip</span>([<span class="bu">str</span>(K) <span class="cf">for</span> K <span class="kw">in</span> Ks], idatas)))</span>
<span id="cb15-2"><a href="#cb15-2"></a>comp</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd_loo</th>
<th data-quarto-table-cell-role="th">p_loo</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
<th data-quarto-table-cell-role="th">scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>0</td>
<td>-5129.403532</td>
<td>10.050910</td>
<td>0.000000</td>
<td>1.000000e+00</td>
<td>30.765814</td>
<td>0.000000</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>-5155.672477</td>
<td>19.914150</td>
<td>26.268945</td>
<td>0.000000e+00</td>
<td>31.333449</td>
<td>4.312002</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>2</td>
<td>-5192.861947</td>
<td>15.129354</td>
<td>63.458415</td>
<td>0.000000e+00</td>
<td>32.182557</td>
<td>9.178287</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>-5215.851380</td>
<td>3.201959</td>
<td>86.447848</td>
<td>4.024514e-11</td>
<td>33.499721</td>
<td>11.948419</td>
<td>False</td>
<td>log</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="e58861e0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>az.plot_compare(comp, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>), plot_ic_diff<span class="op">=</span><span class="va">False</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>El ejemplo de los desplazamientos químicos, aunque simple, muestra las ideas principales sobre los modelos de mezclas finitas. Para este ejemplo, utilizamos gaussianos porque proporcionan una buena aproximación para modelar los datos. Sin embargo, somos libres de utilizar componentes no gaussianos si es necesario. Por ejemplo, podríamos usar un:</p>
<ul>
<li><strong>Modelo de mezcla de Poisson</strong>: suponga que está monitoreando la cantidad de clientes que ingresan a una tienda cada hora. Un modelo mixto de Poisson puede ayudar a identificar diferentes patrones de tráfico de clientes, como horas o días pico, suponiendo que los datos siguen una combinación de distribuciones de Poisson.</li>
<li><strong>Modelo de mezcla exponencial</strong>: Imagina que estás estudiando la vida útil de cierto tipo de bombilla. Un modelo de mezcla exponencial puede ayudar a identificar diferentes grupos de bombillas con diferentes vidas útiles, sugiriendo posibles diferencias en la calidad de fabricación o factores ambientales.</li>
</ul>
<p>En la siguiente sección, exploraremos dos tipos muy particulares de modelos mixto.</p>
</section>
<section id="modelos-zero-inflados-y-modelos-hurdle" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="modelos-zero-inflados-y-modelos-hurdle"><span class="header-section-number">6.5</span> Modelos zero-inflados y modelos hurdle</h2>
<p>Al contar cosas, como autos en una ruta, estrellas en el cielo, lunares en la piel o prácticamente cualquier otra cosa, una posiblidad es no contar nada, es decir, obtener cero. Podemos obtener cero por muchas razones; si estamos en una esquina contando autos rojos por hora podemos contar 0 autos rojos, por que ninguno pasó o por que pasó uno detras de un camión y no lo pudimos ver. Si utilizamos una distribución Poisson o NegativaBinomial para modelar dichos datos, es posible que notemos que el modelo genera menos ceros en comparación con los datos.</p>
<p>¿Cómo arreglamos eso? Una posible solución es suponer que nuestras observaciones siguen un proceso que es en realidad una mezcla de dos procesos:</p>
<ul>
<li>Uno modelado por una distribución discreta con probabilidad <span class="math inline">\(\psi\)</span></li>
<li>Uno dando ceros adicionales con probabilidad <span class="math inline">\(1 - \psi\)</span></li>
</ul>
<p>Un detalle, simple, pero que nos puede generar sorpresas si no prestamos atención es que en algunos textos (y software) el significado de <span class="math inline">\(\psi\)</span> está invertido, representando la probabilidad de ceros adiciones.</p>
<p>La familia de distribuciones que permiten ceros “adicionales” se conoce como distribución inflada en cero. Los miembros más comunes de esa familia son:</p>
<ul>
<li>Poisson inflada en cero</li>
<li>NegativaBinomial inflada en cero</li>
<li>Binomial inflada en cero</li>
</ul>
<p>Dada una distribución base con función de masa de probabilidad (PMF). Podemos describir una distribución Hurdle como:</p>
<span class="math display">\[\begin{split}
f(x \mid \psi, n, p) = \left\{ \begin{array}{l}
    (1-\psi) + \psi \; \text{PMF}(0), \text{si } x = 0 \\
    \psi \; \text{PMF}(x), \text{si } x=1,2,3,\ldots,n
    \end{array} \right.
\end{split}\]</span>
<p>En la siguiente sección, usaremos Poisson inflado de ceros para resolver un problema de regresión.</p>
</section>
<section id="regresión-de-poisson-inflada-en-cero" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="regresión-de-poisson-inflada-en-cero"><span class="header-section-number">6.6</span> Regresión de Poisson inflada en cero</h2>
<p>Para ejemplificar un modelo de regresión de Poisson inflado en cero, vamos a trabajar con un conjunto de datos tomado del <a href="http://www.ats.ucla.edu/stat/data">Instituto de Investigación y Educación Digital</a>. Tenemos 250 grupos de visitantes a un parque, para cada grupo tenemos el registro de la cantidad de peces que capturaron <code>count</code>, cuántos niños había en el grupo <code>child</code> y si trajeron una casa-rodante/caravana al parque <code>camper</code>. Usando estos datos, vamos a construir un modelo de la cantidad de peces capturados en función de las variables del niño y del campista.</p>
<div id="68517516" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>pesca <span class="op">=</span> pd.read_csv(<span class="st">'datos/pesca.csv'</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Usando PyMC podemos escribir un modelo para estos datos como:</p>
<div id="27b32c9c" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> ZIP_reg:</span>
<span id="cb18-2"><a href="#cb18-2"></a>    ψ <span class="op">=</span> pm.Beta(<span class="st">'ψ'</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-3"><a href="#cb18-3"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb18-4"><a href="#cb18-4"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, <span class="dv">0</span>, <span class="dv">1</span>, shape<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb18-5"><a href="#cb18-5"></a>    θ <span class="op">=</span> pm.math.exp(α <span class="op">+</span> β[<span class="dv">0</span>] <span class="op">*</span> pesca[<span class="st">'child'</span>] <span class="op">+</span> β[<span class="dv">1</span>] <span class="op">*</span> pesca[<span class="st">'camper'</span>])</span>
<span id="cb18-6"><a href="#cb18-6"></a>    yl <span class="op">=</span> pm.ZeroInflatedPoisson(<span class="st">'yl'</span>, ψ, θ, observed<span class="op">=</span>pesca[<span class="st">'count'</span>])</span>
<span id="cb18-7"><a href="#cb18-7"></a>    idata_ZIP_reg <span class="op">=</span> pm.sample()</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [ψ, α, β]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"74c1a41cb5704e74b9e1447e0352c119","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<p><code>camper</code> es una variable binaria con 0 si el grupo no entró al parque en casa-rodante y 1 si lo hizo. A una variable que indica la ausencia/presencia de un atributo se le suele llamar variable binaria, dicotómica, “dummy” o variable indicadora. Es importante notar que cuando <code>camper</code> toma el valor de 0, el término que involucra a <span class="math inline">\(\beta_1\)</span> también será 0 y el modelo se reduce a una regresión con una sola variable independiente. Ya discutimos esto cuando discutimos el uso de covariables categóricas.</p>
<p>Los resultados se muestran en la siguiente figura. Podemos ver que cuanto mayor es el número de niños, menor es el número de peces capturados. Además, las personas que viajan con una casa-rodante generalmente pescan más. Si revisamos los coeficientes asociados a <code>child</code> y <code>camper</code>, veremos que podemos decir:</p>
<ul>
<li>Por cada niño adicional, el recuento esperado de peces capturados disminuye en <span class="math inline">\(\approx 0,4\)</span></li>
<li>Acampar con una casa-rodante aumenta la cantidad esperada de peces capturados en <span class="math inline">\(\approx 2\)</span></li>
</ul>
<p>Los modelos inflados en cero están estrechamente asociados con los modelos hurdle (obstáculos) y puede ser fácil confundirlos. Por lo que es buena idea discutir ambos modelos en simultaneo.</p>
<div id="74a42275" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>children <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb20-2"><a href="#cb20-2"></a>fish_count_pred_0 <span class="op">=</span> []</span>
<span id="cb20-3"><a href="#cb20-3"></a>fish_count_pred_1 <span class="op">=</span> []</span>
<span id="cb20-4"><a href="#cb20-4"></a></span>
<span id="cb20-5"><a href="#cb20-5"></a>posterior <span class="op">=</span> az.extract(idata_ZIP_reg)</span>
<span id="cb20-6"><a href="#cb20-6"></a></span>
<span id="cb20-7"><a href="#cb20-7"></a>without_camper <span class="op">=</span> posterior[<span class="st">'α'</span>] <span class="op">+</span> posterior[<span class="st">'β'</span>][<span class="dv">0</span>] <span class="op">*</span> xr.DataArray(children)</span>
<span id="cb20-8"><a href="#cb20-8"></a>with_camper <span class="op">=</span> without_camper <span class="op">+</span> posterior[<span class="st">'β'</span>][<span class="dv">1</span>]</span>
<span id="cb20-9"><a href="#cb20-9"></a>fish_count_pred_0 <span class="op">=</span> np.exp(without_camper)</span>
<span id="cb20-10"><a href="#cb20-10"></a>fish_count_pred_1 <span class="op">=</span> np.exp(with_camper)</span>
<span id="cb20-11"><a href="#cb20-11"></a></span>
<span id="cb20-12"><a href="#cb20-12"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb20-13"><a href="#cb20-13"></a>ax.plot(children, fish_count_pred_0.T, <span class="st">'C0.'</span>, alpha<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb20-14"><a href="#cb20-14"></a>ax.plot(children, fish_count_pred_1.T, <span class="st">'C1.'</span>, alpha<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb20-15"><a href="#cb20-15"></a>ax.plot(children, fish_count_pred_0.mean(<span class="st">"sample"</span>), <span class="st">'C0'</span>, ls<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb20-16"><a href="#cb20-16"></a>ax.plot(children, fish_count_pred_1.mean(<span class="st">"sample"</span>), <span class="st">'C1'</span>, ls<span class="op">=</span><span class="st">"--"</span>)</span>
<span id="cb20-17"><a href="#cb20-17"></a>ax.set_xticks(children)</span>
<span id="cb20-18"><a href="#cb20-18"></a>ax.set_xlabel(<span class="st">'Número de niños'</span>)</span>
<span id="cb20-19"><a href="#cb20-19"></a>ax.set_ylabel(<span class="st">'Peces'</span>)</span>
<span id="cb20-20"><a href="#cb20-20"></a>ax.plot([], <span class="st">'C0o'</span>, label<span class="op">=</span><span class="st">'sin casa-rodante'</span>)</span>
<span id="cb20-21"><a href="#cb20-21"></a>ax.plot([], <span class="st">'C1o'</span>, label<span class="op">=</span><span class="st">'con casa-rodante'</span>)</span>
<span id="cb20-22"><a href="#cb20-22"></a>plt.legend()<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="modelos-hurdle" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="modelos-hurdle"><span class="header-section-number">6.6.1</span> Modelos hurdle</h3>
<p>Los modelos de hurdle (obstáculo), también se describien como una mezcla de dos procesos de forma similar a los modelos inflados en cero. La diferencia es que en los modelos hurdles los ceros vienen dados <strong>exclusivamente</strong> con probabilidad <span class="math inline">\(1 - \psi\)</span> y los valores positivos vienen dados por una distribución base truncada en cero. Como consecuencia, un modelo inflado en cero solo puede aumentar la probabilidad de <span class="math inline">\(P(x= 0)\)</span>, pero para los modelos hurdle, la probabilidad puede ser mayor o menor que en la distribución base. La razón del nombre hurdle (obstáculo) es que podemos pensar a estas distribuciones como que estamos modelado la presencia de un obstáculo, que hae que nuestra respuesta sea cero, una vez superado el obstáculo la respuesta puede ser distinta de cero.</p>
<p>Algunas “distribuciones hurdle” comunente usadas son:</p>
<ul>
<li>Poisson Hurdle</li>
<li>NegativaBinomial Hurdle</li>
<li>Gamma Hurdle</li>
<li>Normal Hurdle</li>
</ul>
<p>Fijensé que contrario a los modelos inflados en cero, cuya distribución base son discretas acá tenemos un par de casos de distribuciones continuas y por lo tanto obtenemos distribuciones que no son continuas ni discretas, si no una mezcla.</p>
<p>Dada una distribución base con función de distribución acumulada (CDF) y función de masa/densidad de probabilidad (PDF). Podemos describir una distribución Hurdle como:</p>
<span class="math display">\[\begin{split}f(x \mid \psi, \mu) =
    \left\{
        \begin{array}{l}
        (1 - \psi)  \ \text{si } x = 0 \\
        \psi
        \frac{\text{PDF}(x \mid \mu))}
        {1 - \text{CDF}(0 \mid \mu)} \ \text{si } x \not= 0\ldots
        \end{array}
    \right.
\end{split}\]</span>
<p>Para ilustrar los modelos hurdle, vamos a utilizar el conjunto de datos del cangrejo herradura <a href="https://onlinelibrary.wiley.com/doi/10.1111/j.1439-0310.1996.tb01099.x">Brockmann_1996</a>.</p>
<p>Los cangrejos herradura llegan a la playa en parejas para su ritual de desove. Los machos solitarios se agrupan alrededor de las parejas que anidan y compiten por la oportunidad de fertilizar los huevos. Estos individuos, conocidos como machos satélites, a menudo se congregan cerca de ciertas parejas, e ignoran a otras. Queremos modelar el número de <code>satelites</code>. Sospechamos que este número está relacionado con las propiedades de las hembras de cangrejo. Como predictores vamos a utilizar propiedades del caparazón <code>width</code> y <code>color</code>. El color se codifica utilizando los números enteros del 1 al 4, desde tonos más claros a más oscuros.</p>
<p>Usaremos Bambi para escribir y ajustar cuatro modelos. La principal diferencia entre los cuatro modelos es que vamos a utilizar cuatro likelihoods diferentes, a saber, Poisson, Hurdle Poisson, NegativeBinomial y Hurdle NegativeBinomial.</p>
<div id="cdbb780e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>crab <span class="op">=</span> pd.read_csv(<span class="st">"datos/horseshoe_crab.csv"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="326d3d73" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>familias <span class="op">=</span> [<span class="st">"poisson"</span>, <span class="st">"hurdle_poisson"</span>, <span class="st">"negativebinomial"</span>, <span class="st">"hurdle_negativebinomial"</span>]</span>
<span id="cb22-2"><a href="#cb22-2"></a></span>
<span id="cb22-3"><a href="#cb22-3"></a>modelos <span class="op">=</span> []</span>
<span id="cb22-4"><a href="#cb22-4"></a>idatas <span class="op">=</span> []</span>
<span id="cb22-5"><a href="#cb22-5"></a></span>
<span id="cb22-6"><a href="#cb22-6"></a><span class="cf">for</span> familia <span class="kw">in</span> familias:</span>
<span id="cb22-7"><a href="#cb22-7"></a>    modelo <span class="op">=</span> bmb.Model(<span class="st">"satellite ~ width + C(color)"</span>, family<span class="op">=</span>familia, data<span class="op">=</span>crab)</span>
<span id="cb22-8"><a href="#cb22-8"></a>    idata <span class="op">=</span> modelo.fit(idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>}, random_seed<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb22-9"><a href="#cb22-9"></a>    modelo.predict(idata, kind<span class="op">=</span><span class="st">"pps"</span>)</span>
<span id="cb22-10"><a href="#cb22-10"></a>    idatas.append(idata)</span>
<span id="cb22-11"><a href="#cb22-11"></a>    modelos.append(modelo)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [Intercept, width, C(color)]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [satellite_psi, Intercept, width, C(color)]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [satellite_alpha, Intercept, width, C(color)]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [satellite_alpha, satellite_psi, Intercept, width, C(color)]
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.
/home/osvaldo/anaconda3/envs/EI2/lib/python3.11/site-packages/pytensor/tensor/rewriting/elemwise.py:702: UserWarning: Optimization Warning: The Op betainc does not provide a C implementation. As well as being potentially slow, this also disables loop fusion.
  warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bc2ade4653c4450b935c84f5b0a7e65d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f84e8271fe2343f89a08df7d72dea041","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3cba6d2a325240b6b687780923bee4f2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c1c5142ac5f14e319b73b68c282cea28","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
<p>Primero hagamos una comparación en términos del ELPD</p>
<div id="c8cfe160" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="bu">cmp</span> <span class="op">=</span> az.compare(<span class="bu">dict</span>(<span class="bu">zip</span>(familias, idatas)))</span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="bu">cmp</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd_loo</th>
<th data-quarto-table-cell-role="th">p_loo</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
<th data-quarto-table-cell-role="th">scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">hurdle_negativebinomial</td>
<td>0</td>
<td>-372.810467</td>
<td>6.341265</td>
<td>0.000000</td>
<td>0.00000</td>
<td>13.689807</td>
<td>0.000000</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">negativebinomial</td>
<td>1</td>
<td>-380.355948</td>
<td>5.654806</td>
<td>7.545481</td>
<td>0.41551</td>
<td>14.122017</td>
<td>5.727093</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">hurdle_poisson</td>
<td>2</td>
<td>-382.358981</td>
<td>8.595326</td>
<td>9.548513</td>
<td>0.58449</td>
<td>17.719552</td>
<td>6.573658</td>
<td>False</td>
<td>log</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">poisson</td>
<td>3</td>
<td>-468.366717</td>
<td>16.124879</td>
<td>95.556249</td>
<td>0.00000</td>
<td>24.794667</td>
<td>19.441265</td>
<td>False</td>
<td>log</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div id="160811f2" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>az.plot_compare(<span class="bu">cmp</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">2.5</span>), plot_ic_diff<span class="op">=</span><span class="va">False</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Una forma útil de evaluar visualmente el ajuste en modelos de conteo son los “<a href="https://arxiv.org/abs/1605.01311">hanging rootograms</a>” (raizogramas colgantes), como se ve en la siguiente figura.</p>
<p>En los raizogramas colgantes, dibujamos las raíces cuadradas de los valores observados y predichos. Esta es una forma rápida de ajustar aproximadamente las diferencias de escala facilitando la comparación de frecuencias observadas y esperadas incluso para frecuencias bajas. En segundo lugar, las barras representando los datos observados <em>cuelgan</em> de los valores esperados, en lugar de <em>crecer</em> desde el cero. Debido a que las barras están valor, y si la barra cae por debajo de cero, entonces el modelo está subestimando ese valor.</p>
<div id="e939d53c" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Mostrar Código</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="kw">def</span> rotogram(idata, ax):</span>
<span id="cb26-2"><a href="#cb26-2"></a>    max_ <span class="op">=</span> <span class="dv">17</span></span>
<span id="cb26-3"><a href="#cb26-3"></a>    bins <span class="op">=</span> np.array(<span class="bu">range</span>(<span class="dv">0</span>, max_))</span>
<span id="cb26-4"><a href="#cb26-4"></a>    dims <span class="op">=</span> idata.posterior_predictive.dims</span>
<span id="cb26-5"><a href="#cb26-5"></a>    n_samples <span class="op">=</span> dims[<span class="st">"chain"</span>] <span class="op">*</span> dims[<span class="st">"draw"</span>]</span>
<span id="cb26-6"><a href="#cb26-6"></a>    pred <span class="op">=</span>  (np.histogram(idata.posterior_predictive[<span class="st">"satellite"</span>].values.ravel(),  bins<span class="op">=</span>bins)[<span class="dv">0</span>] <span class="op">/</span> n_samples)<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb26-7"><a href="#cb26-7"></a>    observed <span class="op">=</span> np.histogram(crab[<span class="st">"satellite"</span>].values, bins<span class="op">=</span>bins)[<span class="dv">0</span>]<span class="op">**</span><span class="fl">0.5</span></span>
<span id="cb26-8"><a href="#cb26-8"></a></span>
<span id="cb26-9"><a href="#cb26-9"></a>    ax.bar(bins[:<span class="op">-</span><span class="dv">1</span>], observed, <span class="fl">0.5</span>, bottom<span class="op">=</span>pred<span class="op">-</span>observed, color<span class="op">=</span><span class="st">"C0"</span>)</span>
<span id="cb26-10"><a href="#cb26-10"></a>    ax.plot(bins[:<span class="op">-</span><span class="dv">1</span>], pred,  <span class="st">"k.--"</span>)</span>
<span id="cb26-11"><a href="#cb26-11"></a>    ax.hlines(<span class="dv">0</span>, <span class="op">-</span><span class="fl">0.5</span>, max_<span class="op">-</span><span class="fl">1.5</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"0.5"</span>)</span>
<span id="cb26-12"><a href="#cb26-12"></a></span>
<span id="cb26-13"><a href="#cb26-13"></a></span>
<span id="cb26-14"><a href="#cb26-14"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb26-15"><a href="#cb26-15"></a><span class="cf">for</span> ax, idata, model <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), idatas, modelos):</span>
<span id="cb26-16"><a href="#cb26-16"></a>    rotogram(idata, ax)</span>
<span id="cb26-17"><a href="#cb26-17"></a>    ax.set_title(model.family.name)</span>
<span id="cb26-18"><a href="#cb26-18"></a></span>
<span id="cb26-19"><a href="#cb26-19"></a>axes[<span class="dv">1</span>,<span class="dv">1</span>].set_xlabel(<span class="st">"Satellites"</span>)</span>
<span id="cb26-20"><a href="#cb26-20"></a>axes[<span class="dv">1</span>,<span class="dv">0</span>].set_xlabel(<span class="st">"Satellites"</span>)</span>
<span id="cb26-21"><a href="#cb26-21"></a>fig.text(<span class="op">-</span><span class="fl">0.03</span>, <span class="fl">0.5</span>, <span class="st">"$\sqrt</span><span class="sc">{frecuencia}</span><span class="st">$"</span>, va<span class="op">=</span><span class="st">"center"</span>, rotation<span class="op">=</span><span class="st">"vertical"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/tmp/ipykernel_19366/424556328.py:7: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.
  n_samples = dims["chain"] * dims["draw"]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-20-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Resumamos cada uno de los 4 paneles en la figura anterior</p>
<ul>
<li>Poisson: Los ceros están subestimados y los conteos del 1 al 4 están sobreestimados. La mayoría de los valores a partir de 6 también están subestimados. Este patrón indica sobredispersión en los datos, y la enorme diferencia para 0 indica un exceso de ceros.</li>
<li>NegativoBinomial: Vemos que la sobredispersión se maneja mucho mejor en comparación con el modelo de Poisson. Todavía vemos que los ceros están subestimados y los valores 1 y 2 están sobreestimados, lo que probablemente indica un exceso de ceros.</li>
<li>Hurdle Poisson: Como se esperaba de un modelo hurdle, obtenemos un ajuste perfecto para los ceros. Para los valores positivos todavía tenemos algunas desviaciones.</li>
<li>Hurdle NegativoBinomial: Vemos que el modelo puede ajustarse muy bien a los datos, siendo las desviaciones muy pequeñas.</li>
</ul>
</section>
</section>
<section id="modelos-mixtos-no-finitos" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="modelos-mixtos-no-finitos"><span class="header-section-number">6.7</span> Modelos mixtos no-finitos</h2>
<p>Para algunos problemas, como intentar agrupar dígitos escritos a mano, es fácil justificar el número de grupos que esperamos encontrar en los datos. Para otros problemas, podemos tener buenas conjeturas; por ejemplo, podemos saber que nuestra muestra de flores de Iris se tomó de una región donde sólo crecen tres especies de Iris, por lo que utilizar tres componentes es un punto de partida razonable. Cuando no estamos tan seguros de la cantidad de componentes, podemos usar la selección de modelos para ayudarnos a elegir la cantidad de grupos. Sin embargo, para otros problemas, elegir a priori el número de grupos puede ser un inconveniente, o puede que nos interese estimar este número directamente a partir de los datos. Una solución Bayesiana para este tipo de problemas viene dada por el proceso de Dirichlet.</p>
<section id="procesos-de-dirichlet" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="procesos-de-dirichlet"><span class="header-section-number">6.7.1</span> Procesos de Dirichlet</h3>
<p>Todos los modelos que hemos visto hasta ahora han sido modelos paramétricos, es decir, modelos con un número fijo de parámetros. En estos modelos asumimos una distribución para los datos (likelihood) y luego una distribución para los parámetros desconocidos. Pero también es posible crear modelos no-paramétricos. Este tipo de modelos no es que no tenga parámetros es que el número de parámetros es variable y depende en alguna medida de lo datos. Podemos pensar en los modelos no paramétricos como modelos con un número teóricamente infinito de parámetros junto a algún mecanismo que en la práctica nos permita trabajar con objetos finitos.</p>
<p>En este curso veremos tres ejemplos de dichos modelos: el proceso gaussiano, los árboles de regresión aditiva bayesiana y el proceso de Dirichlet.</p>
<p>La definición formal de un Proceso de Dirichlet (PD) es algo opaca y requiere de familiaridad con procesos estocásticos y teoría de la medida. En la literatura es común encontrarla definida de forma implicita mediante varios mecanismos alternativos. Uno de ellos es el proceso de rotura de palos. Veamos.</p>
<p>Primero generamos una serie de pesos:</p>
<p><span class="math display">\[\begin{align}
\beta_i &amp; \sim \text{Beta}(1, \alpha) \\
w_i &amp; = \beta_i \prod_{j=1}^{i-1} (1 - \beta_j)
\end{align}\]</span></p>
<p>Este proceso es análogo a imaginar que tenemos un palo de longitud 1, lo partimos en dos partes. Guardamos una de las partes y partimos la restante nuevamente, repetimos indefinidamente. Podemos ver que <span class="math inline">\(\alpha\)</span> controla el proceso de rotura. Cuando <span class="math inline">\(\alpha\)</span> se aproxima a 0, la distribución Beta se concentra hacia el valor 1, cuando <span class="math inline">\(\alpha=1\)</span> la distribución Beta es uniforme y a medida que <span class="math inline">\(\alpha\)</span> crece la distribución Beta se concentra hacia 0. Por lo que un valor alto de <span class="math inline">\(alpha\)</span> favorece pesos pequeños.</p>
<p>El proceso continua asignado una ubicación <span class="math inline">\(\theta_i\)</span> al peso <span class="math inline">\(w_i\)</span>:</p>
<p><span class="math display">\[
\theta_i \sim H
\]</span></p>
<p><span class="math inline">\(H\)</span> es la distribución base del PD</p>
<p>Dados estos elementos podemos definir a un proceso de Dirichlet <span class="math inline">\(G \sim DP(\alpha, H)\)</span> como una suma pesada de masas puntuales localizadas según la distribución base.</p>
<p><span class="math display">\[
G = \sum_{i=1}^{\infty} w_i \delta_{\theta_i}
\]</span></p>
<p>donde <span class="math inline">\(\delta_{\theta_i}\)</span> es la función delta de Dirac centrada en <span class="math inline">\(\theta_i\)</span></p>
<p>La siguiente figura muestra un ejemplo de una relización (muestra) de un proceso de Dirichlet para 4 valores distintos de <span class="math inline">\(\alpha\)</span></p>
<p>Asi como la distribución de Dirichlet es la generalización n-dimensional de la distribución Beta, el proceso de Dirichlet es la generalización de dimensión infinita de la distribución de Dirichlet.</p>
<div id="99887649" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="kw">def</span> stick_breaking_process(alpha, base_dist):</span>
<span id="cb28-2"><a href="#cb28-2"></a>    <span class="co">"""</span></span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="co">    Generate a realization from a Dirichlet Process using the stick-breaking process.</span></span>
<span id="cb28-4"><a href="#cb28-4"></a></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="co">    Parameters:</span></span>
<span id="cb28-6"><a href="#cb28-6"></a><span class="co">    ----------</span></span>
<span id="cb28-7"><a href="#cb28-7"></a><span class="co">    </span></span>
<span id="cb28-8"><a href="#cb28-8"></a><span class="co">    alpha : float</span></span>
<span id="cb28-9"><a href="#cb28-9"></a><span class="co">        Concentration parameter of the Dirichlet Process</span></span>
<span id="cb28-10"><a href="#cb28-10"></a><span class="co">    base_dist : PreliZ distribution</span></span>
<span id="cb28-11"><a href="#cb28-11"></a><span class="co">        Base distribution</span></span>
<span id="cb28-12"><a href="#cb28-12"></a><span class="co">    """</span></span>
<span id="cb28-13"><a href="#cb28-13"></a>    K_max <span class="op">=</span> <span class="bu">max</span>(<span class="dv">10</span>, <span class="bu">int</span>(alpha<span class="op">/</span><span class="dv">10</span>)) </span>
<span id="cb28-14"><a href="#cb28-14"></a>    beta <span class="op">=</span> pz.Beta(<span class="dv">1</span>, alpha).rvs(K_max)</span>
<span id="cb28-15"><a href="#cb28-15"></a>    w <span class="op">=</span> np.empty(K_max)</span>
<span id="cb28-16"><a href="#cb28-16"></a>    w[<span class="dv">0</span>] <span class="op">=</span> beta[<span class="dv">0</span>]</span>
<span id="cb28-17"><a href="#cb28-17"></a>    w[<span class="dv">1</span>:] <span class="op">=</span> beta[<span class="dv">1</span>:] <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> beta[:<span class="op">-</span><span class="dv">1</span>]).cumprod()</span>
<span id="cb28-18"><a href="#cb28-18"></a>    w <span class="op">/=</span> w.<span class="bu">sum</span>()  </span>
<span id="cb28-19"><a href="#cb28-19"></a></span>
<span id="cb28-20"><a href="#cb28-20"></a>    loc <span class="op">=</span> base_dist.rvs(K_max)</span>
<span id="cb28-21"><a href="#cb28-21"></a></span>
<span id="cb28-22"><a href="#cb28-22"></a>    samples <span class="op">=</span> np.random.choice(loc, p<span class="op">=</span>w, size<span class="op">=</span>K_max)</span>
<span id="cb28-23"><a href="#cb28-23"></a></span>
<span id="cb28-24"><a href="#cb28-24"></a>    <span class="cf">return</span> samples</span>
<span id="cb28-25"><a href="#cb28-25"></a></span>
<span id="cb28-26"><a href="#cb28-26"></a>N <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb28-27"><a href="#cb28-27"></a>base_distribution <span class="op">=</span> pz.Normal(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb28-28"><a href="#cb28-28"></a></span>
<span id="cb28-29"><a href="#cb28-29"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-30"><a href="#cb28-30"></a></span>
<span id="cb28-31"><a href="#cb28-31"></a><span class="cf">for</span> alpha, ax <span class="kw">in</span> <span class="bu">zip</span>([<span class="dv">1</span>, <span class="dv">100</span>, <span class="dv">1000</span>], axes.ravel()):</span>
<span id="cb28-32"><a href="#cb28-32"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb28-33"><a href="#cb28-33"></a>        sample <span class="op">=</span> stick_breaking_process(alpha, base_distribution)</span>
<span id="cb28-34"><a href="#cb28-34"></a>        ax.ecdf(sample, color<span class="op">=</span><span class="st">"0.5"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb28-35"><a href="#cb28-35"></a>        </span>
<span id="cb28-36"><a href="#cb28-36"></a>    pz.Normal(<span class="dv">0</span>, <span class="dv">1</span>).plot_cdf(legend<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span>ax)</span>
<span id="cb28-37"><a href="#cb28-37"></a>    ax.set_title(<span class="vs">fr"$\alpha$=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="vs">"</span>)</span>
<span id="cb28-38"><a href="#cb28-38"></a>    </span>
<span id="cb28-39"><a href="#cb28-39"></a>plt.suptitle(<span class="ss">f'</span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> Realizaciones de un proceso de Dirichlet'</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e44772e5" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>K <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb29-2"><a href="#cb29-2"></a></span>
<span id="cb29-3"><a href="#cb29-3"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_DP:</span>
<span id="cb29-4"><a href="#cb29-4"></a>    α <span class="op">=</span> pm.Gamma(<span class="st">'α'</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb29-5"><a href="#cb29-5"></a></span>
<span id="cb29-6"><a href="#cb29-6"></a>    w <span class="op">=</span> pm.StickBreakingWeights(<span class="st">"w"</span>, α, K<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb29-7"><a href="#cb29-7"></a>    means <span class="op">=</span> pm.Normal(<span class="st">'means'</span>,</span>
<span id="cb29-8"><a href="#cb29-8"></a>                      mu<span class="op">=</span>np.linspace(cs_exp.<span class="bu">min</span>(), cs_exp.<span class="bu">max</span>(), K),</span>
<span id="cb29-9"><a href="#cb29-9"></a>                      sigma<span class="op">=</span><span class="dv">5</span>, shape<span class="op">=</span>K,</span>
<span id="cb29-10"><a href="#cb29-10"></a>                      transform<span class="op">=</span>pm.distributions.transforms.ordered,</span>
<span id="cb29-11"><a href="#cb29-11"></a>                     )</span>
<span id="cb29-12"><a href="#cb29-12"></a>    </span>
<span id="cb29-13"><a href="#cb29-13"></a>    sd <span class="op">=</span> pm.HalfNormal(<span class="st">'sd'</span>, sigma<span class="op">=</span><span class="dv">5</span>, shape<span class="op">=</span>K)</span>
<span id="cb29-14"><a href="#cb29-14"></a>    obs <span class="op">=</span> pm.NormalMixture(<span class="st">'obs'</span>, w, means, sigma<span class="op">=</span>sd, observed<span class="op">=</span>cs_exp.values)</span>
<span id="cb29-15"><a href="#cb29-15"></a>    idata <span class="op">=</span> pm.sample(random_seed<span class="op">=</span><span class="dv">123</span>, target_accept<span class="op">=</span><span class="fl">0.9</span>, nuts_sampler<span class="op">=</span><span class="st">"nutpie"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    :root {
        --column-width-1: 40%; /* Progress column width */
        --column-width-2: 15%; /* Chain column width */
        --column-width-3: 15%; /* Divergences column width */
        --column-width-4: 15%; /* Step Size column width */
        --column-width-5: 15%; /* Gradients/Draw column width */
    }

    .nutpie {
        max-width: 800px;
        margin: 10px auto;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        //color: #333;
        //background-color: #fff;
        padding: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-radius: 8px;
        font-size: 14px; /* Smaller font size for a more compact look */
    }
    .nutpie table {
        width: 100%;
        border-collapse: collapse; /* Remove any extra space between borders */
    }
    .nutpie th, .nutpie td {
        padding: 8px 10px; /* Reduce padding to make table more compact */
        text-align: left;
        border-bottom: 1px solid #888;
    }
    .nutpie th {
        //background-color: #f0f0f0;
    }

    .nutpie th:nth-child(1) { width: var(--column-width-1); }
    .nutpie th:nth-child(2) { width: var(--column-width-2); }
    .nutpie th:nth-child(3) { width: var(--column-width-3); }
    .nutpie th:nth-child(4) { width: var(--column-width-4); }
    .nutpie th:nth-child(5) { width: var(--column-width-5); }

    .nutpie progress {
        width: 100%;
        height: 15px; /* Smaller progress bars */
        border-radius: 5px;
    }
    progress::-webkit-progress-bar {
        background-color: #eee;
        border-radius: 5px;
    }
    progress::-webkit-progress-value {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    progress::-moz-progress-bar {
        background-color: #5cb85c;
        border-radius: 5px;
    }
    .nutpie .progress-cell {
        width: 100%;
    }

    .nutpie p strong { font-size: 16px; font-weight: bold; }

    @media (prefers-color-scheme: dark) {
        .nutpie {
            //color: #ddd;
            //background-color: #1e1e1e;
            box-shadow: 0 4px 6px rgba(0,0,0,0.2);
        }
        .nutpie table, .nutpie th, .nutpie td {
            border-color: #555;
            color: #ccc;
        }
        .nutpie th {
            background-color: #2a2a2a;
        }
        .nutpie progress::-webkit-progress-bar {
            background-color: #444;
        }
        .nutpie progress::-webkit-progress-value {
            background-color: #3178c6;
        }
        .nutpie progress::-moz-progress-bar {
            background-color: #3178c6;
        }
    }
</style>
</div>
<div class="cell-output cell-output-display">

<div class="nutpie">
    <p><strong>Sampler Progress</strong></p>
    <p>Total Chains: <span id="total-chains">4</span></p>
    <p>Active Chains: <span id="active-chains">0</span></p>
    <p>
        Finished Chains:
        <span id="active-chains">4</span>
    </p>
    <p>Sampling for 5 minutes</p>
    <p>
        Estimated Time to Completion:
        <span id="eta">now</span>
    </p>

    <progress id="total-progress-bar" max="8000" value="8000">
    </progress>
    <table>
        <thead>
            <tr>
                <th>Progress</th>
                <th>Draws</th>
                <th>Divergences</th>
                <th>Step Size</th>
                <th>Gradients/Draw</th>
            </tr>
        </thead>
        <tbody id="chain-details">
            
                <tr>
                    <td class="progress-cell">
                        <progress max="2000" value="2000">
                        </progress>
                    </td>
                    <td>2000</td>
                    <td>19</td>
                    <td>0.07</td>
                    <td>127</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="2000" value="2000">
                        </progress>
                    </td>
                    <td>2000</td>
                    <td>12</td>
                    <td>0.08</td>
                    <td>511</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="2000" value="2000">
                        </progress>
                    </td>
                    <td>2000</td>
                    <td>1</td>
                    <td>0.07</td>
                    <td>255</td>
                </tr>
            
                <tr>
                    <td class="progress-cell">
                        <progress max="2000" value="2000">
                        </progress>
                    </td>
                    <td>2000</td>
                    <td>0</td>
                    <td>0.05</td>
                    <td>383</td>
                </tr>
            
            
        </tbody>
    </table>
</div>
</div>
</div>
<p>Debido a que estamos aproximando el DP (infinito) con un valor finito, es importante verificar que el valor de truncamiento (<span class="math inline">\(K=15\)</span> en este ejemplo) no introduzca ningún sesgo. Una forma sencilla de hacerlo es calcular el peso promedio de cada componente, ordenarlos y luego visualizar la suma acumulada. Para estar seguros, deberíamos tener al menos algunos componentes con un peso insignificante; de lo contrario, debemos aumentar el valor de truncamiento. El siguiente gráfico es un ejemplo de esto.</p>
<div id="314c2753" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb30-2"><a href="#cb30-2"></a>plot_w <span class="op">=</span> np.arange(K)</span>
<span id="cb30-3"><a href="#cb30-3"></a>ax.plot(np.cumsum(np.sort(idata.posterior[<span class="st">'w'</span>].mean((<span class="st">"chain"</span>, <span class="st">"draw"</span>)))[::<span class="op">-</span><span class="dv">1</span>]), <span class="st">'o-'</span>)</span>
<span id="cb30-4"><a href="#cb30-4"></a>ax.hlines(<span class="fl">0.99</span>, <span class="dv">0</span>, K, ls<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"0.5"</span>)</span>
<span id="cb30-5"><a href="#cb30-5"></a>ax.set_xticks(plot_w, plot_w<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb30-6"><a href="#cb30-6"></a>ax.set_xlabel(<span class="st">'Número de componentes'</span>)</span>
<span id="cb30-7"><a href="#cb30-7"></a>ax.set_ylabel(<span class="st">'Peso promedio'</span>)<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Podemos ver que los primeros 9 componentes representan más del 99% del peso total (línea discontinua gris en la figura anterior) y por lo tanto podemos estar seguros de que el valor elegido (<span class="math inline">\(K=15\)</span>) es adecuado para estos datos.</p>
<div id="9260c615" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>x_plot <span class="op">=</span> np.linspace(cs_exp.<span class="bu">min</span>()<span class="op">-</span><span class="dv">1</span>, cs_exp.<span class="bu">max</span>()<span class="op">+</span><span class="dv">1</span>, <span class="dv">500</span>)</span>
<span id="cb31-2"><a href="#cb31-2"></a></span>
<span id="cb31-3"><a href="#cb31-3"></a>posterior <span class="op">=</span> idata.posterior.stack(samples<span class="op">=</span>(<span class="st">"chain"</span>, <span class="st">"draw"</span>))</span>
<span id="cb31-4"><a href="#cb31-4"></a></span>
<span id="cb31-5"><a href="#cb31-5"></a>post_pdf_contribs <span class="op">=</span> pz.Normal(posterior[<span class="st">'means'</span>].values[:, <span class="va">None</span>, :],</span>
<span id="cb31-6"><a href="#cb31-6"></a>                              posterior[<span class="st">'sd'</span>].values[:, <span class="va">None</span>, :]).pdf(np.atleast_3d(x_plot))</span>
<span id="cb31-7"><a href="#cb31-7"></a></span>
<span id="cb31-8"><a href="#cb31-8"></a>post_pdfs <span class="op">=</span> (posterior[<span class="st">'w'</span>].values[:, np.newaxis, :] <span class="op">*</span> post_pdf_contribs).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb31-9"><a href="#cb31-9"></a></span>
<span id="cb31-10"><a href="#cb31-10"></a></span>
<span id="cb31-11"><a href="#cb31-11"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb31-12"><a href="#cb31-12"></a></span>
<span id="cb31-13"><a href="#cb31-13"></a>ax.plot(x_plot, post_pdfs[:,::<span class="dv">100</span>], c<span class="op">=</span><span class="st">'C1'</span>, alpha<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb31-14"><a href="#cb31-14"></a>ax.plot(x_plot, post_pdfs.mean(axis<span class="op">=</span><span class="dv">1</span>), c<span class="op">=</span><span class="st">'k'</span>, label<span class="op">=</span><span class="st">"media a posteriori"</span>)</span>
<span id="cb31-15"><a href="#cb31-15"></a></span>
<span id="cb31-16"><a href="#cb31-16"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb31-17"><a href="#cb31-17"></a>ax.set_yticks([])</span>
<span id="cb31-18"><a href="#cb31-18"></a>ax.legend()<span class="op">;</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="06_modelos_de_mezcla_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="mezclas-continuas" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="mezclas-continuas"><span class="header-section-number">6.8</span> Mezclas continuas</h2>
<p>El enfoque de este capítulo estuvo en los modelos de mezcla discreta, pero también podemos tener modelos de mezcla continua. Y de hecho ya conocemos algunos de ellos. Por ejemplo, los modelos jerárquicos también pueden interpretarse como modelos de mezcla continua donde los parámetros de cada grupo provienen de una distribución continua en el nivel superior. Para hacerlo más concreto, piense en realizar una regresión lineal para varios grupos. Podemos suponer que cada grupo tiene su propia pendiente o que todos los grupos comparten la misma pendiente. Alternativamente, en lugar de enmarcar nuestro problema como dos opciones discretas extremas, un modelo jerárquico nos permite modelar efectivamente una mezcla continua de estas dos opciones.</p>
<section id="algunas-distribuciones-comunes-son-mezclas" class="level3" data-number="6.8.1">
<h3 data-number="6.8.1" class="anchored" data-anchor-id="algunas-distribuciones-comunes-son-mezclas"><span class="header-section-number">6.8.1</span> Algunas distribuciones comunes son mezclas</h3>
<p>BetaBinomial es una distribución discreta que generalmente se utiliza para describir el número de éxitos <span class="math inline">\(y\)</span> para <span class="math inline">\(n\)</span> ensayos de Bernoulli cuando se desconoce la probabilidad de éxito <span class="math inline">\(p\)</span> en cada ensayo y se supone que sigue una distribución beta con parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\text{BetaBinomial}(y \mid n, \alpha,\beta) = \int_0^1 \text{Bin}(y \mid p, n) \; \text{Beta}(p \mid \alpha, \beta) dp
\]</span></p>
<p>Es decir, para encontrar la probabilidad de observar el resultado <span class="math inline">\(y\)</span>, promediamos todos los valores posibles (y continuos) de <span class="math inline">\(p\)</span>. Por tanto, el BetaBinomial puede considerarse como un modelo de mezcla continua. Si el modelo BetaBinomial te suena familiar es porque estuviste prestando atención en los dos primeros capítulos del libro. Este es el modelo que usamos para el problema de lanzar una moneda, aunque usamos explícitamente una distribución Beta y Binomial, en lugar de usar la distribución Beta-Binomio ya .</p>
<p>De manera similar tenemos la distribución Binomial Negativa, que puede entenderse como una mezcla Gamma-Poisson. Es decir, una mezcla de distribuciones de Poisson donde el parámetro de velocidad tiene una distribución Gamma. La distribución binomial negativa se utiliza a menudo para evitar un problema común que se encuentra al tratar con datos de conteo. Este problema se conoce como sobredispersión. Suponga que está utilizando una distribución de Poisson para modelar los datos de recuento y luego se da cuenta de que la varianza en sus datos excede la del modelo; El problema con el uso de una distribución de Poisson es que la media y la varianza se describen mediante el mismo parámetro. Una forma de explicar la sobredispersión es modelar los datos como una mezcla (continua) de distribuciones de Poisson. Al considerar una combinación de distribuciones, nuestro modelo tiene más flexibilidad y puede adaptarse mejor a la media y la varianza de los datos.</p>
<p>Otro ejemplo de mezcla de distribuciones es la distribución t de Student. Introdujimos esta distribución como una alternativa sólida a la distribución gaussiana. En este caso, la distribución t resulta de una mezcla de distribuciones gaussianas con media <span class="math inline">\(\mu\)</span> y varianza desconocida distribuida como una distribución Gamma inversa.</p>
</section>
</section>
<section id="resumen" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="resumen"><span class="header-section-number">6.9</span> Resumen</h2>
<p>Muchos problemas pueden describirse como una población general compuesta de distintas subpoblaciones. Cuando sabemos a qué subpoblación pertenece cada observación, podemos modelar específicamente cada subpoblación como un grupo separado. Sin embargo, muchas veces no tenemos acceso directo a esta información, por lo que puede ser apropiado modelar esos datos utilizando modelos mixtos. Podemos utilizar modelos mixtos para intentar capturar subpoblaciones reales en los datos o como un truco estadístico general para modelar distribuciones complejas combinando distribuciones más simples.</p>
<p>En este capítulo, dividimos los modelos de mezclas en tres clases: modelos de mezclas finitas, modelos de mezclas no finitas y modelos de mezclas continuas. Un modelo de mezcla finita es una mezcla finita ponderada de dos o más distribuciones, donde cada distribución o componente representa un subgrupo de datos. En principio, los componentes pueden ser prácticamente cualquier cosa que consideremos útil, desde distribuciones simples, como una gaussiana o una Poisson, hasta objetos más complejos, como modelos jerárquicos o redes neuronales. Conceptualmente, para resolver un modelo mixto, todo lo que necesitamos hacer es asignar adecuadamente cada punto de datos a uno de los componentes. Podemos hacer esto introduciendo una variable latente <span class="math inline">\(z\)</span>. Usamos una distribución categórica para <span class="math inline">\(z\)</span>, que es la distribución discreta más general, con un previo de Dirichlet, que es la generalización n-dimensional de la distribución Beta. El muestreo de la variable discreta <span class="math inline">\(z\)</span> puede ser problemático, por lo que puede resultar conveniente marginarla. PyMC incluye una distribución de mezcla normal y una distribución de mezcla que realiza esta marginación por nosotros, lo que facilita la construcción de modelos de mezcla con PyMC.</p>
<p>Un problema común que analizamos en este capítulo cuando trabajamos con modelos mixtos es que este modelo puede conducir al problema de cambio de etiqueta, una forma de no identificabilidad. Una forma de eliminar la no identificabilidad es forzar el pedido de los componentes. Un desafío con los modelos de mezclas finitas es cómo decidir el número de componentes. Una solución es realizar una comparación de modelos para un conjunto de modelos en torno a un número estimado de componentes. Esa estimación debe guiarse, cuando sea posible, por nuestro conocimiento del problema en cuestión. Otra opción es intentar estimar automáticamente la cantidad de componentes a partir de los datos. Por esta razón, introdujimos el concepto del proceso de Dirichlet como una versión de dimensión infinita de la distribución de Dirichlet que podemos usar para construir un modelo de mezcla no paramétrico.</p>
<p>Finalmente, para cerrar el capítulo, discutimos brevemente cuántos modelos, como el BetaBinomial (el que se usa para el problema de lanzar una moneda), el Binomial Negativo, la distribución t de Student e incluso los modelos jerárquicos, pueden interpretarse como modelos de mezcla continua.</p>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"state":{"0329cb90187846ed902ab9976755392b":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_83882f639e484bd9a7eb7df0b5045d5a","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:14</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:14\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"03ed9b11e11c48dc88c4e76f51c0e4ef":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"1ef0c3196cbf4343916de4a497164c28":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"1f763f67c18a4f37969424095df295f3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"2369864a1f1142f599a36d1bb4137b5a":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_cd6feb1419a94fe79175559e9dea5148","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 40 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n","text/plain":"Sampling 4 chains, 40 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:43\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"3cba6d2a325240b6b687780923bee4f2":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_fecde999fd2d46d59aeebbf314e2d1c9","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:03</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:03\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"46228ce024e244d481a949740d5fbe95":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"6249c544c3d642bca8460e51a3fd3d4a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"6ba09116533c48acad127a52e1cc0bdc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"74c1a41cb5704e74b9e1447e0352c119":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_c108d048bc8e40e88b67585776938529","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:03</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:03\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"7cbacf783fd04acabafe0d21832a82d2":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_1f763f67c18a4f37969424095df295f3","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:15</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:15\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"83882f639e484bd9a7eb7df0b5045d5a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"90eea8c4cb254db59c189061f0608ff8":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_03ed9b11e11c48dc88c4e76f51c0e4ef","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:30</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:30\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"a5107518b736491eb6aca9564b848587":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_6ba09116533c48acad127a52e1cc0bdc","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 9 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:54</span>\n</pre>\n","text/plain":"Sampling 4 chains, 9 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:54\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"a9051027338e44909381a28349cf4081":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"bc2ade4653c4450b935c84f5b0a7e65d":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_a9051027338e44909381a28349cf4081","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:02</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:02\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"c108d048bc8e40e88b67585776938529":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"c1c5142ac5f14e319b73b68c282cea28":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_1ef0c3196cbf4343916de4a497164c28","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:09</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:09\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"cd6feb1419a94fe79175559e9dea5148":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"d6709f69adb84a1e9221139e1a2e6d3a":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_6249c544c3d642bca8460e51a3fd3d4a","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:14</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:14\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"e1485fa435d24ad49a9be9effecf7082":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_46228ce024e244d481a949740d5fbe95","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:04\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"e36c37f7eea247ea99a0a1c1e15afda6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}},"f84e8271fe2343f89a08df7d72dea041":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"layout":"IPY_MODEL_e36c37f7eea247ea99a0a1c1e15afda6","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling 4 chains, 0 divergences <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> / <span style=\"color: #808000; text-decoration-color: #808000\">0:00:04</span>\n</pre>\n","text/plain":"Sampling 4 chains, 0 divergences \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m / \u001b[33m0:00:04\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}},"fecde999fd2d46d59aeebbf314e2d1c9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{}}},"version_major":2,"version_minor":0}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05_GLMS.html" class="pagination-link" aria-label="Modelos lineales y generalizaciones">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos lineales y generalizaciones</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08_BART.html" class="pagination-link" aria-label="Árboles de regresión aditivos Bayesianos">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Árboles de regresión aditivos Bayesianos</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Licencia Creative Commons" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png"></a><br>Este obra está bajo <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">licencia Creative Commons Reconocimiento 4.0 Internacional</a>.</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>